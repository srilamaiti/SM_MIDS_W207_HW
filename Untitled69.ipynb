{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/srilamaiti/SM_MIDS_W207_HW/blob/main/Untitled69.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***1. Setup***"
      ],
      "metadata": {
        "id": "NUylKvIS6Lsf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***A. Installing New Libraries***"
      ],
      "metadata": {
        "id": "5dlGr3VX6DyA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kAIyFDyH5uLR",
        "outputId": "2e8eb0f1-6584-45ca-cf56-360b0d579cdc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: imgaug in /usr/local/lib/python3.7/dist-packages (0.4.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from imgaug) (1.7.3)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.7/dist-packages (from imgaug) (1.8.5.post1)\n",
            "Requirement already satisfied: scikit-image>=0.14.2 in /usr/local/lib/python3.7/dist-packages (from imgaug) (0.18.3)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.7/dist-packages (from imgaug) (2.9.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from imgaug) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from imgaug) (1.21.6)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from imgaug) (3.2.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from imgaug) (7.1.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from imgaug) (4.6.0.66)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.2->imgaug) (2.6.3)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.2->imgaug) (1.3.0)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.2->imgaug) (2021.11.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug) (1.4.4)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug) (3.0.9)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->imgaug) (4.1.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install imgaug"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install livelossplot"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91Xb-Plzo2E5",
        "outputId": "905b617e-e54c-433d-dfae-763b39fe5f79"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting livelossplot\n",
            "  Downloading livelossplot-0.5.5-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: bokeh in /usr/local/lib/python3.7/dist-packages (from livelossplot) (2.3.3)\n",
            "Requirement already satisfied: ipython==7.* in /usr/local/lib/python3.7/dist-packages (from livelossplot) (7.9.0)\n",
            "Requirement already satisfied: numpy<1.22 in /usr/local/lib/python3.7/dist-packages (from livelossplot) (1.21.6)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from livelossplot) (3.2.2)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython==7.*->livelossplot) (0.2.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython==7.*->livelossplot) (57.4.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython==7.*->livelossplot) (0.7.5)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython==7.*->livelossplot) (4.4.2)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from ipython==7.*->livelossplot) (2.0.10)\n",
            "Collecting jedi>=0.10\n",
            "  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 7.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython==7.*->livelossplot) (4.8.0)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython==7.*->livelossplot) (5.1.1)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython==7.*->livelossplot) (2.6.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.10->ipython==7.*->livelossplot) (0.8.3)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython==7.*->livelossplot) (1.15.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython==7.*->livelossplot) (0.2.5)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.7/dist-packages (from bokeh->livelossplot) (6.0)\n",
            "Requirement already satisfied: pillow>=7.1.0 in /usr/local/lib/python3.7/dist-packages (from bokeh->livelossplot) (7.1.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from bokeh->livelossplot) (4.1.1)\n",
            "Requirement already satisfied: packaging>=16.8 in /usr/local/lib/python3.7/dist-packages (from bokeh->livelossplot) (21.3)\n",
            "Requirement already satisfied: Jinja2>=2.9 in /usr/local/lib/python3.7/dist-packages (from bokeh->livelossplot) (2.11.3)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from bokeh->livelossplot) (2.8.2)\n",
            "Requirement already satisfied: tornado>=5.1 in /usr/local/lib/python3.7/dist-packages (from bokeh->livelossplot) (6.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.9->bokeh->livelossplot) (2.0.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=16.8->bokeh->livelossplot) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->livelossplot) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->livelossplot) (1.4.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython==7.*->livelossplot) (0.7.0)\n",
            "Installing collected packages: jedi, livelossplot\n",
            "Successfully installed jedi-0.18.2 livelossplot-0.5.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***B. Importing Libraries***"
      ],
      "metadata": {
        "id": "UQBd_dFh6S1S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***a. Importing General Purpose Libraries***"
      ],
      "metadata": {
        "id": "Iv-y8vdS62gV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import joblib\n",
        "import glob\n",
        "import random\n",
        "from itertools import product\n",
        "import gc\n",
        "import subprocess\n",
        "import shutil\n",
        "import copy\n",
        "import statistics as st\n",
        "from scipy import stats"
      ],
      "metadata": {
        "id": "ujHcENda69HI"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***b. Importing Image Processing and Visualization Libraries***"
      ],
      "metadata": {
        "id": "xM_Fw_tt7EpU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from imutils import rotate as rotate\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "import matplotlib.patches as patches\n",
        "from matplotlib.patches import Polygon\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "from skimage.color import gray2rgb\n",
        "import skimage.io as skio\n",
        "from imgaug import augmenters as img_aug\n",
        "import imgaug as iaug"
      ],
      "metadata": {
        "id": "0NV7G1UoIi4I"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***c. Importing Sklearn Functionalities***"
      ],
      "metadata": {
        "id": "qSyqwXIMIp7t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import shuffle\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.decomposition import IncrementalPCA\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import auc\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.model_selection import StratifiedShuffleSplit"
      ],
      "metadata": {
        "id": "fUh7ts6QI8Lx"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***d. Importing Tensorflow Libraries***"
      ],
      "metadata": {
        "id": "2C55GxBKnW3V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from livelossplot import PlotLossesKeras\n",
        "from keras.utils.layer_utils import count_params\n",
        "\n",
        "from tensorflow.keras.layers import RandomFlip\n",
        "from tensorflow.keras.layers import RandomZoom\n",
        "from tensorflow.keras.layers import RandomRotation\n",
        "from tensorflow.keras.layers import Conv1D\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import Concatenate\n",
        "from tensorflow.keras.layers import MaxPooling1D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.layers import AveragePooling2D\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import GlobalMaxPooling2D\n",
        "from tensorflow.keras.layers import GlobalAveragePooling1D\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
        "from tensorflow.keras.layers import Lambda\n",
        "from tensorflow.keras.layers import Multiply\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.layers import Bidirectional\n",
        "from tensorflow.keras.layers import PReLU\n",
        "from keras.layers.core import Activation\n",
        "from keras.layers.convolutional import SeparableConv1D\n",
        "from keras.layers.convolutional import SeparableConv2D\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.applications.vgg19 import VGG19\n",
        "from keras.applications.densenet import *\n",
        "from keras.applications.resnet import ResNet152\n",
        "from keras.applications.nasnet import NASNetMobile\n",
        "from keras.applications.nasnet import NASNetLarge\n",
        "from keras.applications.nasnet import preprocess_input\n",
        "from keras.applications import MobileNetV2\n",
        "from keras.applications.xception import Xception\n",
        "from keras.applications.inception_v3 import *\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import array_to_img\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.preprocessing.image import save_img\n",
        "\n",
        "from tensorflow.python.ops.numpy_ops import np_config\n",
        "\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "\n",
        "from tensorflow.keras.losses import mae\n",
        "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
        "from tensorflow.keras.losses import binary_crossentropy\n",
        "\n",
        "from keras.models import Model\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from keras.models import load_model\n"
      ],
      "metadata": {
        "id": "eUXe1TURnkN5"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***C. Mounting Google Drive***"
      ],
      "metadata": {
        "id": "JLAsViNZnt1V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Required to read the data from Kaggle\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = \"/content/gdrive/MyDrive/Kaggle\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bCewn8D_n4oL",
        "outputId": "dfd1c231-0af0-4e57-9275-b73dfb6b05a9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***D. Downloading Data from Kaggle***"
      ],
      "metadata": {
        "id": "0mavHZlbpFpR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!bash /content/gdrive/MyDrive/Kaggle/download_kaggle_data.ksh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qxaSmgjsoxfh",
        "outputId": "a0276789-da2c-42c2-adb8-e75e5274dcf3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading histopathologic-cancer-detection.zip to /content\n",
            "100% 6.29G/6.31G [00:44<00:00, 207MB/s]\n",
            "100% 6.31G/6.31G [00:44<00:00, 153MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!kaggle competitions download -c histopathologic-cancer-detection\n",
        "#!unzip -o -qq \\*.zip  && rm *.zip"
      ],
      "metadata": {
        "id": "fDXH4brO_sGj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***E. Defining Vartiables***"
      ],
      "metadata": {
        "id": "aZ9PZBKVtI__"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#sample_size = 80000\n",
        "sample_size = 40000\n",
        "#batch_size = 256\n",
        "batch_size = 64\n",
        "epochs = 10\n",
        "\n",
        "image_size = 96\n",
        "#number_of_splits = 8\n",
        "number_of_splits = 8\n",
        "run_mode = ['interim_test', 'final_test']\n",
        "\n",
        "# Transfer learning model list\n",
        "transfer_learning_model_list = ['VGG16', \n",
        "                                'VGG19', \n",
        "                                'DenseNet201', \n",
        "                                'InceptionV3', \n",
        "                                'ResNet50', \n",
        "                                'EfficientNetB7', \n",
        "                                'MobileNet', \n",
        "                                'Xception'\n",
        "                               ]\n",
        "learning_rate_list = [.01, .001, .0001, .00001]\n",
        "optimizer_list = ['sgd', 'adam']\n",
        "dropout_list = [.2, .4, .6]\n",
        "kernel_size_list = [(3,3), (4,4), (5,5)]\n",
        "dense_layer_node_list = [512, 256, 128]\n",
        "fully_conneted_layer_list = [1, 2, 3]\n",
        "epoch_list = [5, 10, 15, 20]\n",
        "\n",
        "train_path = os.getcwd() + \"/train/\"\n",
        "test_path = os.getcwd() + \"/test/\"\n",
        "\n",
        "original_input_file_list = train_path + '*.tif'\n",
        "original_output_file_list = test_path + '*.tif'\n",
        "\n",
        "current_working_dir = os.getcwd()\n",
        "\n",
        "train_label_file = 'train_labels.csv'\n",
        "test_label_file = 'sample_submission.csv'\n",
        "\n",
        "image_file_extension = '.tif'\n",
        "\n",
        "train_files_path = os.path.join(current_working_dir, train_path)\n",
        "test_files_path = os.path.join(current_working_dir, test_path)\n",
        "\n",
        "image_processing_train_positive_path = '/content/image_processing/train/positive'\n",
        "image_processing_train_negative_path = '/content/image_processing/train/negative'\n",
        "\n",
        "image_processing_validation_positive_path = '/content/image_processing/validation/positive'\n",
        "image_processing_validation_negative_path = '/content/image_processing/validation/negative'\n",
        "\n",
        "image_processing_test_positive_path = '/content/image_processing/test/positive'\n",
        "image_processing_test_negative_path = '/content/image_processing/test/negative'\n",
        "\n",
        "image_processing_train_path = \"/content/image_processing/train/\"\n",
        "image_processing_validation_path = \"/content/image_processing/validation/\"\n",
        "image_processing_test_path = \"/content/image_processing/test/\"\n",
        "\n",
        "random.seed(1)\n",
        "random_state = 1234\n",
        "\n",
        "dropout_rate = .5\n",
        "\n",
        "training_accuracy_col_list   = ['training_accuracy_k' + str(k) + '_fold_accuracy' for k in range(1, number_of_splits + 1)]\n",
        "validation_accuracy_col_list = ['validation_accuracy_k' + str(k) + '_fold_accuracy' for k in range(1, number_of_splits + 1)]\n",
        "training_loss_col_list = ['training_loss_k' + str(k) + '_fold_loss' for k in range(1, number_of_splits + 1)]\n",
        "validation_loss_col_list = ['validation_loss_k' + str(k) + '_fold_loss' for k in range(1, number_of_splits + 1)]\n",
        "consolidated_df_model_kpi = pd.DataFrame()\n",
        "\n",
        "df_model_kfold_epoch_pred_pct = pd.DataFrame()\n",
        "df_model_kfold_epoch_pred_bin = pd.DataFrame()\n",
        "\n",
        "saved_model_names_list = []\n",
        "\n",
        "grayscale_image_augmentation_list = ['adjust_random_brightness',\n",
        "                                     'adjust_random_contrast',\n",
        "                                     'random_flip_left_right',\n",
        "                                     'random_flip_up_down',\n",
        "                                     'rotate_image_by_angle',\n",
        "                                     'rotate_image_by_90_or_180_or_270_deg',\n",
        "                                     'random_zoom',\n",
        "                                     'resize_with_crop_or_pad'\n",
        "                                    ]"
      ],
      "metadata": {
        "id": "e4rSklTftQY-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***F. Misclenious Processing Class***"
      ],
      "metadata": {
        "id": "m2j3vtPothqH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class misc_processing:\n",
        "    \"\"\"\n",
        "    This class contains methods for misclenious processings.\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        None\n",
        "  \n",
        "    def create_dir_structure(self, root_directory):\n",
        "        \"\"\"\n",
        "        This method creates a directory tree in the form below:-\n",
        "        image_processing--| train         |---positive\n",
        "                          |               |---negative\n",
        "                          |  \n",
        "                          | validation    |---positive\n",
        "                          |               |---negative\n",
        "                          |\n",
        "                          | test          |---positive\n",
        "                          |               |---negative\n",
        "\n",
        "        \"\"\"\n",
        "        os.makedirs(f'{root_directory}', exist_ok = True)\n",
        "        for sub_folder in ['train', 'validation', 'test']:\n",
        "            for grp in ['positive', 'negative']:\n",
        "                os.makedirs(f'{root_directory}/{sub_folder}/{grp}', exist_ok=True)\n",
        "\n",
        "    def remove_files_from_dir(self, path):\n",
        "        \"\"\"\n",
        "        This method deletes all files under a given path.\n",
        "        \"\"\"\n",
        "        print()\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"*****************************************************\")\n",
        "        print(f\"Starting to remove files under {path}...\")\n",
        "        shutil.rmtree(path)\n",
        "        os.mkdir(path)\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"*****************************************************\")\n",
        "        print()\n",
        "    \n",
        "    def generate_fully_qualified_file_name_list(self, file_list):\n",
        "        \"\"\"\n",
        "        This method generates a list of fully qualified file names.\n",
        "        \"\"\"\n",
        "        qualified_file_name_list = [os.path.join(current_working_dir, train_path) + \n",
        "                                    img + \n",
        "                                    '.tif' \n",
        "                                    for img in file_list\n",
        "                                   ]\n",
        "        return qualified_file_name_list\n",
        "\n",
        "    def print_image_original(self, image_file_list, label_list):\n",
        "        \"\"\"\n",
        "        This method prints original images.\n",
        "        \"\"\"\n",
        "        nrows, ncols = 1,4 #print first 4 images\n",
        "        f, axs = plt.subplots(nrows, ncols, figsize=(14,12))\n",
        "        for i, image in enumerate(image_file_list):\n",
        "            axs[i].imshow(array_to_img(image))\n",
        "            pf = Polygon(((32, 32), (64, 32), (64, 64), (32, 64)),\n",
        "                         fc=(0.0, 0.0, 0.0, 0.0), \n",
        "                         ec=(0.0, 0.9, 0.0 ,0.9), lw=4, linestyle='--')\n",
        "            pf.set_edgecolor('r')\n",
        "            axs[i].add_patch(pf)\n",
        "            axs[i].set(title=label_list[i])\n",
        "\n",
        "    def print_image_in_diff_orientation(self, image_file):\n",
        "        \"\"\"\n",
        "        This method prints images.\n",
        "        \"\"\"\n",
        "        tf.random.set_seed(1234)\n",
        "        fig = plt.figure(figsize=(14, 12))\n",
        "        #fig = plt.figure()\n",
        "        image = skio.imread(image_file, plugin = \"tifffile\")\n",
        "        \n",
        "        # plot original\n",
        "        ax = fig.add_subplot(1, 5, 1)\n",
        "        ax.imshow(array_to_img(image))\n",
        "        pf = Polygon(((32, 32), (64, 32), (64, 64), (32, 64)),\n",
        "                fc = (0.0, 0.0, 0.0, 0.0), \n",
        "                ec = (0.0, 0.9, 0.0 ,0.9), lw=4, linestyle='--')\n",
        "        pf.set_edgecolor('r')\n",
        "        ax.add_patch(pf)\n",
        "        ax.set_title('Original', size=15);\n",
        "        \n",
        "        # resize\n",
        "        ax = fig.add_subplot(1, 5, 2)\n",
        "        img_resize = tf.image.resize(image, size=(224, 224))\n",
        "        ax.imshow(array_to_img(img_resize))\n",
        "        pf = Polygon(((80, 80), (144, 80), (144, 144), (80, 144)),\n",
        "                fc = (0.0, 0.0, 0.0, 0.0), \n",
        "                ec = (0.0, 0.9, 0.0 ,0.9), lw=4, linestyle='--')\n",
        "        pf.set_edgecolor('r')\n",
        "        ax.add_patch(pf)\n",
        "        ax.set_title('Step 1: Resize', size=15);\n",
        "        \n",
        "        # adjust brightness\n",
        "        ax = fig.add_subplot(1, 5, 3)\n",
        "        img_bright = tf.image.adjust_brightness(img_resize, 0.3)\n",
        "        ax.imshow(array_to_img(img_bright))\n",
        "        pf = Polygon(((80, 80), (144, 80), (144, 144), (80, 144)),\n",
        "                fc = (0.0, 0.0, 0.0, 0.0), \n",
        "                ec = (0.0, 0.9, 0.0 ,0.9), lw=4, linestyle='--')\n",
        "        pf.set_edgecolor('r')\n",
        "        ax.add_patch(pf)\n",
        "        ax.set_title('Step 2: Brightness', size=15);\n",
        "        \n",
        "        # adjust contrast\n",
        "        ax = fig.add_subplot(1, 5, 4)\n",
        "        img_contrast = tf.image.adjust_contrast(img_bright, contrast_factor=3)\n",
        "        ax.imshow(array_to_img(img_contrast))\n",
        "        pf = Polygon(((80, 80), (144, 80), (144, 144), (80, 144)),\n",
        "                fc = (0.0, 0.0, 0.0, 0.0), \n",
        "                ec = (0.0, 0.9, 0.0 ,0.9), lw=4, linestyle='--')\n",
        "        pf.set_edgecolor('r')\n",
        "        ax.add_patch(pf)\n",
        "        ax.set_title('Step 3: Contrast', size=15);\n",
        "        \n",
        "        # flip left right\n",
        "        ax = fig.add_subplot(1, 5, 5)\n",
        "        img_flip = tf.image.flip_left_right(img_contrast)\n",
        "        ax.imshow(array_to_img(img_flip))\n",
        "        pf = Polygon(((80, 80), (144, 80), (144, 144), (80, 144)),\n",
        "                fc = (0.0, 0.0, 0.0, 0.0), \n",
        "                ec = (0.0, 0.9, 0.0 ,0.9), lw=4, linestyle='--')\n",
        "        pf.set_edgecolor('r')\n",
        "        ax.add_patch(pf)\n",
        "        ax.set_title('Step 4: Flip left right');\n",
        "\n",
        "    def get_id_and_label_list(self, file_path, file_extension):\n",
        "        \"\"\"\n",
        "        This function gets the imgae id and corresponding label.\n",
        "        \"\"\"\n",
        "        file_list = []\n",
        "        for file_name in glob.glob(file_path + '*' + file_extension):\n",
        "            file_list.append(file_name)\n",
        "        return file_list\n",
        "\n",
        "    def compute_mean_and_std(self, image_file_list, r_mid_pos = 48, c_mid_pos = 48):\n",
        "        \"\"\"\n",
        "        This method computes mean and std at the center of the image.\n",
        "        \"\"\"\n",
        "        center_pixel_value_list = []\n",
        "        for image_file in image_file_list:\n",
        "            image = skio.imread(image_file, plugin = \"tifffile\")\n",
        "            center_pixel_value_list.append(image[r_mid_pos, c_mid_pos])\n",
        "        np_array_center_pixel_value = np.array(center_pixel_value_list)\n",
        "        return np.mean(np_array_center_pixel_value), np.std(np_array_center_pixel_value)\n",
        "\n",
        "    def copy_file_from_one_to_other(self, file_names, dest_path):\n",
        "        \"This method moves chunks of files in one to other.\"\n",
        "        os.system('cp -r ' + file_names + ' ' + dest_path)\n",
        "\n",
        "    def process_copy_files(self, file_name_list, dest_path):\n",
        "        \"\"\"\"\n",
        "        This method processes moving files from one dir to the other. \n",
        "        This is the master process to run actual moving in chunks.\n",
        "        \"\"\"\n",
        "        '''\n",
        "        process_chunk_size = 100\n",
        "        for idx in range(0, len(file_name_list), process_chunk_size):\n",
        "            if idx % 10000 == 0:\n",
        "                print(\"Processing index: \", idx)\n",
        "            self.copy_file_from_one_to_other(' '.join(file_name_list[idx : idx + process_chunk_size]), dest_path)\n",
        "        '''\n",
        "        for file in file_name_list:\n",
        "            shutil.copy(file, dest_path)\n",
        "    \n",
        "    def check_file_count_in_a_directory(self, dir_path):\n",
        "        \"\"\"\n",
        "        This method checks the file count in a directory\n",
        "        \"\"\"\n",
        "        cmd_string = 'ls ' + dir_path + \" | wc -l\"\n",
        "        file_count = int(subprocess.check_output(cmd_string, shell=True, text=True).strip())\n",
        "        return file_count\n",
        "\n",
        "    def get_mini_batch_data(self, image_list, mini_batch_size):\n",
        "        \"\"\"\n",
        "        This method performs as a generator to spit out data in small batches.\n",
        "        \"\"\"\n",
        "        return (image_list[idx : idx + mini_batch_size] for idx in range(0, len(image_list), mini_batch_size))\n",
        "\n",
        "    def get_aug_step_list(self):\n",
        "        \"\"\"\n",
        "        This method executes image augmentation pipeline.\n",
        "        \"\"\"\n",
        "        sometimes = lambda aug: img_aug.Sometimes(0.5, aug)\n",
        "        img_aug_seq = img_aug.Sequential(\n",
        "        [\n",
        "            # apply the following augmenters to most images\n",
        "            img_aug.Fliplr(0.5), # horizontally flip 50% of all images\n",
        "            img_aug.Flipud(0.2), # vertically flip 20% of all images\n",
        "            sometimes(img_aug.Affine(\n",
        "                scale={\"x\": (0.9, 1.1), \"y\": (0.9, 1.1)}, # scale images to 80-120% of their size, individually per axis\n",
        "                translate_percent={\"x\": (-0.1, 0.1), \"y\": (-0.1, 0.1)}, # translate by -20 to +20 percent (per axis)\n",
        "                rotate=(-10, 10), # rotate by -45 to +45 degrees\n",
        "                shear=(-5, 5), # shear by -16 to +16 degrees\n",
        "                order=[0, 1], # use nearest neighbour or bilinear interpolation (fast)\n",
        "                cval=(0, 255), # if mode is constant, use a cval between 0 and 255\n",
        "                mode=iaug.ALL # use any of scikit-image's warping modes (see 2nd image from the top for examples)\n",
        "            )),\n",
        "            # execute 0 to 5 of the following (less important) augmenters per image\n",
        "            # don't execute all of them, as that would often be way too strong\n",
        "            img_aug.SomeOf((0, 5),\n",
        "                [\n",
        "                    sometimes(img_aug.Superpixels(p_replace=(0, 1.0), n_segments=(20, 200))), # convert images into their superpixel representation\n",
        "                    img_aug.OneOf([\n",
        "                        img_aug.GaussianBlur((0, 1.0)), # blur images with a sigma between 0 and 3.0\n",
        "                        img_aug.AverageBlur(k=(3, 5)), # blur image using local means with kernel sizes between 2 and 7\n",
        "                        img_aug.MedianBlur(k=(3, 5)), # blur image using local medians with kernel sizes between 2 and 7\n",
        "                    ]),\n",
        "                    img_aug.Sharpen(alpha=(0, 1.0), lightness=(0.9, 1.1)), # sharpen images\n",
        "                    img_aug.Emboss(alpha=(0, 1.0), strength=(0, 2.0)), # emboss images\n",
        "                    # search either for all edges or for directed edges,\n",
        "                    # blend the result with the original image using a blobby mask\n",
        "                    img_aug.SimplexNoiseAlpha(img_aug.OneOf([\n",
        "                        img_aug.EdgeDetect(alpha=(0.5, 1.0)),\n",
        "                        img_aug.DirectedEdgeDetect(alpha=(0.5, 1.0), direction=(0.0, 1.0)),\n",
        "                    ])),\n",
        "                    img_aug.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.01*255), per_channel=0.5), # add gaussian noise to images\n",
        "                    img_aug.OneOf([\n",
        "                        img_aug.Dropout((0.01, 0.05), per_channel=0.5), # randomly remove up to 10% of the pixels\n",
        "                        img_aug.CoarseDropout((0.01, 0.03), size_percent=(0.01, 0.02), per_channel=0.2),\n",
        "                    ]),\n",
        "                    img_aug.Invert(0.01, per_channel=True), # invert color channels\n",
        "                    img_aug.Add((-2, 2), per_channel=0.5), # change brightness of images (by -10 to 10 of original value)\n",
        "                    img_aug.AddToHueAndSaturation((-1, 1)), # change hue and saturation\n",
        "                    # either change the brightness of the whole image (sometimes\n",
        "                    # per channel) or change the brightness of subareas\n",
        "                    img_aug.OneOf([\n",
        "                        img_aug.Multiply((0.9, 1.1), per_channel=0.5),\n",
        "                        img_aug.FrequencyNoiseAlpha(\n",
        "                            exponent=(-1, 0),\n",
        "                            first=img_aug.Multiply((0.9, 1.1), per_channel=True),\n",
        "                            second=img_aug.ContrastNormalization((0.9, 1.1))\n",
        "                        )\n",
        "                    ]),\n",
        "                    sometimes(img_aug.ElasticTransformation(alpha=(0.5, 3.5), sigma=0.25)), # move pixels locally around (with random strengths)\n",
        "                    sometimes(img_aug.PiecewiseAffine(scale=(0.01, 0.05))), # sometimes move parts of the image around\n",
        "                    sometimes(img_aug.PerspectiveTransform(scale=(0.01, 0.1)))\n",
        "                ],\n",
        "                random_order=True\n",
        "            )\n",
        "        ],\n",
        "        random_order=True\n",
        "        )\n",
        "        return img_aug_seq\n",
        "\n",
        "    def get_id_label_map(self, df, filter_list):\n",
        "        \"\"\"\n",
        "        This method generates the id and label dictionary.\n",
        "        \"\"\"\n",
        "        return {k : v for k, v in zip(df[df.id.isin(filter_list)].id.values, \n",
        "                                      df[df.id.isin(filter_list)].label.values\n",
        "                                     )\n",
        "               }\n",
        "\n",
        "    def image_data_generator(self, list_files, label_list, batch_size, augment=False):\n",
        "        \"\"\"\n",
        "        This method is a generrator function to produce mini batch of data.\n",
        "        \"\"\"\n",
        "        image_augmentation_steps = self.get_aug_step_list()\n",
        "        while True:\n",
        "            shuffle(list_files)\n",
        "            for mini_batch in self.get_mini_batch_data(list_files, batch_size):\n",
        "                X = [cv2.imread(x) for x in mini_batch]\n",
        "                y = label_list\n",
        "                if augment:\n",
        "                    aug_X = image_augmentation_steps.augment_images(X)\n",
        "                    aug_y = y\n",
        "                    X = X + aug_X\n",
        "                X = [preprocess_input(x) for x in X]\n",
        "                \n",
        "        yield np.array(X), np.array(y)\n",
        "\n",
        "misc_proc = misc_processing()\n",
        "misc_proc.create_dir_structure(root_directory = '/content/image_processing')"
      ],
      "metadata": {
        "id": "KMaqq9V4toXo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***G. Visualization Processing Class***"
      ],
      "metadata": {
        "id": "jStvd4wGp8Ju"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class data_viz_processing:\n",
        "    \"\"\"\n",
        "    This class contains methods to display various plots.\n",
        "    \"\"\"\n",
        "    def count_plot(self, data, label_col, title_val):\n",
        "        \"\"\"\n",
        "        This method plots count plot of the input data set.\n",
        "        \"\"\"\n",
        "        sns.countplot(data = data, x = label_col)\n",
        "        plt.title(title_val)\n",
        "        plt.show(block = False)\n",
        "\n",
        "    def pie_chart_plot(self, data, label_col, title_val):\n",
        "        \"\"\"\n",
        "        This method plots pie chart based on the given data.\n",
        "        \"\"\"\n",
        "        fig = px.pie(data, \n",
        "                     values = data[label_col].value_counts().values, \n",
        "                     names = data[label_col].unique())\n",
        "        fig.update_layout(\n",
        "                      title={\n",
        "                             'text'    : title_val,\n",
        "                             'y'       : .99,\n",
        "                             'x'       :  0.5,\n",
        "                             'xanchor' : 'center',\n",
        "                             'yanchor' : 'top'\n",
        "                            }\n",
        "                          )\n",
        "        fig.show()\n",
        "        plt.show(block = False)\n",
        "\n",
        "data_viz = data_viz_processing()"
      ],
      "metadata": {
        "id": "myB5dDG2qBTr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***H. Image Processing Class***"
      ],
      "metadata": {
        "id": "i2353h6hNEnz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class image_processing:\n",
        "    \"\"\"\n",
        "    This class contains methods for image processing.\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        None\n",
        "    \n",
        "    def read_image_file_in_np_array(self, image_list):\n",
        "        \"\"\"\n",
        "        This method reads each image file in a Numpy array and returns it.\n",
        "        \"\"\"\n",
        "        return np.asarray([skio.imread(image_file, plugin = \"tifffile\") for image_file in image_list])\n",
        "    \n",
        "    def convert_np_array_to_tensor(self, np_image_array):\n",
        "        \"\"\"\n",
        "        This method converts the numpy array representation of each image in tensor.\n",
        "        \"\"\"\n",
        "        return tf.convert_to_tensor(np_image_array, dtype = tf.float32)\n",
        "\n",
        "    def convert_int_tf_to_float(self, tf_image_list):\n",
        "        \"\"\"\n",
        "        This method converts integer TF value to float.\n",
        "        \"\"\"\n",
        "        return np.asanyarray([tf.cast(img, tf.float32) for img in tf_image_list])\n",
        "    \n",
        "    def convert_from_rgb_to_grayscale(self, tf_image_list, large_list_ind = False):\n",
        "        \"\"\"\n",
        "        This method converts color image to grayscale.\n",
        "        \"\"\"\n",
        "        if large_list_ind == False:\n",
        "            return tf.image.rgb_to_grayscale(tf_image_list) / 255.0\n",
        "        else:\n",
        "            None\n",
        "    \n",
        "    def combine_train_val(self, x_train, X_val, y_train, y_val):\n",
        "        \"\"\"\n",
        "        This method combines train and validation data, shuffles them and \n",
        "        returns back suffled data for k-fold cross validation.\n",
        "        \"\"\"\n",
        "        X_train_kfold = tf.concat([X_train, X_val] , axis = 0)\n",
        "        y_train_kfold = tf.concat([y_train, y_val] , axis = 0)\n",
        "\n",
        "        print(\"Shuffling the kfold train data...\")\n",
        "        tf.random.set_seed(1234) # for reproducibility\n",
        "    \n",
        "        test_shuffle_indices = tf.random.shuffle(tf.range(tf.shape(X_train_kfold)[0], dtype = tf.int32))\n",
        "        X_train_kfold = tf.gather(X_train_kfold, test_shuffle_indices)\n",
        "        y_train_kfold = tf.gather(y_train_kfold, test_shuffle_indices).numpy()\n",
        "        \n",
        "        print(f\"X_train_kfold shape: {X_train_kfold.shape}\")\n",
        "        print(f\"y_train_kfold shape: {y_train_kfold.shape}\")\n",
        "\n",
        "    def adjust_brightness(self, tf_image_list, delta):\n",
        "        \"\"\"\n",
        "        This method adjusts the image brightness.\n",
        "        \"\"\"\n",
        "        return tf.image.adjust_brightness(tf_image_list, delta = delta)\n",
        "\n",
        "    def adjust_random_brightness(self, tf_image_list, max_delta = .3, seed = (1,2)):\n",
        "        \"\"\"\n",
        "        This method adjusts random image brightness.\n",
        "        \"\"\"\n",
        "        return tf.image.stateless_random_brightness(tf_image_list, max_delta = max_delta, seed = seed)\n",
        "\n",
        "    def adjust_contrast(self, tf_image_list, contrast_factor):\n",
        "        \"\"\"\n",
        "        This method adjusts contrast of the image.\n",
        "        \"\"\"\n",
        "        return tf.image.adjust_contrast(tf_image_list, contrast_factor = contrast_factor)\n",
        "\n",
        "    def adjust_random_contrast(self, contrast_factor, lower = .2, upper = .5, seed = (1,2)):\n",
        "        \"\"\"\n",
        "        This method randomly contrasts images during training.\n",
        "        \"\"\"\n",
        "        return tf.image.stateless_random_contrast(contrast_factor, lower, upper, seed)\n",
        "\n",
        "    def flip_left_right(self, tf_image_list):\n",
        "        \"\"\"\n",
        "        This method applies flips the image from left to right.\n",
        "        \"\"\"\n",
        "        return tf.image.flip_left_right(tf_image_list)\n",
        "\n",
        "    def random_flip_left_right(self, tf_image_list, seed = (1,2)):\n",
        "        \"\"\"\n",
        "        This method randomly flips images left-right during training.\n",
        "        \"\"\"\n",
        "        return tf.image.stateless_random_flip_left_right(tf_image_list, seed)\n",
        "\n",
        "    def flip_up_down(self, tf_image_list):\n",
        "        \"\"\"\n",
        "        This method flips the image up-down.\n",
        "        \"\"\"\n",
        "        return tf.image.flip_up_down(tf_image_list)\n",
        "    \n",
        "    def random_flip_up_down(self, tf_image_list, seed = (1,2)):\n",
        "        \"\"\"\n",
        "        This method flips the image up-down.\n",
        "        \"\"\"\n",
        "        return tf.image.stateless_random_flip_up_down(tf_image_list, seed)\n",
        "\n",
        "    def rotate_image_by_90_or_180_or_270_deg(self, tf_image_list, k = 1):\n",
        "        \"\"\"\n",
        "        This method rotates images by 90/180/270 degrees.\n",
        "        k = 1 : 90 degree rotation\n",
        "        k = 2 : 180 degree rotation\n",
        "        k = 3 : 270 degree rotation\n",
        "        \"\"\"\n",
        "        return tf.image.rot90(tf_image_list, k)\n",
        "\n",
        "    def rotate_image_by_angle(self, tf_image_list, angle = tf.constant(np.pi/8)):\n",
        "        \"\"\"\n",
        "        This method rotates images by a given angle.\n",
        "        \"\"\"\n",
        "        rotate_layer = tf.keras.layers.RandomRotation(0.2)\n",
        "        rotated_image = rotate_layer(tf_image_list) \n",
        "        return rotated_image    \n",
        "    \n",
        "    def random_zoom(self, tf_image_list):\n",
        "        \"\"\"\n",
        "        This method zooms the image.\n",
        "        \"\"\"\n",
        "        zoom_layer = tf.keras.layers.RandomZoom(.5, .2)\n",
        "        zoomed_image = zoom_layer(tf_image_list) \n",
        "        return zoomed_image\n",
        "\n",
        "    def random_crop(self, tf_image_list, crop_height = 16, crop_width = 16):\n",
        "        \"\"\"\n",
        "        This method randomly crops the image.\n",
        "        \"\"\"\n",
        "        crop_layer = tf.keras.layers.RandomCrop(crop_height, crop_width)\n",
        "        cropped_image = crop_layer(tf_image_list) \n",
        "        return cropped_image\n",
        "\n",
        "    def resize_with_crop_or_pad(self, tf_image_list, crop_height = 32, crop_width = 32):\n",
        "        \"\"\"\n",
        "        This method crops and resizes the central part of the image.\n",
        "        \"\"\"\n",
        "        cropped_image = tf.image.resize_with_crop_or_pad(tf_image_list, crop_height, crop_width)\n",
        "        resized_image = tf.image.resize(cropped_image, [96, 96])\n",
        "        return resized_image\n",
        "\n",
        "    def image_augmentation_pipeline(self, train_image_list, test_image_list, validation_image_list):\n",
        "        \"\"\"\n",
        "        This method executes image augmentation tasks.\n",
        "        \"\"\"\n",
        "        for img_aug_func in grayscale_image_augmentation_list:\n",
        "            \n",
        "            print(\"Image augmentation function : \", img_aug_func)\n",
        "            \n",
        "            if img_aug_func == 'adjust_random_brightness':\n",
        "      \n",
        "                print(\"Handling random brightness adjustment for train_image_list\")\n",
        "                train_image_aug_list = self.adjust_random_brightness(tf_image_list = train_image_list, \n",
        "                                                                     max_delta = np.round(random.uniform(.1, .5),1)\n",
        "                                                                    )\n",
        "                gc.collect()\n",
        "                tf.keras.backend.clear_session()\n",
        "                print(f\"Shape of train_image_aug_list : {train_image_aug_list.shape}\")\n",
        "\n",
        "            elif img_aug_func == 'adjust_random_contrast':\n",
        "      \n",
        "                print(\"Handling contrast adjustment for X_train_positive_aug_tf\")\n",
        "                train_image_aug_list = self.adjust_random_contrast(tf_image_list = train_image_aug_list, \n",
        "                                                                   lower = np.round(random.uniform(.1, .3),1), \n",
        "                                                                   upper = np.round(random.uniform(.4, .6),1)\n",
        "                                                                  )\n",
        "                gc.collect()\n",
        "                tf.keras.backend.clear_session()\n",
        "                print(f\"Shape of train_image_aug_list : {train_image_aug_list.shape}\")\n",
        "\n",
        "            elif img_aug_func == 'random_flip_left_right':\n",
        "                \n",
        "                print(\"Handling random flip left and right for train_image_list\")\n",
        "                train_image_aug_list = self.random_flip_left_right(tf_image_list = train_image_aug_list)\n",
        "                gc.collect()\n",
        "                print(f\"Shape of X_train_positive_aug_tf : {train_image_aug_list.shape}\")\n",
        "\n",
        "            elif img_aug_func == 'random_flip_up_down':\n",
        "\n",
        "                print(\"Handling random flip up and down for train_image_list\")\n",
        "                train_image_aug_list = self.random_flip_up_down(tf_image_list = train_image_aug_list)\n",
        "                gc.collect()\n",
        "                tf.keras.backend.clear_session()\n",
        "                print(f\"Shape of X_train_positive_aug_tf : {train_image_aug_list.shape}\")\n",
        "\n",
        "            elif img_aug_func == 'rotate_image_by_angle':\n",
        "                \n",
        "                print(\"Handling image rotation by an angle for train_image_list\")\n",
        "                train_image_aug_list = self.rotate_image_by_angle(tf_image_list = train_image_aug_list)\n",
        "                gc.collect()\n",
        "                tf.keras.backend.clear_session()\n",
        "                print(f\"Shape of X_train_positive_aug_tf : {train_image_aug_list.shape}\")\n",
        "            \n",
        "            elif img_aug_func == 'rotate_image_by_90_or_180_or_270_deg':\n",
        "\n",
        "                print(\"Handling image rotation by 90 deg angle for train_image_list\")\n",
        "                train_image_aug_list = self.rotate_image_by_90_or_180_or_270_deg(tf_image_list = train_image_aug_list, \n",
        "                                                                                 k = random.randrange(1, 3)\n",
        "                                                                                )\n",
        "                gc.collect()\n",
        "                print(f\"Shape of X_train_positive_aug_tf : {train_image_aug_list.shape}\")\n",
        "\n",
        "            elif img_aug_func == 'random_zoom':\n",
        "\n",
        "                print(\"Handling random zoom for X_train_positive_aug_tf\")\n",
        "                train_image_aug_list = self.random_zoom(tf_image_list = train_image_aug_list)\n",
        "                gc.collect()\n",
        "                tf.keras.backend.clear_session()\n",
        "                print(f\"Shape of X_train_positive_aug_tf : {train_image_aug_list.shape}\")\n",
        "        \n",
        "            elif img_aug_func == 'resize_with_crop_or_pad':\n",
        "\n",
        "                print(\"Handling resize with crop or pad for train_image_list\")\n",
        "                train_image_aug_list = self.resize_with_crop_or_pad(tf_image_list = train_image_aug_list)\n",
        "                gc.collect()\n",
        "                print(f\"Shape of X_train_positive_aug_tf : {train_image_aug_list.shape}\")\n",
        "        \n",
        "        return train_image_aug_list\n",
        "\n",
        "img_proc = image_processing()"
      ],
      "metadata": {
        "id": "o4VmIP_cNQCS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***I. Misclenious Model Building, Metric Reporting and Plotting Class***"
      ],
      "metadata": {
        "id": "GSEWn5BEN1Sz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class misc_model_functionality_processing:\n",
        "    \"\"\"\n",
        "    This class contains misclenious methods, required for model KPI or model plotting.\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        tf.random.set_seed(random_state)\n",
        "        np.random.seed(random_state)\n",
        "        tf.keras.backend.clear_session()\n",
        "\n",
        "    def model_summary_and_display_structure(self, model):\n",
        "        \"\"\"\n",
        "        This method shows model summary and displays the model structure.\n",
        "        \"\"\"\n",
        "        model.summary()\n",
        "        tf.keras.utils.plot_model(model)\n",
        "        plt.show(block = False)\n",
        "\n",
        "    def model_save(self, model, model_name):\n",
        "        \"\"\"\n",
        "        This method saves the model in a h5 file.\n",
        "        \"\"\"\n",
        "        tf.keras.backend.clear_session()\n",
        "        model.save(model_name + '.h5')\n",
        "    \n",
        "    def model_evaluation(self, model, X_test, y_test):\n",
        "        \"\"\"\n",
        "        This method evaluates the test data for a given model.\n",
        "        \"\"\"\n",
        "        self.test_results = model.evaluate(X_test, y_test)\n",
        "        print('\\nTest Loss : {:.2f}%'.format(self.test_results[0] * 100))\n",
        "        print('\\nTest Accuracy :  {:.2f}%'.format(self.test_results[1] * 100))\n",
        "\n",
        "    def model_prediction(self, model, X_test):\n",
        "        \"\"\"\n",
        "        This method predicts for a given model.\n",
        "        \"\"\"\n",
        "        # transform logits to probabilities\n",
        "        self.pred_logits = model.predict(X_test)\n",
        "        self.probas = tf.sigmoid(self.pred_logits)\n",
        "        self.probas = self.probas.numpy().flatten() * 100\n",
        "\n",
        "    def plot_model_accuracy_and_loss(self, history, model_name):\n",
        "        \"\"\"\n",
        "        This method plots model training and validation accuracies.\n",
        "        \"\"\"\n",
        "        tf.keras.backend.clear_session()\n",
        "\n",
        "        hist = history.history\n",
        "        x_arr = np.arange(len(hist['loss'])) + 1\n",
        "        \n",
        "        fig = plt.figure(figsize=(12, 4))\n",
        "        ax = fig.add_subplot(1, 2, 1)\n",
        "        ax.plot(x_arr, hist['loss'], '-o', label = 'Train loss')\n",
        "        ax.plot(x_arr, hist['val_loss'], '--<', label = 'Validation loss')\n",
        "        ax.legend(fontsize=15)\n",
        "        ax.set_xlabel('Epoch', size = 15)\n",
        "        ax.set_ylabel('Loss', size = 15)\n",
        "\n",
        "        ax = fig.add_subplot(1, 2, 2)\n",
        "        ax.plot(x_arr, hist['accuracy'], '-o', label = 'Train acc.')\n",
        "        ax.plot(x_arr, hist['val_accuracy'], '--<', label = 'Validation acc.')\n",
        "        ax.legend(fontsize = 15)\n",
        "        ax.set_xlabel('Epoch', size = 15)\n",
        "        ax.set_ylabel('Accuracy', size = 15)\n",
        "        ax.set_ylim(0,1)\n",
        "        plt.title(f\"Training and validation loss and accuracies for model : {model_name}\")\n",
        "        plt.show(block = False)\n",
        "\n",
        "    def build_pretained_model(self, model_name):\n",
        "        \"\"\"\n",
        "        This function utilizes transfer learning of a given model.\n",
        "        \"\"\"\n",
        "        tf.random.set_seed(random_state)\n",
        "        np.random.seed(random_state)\n",
        "        tf.keras.backend.clear_session()\n",
        "        input_shape = (image_size, image_size, 3)\n",
        "        if model_name == 'VGG19':\n",
        "            pretrained_model = VGG19(weights = 'imagenet', include_top = False, input_shape = input_shape)\n",
        "        elif model_name == 'DenseNet201':\n",
        "            pretrained_model = tf.keras.applications.densenet.DenseNet201(weights = 'imagenet', include_top = False, input_shape = input_shape)\n",
        "        elif model_name == 'ResNet50':\n",
        "            pretrained_model = tf.keras.applications.resnet50.ResNet50(weights = 'imagenet', include_top = False, input_shape = input_shape)\n",
        "        elif model_name == 'VGG16':\n",
        "            pretrained_model = VGG16(weights = 'imagenet', include_top = False, input_shape = input_shape)\n",
        "        elif model_name == 'EfficientNetB7':\n",
        "            pretrained_model = tf.keras.applications.efficientnet.EfficientNetB7(weights = 'imagenet', include_top = False, input_shape = input_shape)\n",
        "        elif model_name == 'MobileNet':\n",
        "            pretrained_model = tf.keras.applications.MobileNet(weights = 'imagenet', include_top = False, input_shape = input_shape)\n",
        "        elif model_name == 'Xception':\n",
        "            pretrained_model = tf.keras.applications.Xception(weights = 'imagenet', include_top = False, input_shape = input_shape)\n",
        "        elif model_name == 'InceptionV3':\n",
        "            pretrained_model = tf.keras.applications.InceptionV3(weights = 'imagenet', include_top = False, input_shape = input_shape)\n",
        "        self.model_summary_and_display_structure(pretrained_model)\n",
        "        return pretrained_model\n",
        "\n",
        "    def model_plot_test_vs_predicted(self, X_test, y_test, y_pred):\n",
        "        \"\"\"\n",
        "        This method plots actual vs prected results against each images.\n",
        "        \"\"\"\n",
        "        # plot test data and associated predicred\n",
        "        fig = plt.figure(figsize=(20, 20))\n",
        "        \n",
        "        for j, example in enumerate(X_test[:20]):\n",
        "            ax = fig.add_subplot(8, 4, j+1)\n",
        "            ax.set_xticks([])\n",
        "            ax.set_yticks([])\n",
        "            ax.imshow(array_to_img(example))\n",
        "            if y_test[j]==0:\n",
        "                true_label = 'No Cancer'\n",
        "            else:\n",
        "                true_label = 'Cancer'\n",
        "    \n",
        "            ax.text(\n",
        "                0.5, -0.15, \n",
        "                'True Label: {:s}\\nPr(Cancer)={:.0f}%'.format(y_test, self.probas[j]), \n",
        "                size = 16, \n",
        "                color = 'grey',\n",
        "                horizontalalignment = 'center',\n",
        "                verticalalignment = 'center', \n",
        "                transform = ax.transAxes)\n",
        "    \n",
        "        plt.tight_layout()\n",
        "        plt.show(block = False)\n",
        "    \n",
        "    def plot_model_result_confusion_matrix(self, y_pred_probas, y_test):\n",
        "        \"\"\"\n",
        "        This method plots confusion matrix.\n",
        "        \"\"\"\n",
        "        predictions_val = [1 if x > 50.0 else 0 for x in y_pred_probas]\n",
        "        model_confusion_matrix = confusion_matrix(np.ceil(y_test).astype(int), predictions_val)\n",
        "        #plot_confusion_matrix(y_pred_probas, ['Cancer', 'No Cancer'])\n",
        "        print('ROC AUC Score = ', roc_auc_score(np.ceil(y_test).astype(int), predictions_val))\n",
        "\n",
        "        fig, ax = plot_confusion_matrix(conf_mat = y_pred_probas,\n",
        "                                       show_absolute = True,\n",
        "                                       show_normed = True,\n",
        "                                       colorbar = True,\n",
        "                                       cmap = 'Dark2')\n",
        "        plt.show(block = False)\n",
        "\n",
        "    def plot_roc_auc_curve(self, y_pred_probas, y_test):\n",
        "        \"\"\"\n",
        "        This method plots ROC AUC Curve.\n",
        "        \"\"\"\n",
        "        predictions_val = [1 if x > 50.0 else 0 for x in y_pred_probas]\n",
        "        fpr, tpr, thresholds = roc_curve(np.ceil(y_test).astype(int), \n",
        "                                         predictions_val\n",
        "                                        )\n",
        "        auc = auc(fpr, tpr)\n",
        "        \n",
        "        plt.figure(1)\n",
        "        plt.plot([0, 1], [0, 1], 'k--')\n",
        "        plt.plot(fpr, tpr, label='area = {:.2f}'.format(auc))\n",
        "        plt.xlabel('False positive rate')\n",
        "        plt.ylabel('True positive rate')\n",
        "        plt.title('ROC Curve')\n",
        "        plt.legend(loc = 'best')\n",
        "        plt.show(block = False)\n",
        "\n",
        "    def generate_report(self, y_pred_probas, y_test):\n",
        "        \"\"\"\n",
        "        This method generates model performance report.\n",
        "        \"\"\"\n",
        "        predictions_val = [1 if x > 50.0 else 0 for x in y_pred_probas]\n",
        "        model_report = classification_report(np.ceil(y_test).astype(int), \n",
        "                                                predictions_val, \n",
        "                                                target_names = ['No Cancer', \n",
        "                                                                'Cancer'\n",
        "                                                               ]\n",
        "                                                )\n",
        "        print(model_report)\n",
        "\n",
        "    def ensemble_across_model_kfolds(self, df):\n",
        "        \"\"\"\n",
        "        This method performs ensemble method across model and all kfolds\n",
        "        using majority voting.\n",
        "        \"\"\"\n",
        "        df_kfold_ensemble_stats = df.groupby(['model', 'output_pos']).agg({'pred_bin' : [stats.mode], \n",
        "                                                                           'pred_pct' : [np.mean, np.min, np.max]}).reset_index()\n",
        "        df_kfold_ensemble_stats.columns = ['model', 'output_pos', 'majority_pred_bin', 'avg_pred_pct', 'min_pred_pct', 'max_pred_pct']\n",
        "        df_kfold_ensemble_stats[['majority_class_value', 'majority_count']] = pd.DataFrame(df_kfold_ensemble_stats['majority_pred_bin'].tolist(), \n",
        "                                                                                           index = df_kfold_ensemble_stats.index)\n",
        "        df_kfold_ensemble_stats['majority_class_value'] = df_kfold_ensemble_stats['majority_class_value'].apply(lambda x : x[0])\n",
        "        df_kfold_ensemble_stats['majority_count'] = df_kfold_ensemble_stats['majority_count'].apply(lambda x : x[0])\n",
        "        df_kfold_ensemble_stats['fmt_majority_class_value'] = np.where(df_kfold_ensemble_stats['majority_count'] == 2, \n",
        "                                                                       1, \n",
        "                                                                       df_kfold_ensemble_stats['majority_class_value'])\n",
        "        \n",
        "        # assigning back the actual value corresponding to output_pos\n",
        "        df_kfold_ensemble_stats['actual'] = df_kfold_ensemble_stats['output_pos'].apply(lambda x : data_proc.y_test[x-1])\n",
        "        # majority_class_prob will be calculated based on the majority_class.\n",
        "        df_kfold_ensemble_stats['majority_class_prob'] = None\n",
        "        for index_val, rec in df_kfold_ensemble_stats.iterrows():\n",
        "            model, output_pos, majority_pred_bin = rec[0], rec[1], rec[2]\n",
        "            avg_pred_pct, min_pred_pct, max_pred_pct = rec[3], rec[4], rec[5]\n",
        "            majority_class_value = rec[6]\n",
        "            majority_count = rec[7]\n",
        "            fmt_majority_class_value = rec[8]\n",
        "            actual= rec[9]\n",
        "            majority_class_prob = np.mean(df[(df.model == model) &\n",
        "                                             (df.output_pos == output_pos) &\n",
        "                                             (df.pred_bin == fmt_majority_class_value)\n",
        "                                            ]['pred_pct'])\n",
        "            #print(model, output_pos, fmt_majority_class_value, majority_class_prob)\n",
        "            df_kfold_ensemble_stats.iloc[index_val, -1] = majority_class_prob\n",
        "\n",
        "        df_kfold_ensemble_stats.head()\n",
        "        return df_kfold_ensemble_stats\n",
        "\n",
        "    def ensemble_across_models(self, df):\n",
        "        \"\"\"\n",
        "        This method performs ensemble methods across models using majority voting.\n",
        "        \"\"\"\n",
        "        df_ensemble_stats = df.groupby(['output_pos']).agg({'pred_bin' : [stats.mode], 'pred_pct' : [np.mean, np.min, np.max]}).reset_index()\n",
        "        df_ensemble_stats.columns = ['output_pos', 'majority_pred_bin', 'avg_pred_pct', 'min_pred_pct', 'max_pred_pct']\n",
        "        df_ensemble_stats[['majority_class_value', 'majority_count']] = pd.DataFrame(df_ensemble_stats['majority_pred_bin'].tolist(), \n",
        "                                                                                     index=df_ensemble_stats.index)\n",
        "        df_ensemble_stats['majority_class_value'] = df_ensemble_stats['majority_class_value'].apply(lambda x : x[0])\n",
        "        df_ensemble_stats['majority_count'] = df_ensemble_stats['majority_count'].apply(lambda x : x[0])\n",
        "        df_ensemble_stats['fmt_majority_class_value'] = np.where(df_ensemble_stats['majority_count'] == 2, \n",
        "                                                                 1, \n",
        "                                                                 df_ensemble_stats['majority_class_value'])\n",
        "        # assigning back the actual value corresponding to output_pos\n",
        "        df_ensemble_stats['actual'] = df_ensemble_stats['output_pos'].apply(lambda x : data_proc.y_test[x-1])\n",
        "        \n",
        "        # majority_class_prob will be calculated based on the majority_class.\n",
        "        df_ensemble_stats['majority_class_prob'] = None\n",
        "        \n",
        "        for index, rec in df_ensemble_stats.iterrows():\n",
        "            output_pos, majority_pred_bin = rec[0], rec[1]\n",
        "            avg_pred_pct, min_pred_pct, max_pred_pct = rec[2], rec[3], rec[4]\n",
        "            majority_class_value = rec[5]\n",
        "            majority_count = rec[6]\n",
        "            fmt_majority_class_value = rec[7]\n",
        "            actual= rec[8]\n",
        "\n",
        "            majority_class_prob = np.mean(df_actual_vs_pred_bin_pred_pct[(df.output_pos == output_pos) &\n",
        "                                                                         (df.pred_bin == fmt_majority_class_value)\n",
        "                                                                        ]['pred_pct'])\n",
        "            #print(model, output_pos, fmt_majority_class_value, majority_class_prob)\n",
        "            df_ensemble_stats.iloc[index, -1] = majority_class_prob\n",
        "\n",
        "        \n",
        "        df_ensemble_stats.head()\n",
        "        return df_ensemble_stats\n",
        "\n",
        "    def display_model_stats_across_all_spilts(self, model_name, consolidated_df_model_kpi, df_actual_vs_pred_bin_pred_pct):\n",
        "        \"\"\"\n",
        "        This function displays model specific summary stats across all splits.\n",
        "        \"\"\"\n",
        "        # Displays test accuracy and loss across all spilts.\n",
        "        for fold_idx in range(0, number_of_splits):\n",
        "            print('------------------------------------------------------------------------')\n",
        "            accuracy = df_actual_vs_pred_bin_pred_pct[(df_actual_vs_pred_bin_pred_pct.model == model_name) & \n",
        "                                                      (df_actual_vs_pred_bin_pred_pct.kfold == fold_idx + 1)\n",
        "                                                    ]['test_accuracy'].drop_duplicates() * 100\n",
        "            loss = df_actual_vs_pred_bin_pred_pct[(df_actual_vs_pred_bin_pred_pct.model == model_name) & \n",
        "                                                  (df_actual_vs_pred_bin_pred_pct.kfold == fold_idx + 1)\n",
        "                                                ]['test_loss'].drop_duplicates()\n",
        "            print(f'> Model {model_name} : Fold: {fold_idx + 1} - Loss: {loss[0]} - Accuracy: {accuracy[0]}%')\n",
        "            print('------------------------------------------------------------------------')\n",
        "\n",
        "        # Average and std for train accuracy and loss\n",
        "        average_train_accuracy_per_fold = consolidated_df_model_kpi[(consolidated_df_model_kpi.model == model_name) & \n",
        "                                                                    (consolidated_df_model_kpi.epoch == epochs)\n",
        "                                                                   ].groupby(['model']).agg({'accuracy': np.mean}).values[0][0]\n",
        "        std_for_average_train_accuracy_per_fold = consolidated_df_model_kpi[(consolidated_df_model_kpi.model == model_name) & \n",
        "                                                                    (consolidated_df_model_kpi.epoch == epochs)\n",
        "                                                                   ].groupby(['model']).agg({'accuracy': np.std}).values[0][0]\n",
        "    \n",
        "        average_train_loss_per_fold = consolidated_df_model_kpi[(consolidated_df_model_kpi.model == model_name) & \n",
        "                                                                    (consolidated_df_model_kpi.epoch == epochs)\n",
        "                                                                   ].groupby(['model']).agg({'loss': np.mean}).values[0][0]\n",
        "        std_for_average_train_loss_per_fold = consolidated_df_model_kpi[(consolidated_df_model_kpi.model == model_name) & \n",
        "                                                                    (consolidated_df_model_kpi.epoch == epochs)\n",
        "                                                                   ].groupby(['model']).agg({'loss': np.std}).values[0][0]\n",
        "\n",
        "        # Average and std for validation accuracy and loss\n",
        "        average_validation_accuracy_per_fold = consolidated_df_model_kpi[(consolidated_df_model_kpi.model == model_name) & \n",
        "                                                                    (consolidated_df_model_kpi.epoch == epochs)\n",
        "                                                                   ].groupby(['model']).agg({'val_accuracy': np.mean}).values[0][0]\n",
        "        std_for_average_validation_accuracy_per_fold = consolidated_df_model_kpi[(consolidated_df_model_kpi.model == model_name) & \n",
        "                                                                    (consolidated_df_model_kpi.epoch == epochs)\n",
        "                                                                   ].groupby(['model']).agg({'val_accuracy': np.std}).values[0][0]\n",
        "    \n",
        "        average_validation_loss_per_fold = consolidated_df_model_kpi[(consolidated_df_model_kpi.model == model_name) & \n",
        "                                                                    (consolidated_df_model_kpi.epoch == epochs)\n",
        "                                                                   ].groupby(['model']).agg({'val_loss': np.mean}).values[0][0]\n",
        "        std_for_average_validation_loss_per_fold = consolidated_df_model_kpi[(consolidated_df_model_kpi.model == model_name) & \n",
        "                                                                    (consolidated_df_model_kpi.epoch == epochs)\n",
        "                                                                   ].groupby(['model']).agg({'val_loss': np.std}).values[0][0]\n",
        "\n",
        "        # Average and std for test accuracy and loss\n",
        "        average_test_accuracy_per_fold = np.mean(df_actual_vs_pred_bin_pred_pct[df_actual_vs_pred_bin_pred_pct.model == model_name].test_accuracy)\n",
        "        std_for_average_test_accuracy_per_fold = np.std(df_actual_vs_pred_bin_pred_pct[df_actual_vs_pred_bin_pred_pct.model == model_name].test_accuracy)\n",
        "    \n",
        "        average_test_loss_per_fold = np.mean(df_actual_vs_pred_bin_pred_pct[df_actual_vs_pred_bin_pred_pct.model == model_name].test_loss)\n",
        "        std_for_average_test_loss_per_fold = np.std(df_actual_vs_pred_bin_pred_pct[df_actual_vs_pred_bin_pred_pct.model == model_name].test_loss)\n",
        "    \n",
        "        print(f'Average train, validation and test accuracy and loss for all folds for the model : {model_name}')\n",
        "        print(f'> Train accuracy: {average_train_accuracy_per_fold} (+- {std_for_average_test_accuracy_per_fold})')\n",
        "        print(f'> Train loss: {average_train_loss_per_fold} (+- {std_for_average_train_accuracy_per_fold})')\n",
        "\n",
        "        print(f'> Validation accuracy: {average_validation_accuracy_per_fold} (+- {std_for_average_validation_accuracy_per_fold})')\n",
        "        print(f'> Validation loss: {average_validation_loss_per_fold} (+- {std_for_average_validation_loss_per_fold})')\n",
        "    \n",
        "        print(f'> Test accuracy: {average_test_accuracy_per_fold} (+- {std_for_average_test_accuracy_per_fold})')\n",
        "        print(f'> Test loss: {average_test_loss_per_fold} (+- {std_for_average_test_loss_per_fold})')\n",
        "\n",
        "model_proc = misc_model_functionality_processing()"
      ],
      "metadata": {
        "id": "HC8mI7nSOBnZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***2. Data Processing***"
      ],
      "metadata": {
        "id": "GMct-xh6t74w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class data_processing:\n",
        "\n",
        "    def __init__(self, run_mode):\n",
        "        self.train_file_list = []\n",
        "        self.test_file_list = []\n",
        "        self.run_mode = run_mode\n",
        "        np.random.seed(random_state)\n",
        "                \n",
        "    def get_file_names_list(self):\n",
        "        \"\"\"\n",
        "    \t  This method builds the list of train and test files.\n",
        "        It also reads the original color images and save them with _gs extension \n",
        "        in the same path as the original image. The grayscale images will be \n",
        "        used for modeling whereas the color images are used for data \n",
        "        visualization purposes.\n",
        "    \t  \"\"\"\n",
        "        print()\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"Starting to build fully qualified train and test file name lists...\")\n",
        "        # Original input images are color which we will later convert to grascale.\n",
        "        self.train_file_color_list = misc_proc.get_id_and_label_list(train_files_path, image_file_extension)\n",
        "        self.test_file_color_list = misc_proc.get_id_and_label_list(test_files_path, image_file_extension)\n",
        "        self.train_file_list = []\n",
        "\n",
        "        # Loading the input images as grayscale images and saving them back with \n",
        "        # \"_gs\" extension to distinguish.\n",
        "        # For modeling purpose, we will use the grayscale images and \n",
        "        # for visualization purposes we will use the original color images.\n",
        "        for image_file in self.train_file_color_list:\n",
        "            img_gs = load_img(image_file, color_mode = \"grayscale\")\n",
        "            img_array_gs = img_to_array(img_gs)\n",
        "            save_img(image_file.split(\".\")[0] + '_gs' + image_file_extension, img_array_gs)\n",
        "            self.train_file_list.append(image_file.split(\".\")[0] + '_gs' + image_file_extension)\n",
        "        \n",
        "        if self.run_mode == 'interim_test':\n",
        "            print(f\"Length of train_file_list : {len(self.train_file_list)}\")\n",
        "            print(f\"Length of test_file_list : {len(self.test_file_list)}\")\n",
        "        print(\"Completed building train and test file name lists...\")\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"*****************************************************\")\n",
        "        print()\n",
        "\n",
        "    def get_label_info(self):\n",
        "        \"\"\"\n",
        "    \t  This method reads the train and test label information from \n",
        "        train_labels.csv and sample_submission.csv.\n",
        "        These files have the below structure:-\n",
        "        id and label.\n",
        "        Corresponding to the train or test id, there will be an image file \n",
        "        prssent in the respective train oo test folder.\n",
        "    \t  \"\"\"\n",
        "        print()\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"Starting to get label info...\")\n",
        "        self.train_label = pd.read_csv(train_label_file)\n",
        "        self.test_label = pd.read_csv(test_label_file)\n",
        "        if self.run_mode == 'interim_test':\n",
        "            print(f\"Number of train labels : {len(self.train_label)}\")\n",
        "            print(f\"Number of test labels : {len(self.test_label)}\")\n",
        "\n",
        "        self.qualified_train_file_names_list = misc_proc.generate_fully_qualified_file_name_list(self.train_label.id.values.tolist())\n",
        "        self.qualified_test_file_names_list = misc_proc.generate_fully_qualified_file_name_list(self.test_label.id.values.tolist())\n",
        "        \n",
        "        self.train_label_positive = self.train_label[self.train_label['label'] == 1]\n",
        "        self.train_label_negative = self.train_label[self.train_label['label'] == 0]\n",
        "        \n",
        "        print(\"Completed getting label info...\")\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"*****************************************************\")\n",
        "        print()\n",
        "\n",
        "    def create_labels(self, train_val_test_ind, data):\n",
        "        \"\"\"\n",
        "        This method creates label of given length.\n",
        "        \"\"\"\n",
        "        print()\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"*****************************************************\")\n",
        "        print(f\"Starting to create labels for {train_val_test_ind}...\")\n",
        "        if train_val_test_ind.lower() == 'train':\n",
        "            self.y_train = np.asarray(data['label'].values.tolist())\n",
        "        elif train_val_test_ind.lower() == 'test':\n",
        "            self.y_test = np.asarray(data['label'].values.tolist())\n",
        "        elif train_val_test_ind.lower() == 'validation':\n",
        "            self.y_validation = np.asarray(data['label'].values.tolist())    \n",
        "        print(f\"Completed building labels for {train_val_test_ind}...\")\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"*****************************************************\")\n",
        "        print()\n",
        "\n",
        "    def split_data_based_on_indices(self, train_indices, validation_indices):\n",
        "        \"\"\"\n",
        "        This method splits data based on indices.\n",
        "        \"\"\"\n",
        "        print()\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"Starting to split data based on indices...\")\n",
        "        # New train and validation set and corresponding labels based on the kfold split process generated indices.\n",
        "        self.df_train = self.df_train_original.iloc[train_indices]\n",
        "        self.df_validation = self.df_train_original.iloc[validation_indices]\n",
        "        self.create_labels(train_val_test_ind = 'train', data = self.df_train)\n",
        "        self.create_labels(train_val_test_ind = 'validation', data = self.df_validation)\n",
        "        \n",
        "        if self.run_mode == 'interim_test':\n",
        "            print(f\"Length of train data : {len(self.df_train)}, length of validation data : {len(self.df_validation)}, length of test data : {len(self.df_test)}\")\n",
        "            print(f\"Length of train positive data : {len(self.df_train[self.df_train.label == 1])}, length of validation positive data : {len(self.df_validation[self.df_validation.label == 1])}, length of test positive data : {len(self.df_test[self.df_test.label == 1])}\")\n",
        "            print(f\"Length of train negative data : {len(self.df_train[self.df_train.label == 0])}, length of validation negative data : {len(self.df_validation[self.df_validation.label == 0])}, length of test negative data : {len(self.df_test[self.df_test.label == 0])}\")\n",
        "        \n",
        "        \"\"\"\n",
        "        Both df_train and df_validation have three columns id, id_gs and label.\n",
        "        id is the original color file name without extension and id_gs is the\n",
        "        grayscale file name, derived off id column along with a \"_gs\" suffix.\n",
        "        For modeling purpose, we will use the _gs file and for data visulaization\n",
        "        purposes, we will use the original color images.\n",
        "        Thus, to move the files in a different directory, we will move the \n",
        "        grayscale images.\n",
        "        \"\"\"\n",
        "        misc_proc.remove_files_from_dir(image_processing_train_positive_path)\n",
        "        misc_proc.remove_files_from_dir(image_processing_train_negative_path)\n",
        "        self.train_positive_file_list = misc_proc.generate_fully_qualified_file_name_list(self.df_train[self.df_train.label == 1].id_gs.values.tolist())\n",
        "        self.train_negative_file_list = misc_proc.generate_fully_qualified_file_name_list(self.df_train[self.df_train.label == 0].id_gs.values.tolist())\n",
        "        print(f\"Copying test_positive_file_list under {image_processing_train_positive_path}\")\n",
        "        misc_proc.process_copy_files(self.train_positive_file_list, image_processing_train_positive_path)\n",
        "        print(f\"Copying test_negative_file_list under {image_processing_train_negative_path}\")\n",
        "        misc_proc.process_copy_files(self.train_negative_file_list, image_processing_train_negative_path)\n",
        "        print(f\"File count under {image_processing_train_positive_path} after moving new files is: {misc_proc.check_file_count_in_a_directory(image_processing_train_positive_path)}\")\n",
        "        print(f\"File count under {image_processing_train_negative_path} after moving new files is : {misc_proc.check_file_count_in_a_directory(image_processing_train_negative_path)}\")\n",
        "        \n",
        "        misc_proc.remove_files_from_dir(image_processing_validation_positive_path)\n",
        "        misc_proc.remove_files_from_dir(image_processing_validation_negative_path)\n",
        "        self.validation_positive_file_list = misc_proc.generate_fully_qualified_file_name_list(self.df_validation[self.df_validation.label == 1].id_gs.values.tolist())\n",
        "        self.validation_negative_file_list = misc_proc.generate_fully_qualified_file_name_list(self.df_validation[self.df_validation.label == 0].id_gs.values.tolist())\n",
        "        print(f\"Copying test_positive_file_list under {image_processing_validation_positive_path}\")\n",
        "        misc_proc.process_copy_files(self.validation_positive_file_list, image_processing_validation_positive_path)\n",
        "        print(f\"Copying test_negative_file_list under {image_processing_validation_negative_path}\")\n",
        "        misc_proc.process_copy_files(self.validation_negative_file_list, image_processing_validation_negative_path)\n",
        "        print(f\"File count under {image_processing_validation_positive_path} after moving new files is: {misc_proc.check_file_count_in_a_directory(image_processing_validation_positive_path)}\")\n",
        "        print(f\"File count under {image_processing_validation_negative_path} after moving new files is : {misc_proc.check_file_count_in_a_directory(image_processing_validation_negative_path)}\")\n",
        "            \n",
        "        print(\"Completed spliting the data sets based on indices...\")\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"*****************************************************\")\n",
        "        print()\n",
        "\n",
        "    def initial_split_data(self):\n",
        "        \"\"\"\n",
        "    \t  This method uses train data to split into train, validation and test sets.\n",
        "    \t  The reason we are repurposing the train set is because we do not have labels for test data.\n",
        "    \t  We also see data imbalance issue and thus we are undersampling the most populated class (negative images).\n",
        "    \t  \"\"\"\n",
        "        print()\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"Starting to split data...\")\n",
        "\n",
        "        \"\"\"\n",
        "        Extracting top sample_size records from train_label_positive and \n",
        "        train_label_negative seperately and then combine them together so \n",
        "        that distribution is uniform.\n",
        "        \"\"\"\n",
        "        self.train_label_sample_positive = self.train_label_positive.head(sample_size)\n",
        "        self.train_label_sample_negative = self.train_label_negative.head(sample_size)\n",
        "        self.train_label_processed = pd.concat([self.train_label_sample_negative, \n",
        "          \t                                    self.train_label_sample_positive\n",
        "        \t                                     ], \n",
        "        \t                                     axis = 0).reset_index(drop = True)\n",
        "\n",
        "        \"\"\"\n",
        "        Getting the remaining records (length of uiverse - sample size) serves\n",
        "        as test data set. We have also made sure distribution is uniform here.\n",
        "        \"\"\"\n",
        "        '''\n",
        "        remaining_length = 50 #len(self.train_label_positive) - len(self.train_label_sample_positive)\n",
        "        self.test_positive_df = self.train_label_positive[sample_size : sample_size + remaining_length]\n",
        "        self.test_negative_df = self.train_label_negative[sample_size : sample_size + remaining_length]\n",
        "        self.df_test = pd.concat([self.test_positive_df, self.test_negative_df], axis = 0).reset_index(drop = True)\n",
        "        self.df_test = shuffle(self.df_test, random_state = random_state)\n",
        "        self.create_labels(train_val_test_ind = 'test', data = self.df_test)\n",
        "        '''\n",
        "\n",
        "        # shuffle\n",
        "        self.train_label_processed = shuffle(self.train_label_processed, random_state = random_state)\n",
        "        label = self.train_label_processed['label']\n",
        "        self.df_train, self.df_test = train_test_split(self.train_label_processed, \n",
        "          \t                                                 test_size = 0.1, \n",
        "        \t                                                   random_state = random_state, \n",
        "        \t                                                   stratify = label\n",
        "        \t                                                  )\n",
        "        self.create_labels(train_val_test_ind = 'train', data = self.df_train)\n",
        "        self.create_labels(train_val_test_ind = 'test', data = self.df_test)\n",
        "        self.df_train['id_gs'] = self.df_train['id'].apply(lambda x : x + '_gs')\n",
        "        self.df_test['id_gs']  = self.df_test['id'].apply(lambda x : x + '_gs')\n",
        "        self.df_train_original = copy.deepcopy(self.df_train)\n",
        "\n",
        "        \"\"\"\n",
        "        At this point, df_test has three columns id, id_gs and label.\n",
        "        id denotes original color image name without extension and id_gs is the\n",
        "        grayscale image name derived off id column data, suffixed with '_gs'\n",
        "        extension.\n",
        "        We will use grayscale images for all our training, so while moving the\n",
        "        images to appropriate directory, we need to move the grayscale images.\n",
        "        \"\"\"\n",
        "        self.test_positive_file_list = misc_proc.generate_fully_qualified_file_name_list(self.df_test[self.df_test.label == 1].id_gs.values.tolist())\n",
        "        self.test_negative_file_list = misc_proc.generate_fully_qualified_file_name_list(self.df_test[self.df_test.label == 0].id_gs.values.tolist())\n",
        "        print(f\"Copying test_positive_file_list under {image_processing_test_positive_path}\")\n",
        "        misc_proc.process_copy_files(self.test_positive_file_list, image_processing_test_positive_path)\n",
        "        print(f\"Copying test_negative_file_list under {image_processing_test_negative_path}\")\n",
        "        misc_proc.process_copy_files(self.test_negative_file_list, image_processing_test_negative_path)\n",
        "        print(f\"File count under {image_processing_test_positive_path} is {misc_proc.check_file_count_in_a_directory(image_processing_test_positive_path)}\")\n",
        "        print(f\"File count under {image_processing_test_negative_path} is {misc_proc.check_file_count_in_a_directory(image_processing_test_negative_path)}\")\n",
        "\n",
        "        self.sample_positive_label = self.train_label_sample_positive['label'].values.tolist()\n",
        "        self.sample_negative_label = self.train_label_sample_negative['label'].values.tolist()\n",
        "\n",
        "        self.df_train_positive = self.df_train[self.df_train.label == 1]\n",
        "        self.df_train_negative = self.df_train[self.df_train.label == 0]\n",
        "\n",
        "        self.df_test_positive = self.df_test[self.df_test.label == 1]\n",
        "        self.df_test_negative = self.df_test[self.df_test.label == 0]\n",
        "\n",
        "        # Train color files\n",
        "        self.train_positive_color_file_list = misc_proc.generate_fully_qualified_file_name_list(self.df_train_positive.id.values.tolist())\n",
        "        self.train_negative_color_file_list = misc_proc.generate_fully_qualified_file_name_list(self.df_train_negative.id.values.tolist())\n",
        "\n",
        "        # Test color files\n",
        "        self.test_positive_color_file_list = misc_proc.generate_fully_qualified_file_name_list(self.df_test_positive.id.tolist())\n",
        "        self.test_negative_color_file_list = misc_proc.generate_fully_qualified_file_name_list(self.df_test_negative.id.tolist())\n",
        "\n",
        "        # Train grayscale files\n",
        "        self.train_positive_file_list = misc_proc.generate_fully_qualified_file_name_list(self.df_train_positive.id_gs.values.tolist())\n",
        "        self.train_negative_file_list = misc_proc.generate_fully_qualified_file_name_list(self.df_train_negative.id_gs.values.tolist())\n",
        "\n",
        "        # Test grayscale files\n",
        "        self.test_positive_file_list = misc_proc.generate_fully_qualified_file_name_list(self.df_test_positive.id_gs.tolist())\n",
        "        self.test_negative_file_list = misc_proc.generate_fully_qualified_file_name_list(self.df_test_negative.id_gs.tolist())\n",
        "\n",
        "        if self.run_mode == 'interim_test':\n",
        "            \n",
        "            print(f\"Length of df_train : {len(self.df_train)}\")\n",
        "            print(f\"Length of df_test : {len(self.df_test)}\")\n",
        "            print(f\"Length of y_train : {len(self.y_train)}\")\n",
        "            print(f\"Length of y_test : {len(self.y_test)}\")\n",
        "\n",
        "            print(\"Positive and negative images distribution in df_train\")\n",
        "            print(self.df_train['label'].value_counts())\n",
        "\n",
        "            print(\"Positive and negative images distribution in df_test\")\n",
        "            print(self.df_test['label'].value_counts())\n",
        "\n",
        "            print(f\"Length of df_train_positive : {len(self.df_train_positive)}\")\n",
        "            print(f\"Length of df_train_positive : {len(self.df_train_positive)}\")\n",
        "\n",
        "            print(f\"Length of df_test_positive : {len(self.df_test_positive)}\")\n",
        "            print(f\"Length of df_test_negative : {len(self.df_test_negative)}\")\n",
        "\n",
        "            print(f\"Length of train_positive_file_list : {len(self.train_positive_file_list)}\")\n",
        "            print(f\"Length of train_negative_file_list : {len(self.train_negative_file_list)}\")\n",
        "\n",
        "            print(f\"Length of test_positive_file_list : {len(self.test_positive_file_list)}\")\n",
        "            print(f\"Length of test_negative_file_list : {len(self.test_negative_file_list)}\")\n",
        "\n",
        "        print(\"Completed spliting the data sets...\")\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"*****************************************************\")\n",
        "        print()\n",
        "\n",
        "    def get_data_distribution(self, train_or_test_ind):\n",
        "        \"\"\"\n",
        "     \t  This method shows the distribution of positive and negative images in the data set. \n",
        "     \t  \"\"\"\n",
        "        print()\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"*****************************************************\")\n",
        "        print(f\"Starting to get data distributions for {train_or_test_ind}...\")\n",
        "        if train_or_test_ind.lower() == 'train':\n",
        "            print(\"Data distribution in the train data set\")\n",
        "            print(self.train_label['label'].value_counts())\n",
        "            data_viz.count_plot(data = self.train_label, \n",
        "                                 label_col = 'label',\n",
        "                                 title_val = \"Distribution of Labels in Train Data\"\n",
        "                                )\n",
        "            data_viz.pie_chart_plot(data = self.train_label, \n",
        "                                     label_col = 'label',\n",
        "                                     title_val = \"Train Label Percentage Pie Chart\"\n",
        "                                    )\n",
        "        elif train_or_test_ind.lower() == 'test':\n",
        "            print(\"Data distribution in the test data set\")\n",
        "            print(self.test_label['label'].value_counts())  \n",
        "            data_viz.count_plot(data = self.test_label, \n",
        "                                 label_col = 'label',\n",
        "                                 title_val = \"Distribution of Labels in Test Data\"\n",
        "                                )\n",
        "            data_viz.pie_chart_plot(data = self.test_label, \n",
        "                                     label_col = 'label',\n",
        "                                     title_val = \"Test Label Percentage Pie Chart\"\n",
        "                                    )\n",
        "        print(f\"Completed getting data distributions for {train_or_test_ind}...\")\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"*****************************************************\")\n",
        "        print()\n",
        "\n",
        "    def check_duplicate_ids(self, train_or_test_ind):\n",
        "        \"\"\"\n",
        "    \t  This method checks if there is any duplicate ids in the data set.\n",
        "    \t  \"\"\"\n",
        "        print()\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"*****************************************************\")\n",
        "        print(f\"Starting to check duplicates for {train_or_test_ind}...\")\n",
        "        if train_or_test_ind.lower() == 'train':\n",
        "            df_train_id_count = pd.DataFrame(self.train_label.groupby(['id'])['id'].count())\n",
        "            df_train_id_count.columns = ['id_count']\n",
        "            df_train_id_count.reset_index(inplace = True)\n",
        "            print(\"Number of train duplicate entries : \", len(df_train_id_count[df_train_id_count.id_count > 1]))\n",
        "        elif train_or_test_ind.lower() == 'test':\n",
        "            df_test_id_count = pd.DataFrame(self.test_label.groupby(['id'])['id'].count())\n",
        "            df_test_id_count.columns = ['id_count']\n",
        "            df_test_id_count.reset_index(inplace = True)\n",
        "            print(\"Number of test duplicate entries : \", len(df_test_id_count[df_test_id_count.id_count > 1]))\n",
        "        print(f\"Completed checking duplicates for {train_or_test_ind}...\")\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"*****************************************************\")\n",
        "        print()\n",
        "\n",
        "    def data_visualization(self, train_or_test_ind, positive_or_negative_ind, image_list, number_of_images = 5):\n",
        "        \"\"\"\n",
        "        This method visualizes the data.\n",
        "        \"\"\"\n",
        "        print()\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"*****************************************************\")\n",
        "        print(f\"Starting data visualization for {train_or_test_ind} and {positive_or_negative_ind}...\")\n",
        "        if train_or_test_ind.lower() == 'train':\n",
        "            print(f\"Displaying training {positive_or_negative_ind.lower()} images\")\n",
        "        if train_or_test_ind.lower() == 'test':\n",
        "            print(f\"Displaying test {positive_or_negative_ind.lower()} images\")\n",
        "\n",
        "        for image in image_list[:number_of_images]:\n",
        "            misc_proc.print_image_in_diff_orientation(image)\n",
        "            plt.show(block = False)\n",
        "\n",
        "        print(f\"Completed getting data visualizations for {train_or_test_ind}...\")\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"*****************************************************\")\n",
        "        print()\n",
        "\n",
        "    def get_image_summary_stats(self):\n",
        "        \"\"\"\n",
        "        This method gets positive and negative images summary stats at the picture level and each color (R, G, B) channel level.\n",
        "        \"\"\"\n",
        "        print()\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"Starting to get positive and negative images summary stats...\")\n",
        "\n",
        "        # Whole image wise stats\n",
        "        print(\"Mean and standard deviation at center for positive train images: \", misc_proc.compute_mean_and_std(self.train_positive_color_file_list))\n",
        "        print(\"Mean and standard deviation at center for negative train images: \", misc_proc.compute_mean_and_std(self.train_negative_color_file_list))\n",
        "\n",
        "        number_of_bins = 64 \n",
        "        figw, axw = plt.subplots(1,2, sharey = True, sharex = True, figsize = (8,2), dpi = 150)\n",
        "        axw[0].hist(img_proc.read_image_file_in_np_array(self.train_positive_color_file_list)[:,:,:,(0,1,2)].flatten(),\n",
        "                                                        bins = number_of_bins, \n",
        "                                                        density = True);\n",
        "        axw[1].hist(img_proc.read_image_file_in_np_array(self.train_negative_color_file_list)[:,:,:,(0,1,2)].flatten(),\n",
        "                                                        bins = number_of_bins, \n",
        "                                                        density = True);\n",
        "\n",
        "        axw[0].set_title(\"Train positive images\");\n",
        "        axw[1].set_title(\"Train negative images\");\n",
        "\n",
        "        axw[0].set_xlabel(\"Mean brightness\")\n",
        "        axw[1].set_xlabel(\"Mean brightness\")\n",
        "        axw[0].set_ylabel(\"Relative frequency\")\n",
        "        axw[1].set_ylabel(\"Relative frequency\")\n",
        "        plt.show(block = False);\n",
        "\n",
        "        # Channel wise stats\n",
        "        print(\"Average across red, green and blue channels for train positive images\")\n",
        "        print(np.mean(img_proc.read_image_file_in_np_array(self.train_positive_color_file_list), axis = (0,1,2)))\n",
        "        print(\"Standard Deviation across red, green and blue channels for Train positive images\")\n",
        "        print(np.std(img_proc.read_image_file_in_np_array(self.train_positive_color_file_list), axis = (0,1,2)))\n",
        "\n",
        "        print(\"Average across red, green and blue channels for train X_train_img_file_negative images\")\n",
        "        print(np.mean(img_proc.read_image_file_in_np_array(self.train_negative_color_file_list), axis = (0,1,2)))\n",
        "        print(\"Standard Deviation across red, green and blue channels for train X_train_img_file_negative images\")\n",
        "        print(np.std(img_proc.read_image_file_in_np_array(self.train_negative_color_file_list), axis = (0,1,2)))\n",
        "\n",
        "        # Red Channel\n",
        "        figr, axr = plt.subplots(1,2, sharey = True, sharex = True, figsize = (8,2), dpi = 150)\n",
        "        axr[0].hist(img_proc.read_image_file_in_np_array(self.train_positive_color_file_list)[:,:,:,(0)].flatten(),\n",
        "                                                        bins = number_of_bins, \n",
        "                                                        density = True);\n",
        "        axr[1].hist(img_proc.read_image_file_in_np_array(self.train_negative_color_file_list)[:,:,:,(0)].flatten(),\n",
        "                                                        bins = number_of_bins, \n",
        "                                                        density = True);\n",
        "\n",
        "        axr[0].set_title(\"Train positive images\");\n",
        "        axr[1].set_title(\"Train negative images\");\n",
        "\n",
        "        axr[0].set_xlabel(\"Mean red brightness\")\n",
        "        axr[1].set_xlabel(\"Mean red brightness\")\n",
        "        axr[0].set_ylabel(\"Relative frequency\")\n",
        "        axr[1].set_ylabel(\"Relative frequency\")\n",
        "        plt.show(block = False);\n",
        "\n",
        "        # Green Channel\n",
        "        figg, axg = plt.subplots(1,2, sharey = True, sharex = True, figsize = (8,2), dpi = 150)\n",
        "        axg[0].hist(img_proc.read_image_file_in_np_array(self.train_positive_color_file_list)[:,:,:,(1)].flatten(),\n",
        "                                                        bins = number_of_bins, \n",
        "                                                        density = True);\n",
        "        axg[1].hist(img_proc.read_image_file_in_np_array(self.train_negative_color_file_list)[:,:,:,(1)].flatten(),\n",
        "                                                        bins = number_of_bins, \n",
        "                                                        density = True);\n",
        "\n",
        "        axg[0].set_title(\"Train positive images\");\n",
        "        axg[1].set_title(\"Train negative images\");\n",
        "\n",
        "        axg[0].set_xlabel(\"Mean green brightness\")\n",
        "        axg[1].set_xlabel(\"Mean green brightness\")\n",
        "        axg[0].set_ylabel(\"Relative frequency\")\n",
        "        axg[1].set_ylabel(\"Relative frequency\")\n",
        "        plt.show(block = False);\n",
        "\n",
        "        # Blue Channel\n",
        "        figb, axb = plt.subplots(1,2, sharey = True, sharex = True, figsize = (8,2), dpi = 150)\n",
        "        axb[0].hist(img_proc.read_image_file_in_np_array(self.train_positive_color_file_list)[:,:,:,(2)].flatten(),\n",
        "                                                        bins = number_of_bins, \n",
        "                                                        density = True);\n",
        "        axb[1].hist(img_proc.read_image_file_in_np_array(self.train_negative_color_file_list)[:,:,:,(2)].flatten(),\n",
        "                                                        bins = number_of_bins, \n",
        "                                                        density = True);\n",
        "\n",
        "        axb[0].set_title(\"Train positive images\");\n",
        "        axb[1].set_title(\"Train negative images\");\n",
        "\n",
        "        axb[0].set_xlabel(\"Mean blue brightness\")\n",
        "        axb[1].set_xlabel(\"Mean blue brightness\")\n",
        "        axb[0].set_ylabel(\"Relative frequency\")\n",
        "        axb[1].set_ylabel(\"Relative frequency\")\n",
        "        plt.show(block = False);\n",
        "\n",
        "        print(f\"Completed get positive and negative images summary stats...\")\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"*****************************************************\")\n",
        "        print()\n",
        "\n",
        "    def data_processing_pipeline(self):\n",
        "        \"\"\"\n",
        "        This method performs required data processing steps.\n",
        "        \"\"\"\n",
        "        print()\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"Starting data processing pipeline...\")\n",
        "        self.get_file_names_list()\n",
        "        self.get_label_info()\n",
        "        self.initial_split_data()\n",
        "        \n",
        "        if self.run_mode == 'interim_test':\n",
        "            self.check_duplicate_ids('train')\n",
        "            self.check_duplicate_ids('test')\n",
        "            self.get_data_distribution('train')\n",
        "            self.get_data_distribution('test')\n",
        "            self.get_image_summary_stats()\n",
        "            \n",
        "        #self.move_files()\n",
        "        print(\"Completed data processing pipeline...\")\n",
        "        print()\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"*****************************************************\")\n",
        "\n",
        "'''\n",
        "data_proc = data_processing(run_mode = 'final_test')\n",
        "'''\n",
        "# Used for testing\n",
        "#data_proc = data_processing(run_mode = 'interim_test') \n",
        "data_proc = data_processing(run_mode = 'final_test')\n",
        "data_proc.data_processing_pipeline()\n",
        "\n",
        "# Data visualizations\n",
        "data_proc.data_visualization(train_or_test_ind = 'train', positive_or_negative_ind = 'positive', image_list = data_proc.train_positive_color_file_list)\n",
        "data_proc.data_visualization(train_or_test_ind = 'train', positive_or_negative_ind = 'negative', image_list = data_proc.train_positive_color_file_list)"
      ],
      "metadata": {
        "id": "9ASpSKwV7EnJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***3. Model Building***"
      ],
      "metadata": {
        "id": "ISUTBnGe72tT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data generators\n",
        "\n",
        "'''\n",
        "rotation rules\n",
        "(x, y) -90->  (-y, x)\n",
        "(x, y) -180-> (-x, -y)\n",
        "(x, y) -270-> (y, -x)\n",
        "(x, y) --90-> (y, -x)\n",
        "(x, y) -180-> (-x, -y)\n",
        "(x, y) -270-> (-y, x)\n",
        "'''\n",
        "consolidated_history_df = pd.DataFrame()\n",
        "consolidaed_test_kpi_df = pd.DataFrame()\n",
        "test_kpi_df = pd.DataFrame()\n",
        "pred_list = []\n",
        "def custom_augmentation(np_tensor):\n",
        " \n",
        "    def random_contrast(np_tensor):\n",
        "        return tf.image.random_contrast(np_tensor, 0.5, 2)\n",
        " \n",
        "    def random_hue(np_tensor):\n",
        "        return tf.image.random_hue(np_tensor, 0.5)\n",
        " \n",
        "    def random_saturation(np_tensor):\n",
        "        return tf.image.random_saturation(np_tensor, 0.2, 3)\n",
        " \n",
        "    def gaussian_noise(np_tensor):\n",
        "        mean = 0\n",
        "        # variance: randomly between 1 to 25\n",
        "        var = np.random.randint(1, 26)\n",
        "        # sigma is square root of the variance value\n",
        "        noise = np.random.normal(mean,var**0.5,np_tensor.shape)\n",
        "        return np.clip(np_tensor + noise, 0, 255).astype('int')\n",
        "\n",
        "    augmnted_tensor = random_contrast(np_tensor)\n",
        "    augmnted_tensor = random_hue(augmnted_tensor)\n",
        "    augmnted_tensor = random_saturation(augmnted_tensor)\n",
        "    augmented_tensor = gaussian_noise(augmnted_tensor)\n",
        "  \n",
        "    return np.array(augmnted_tensor)\n",
        "\n",
        "# Train data generator\n",
        "'''\n",
        "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    #featurewise_center            = True, \n",
        "    #featurewise_std_normalization = True,\n",
        "    rescale                       = 1.0/255,\n",
        "    horizontal_flip               = True, \n",
        "    vertical_flip                 = True, \n",
        "    #zca_whitening                 = random.choice([True, False]), \n",
        "    zoom_range                    = [0.8, 1.25],\n",
        "    rotation_range                = 90,\n",
        "    width_shift_range             = 0.30, \n",
        "    height_shift_range            = 0.30,\n",
        "    shear_range                   = 45, \n",
        "    brightness_range              = [.3, 1.2],\n",
        "    preprocessing_function        = custom_augmentation \n",
        ")\n",
        "'''\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   horizontal_flip = True,\n",
        "                                   vertical_flip = True,\n",
        "                                   rotation_range = 180,\n",
        "                                   zoom_range = 0.4, \n",
        "                                   width_shift_range = 0.3,\n",
        "                                   height_shift_range = 0.3,\n",
        "                                   shear_range = 0.3)\n",
        "\n",
        "# Validation data generator\n",
        "val_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    #featurewise_center            = True, \n",
        "    #featurewise_std_normalization = True\n",
        "    rescale = 1.0/255\n",
        "    )\n",
        "\n",
        "# Test data generator\n",
        "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    #featurewise_center            = True, \n",
        "    #featurewise_std_normalization = True\n",
        "    rescale = 1.0/255\n",
        "    )\n",
        "\n",
        "# Stores each model and kfold specific train and validation accuracies \n",
        "# and losses for each epoch\n",
        "temp_df_model_kpi = pd.DataFrame()\n",
        "# Consolidates the above results across all model and kfolds.\n",
        "consolidated_df_model_kpi = pd.DataFrame()\n",
        "\n",
        "# Holds model and kfold specific actual, prediction %, perdiction binary value\n",
        "# along with test loss and accuracy.\n",
        "temp_df_acttual_vs_pred_bin_pred_pct = pd.DataFrame()\n",
        "# Consolidates the above result for each model and kfold.\n",
        "df_actual_vs_pred_bin_pred_pct = pd.DataFrame()\n",
        "\n",
        "df_kfold_ensemble_stats = pd.DataFrame()\n",
        "test_result_list = []\n",
        "for kfold, (train_indices, validation_indices) in enumerate(StratifiedKFold(n_splits =  number_of_splits, \n",
        "                                                                                shuffle = True, \n",
        "                                                                                random_state = random_state\n",
        "                                                                               ).split(data_proc.df_train_original['label'].values.tolist(), \n",
        "                                                                                       data_proc.df_train_original['label'].values.tolist()\n",
        "                                                                                      )):\n",
        "    print(f\"k-fold : {kfold + 1}, length of train data : {len(train_indices)}, length of validation data : {len(validation_indices)}\")\n",
        "    data_proc.split_data_based_on_indices(train_indices = train_indices, validation_indices = validation_indices)\n",
        "\n",
        "    train_dataset_from_data_generator = train_datagen.flow_from_directory(image_processing_train_path,\n",
        "                                                                          target_size = (image_size, image_size),\n",
        "                                                                          class_mode = 'binary',\n",
        "                                                                          batch_size = batch_size,\n",
        "                                                                          color_mode = 'rgb',\n",
        "                                                                          shuffle = True,\n",
        "                                                                          seed = random_state\n",
        "                                                                         )\n",
        "    validation_dataset_from_data_generator = val_datagen.flow_from_directory(image_processing_validation_path,\n",
        "                                                                             target_size = (image_size, image_size),\n",
        "                                                                             class_mode = 'binary',\n",
        "                                                                             batch_size = batch_size,\n",
        "                                                                             color_mode = 'rgb',\n",
        "                                                                             shuffle = True,\n",
        "                                                                             seed = random_state\n",
        "                                                                           )\n",
        "    test_dataset_from_data_generator = test_datagen.flow_from_directory(image_processing_test_path,\n",
        "                                                                        target_size = (image_size, image_size),\n",
        "                                                                        batch_size = batch_size,\n",
        "                                                                        class_mode = 'binary',\n",
        "                                                                        color_mode = 'rgb',\n",
        "                                                                        shuffle = False,\n",
        "                                                                        seed = random_state\n",
        "                                                                       )\n",
        "        \n",
        "    tf.random.set_seed(random_state)\n",
        "    np.random.seed(random_state)\n",
        "\n",
        "    input_shape = (image_size, image_size, 3)\n",
        "    inputs = Input(input_shape)\n",
        "\n",
        "    xception = Xception(include_top=False, input_shape=input_shape)(inputs)\n",
        "    resnet = ResNet152(include_top=False, input_shape=input_shape)(inputs)\n",
        "    vgg19 = VGG19(include_top=False, input_shape=input_shape)(inputs)\n",
        "\n",
        "    outputs = Concatenate(axis=-1)([GlobalAveragePooling2D()(xception), \n",
        "                                    GlobalAveragePooling2D()(resnet),\n",
        "                                    GlobalAveragePooling2D()(vgg19)\n",
        "                                   ])\n",
        "    outputs = Dropout(0.5)(outputs)\n",
        "    outputs = Dense(1, activation = 'sigmoid')(outputs)\n",
        "\n",
        "    model = Model(inputs, outputs)\n",
        "    trainable_count = count_params(model.trainable_weights)\n",
        "    non_trainable_count = count_params(model.non_trainable_weights)\n",
        "    print(f\"Traininable parameters : {trainable_count}, non trainable parameters : {non_trainable_count}\")\n",
        "\n",
        "    model.compile(optimizer = Adam(learning_rate = 0.0001, \n",
        "                                 decay = 0.00001),\n",
        "                  loss = 'binary_crossentropy',\n",
        "                  metrics = [\n",
        "                               tf.keras.metrics.BinaryAccuracy(name = 'accuracy'),\n",
        "                               tf.keras.metrics.Precision(name = 'precision'),\n",
        "                               tf.keras.metrics.Recall(name = 'recall'),  \n",
        "                               tf.keras.metrics.AUC(name = 'auc')\n",
        "                            ]\n",
        "                  )\n",
        "    model.summary()\n",
        "    tf.keras.utils.plot_model(model, \n",
        "                              to_file='model_structure.png', \n",
        "                              show_shapes = True,\n",
        "                              show_layer_names = True)\n",
        "    plt.show(block = False)\n",
        "\n",
        "    history = model.fit(train_dataset_from_data_generator,\n",
        "                        epochs = epochs,\n",
        "                        steps_per_epoch = len(train_dataset_from_data_generator),\n",
        "                        validation_data = validation_dataset_from_data_generator,\n",
        "                        validation_steps = len(validation_dataset_from_data_generator),\n",
        "                        verbose = 1\n",
        "                      )\n",
        "\n",
        "    # Model save\n",
        "    print(\"Saving model...\")\n",
        "    tf.keras.backend.clear_session()\n",
        "    gc.collect()\n",
        "    model_name = f'tumor_detection_xception_resnet_and_vgg19_combo_{kfold + 1}.h5'\n",
        "    model.save(model_name)\n",
        "\n",
        "    temp_result_df = pd.DataFrame()\n",
        "    temp_result_df = pd.DataFrame(history.history)\n",
        "    temp_result_df['kfold'] = kfold + 1\n",
        "    consolidated_history_df = pd.concat([temp_result_df, \n",
        "                                         consolidated_history_df\n",
        "                                        ], \n",
        "                                        axis = 1 \n",
        "                                       )\n",
        "\n",
        "    model_proc.plot_model_accuracy_and_loss(history = history, model_name = 'xception_resnet_and_vgg19_combo')\n",
        "\n",
        "    # Model Predict, transform logits to probabilities\n",
        "    step_size_test = np.ceil(test_dataset_from_data_generator.n / test_dataset_from_data_generator.batch_size)\n",
        "    test_dataset_from_data_generator.reset()\n",
        "    pred_logits = model.predict(test_dataset_from_data_generator, steps = step_size_test, verbose = 1)\n",
        "    probas_sigmoid = tf.sigmoid(pred_logits)\n",
        "    probas_sigmoid = probas_sigmoid.numpy().flatten() * 100\n",
        "    predictions_binary = [1 if x > 50.0 else 0 for x in probas_sigmoid]\n",
        "    pred_list.append((kfold + 1, probas_sigmoid, predictions_binary, data_proc.y_test))\n",
        "    test_loss, test_accuracy, test_precission, test_recall, test_auc = model.evaluate(test_dataset_from_data_generator, verbose = 0)\n",
        "    print(f\"test loss {test_loss}, test accuracy {test_accuracy}, test precision : {test_precission}, test recall : {test_recall}, test auc : {test_auc}\")\n",
        "    print(\"***********************************************************************************************************************************************\")\n",
        "    print(\"***********************************************************************************************************************************************\")\n",
        "    test_kpi_df = pd.DataFrame([kfold+1,\n",
        "                                test_loss, \n",
        "                                test_accuracy,\n",
        "                                test_precission,\n",
        "                                test_recall,\n",
        "                                test_auc\n",
        "                               ],\n",
        "                               columns = ['kfold', \n",
        "                                          'test_loss', \n",
        "                                          'test_accuracy',\n",
        "                                          'test_precission',\n",
        "                                          'test_recall',\n",
        "                                          'test_auc'\n",
        "                                        ]\n",
        "                              )\n",
        "    consolidated_test_kpi_df = pd.concat([test_kpi_df, \n",
        "                                         consolidated_test_kpi_df\n",
        "                                        ], \n",
        "                                        axis = 1 \n",
        "                                       )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Xv4rrJ4ivweJ",
        "outputId": "a77b528b-4c02-4533-d28b-d4654b7c4587"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "k-fold : 1, length of train data : 63000, length of validation data : 9000\n",
            "\n",
            "*****************************************************\n",
            "*****************************************************\n",
            "Starting to split data based on indices...\n",
            "\n",
            "*****************************************************\n",
            "*****************************************************\n",
            "Starting to create labels for train...\n",
            "Completed building labels for train...\n",
            "*****************************************************\n",
            "*****************************************************\n",
            "\n",
            "\n",
            "*****************************************************\n",
            "*****************************************************\n",
            "Starting to create labels for validation...\n",
            "Completed building labels for validation...\n",
            "*****************************************************\n",
            "*****************************************************\n",
            "\n",
            "\n",
            "*****************************************************\n",
            "*****************************************************\n",
            "Starting to remove files under /content/image_processing/train/positive...\n",
            "*****************************************************\n",
            "*****************************************************\n",
            "\n",
            "\n",
            "*****************************************************\n",
            "*****************************************************\n",
            "Starting to remove files under /content/image_processing/train/negative...\n",
            "*****************************************************\n",
            "*****************************************************\n",
            "\n",
            "Copying test_positive_file_list under /content/image_processing/train/positive\n",
            "Copying test_negative_file_list under /content/image_processing/train/negative\n",
            "File count under /content/image_processing/train/positive after moving new files is: 31500\n",
            "File count under /content/image_processing/train/negative after moving new files is : 31500\n",
            "\n",
            "*****************************************************\n",
            "*****************************************************\n",
            "Starting to remove files under /content/image_processing/validation/positive...\n",
            "*****************************************************\n",
            "*****************************************************\n",
            "\n",
            "\n",
            "*****************************************************\n",
            "*****************************************************\n",
            "Starting to remove files under /content/image_processing/validation/negative...\n",
            "*****************************************************\n",
            "*****************************************************\n",
            "\n",
            "Copying test_positive_file_list under /content/image_processing/validation/positive\n",
            "Copying test_negative_file_list under /content/image_processing/validation/negative\n",
            "File count under /content/image_processing/validation/positive after moving new files is: 4500\n",
            "File count under /content/image_processing/validation/negative after moving new files is : 4500\n",
            "Completed spliting the data sets based on indices...\n",
            "*****************************************************\n",
            "*****************************************************\n",
            "\n",
            "Found 63000 images belonging to 2 classes.\n",
            "Found 9000 images belonging to 2 classes.\n",
            "Found 8000 images belonging to 2 classes.\n",
            "Traininable parameters : 99055465, non trainable parameters : 205952\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 96, 96, 3)]  0           []                               \n",
            "                                                                                                  \n",
            " xception (Functional)          (None, 3, 3, 2048)   20861480    ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " resnet152 (Functional)         (None, 3, 3, 2048)   58370944    ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " vgg19 (Functional)             (None, 3, 3, 512)    20024384    ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " global_average_pooling2d (Glob  (None, 2048)        0           ['xception[0][0]']               \n",
            " alAveragePooling2D)                                                                              \n",
            "                                                                                                  \n",
            " global_average_pooling2d_1 (Gl  (None, 2048)        0           ['resnet152[0][0]']              \n",
            " obalAveragePooling2D)                                                                            \n",
            "                                                                                                  \n",
            " global_average_pooling2d_2 (Gl  (None, 512)         0           ['vgg19[0][0]']                  \n",
            " obalAveragePooling2D)                                                                            \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 4608)         0           ['global_average_pooling2d[0][0]'\n",
            "                                                                 , 'global_average_pooling2d_1[0][\n",
            "                                                                 0]',                             \n",
            "                                                                  'global_average_pooling2d_2[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 4608)         0           ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 1)            4609        ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 99,261,417\n",
            "Trainable params: 99,055,465\n",
            "Non-trainable params: 205,952\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/10\n",
            "985/985 [==============================] - 241s 217ms/step - loss: 0.3940 - accuracy: 0.8277 - precision: 0.8395 - recall: 0.8103 - auc: 0.9054 - val_loss: 1.2312 - val_accuracy: 0.5794 - val_precision: 0.9673 - val_recall: 0.1644 - val_auc: 0.8739\n",
            "Epoch 2/10\n",
            "985/985 [==============================] - 209s 212ms/step - loss: 0.3243 - accuracy: 0.8640 - precision: 0.8760 - recall: 0.8481 - auc: 0.9358 - val_loss: 0.3143 - val_accuracy: 0.8622 - val_precision: 0.9480 - val_recall: 0.7664 - val_auc: 0.9550\n",
            "Epoch 3/10\n",
            "985/985 [==============================] - 210s 213ms/step - loss: 0.2974 - accuracy: 0.8741 - precision: 0.8860 - recall: 0.8588 - auc: 0.9457 - val_loss: 0.2844 - val_accuracy: 0.8862 - val_precision: 0.9328 - val_recall: 0.8324 - val_auc: 0.9575\n",
            "Epoch 4/10\n",
            "985/985 [==============================] - 208s 211ms/step - loss: 0.2915 - accuracy: 0.8800 - precision: 0.8916 - recall: 0.8653 - auc: 0.9482 - val_loss: 0.2604 - val_accuracy: 0.9057 - val_precision: 0.9122 - val_recall: 0.8978 - val_auc: 0.9627\n",
            "Epoch 5/10\n",
            "985/985 [==============================] - 210s 213ms/step - loss: 0.2766 - accuracy: 0.8866 - precision: 0.8969 - recall: 0.8735 - auc: 0.9529 - val_loss: 0.2615 - val_accuracy: 0.9131 - val_precision: 0.9287 - val_recall: 0.8949 - val_auc: 0.9675\n",
            "Epoch 6/10\n",
            "985/985 [==============================] - 209s 212ms/step - loss: 0.2634 - accuracy: 0.8945 - precision: 0.9071 - recall: 0.8791 - auc: 0.9570 - val_loss: 0.2730 - val_accuracy: 0.8896 - val_precision: 0.9425 - val_recall: 0.8298 - val_auc: 0.9631\n",
            "Epoch 7/10\n",
            "985/985 [==============================] - 211s 214ms/step - loss: 0.2537 - accuracy: 0.8967 - precision: 0.9089 - recall: 0.8817 - auc: 0.9599 - val_loss: 0.2411 - val_accuracy: 0.9043 - val_precision: 0.9103 - val_recall: 0.8971 - val_auc: 0.9662\n",
            "Epoch 8/10\n",
            "985/985 [==============================] - 209s 212ms/step - loss: 0.2485 - accuracy: 0.9000 - precision: 0.9123 - recall: 0.8851 - auc: 0.9616 - val_loss: 0.2489 - val_accuracy: 0.9036 - val_precision: 0.9597 - val_recall: 0.8424 - val_auc: 0.9724\n",
            "Epoch 9/10\n",
            "985/985 [==============================] - 209s 212ms/step - loss: 0.2414 - accuracy: 0.9030 - precision: 0.9149 - recall: 0.8885 - auc: 0.9636 - val_loss: 0.2825 - val_accuracy: 0.9042 - val_precision: 0.9015 - val_recall: 0.9076 - val_auc: 0.9618\n",
            "Epoch 10/10\n",
            "985/985 [==============================] - 210s 213ms/step - loss: 0.2325 - accuracy: 0.9073 - precision: 0.9200 - recall: 0.8921 - auc: 0.9659 - val_loss: 0.2113 - val_accuracy: 0.9174 - val_precision: 0.9502 - val_recall: 0.8811 - val_auc: 0.9753\n",
            "Saving model...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-afbbb6cae529>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'tumor_detection_xception_resnet_and_vgg19_combo_{kfold + 1}.h5'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m     \u001b[0mtemp_result_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[0mtemp_result_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/h5py/_hl/group.py\u001b[0m in \u001b[0;36mcreate_dataset\u001b[0;34m(self, name, shape, dtype, data, **kwds)\u001b[0m\n\u001b[1;32m    146\u001b[0m                     \u001b[0mgroup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequire_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m             \u001b[0mdsid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_new_dset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m             \u001b[0mdset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdsid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mdset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/h5py/_hl/dataset.py\u001b[0m in \u001b[0;36mmake_new_dset\u001b[0;34m(parent, shape, dtype, data, name, chunks, compression, shuffle, fletcher32, maxshape, compression_opts, fillvalue, scaleoffset, track_times, external, track_order, dcpl, allow_unknown_filter)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m     \u001b[0mdset_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdcpl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/h5d.pyx\u001b[0m in \u001b[0;36mh5py.h5d.create\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Unable to create dataset (name already exists)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "consolidated_df_model_kpi.to_csv('consolidated_model_kpi.csv', index = False)\n",
        "consolidated_test_kpi_df.to_csv(\"consolidated_test_kpi.csv\", index = False)"
      ],
      "metadata": {
        "id": "QARWxJyL6lDc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFramw(test_result_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o5HoOyEqSDT5",
        "outputId": "330c492e-0bda-4c8f-b88f-1bdc0947a14c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(1,\n",
              "  0.26152166724205017,\n",
              "  0.8936190605163574,\n",
              "  0.4071548283100128,\n",
              "  0.8902222514152527,\n",
              "  array([50.03055 , 50.077927, 50.040947, ..., 73.10585 , 73.099174,\n",
              "         73.10585 ], dtype=float32),\n",
              "  [1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   ...],\n",
              "  0.4410099983215332,\n",
              "  0.8731069564819336),\n",
              " (2,\n",
              "  0.26093029975891113,\n",
              "  0.892730176448822,\n",
              "  0.28343844413757324,\n",
              "  0.8928889036178589,\n",
              "  array([50.006233, 50.166203, 50.00623 , ..., 73.095604, 62.189526,\n",
              "         73.10323 ], dtype=float32),\n",
              "  [1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   ...],\n",
              "  0.35787680745124817,\n",
              "  0.879990816116333),\n",
              " (3,\n",
              "  0.259871244430542,\n",
              "  0.8930476307868958,\n",
              "  0.2378941774368286,\n",
              "  0.9120000004768372,\n",
              "  array([50.01657 , 50.04039 , 50.046783, ..., 73.06994 , 72.36684 ,\n",
              "         72.76582 ], dtype=float32),\n",
              "  [1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   ...],\n",
              "  0.2558005750179291,\n",
              "  0.90362548828125),\n",
              " (4,\n",
              "  0.2660136818885803,\n",
              "  0.8909206390380859,\n",
              "  0.2675749957561493,\n",
              "  0.8984444737434387,\n",
              "  array([50.096863, 50.063904, 50.146866, ..., 73.09937 , 73.09892 ,\n",
              "         73.02155 ], dtype=float32),\n",
              "  [1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   ...],\n",
              "  0.26630812883377075,\n",
              "  0.8914639949798584),\n",
              " (5,\n",
              "  0.26604926586151123,\n",
              "  0.8901904821395874,\n",
              "  0.29108843207359314,\n",
              "  0.8915555477142334,\n",
              "  array([50.10088 , 50.00696 , 50.028984, ..., 73.0692  , 70.856514,\n",
              "         73.06278 ], dtype=float32),\n",
              "  [1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   ...],\n",
              "  0.30063748359680176,\n",
              "  0.8857274055480957),\n",
              " (6,\n",
              "  0.2588522434234619,\n",
              "  0.8946666717529297,\n",
              "  1.3347615003585815,\n",
              "  0.8497777581214905,\n",
              "  array([50.      , 50.007637, 50.042076, ..., 69.72673 , 71.584984,\n",
              "         58.44651 ], dtype=float32),\n",
              "  [0,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   0,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   0,\n",
              "   1,\n",
              "   0,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   0,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   0,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   0,\n",
              "   0,\n",
              "   1,\n",
              "   0,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   0,\n",
              "   0,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   0,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   0,\n",
              "   0,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   0,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   0,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   0,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   0,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   0,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   0,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   0,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   0,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   0,\n",
              "   0,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   0,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   0,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   0,\n",
              "   1,\n",
              "   1,\n",
              "   0,\n",
              "   0,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   0,\n",
              "   1,\n",
              "   0,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   0,\n",
              "   1,\n",
              "   0,\n",
              "   1,\n",
              "   0,\n",
              "   0,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   0,\n",
              "   1,\n",
              "   1,\n",
              "   0,\n",
              "   0,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   0,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   0,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   0,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   0,\n",
              "   1,\n",
              "   1,\n",
              "   0,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   0,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   0,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   0,\n",
              "   0,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   0,\n",
              "   1,\n",
              "   1,\n",
              "   0,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   0,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   0,\n",
              "   0,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   0,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   0,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   0,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   0,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   0,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   0,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   0,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   0,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   0,\n",
              "   0,\n",
              "   1,\n",
              "   0,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   0,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   0,\n",
              "   1,\n",
              "   0,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   0,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   0,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   0,\n",
              "   0,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   0,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   0,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   0,\n",
              "   0,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   0,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   0,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   0,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   0,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   0,\n",
              "   0,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   0,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   0,\n",
              "   1,\n",
              "   0,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   0,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   0,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   0,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   0,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   0,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   0,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   0,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   0,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   0,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   0,\n",
              "   1,\n",
              "   ...],\n",
              "  1.5644915103912354,\n",
              "  0.8476365208625793),\n",
              " (7,\n",
              "  0.2714308798313141,\n",
              "  0.8912380933761597,\n",
              "  0.2760298550128937,\n",
              "  0.8935555815696716,\n",
              "  array([50.023247, 50.0974  , 50.0252  , ..., 72.42921 , 72.91174 ,\n",
              "         72.75678 ], dtype=float32),\n",
              "  [1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   ...],\n",
              "  0.2886475622653961,\n",
              "  0.8804497718811035),\n",
              " (8,\n",
              "  0.26541027426719666,\n",
              "  0.8913650512695312,\n",
              "  0.3673609495162964,\n",
              "  0.8904444575309753,\n",
              "  array([50.013382, 50.029667, 50.135307, ..., 73.10585 , 70.924545,\n",
              "         73.10585 ], dtype=float32),\n",
              "  [1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   ...],\n",
              "  0.3741241693496704,\n",
              "  0.8815970420837402)]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history.history['loss'][-1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4RvUXG-ByPub",
        "outputId": "6bc7685a-c2e2-4a6d-9dbb-6c0ae13cc6b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.2636861801147461"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result  = list(StratifiedKFold(n_splits =  number_of_splits, \n",
        "                                                                                shuffle = True, \n",
        "                                                                                random_state = random_state\n",
        "                                                                               ).split(data_proc.df_train_original['label'].values.tolist(), \n",
        "                                                                                       data_proc.df_train_original['label'].values.tolist()\n",
        "                                                                                      ))\n",
        "train_indices, validation_indices = result[0][0], result[0][1]\n",
        "data_proc.split_data_based_on_indices(train_indices, validation_indices)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ihcj1FZVlaGr",
        "outputId": "f9fbf290-659d-4c80-dfb9-f7b16efbefba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "*****************************************************\n",
            "*****************************************************\n",
            "Starting to split data based on indices...\n",
            "\n",
            "*****************************************************\n",
            "*****************************************************\n",
            "Starting to create labels for train...\n",
            "Completed building labels for train...\n",
            "*****************************************************\n",
            "*****************************************************\n",
            "\n",
            "\n",
            "*****************************************************\n",
            "*****************************************************\n",
            "Starting to create labels for validation...\n",
            "Completed building labels for validation...\n",
            "*****************************************************\n",
            "*****************************************************\n",
            "\n",
            "\n",
            "*****************************************************\n",
            "*****************************************************\n",
            "Starting to remove files under /content/image_processing/train/positive...\n",
            "*****************************************************\n",
            "*****************************************************\n",
            "\n",
            "\n",
            "*****************************************************\n",
            "*****************************************************\n",
            "Starting to remove files under /content/image_processing/train/negative...\n",
            "*****************************************************\n",
            "*****************************************************\n",
            "\n",
            "Copying test_positive_file_list under /content/image_processing/train/positive\n",
            "Copying test_negative_file_list under /content/image_processing/train/negative\n",
            "File count under /content/image_processing/train/positive after moving new files is: 15750\n",
            "File count under /content/image_processing/train/negative after moving new files is : 15750\n",
            "\n",
            "*****************************************************\n",
            "*****************************************************\n",
            "Starting to remove files under /content/image_processing/validation/positive...\n",
            "*****************************************************\n",
            "*****************************************************\n",
            "\n",
            "\n",
            "*****************************************************\n",
            "*****************************************************\n",
            "Starting to remove files under /content/image_processing/validation/negative...\n",
            "*****************************************************\n",
            "*****************************************************\n",
            "\n",
            "Copying test_positive_file_list under /content/image_processing/validation/positive\n",
            "Copying test_negative_file_list under /content/image_processing/validation/negative\n",
            "File count under /content/image_processing/validation/positive after moving new files is: 2250\n",
            "File count under /content/image_processing/validation/negative after moving new files is : 2250\n",
            "Completed spliting the data sets based on indices...\n",
            "*****************************************************\n",
            "*****************************************************\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_augmentation(np_tensor):\n",
        " \n",
        "    def random_contrast(np_tensor):\n",
        "        return tf.image.random_contrast(np_tensor, 0.5, 2)\n",
        " \n",
        "    def random_hue(np_tensor):\n",
        "        return tf.image.random_hue(np_tensor, 0.5)\n",
        " \n",
        "    def random_saturation(np_tensor):\n",
        "        return tf.image.random_saturation(np_tensor, 0.2, 3)\n",
        " \n",
        "    def gaussian_noise(np_tensor):\n",
        "        mean = 0\n",
        "        # variance: randomly between 1 to 25\n",
        "        var = np.random.randint(1, 26)\n",
        "        # sigma is square root of the variance value\n",
        "        noise = np.random.normal(mean,var**0.5,np_tensor.shape)\n",
        "        return np.clip(np_tensor + noise, 0, 255).astype('int')\n",
        "\n",
        "    augmnted_tensor = random_contrast(np_tensor)\n",
        "    augmnted_tensor = random_hue(augmnted_tensor)\n",
        "    augmnted_tensor = random_saturation(augmnted_tensor)\n",
        "    augmented_tensor = gaussian_noise(augmnted_tensor)\n",
        "  \n",
        "    return np.array(augmnted_tensor)\n",
        "\n",
        "# Train data generator\n",
        "'''\n",
        "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    #featurewise_center            = True, \n",
        "    #featurewise_std_normalization = True,\n",
        "    rescale                       = 1.0/255,\n",
        "    horizontal_flip               = True, \n",
        "    vertical_flip                 = True, \n",
        "    #zca_whitening                 = random.choice([True, False]), \n",
        "    zoom_range                    = [0.8, 1.25],\n",
        "    rotation_range                = 90,\n",
        "    width_shift_range             = 0.30, \n",
        "    height_shift_range            = 0.30,\n",
        "    shear_range                   = 45, \n",
        "    brightness_range              = [.3, 1.2],\n",
        "    preprocessing_function        = custom_augmentation \n",
        ")\n",
        "'''\n",
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                             horizontal_flip=True,\n",
        "                                             vertical_flip=True,\n",
        "                                             rotation_range=180,\n",
        "                                             zoom_range=0.4, \n",
        "                                             width_shift_range=0.3,\n",
        "                                             height_shift_range=0.3,\n",
        "                                             shear_range=0.3)\n",
        "\n",
        "# Validation data generator\n",
        "val_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    #featurewise_center            = True, \n",
        "    #featurewise_std_normalization = True\n",
        "    rescale = 1.0/255\n",
        "    )\n",
        "\n",
        "# Test data generator\n",
        "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    #featurewise_center            = True, \n",
        "    #featurewise_std_normalization = True\n",
        "    rescale = 1.0/255\n",
        "    )\n",
        "\n",
        "train_dataset_from_data_generator = train_datagen.flow_from_directory(image_processing_train_path,\n",
        "                                                                     target_size = (image_size, image_size),\n",
        "                                                                     class_mode = 'binary',\n",
        "                                                                     batch_size = batch_size,\n",
        "                                                                     color_mode = 'rgb',\n",
        "                                                                     shuffle = True,\n",
        "                                                                     seed = random_state\n",
        "                                                                    )\n",
        "validation_dataset_from_data_generator = val_datagen.flow_from_directory(image_processing_validation_path,\n",
        "                                                                 target_size = (image_size, image_size),\n",
        "                                                                 class_mode = 'binary',\n",
        "                                                                 batch_size = batch_size,\n",
        "                                                                 color_mode = 'rgb',\n",
        "                                                                 shuffle = True,\n",
        "                                                                 seed = random_state\n",
        "                                                                )\n",
        "test_dataset_from_data_generator = test_datagen.flow_from_directory(image_processing_test_path,\n",
        "                                                                   target_size = (image_size, image_size),\n",
        "                                                                   batch_size = batch_size,\n",
        "                                                                   class_mode = 'binary',\n",
        "                                                                   color_mode = 'rgb',\n",
        "                                                                   shuffle = False,\n",
        "                                                                   seed = random_state\n",
        "                                                                  )\n",
        "\n",
        "skf = StratifiedKFold(n_splits =  number_of_splits, \n",
        "                                                                                shuffle = True, \n",
        "                                                                                random_state = random_state\n",
        "                                                                               ).split(data_proc.df_train_original['label'].values.tolist(), \n",
        "                                                                                       data_proc.df_train_original['label'].values.tolist()\n",
        "                                                                                      )\n",
        "                                                                               \n",
        "input_shape = (image_size, image_size, 3)\n",
        "inputs = Input(input_shape)\n",
        "\n",
        "xception = Xception(include_top=False, input_shape=input_shape)(inputs)\n",
        "resnet = ResNet152(include_top=False, input_shape=input_shape)(inputs)\n",
        "\n",
        "outputs = Concatenate(axis=-1)([GlobalAveragePooling2D()(xception), GlobalAveragePooling2D()(resnet)])\n",
        "outputs = Dropout(0.5)(outputs)\n",
        "outputs = Dense(1, activation='sigmoid')(outputs)\n",
        "\n",
        "model = Model(inputs, outputs)\n",
        "trainable_count = count_params(model.trainable_weights)\n",
        "non_trainable_count = count_params(model.non_trainable_weights)\n",
        "print(f\"Traininable parameters : {trainable_count}, non trainable parameters : {non_trainable_count}\")\n",
        "model.compile(optimizer=Adam(lr=0.0001, decay=0.00001),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "tf.keras.utils.plot_model(model, to_file='convnet.png', show_shapes=True,show_layer_names=True)\n",
        "plt.show(block = False)\n",
        "\n",
        "history = model.fit(train_dataset_from_data_generator,\n",
        "                            epochs = epochs,\n",
        "                            steps_per_epoch = len(train_dataset_from_data_generator),\n",
        "                            validation_data = validation_dataset_from_data_generator,\n",
        "                            validation_steps = len(validation_dataset_from_data_generator),\n",
        "                            verbose = 1\n",
        "                           )\n",
        "\n",
        "# Model save\n",
        "print(\"Saving model...\")\n",
        "tf.keras.backend.clear_session()\n",
        "gc.collect()\n",
        "model.save('tumor_detection.h5')\n",
        "\n",
        "model_proc.plot_model_accuracy_and_loss(history = history, model_name = 'xception_nas_net')\n",
        "\n",
        "# Model Predict, transform logits to probabilities\n",
        "step_size_test = np.ceil(test_dataset_from_data_generator.n / test_dataset_from_data_generator.batch_size)\n",
        "test_dataset_from_data_generator.reset()\n",
        "pred_logits = model.predict(test_dataset_from_data_generator, steps = step_size_test, verbose = 1)\n",
        "probas_sigmoid = tf.sigmoid(pred_logits)\n",
        "probas_sigmoid = probas_sigmoid.numpy().flatten() * 100\n",
        "predictions_binary = [1 if x > 50.0 else 0 for x in probas_sigmoid]\n",
        "test_loss, test_accuracy = model.evaluate(test_dataset_from_data_generator, verbose = 0)\n",
        "print(f\"test loss {test_loss}, test accuracy {test_accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "SFbb9b1Ef2RO",
        "outputId": "da10ae27-98ba-4fd0-ac4f-f1bc2ef4f688"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 31500 images belonging to 2 classes.\n",
            "Found 4500 images belonging to 2 classes.\n",
            "Found 4358 images belonging to 2 classes.\n",
            "Traininable parameters : 79030569, non trainable parameters : 205952\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 96, 96, 3)]  0           []                               \n",
            "                                                                                                  \n",
            " xception (Functional)          (None, 3, 3, 2048)   20861480    ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " resnet152 (Functional)         (None, 3, 3, 2048)   58370944    ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " global_average_pooling2d (Glob  (None, 2048)        0           ['xception[0][0]']               \n",
            " alAveragePooling2D)                                                                              \n",
            "                                                                                                  \n",
            " global_average_pooling2d_1 (Gl  (None, 2048)        0           ['resnet152[0][0]']              \n",
            " obalAveragePooling2D)                                                                            \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 4096)         0           ['global_average_pooling2d[0][0]'\n",
            "                                                                 , 'global_average_pooling2d_1[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 4096)         0           ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 1)            4097        ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 79,236,521\n",
            "Trainable params: 79,030,569\n",
            "Non-trainable params: 205,952\n",
            "__________________________________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "493/493 [==============================] - 119s 191ms/step - loss: 0.4311 - accuracy: 0.8124 - val_loss: 1.2647 - val_accuracy: 0.5004\n",
            "Epoch 2/10\n",
            "493/493 [==============================] - 90s 182ms/step - loss: 0.3640 - accuracy: 0.8450 - val_loss: 0.4134 - val_accuracy: 0.8282\n",
            "Epoch 3/10\n",
            "493/493 [==============================] - 90s 182ms/step - loss: 0.3356 - accuracy: 0.8583 - val_loss: 0.3403 - val_accuracy: 0.8664\n",
            "Epoch 4/10\n",
            "493/493 [==============================] - 89s 180ms/step - loss: 0.3204 - accuracy: 0.8687 - val_loss: 0.3401 - val_accuracy: 0.8884\n",
            "Epoch 5/10\n",
            "493/493 [==============================] - 90s 182ms/step - loss: 0.3067 - accuracy: 0.8713 - val_loss: 0.3471 - val_accuracy: 0.8818\n",
            "Epoch 6/10\n",
            "493/493 [==============================] - 89s 181ms/step - loss: 0.2945 - accuracy: 0.8777 - val_loss: 0.3368 - val_accuracy: 0.8740\n",
            "Epoch 7/10\n",
            "493/493 [==============================] - 90s 182ms/step - loss: 0.2857 - accuracy: 0.8825 - val_loss: 0.5736 - val_accuracy: 0.8924\n",
            "Epoch 8/10\n",
            "493/493 [==============================] - 90s 183ms/step - loss: 0.2792 - accuracy: 0.8850 - val_loss: 0.2833 - val_accuracy: 0.8967\n",
            "Epoch 9/10\n",
            "493/493 [==============================] - 89s 181ms/step - loss: 0.2727 - accuracy: 0.8895 - val_loss: 0.2801 - val_accuracy: 0.9053\n",
            "Epoch 10/10\n",
            "493/493 [==============================] - 89s 179ms/step - loss: 0.2637 - accuracy: 0.8931 - val_loss: 0.3842 - val_accuracy: 0.8627\n",
            "Saving model...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "69/69 [==============================] - 7s 45ms/step\n",
            "test loss 0.40154993534088135, test accuracy 0.858421266078949\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_indices, validation_indices = result[1][0], result[1][1]\n",
        "data_proc.split_data_based_on_indices(train_indices, validation_indices)\n",
        "def custom_augmentation(np_tensor):\n",
        " \n",
        "    def random_contrast(np_tensor):\n",
        "        return tf.image.random_contrast(np_tensor, 0.5, 2)\n",
        " \n",
        "    def random_hue(np_tensor):\n",
        "        return tf.image.random_hue(np_tensor, 0.5)\n",
        " \n",
        "    def random_saturation(np_tensor):\n",
        "        return tf.image.random_saturation(np_tensor, 0.2, 3)\n",
        " \n",
        "    def gaussian_noise(np_tensor):\n",
        "        mean = 0\n",
        "        # variance: randomly between 1 to 25\n",
        "        var = np.random.randint(1, 26)\n",
        "        # sigma is square root of the variance value\n",
        "        noise = np.random.normal(mean,var**0.5,np_tensor.shape)\n",
        "        return np.clip(np_tensor + noise, 0, 255).astype('int')\n",
        "\n",
        "    augmnted_tensor = random_contrast(np_tensor)\n",
        "    augmnted_tensor = random_hue(augmnted_tensor)\n",
        "    augmnted_tensor = random_saturation(augmnted_tensor)\n",
        "    augmented_tensor = gaussian_noise(augmnted_tensor)\n",
        "  \n",
        "    return np.array(augmnted_tensor)\n",
        "\n",
        "# Train data generator\n",
        "'''\n",
        "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    #featurewise_center            = True, \n",
        "    #featurewise_std_normalization = True,\n",
        "    rescale                       = 1.0/255,\n",
        "    horizontal_flip               = True, \n",
        "    vertical_flip                 = True, \n",
        "    #zca_whitening                 = random.choice([True, False]), \n",
        "    zoom_range                    = [0.8, 1.25],\n",
        "    rotation_range                = 90,\n",
        "    width_shift_range             = 0.30, \n",
        "    height_shift_range            = 0.30,\n",
        "    shear_range                   = 45, \n",
        "    brightness_range              = [.3, 1.2],\n",
        "    preprocessing_function        = custom_augmentation \n",
        ")\n",
        "'''\n",
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                             horizontal_flip=True,\n",
        "                                             vertical_flip=True,\n",
        "                                             rotation_range=180,\n",
        "                                             zoom_range=0.4, \n",
        "                                             width_shift_range=0.3,\n",
        "                                             height_shift_range=0.3,\n",
        "                                             shear_range=0.3)\n",
        "\n",
        "# Validation data generator\n",
        "val_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    #featurewise_center            = True, \n",
        "    #featurewise_std_normalization = True\n",
        "    rescale = 1.0/255\n",
        "    )\n",
        "\n",
        "# Test data generator\n",
        "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    #featurewise_center            = True, \n",
        "    #featurewise_std_normalization = True\n",
        "    rescale = 1.0/255\n",
        "    )\n",
        "\n",
        "train_dataset_from_data_generator = train_datagen.flow_from_directory(image_processing_train_path,\n",
        "                                                                     target_size = (image_size, image_size),\n",
        "                                                                     class_mode = 'binary',\n",
        "                                                                     batch_size = batch_size,\n",
        "                                                                     color_mode = 'rgb',\n",
        "                                                                     shuffle = True,\n",
        "                                                                     seed = random_state\n",
        "                                                                    )\n",
        "validation_dataset_from_data_generator = val_datagen.flow_from_directory(image_processing_validation_path,\n",
        "                                                                 target_size = (image_size, image_size),\n",
        "                                                                 class_mode = 'binary',\n",
        "                                                                 batch_size = batch_size,\n",
        "                                                                 color_mode = 'rgb',\n",
        "                                                                 shuffle = True,\n",
        "                                                                 seed = random_state\n",
        "                                                                )\n",
        "test_dataset_from_data_generator = test_datagen.flow_from_directory(image_processing_test_path,\n",
        "                                                                   target_size = (image_size, image_size),\n",
        "                                                                   batch_size = batch_size,\n",
        "                                                                   class_mode = 'binary',\n",
        "                                                                   color_mode = 'rgb',\n",
        "                                                                   shuffle = False,\n",
        "                                                                   seed = random_state\n",
        "                                                                  )\n",
        "\n",
        "input_shape = (image_size, image_size, 3)\n",
        "inputs = Input(input_shape)\n",
        "\n",
        "xception = Xception(include_top=False, input_shape=input_shape)(inputs)\n",
        "resnet = ResNet152(include_top=False, input_shape=input_shape)(inputs)\n",
        "\n",
        "outputs = Concatenate(axis=-1)([GlobalAveragePooling2D()(xception), GlobalAveragePooling2D()(resnet)])\n",
        "outputs = Dropout(0.5)(outputs)\n",
        "outputs = Dense(1, activation='sigmoid')(outputs)\n",
        "\n",
        "model = Model(inputs, outputs)\n",
        "trainable_count = count_params(model.trainable_weights)\n",
        "non_trainable_count = count_params(model.non_trainable_weights)\n",
        "print(f\"Traininable parameters : {trainable_count}, non trainable parameters : {non_trainable_count}\")\n",
        "model.compile(optimizer=Adam(lr=0.0001, decay=0.00001),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.summary()\n",
        "from IPython.display import Image\n",
        "tf.keras.utils.plot_model(model, to_file='convnet.png', show_shapes=True,show_layer_names=True)\n",
        "plt.show(block = False)\n",
        "\n",
        "history = model.fit(train_dataset_from_data_generator,\n",
        "                            epochs = epochs,\n",
        "                            steps_per_epoch = len(train_dataset_from_data_generator),\n",
        "                            validation_data = validation_dataset_from_data_generator,\n",
        "                            validation_steps = len(validation_dataset_from_data_generator),\n",
        "                            verbose = 1\n",
        "                           )\n",
        "\n",
        "# Model save\n",
        "print(\"Saving model...\")\n",
        "tf.keras.backend.clear_session()\n",
        "gc.collect()\n",
        "model.save('tumor_detection_k2.h5')\n",
        "\n",
        "model_proc.plot_model_accuracy_and_loss(history = history, model_name = 'xception_nas_net')\n",
        "\n",
        "# Model Predict, transform logits to probabilities\n",
        "step_size_test = np.ceil(test_dataset_from_data_generator.n / test_dataset_from_data_generator.batch_size)\n",
        "test_dataset_from_data_generator.reset()\n",
        "pred_logits = model.predict(test_dataset_from_data_generator, steps = step_size_test, verbose = 1)\n",
        "probas_sigmoid = tf.sigmoid(pred_logits)\n",
        "probas_sigmoid = probas_sigmoid.numpy().flatten() * 100\n",
        "predictions_binary = [1 if x > 50.0 else 0 for x in probas_sigmoid]\n",
        "test_loss, test_accuracy = model.evaluate(test_dataset_from_data_generator, verbose = 0)\n",
        "print(f\"test loss {test_loss}, test accuracy {test_accuracy}\")"
      ],
      "metadata": {
        "id": "shCWi-i5vHYb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_img = load_img(data_proc.train_file_list[0], color_mode =\"grayscale\")\n",
        "test_img_arry = img_to_array(test_img)\n",
        "print(type(test_img))\n",
        "print(test_img.format)\n",
        "print(test_img.mode)\n",
        "print(test_img.size)\n",
        "print(test_img.getbands())\n",
        "print(test_img_arry.shape)\n",
        "\n",
        "test_img1 = load_img(data_proc.train_file_list[0])\n",
        "test_img1_arry = img_to_array(test_img1)\n",
        "print(test_img1_arry.shape)\n",
        "print(test_img1.getbands())"
      ],
      "metadata": {
        "id": "F-_a0JOfmzX3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0df55f9c-465d-428b-cb01-f51323cd72b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'PIL.TiffImagePlugin.TiffImageFile'>\n",
            "TIFF\n",
            "L\n",
            "(96, 96)\n",
            "('L',)\n",
            "(96, 96, 1)\n",
            "(96, 96, 3)\n",
            "('R', 'G', 'B')\n"
          ]
        }
      ]
    }
  ]
}