{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "LVFUDthMpIRC",
        "Oj7_lkEuSEgK",
        "3ul4kgxkYvSU",
        "blbLoLnvn8t2"
      ],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMZyAcoDqdGys1WVh6VD3GV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/srilamaiti/SM_MIDS_W207_HW/blob/main/w207_cancer_detection_sm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Cancer Detection***\n",
        "## ***Applied Machine Learning W207 Final Project, Fall 2022***\n",
        "### ***Members***\n",
        "#### ***1. Chenyu Wang***\n",
        "#### ***2. Hector Rincon***\n",
        "#### ***3. Ifrah Javed***\n",
        "#### ***4. Srila Maiti***"
      ],
      "metadata": {
        "id": "trV63iFrganB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***A. Importing the Libraries***"
      ],
      "metadata": {
        "id": "8yHdU2FbUlPj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hi17ZecZUbQ_",
        "outputId": "7829e39a-8ec9-4e85-b2a8-f35c9798ff54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import joblib\n",
        "import glob\n",
        "import random\n",
        "from imutils import rotate as rotate\n",
        "from itertools import product\n",
        "import gc\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "import matplotlib.patches as patches\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import RandomFlip\n",
        "from tensorflow.keras.layers import RandomZoom\n",
        "from tensorflow.keras.layers import RandomRotation\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.layers import AveragePooling2D\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.preprocessing.image import array_to_img\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "import cv2 as cv\n",
        "import skimage.io as skio\n",
        "\n",
        "# Required to read the data from Kaggle\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = \"/content/gdrive/MyDrive/Kaggle\"\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter(\"ignore\", category=DeprecationWarning)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "PCaDl92PYpLj",
        "outputId": "c21604a1-073f-44f7-96d4-5cb2c24a1aa2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.8.2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***B. File Processing***"
      ],
      "metadata": {
        "id": "areAkqv9nbDH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***1. Downloading Image Files from Kaggle***"
      ],
      "metadata": {
        "id": "hD5eQnKpUqTy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions download -c histopathologic-cancer-detection"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ParrVdZfUvBy",
        "outputId": "42f8f870-a464-43b8-df9b-42e2a896ce3e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading histopathologic-cancer-detection.zip to /content\n",
            "100% 6.31G/6.31G [00:27<00:00, 226MB/s]\n",
            "100% 6.31G/6.31G [00:27<00:00, 244MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***2. Unzipping the Downaloaded Zip Files***"
      ],
      "metadata": {
        "id": "5X4PUwc_U0Zs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -o -qq \\*.zip  && rm *.zip"
      ],
      "metadata": {
        "id": "liN0YJhXU5rz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***3. Data Validation and Spot Checks***"
      ],
      "metadata": {
        "id": "LVFUDthMpIRC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ***a. Train Files Count***"
      ],
      "metadata": {
        "id": "2qu75MsxbPGw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -ltr /content/train/ |wc -l"
      ],
      "metadata": {
        "id": "RYm2sVsNbMrB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ***b. Validating record count of train_labels.csv with train file count***"
      ],
      "metadata": {
        "id": "C7R3DkvzxCHt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wc -l train_labels.csv"
      ],
      "metadata": {
        "id": "MCBNy_cgw6Jo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ***c. Test Files Count***"
      ],
      "metadata": {
        "id": "FPsn4pC6bUmb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -ltr /content/test/ |wc -l"
      ],
      "metadata": {
        "id": "-Z44YcX2bX1S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ***d. Validating record count of sample_submission.csv with test file count***"
      ],
      "metadata": {
        "id": "3Ixkkkb_bfXP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wc -l sample_submission.csv"
      ],
      "metadata": {
        "id": "FYRHA6yFbi08"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ***e. Explore file structure of train_labels.csv***"
      ],
      "metadata": {
        "id": "0QnoXq7hxvGS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!head train_labels.csv"
      ],
      "metadata": {
        "id": "h0HHg3rwxtM3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ***f. Explore file structure of sample_submission.csv***"
      ],
      "metadata": {
        "id": "dttCA1lnyAnc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!head sample_submission.csv"
      ],
      "metadata": {
        "id": "6EZvcFO2yMAe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***C. Support Functionalities***"
      ],
      "metadata": {
        "id": "4_M8U_LHRy9Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***1. Defining Parameters***"
      ],
      "metadata": {
        "id": "bap3nzRATnbP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CONTRAST_FACTOR = 3\n",
        "DELTA = 0.3\n",
        "\n",
        "train_path = 'train/'\n",
        "test_path = 'test/'\n",
        "\n",
        "current_working_dir = os.getcwd()\n",
        "\n",
        "train_label_file = 'train_labels.csv'\n",
        "test_label_file = 'sample_submission.csv'\n",
        "\n",
        "image_file_extension = '.tif'\n",
        "\n",
        "train_files_path = os.path.join(current_working_dir, train_path)\n",
        "test_files_path = os.path.join(current_working_dir, test_path)\n",
        "\n",
        "# declare constants for reproduciblity\n",
        "RANDOM_STATE = 20220922\n",
        "\n",
        "# Finding split positions\n",
        "split = (0.30, 0.10, 0.10)\n",
        "\n",
        "process_chunk_size = 200\n",
        "\n",
        "tf.random.set_seed(1234)\n",
        "np.random.seed(1234)"
      ],
      "metadata": {
        "id": "e8YWnGlPTrFm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***2. Generating Fully Qualified File Name List***\n",
        "This function generates the list of fully qualified file name list based on the input parameter."
      ],
      "metadata": {
        "id": "Oj7_lkEuSEgK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_fully_qualified_file_name_list(file_list):\n",
        "    \"\"\"\n",
        "    This function generates a list of fully qualified file names.\n",
        "    \"\"\"\n",
        "    qualified_file_name_list = [os.path.join(current_working_dir, train_path) + \n",
        "                                img + \n",
        "                                '.tif' \n",
        "                                for img in file_list\n",
        "                               ]\n",
        "    return qualified_file_name_list"
      ],
      "metadata": {
        "id": "5IsDxtaIQlgu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***3. Printing Images in Different Orientation***\n",
        "This function prints the input imgae in different orientation."
      ],
      "metadata": {
        "id": "Jss2Yk6u0CHr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def print_image_in_diff_orientation(image_file):\n",
        "    \"\"\"\n",
        "    This function prints images.\n",
        "    \"\"\"\n",
        "    tf.random.set_seed(1234)\n",
        "    fig = plt.figure(figsize=(14, 12))\n",
        "    #fig = plt.figure()\n",
        "    image = skio.imread(image_file, plugin = \"tifffile\")\n",
        "        \n",
        "    # plot original\n",
        "    ax = fig.add_subplot(1, 5, 1)\n",
        "    ax.imshow(array_to_img(image))\n",
        "    ax.set_title('Original', size=15);\n",
        "\n",
        "    # resize\n",
        "    ax = fig.add_subplot(1, 5, 2)\n",
        "    img_resize = tf.image.resize(image, size=(224, 224))\n",
        "    ax.imshow(array_to_img(img_resize))\n",
        "    ax.set_title('Step 1: Resize', size=15);\n",
        "\n",
        "    # adjust brightness\n",
        "    ax = fig.add_subplot(1, 5, 3)\n",
        "    img_bright = tf.image.adjust_brightness(img_resize, 0.3)\n",
        "    ax.imshow(array_to_img(img_bright))\n",
        "    ax.set_title('Step 2: Brightness', size=15);\n",
        "\n",
        "    # adjust contrast\n",
        "    ax = fig.add_subplot(1, 5, 4)\n",
        "    img_contrast = tf.image.adjust_contrast(img_bright, contrast_factor=3)\n",
        "    ax.imshow(array_to_img(img_contrast))\n",
        "    ax.set_title('Step 3: Contrast', size=15);\n",
        "\n",
        "    # flip left right\n",
        "    ax = fig.add_subplot(1, 5, 5)\n",
        "    img_flip = tf.image.flip_left_right(img_contrast)\n",
        "    ax.imshow(array_to_img(img_flip))\n",
        "    ax.set_title('Step 4: Flip left right', size=15);"
      ],
      "metadata": {
        "id": "qyp3g5Jdv7I2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***4. Spliting Data in Train, Validation and Test Sets***\n",
        "This function splits the input data set in train, validation and test data set based on the split indices."
      ],
      "metadata": {
        "id": "VB6yblUZQGvw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_data(split_indices, df):\n",
        "    \"\"\"\n",
        "    This function splits the input dataframe in train, validation and test set.\n",
        "    \"\"\"\n",
        "    X_train = df[: split_indices[0]]\n",
        "    X_val = df[split_indices[0] : split_indices[1]]\n",
        "    X_test = df[split_indices[1]:]\n",
        "    #print(len(X_train), len(X_val), len(X_test))\n",
        "    '''\n",
        "    (X_train, \n",
        "     X_val, \n",
        "     X_test) = np.split(shuffled_train_positive_label_df[['id']], \n",
        "                                                         [split_indices[0], \n",
        "                                                         split_indices[0] + \n",
        "                                                         split_indices[1]\n",
        "                                                        ]\n",
        "                       )\n",
        "    '''\n",
        "    return X_train, X_val, X_test"
      ],
      "metadata": {
        "id": "1QsFzFBMOGNj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***5. Get IDs and Labels for the Images***\n",
        "This function gets id and label values for input train and test data set."
      ],
      "metadata": {
        "id": "JwbTSV2RVY1a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_id_and_label_list(file_path, file_extension):\n",
        "    \"\"\"\n",
        "    This function gets the imgae id and corresponding label.\n",
        "    \"\"\"\n",
        "    file_list = []\n",
        "    for file_name in glob.glob(file_path + '*' + file_extension):\n",
        "        file_list.append(file_name)\n",
        "    return file_list"
      ],
      "metadata": {
        "id": "fdzFlI4dVrZy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***6. Read Image File into a Numpy Array***\n",
        "This function reads each image file in a Numpy array and returns it."
      ],
      "metadata": {
        "id": "HnNG6hPBr6th"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_image_file_in_np_array(image_list):\n",
        "    \"\"\"\n",
        "    This function reads each image file in a Numpy array and returns it.\n",
        "    \"\"\"\n",
        "    return np.asarray([skio.imread(image_file, plugin = \"tifffile\") for image_file in image_list])"
      ],
      "metadata": {
        "id": "9KRGcoAKsAzI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***7. Converts Numpy Array to Tensor***\n",
        "This function converts the numpy array representation of an image to a Tensor."
      ],
      "metadata": {
        "id": "VFJ0PiS5tQV0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_np_array_to_tensor(np_image_array):\n",
        "    \"\"\"\n",
        "    This function converts the numpy array representation of each image in tensor.\n",
        "    \"\"\"\n",
        "    return [tf.convert_to_tensor(img_np_array) for img_np_array in np_image_array]"
      ],
      "metadata": {
        "id": "DzRkQ9l6te42"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***8. Converting Int Tensor to Float***\n",
        "This function converts integer TF to Float."
      ],
      "metadata": {
        "id": "hKdbhiAKN9FP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_int_tf_to_float(tf_image_list):\n",
        "    \"\"\"\n",
        "    This function converts integer TF value to float.\n",
        "    \"\"\"\n",
        "    return np.asanyarray([tf.cast(img, tf.float32) for img in tf_image_list])"
      ],
      "metadata": {
        "id": "iq0XJGnAOGLh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***9. Converting to Grayscale***\n",
        "This function converts color image to grayscale."
      ],
      "metadata": {
        "id": "sAjZLxwTi9aP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_to_grayscale(tf_image_list):\n",
        "    \"\"\"\n",
        "    This function converts color image to grayscale.\n",
        "    \"\"\"\n",
        "    return tf.image.rgb_to_grayscale(tf_image_list) / 255.0"
      ],
      "metadata": {
        "id": "w0_L44KyjFOh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***10. Adjusting Brightness***\n",
        "This function adjusts brightness of the images. "
      ],
      "metadata": {
        "id": "QkYRDJDBObaA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def adjust_brightness(tf_image_list, delta):\n",
        "    \"\"\"\n",
        "    This function adjusts the image brightness.\n",
        "    \"\"\"\n",
        "    return tf.image.adjust_brightness(tf_image_list, delta = delta)"
      ],
      "metadata": {
        "id": "6a3CSJssOrZJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***11. Adjusting Contrast***\n",
        "This function adjusts image contrast."
      ],
      "metadata": {
        "id": "B5xqmZIQPEQG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def adjust_contrast(tf_image_list, contrast_factor):\n",
        "    \"\"\"\n",
        "    This function adjusts contrast of the image.\n",
        "    \"\"\"\n",
        "    return tf.image.adjust_contrast(tf_image_list, contrast_factor = contrast_factor)"
      ],
      "metadata": {
        "id": "-k4Gz84aPS_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***12. Random Flip Left Right***\n",
        "This function applies random flip to the image."
      ],
      "metadata": {
        "id": "zYRonDvrPzqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def random_flip_left_right(tf_image_list):\n",
        "    \"\"\"\n",
        "    This function applies random flip to the image.\n",
        "    \"\"\"\n",
        "    return tf.image.random_flip_left_right(tf_image_list)"
      ],
      "metadata": {
        "id": "eEcqzQ79P-ab"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***13. Rotate Images 90/180/270 Degrees***\n",
        "This function rotates images 90/180/270 degrees."
      ],
      "metadata": {
        "id": "2oFKjfmgdolc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rotate_image(tf_image_list, k = 1):\n",
        "    \"\"\"\n",
        "    This function rotates images by 90/180/270 degrees.\n",
        "    k = 1 : 90 degree rotation\n",
        "    k = 2 : 180 degree rotation\n",
        "    k = 3 : 270 degree rotation\n",
        "    \"\"\"\n",
        "    return tf.image.rot90(tf_image_list, k)"
      ],
      "metadata": {
        "id": "QLSxs7sFd26l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***14. Create Labels***\n",
        "This function creates labels with 1 or 0."
      ],
      "metadata": {
        "id": "NEf1ceMatXq0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_label(shape, label = 1):\n",
        "    \"\"\"\n",
        "    This function creates labels.\n",
        "    \"\"\"\n",
        "    if label == 1:\n",
        "        return np.ones(shape).flatten()\n",
        "    elif label == 0:\n",
        "        return np.zeros(shape).flatten()"
      ],
      "metadata": {
        "id": "N8F58ARTtwzR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***D. Collecting File Information***"
      ],
      "metadata": {
        "id": "3ul4kgxkYvSU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***1. Get the Image IDs and Corresponding Labels***\n",
        "\n",
        "There are 220,025 and 57,458 train and test images respectively(tiff \n",
        "extension). Each image is 96 X 96 color images (with 3 channels). We are also given train_labels.csv and sample_submission.csv which contain label information for train and test images respectively."
      ],
      "metadata": {
        "id": "blbLoLnvn8t2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#get file names for train and test\n",
        "train_file_list = []\n",
        "test_file_list = []\n",
        "\n",
        "train_file_list = get_id_and_label_list(train_files_path, image_file_extension)\n",
        "test_file_list = get_id_and_label_list(test_files_path, image_file_extension)\n",
        "\n",
        "train_label = pd.read_csv(train_label_file)\n",
        "test_label = pd.read_csv(test_label_file)\n",
        "\n",
        "print(f\"Number of train files : {len(train_file_list)}\")\n",
        "print(f\"Number of train files : {len(test_file_list)}\")"
      ],
      "metadata": {
        "id": "0JVmzqZaYqd_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***2. Checking for Duplicate IDs***"
      ],
      "metadata": {
        "id": "K0vWYDZYw9zz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_train_id_count = pd.DataFrame(train_label.groupby(['id'])['id'].count())\n",
        "df_train_id_count.columns = ['id_count']\n",
        "df_train_id_count.reset_index(inplace = True)\n",
        "print(\"Number of train duplicate entries : \", len(df_train_id_count[df_train_id_count.id_count > 1]))\n",
        "\n",
        "df_test_id_count = pd.DataFrame(test_label.groupby(['id'])['id'].count())\n",
        "df_test_id_count.columns = ['id_count']\n",
        "df_test_id_count.reset_index(inplace = True)\n",
        "print(\"Number of test duplicate entries : \", len(df_test_id_count[df_test_id_count.id_count > 1]))"
      ],
      "metadata": {
        "id": "PFCggDOevtOY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***3. Seperating Postive and Negative Images from the Training Data***"
      ],
      "metadata": {
        "id": "H0FC0Iv2GowK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_positive_image_id_list = list(train_label[train_label.label==1].id)\n",
        "train_negative_image_id_list = list(train_label[train_label.label==0].id)\n",
        "\n",
        "train_positive_images_list = generate_fully_qualified_file_name_list(train_positive_image_id_list)\n",
        "train_negative_images_list = generate_fully_qualified_file_name_list(train_negative_image_id_list)\n",
        "\n",
        "print(f\"Number of positive images in train set: {len(train_positive_images_list)}\")\n",
        "print(f\"Number of negative images in train set: {len(train_negative_images_list)}\")"
      ],
      "metadata": {
        "id": "Wyqt0qWvRMvj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***E. Data Visualization***"
      ],
      "metadata": {
        "id": "OU0UfK3dlHGl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***1. Count Distribution of Train Data***"
      ],
      "metadata": {
        "id": "so88Po_clN0o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(data = train_label, x = 'label')\n",
        "plt.title(\"Train Data label Count\")"
      ],
      "metadata": {
        "id": "xR1mqx_3zX40"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***2. Train Label Percentage Pie Chart***"
      ],
      "metadata": {
        "id": "saS8AVSGla4F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig = px.pie(train_label, \n",
        "             values = train_label['label'].value_counts().values, \n",
        "             names = train_label['label'].unique())\n",
        "fig.update_layout(\n",
        "    title={\n",
        "        'text': \"Train Label Percentage Pie Chart\",\n",
        "        'y':.99,\n",
        "        'x':0.5,\n",
        "        'xanchor': 'center',\n",
        "        'yanchor': 'top'})\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "7O7qohUd0q0s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***3. Count Distribution of Test Data***"
      ],
      "metadata": {
        "id": "rzLdmu8xlqYS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(data = test_label, x = 'label')\n",
        "plt.title(\"Test Data label Count\")"
      ],
      "metadata": {
        "id": "fE8VvFbU0Acd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***4. Train Label Percentage Pie Chart***"
      ],
      "metadata": {
        "id": "quSgW7zBlzg8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig = px.pie(test_label, \n",
        "             values = test_label['label'].value_counts().values, \n",
        "             names = test_label['label'].unique())\n",
        "fig.update_layout(\n",
        "    title={\n",
        "        'text': \"Test Label Percentage Pie Chart\",\n",
        "        'y':.99,\n",
        "        'x':0.5,\n",
        "        'xanchor': 'center',\n",
        "        'yanchor': 'top'})\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "dLBRVr6504n7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***5. Printing Positive Images (Cancer Present) in Different Orientation***"
      ],
      "metadata": {
        "id": "bvZWTNdd1B8S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for image in train_positive_images_list[:5]:\n",
        "    print_image_in_diff_orientation(image)"
      ],
      "metadata": {
        "id": "5i2k899rxFtG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***6. Printing Negative Images (No Cancer) in Different Orientation***"
      ],
      "metadata": {
        "id": "YVFaCkL71JPw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for image in train_negative_images_list[:5]:\n",
        "    print_image_in_diff_orientation(image)"
      ],
      "metadata": {
        "id": "0CSu59Jf0gEW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras_preprocessing\n",
        "from keras_preprocessing import image\n",
        "from keras_preprocessing.image import ImageDataGenerator\n",
        "\n",
        "TRAINING_DIR = \"/content/temp/\"\n",
        "training_datagen = ImageDataGenerator(\n",
        "      rescale = 1./255,\n",
        "\t    rotation_range=40,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest')\n",
        "training_datagen"
      ],
      "metadata": {
        "id": "R7oe_ZtSDa98"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***F. Considerations*** \n",
        "### ***1. We see an imbalance between positive and negative images.***\n",
        "We will consider equal number of positive and negative images for training and test data. \n",
        "### ***2. We do not have correct label for test data.***\n",
        "We will repurpose part of train data for testing."
      ],
      "metadata": {
        "id": "3OHvjJaeSVVE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***G. Data Preprocessing***"
      ],
      "metadata": {
        "id": "0KJlo8fmpaes"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***1. Shuffling Data***"
      ],
      "metadata": {
        "id": "ZgwcHaLYp1yB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Shuffling data\n",
        "shuffled_train_label = shuffle(train_label)\n",
        "len_shuffled_train_label = len(shuffled_train_label)\n",
        "\n",
        "# Selecting positive and negative images from the shuffled list\n",
        "shuffled_train_positive_label_df = shuffled_train_label[shuffled_train_label.label == 1]\n",
        "shuffled_train_negative_label_df = shuffled_train_label[shuffled_train_label.label == 0]\n",
        "\n",
        "print(f\"Length of shuffled_train_positive_label_df : {len(shuffled_train_positive_label_df)}\")\n",
        "print(f\"Length of shuffled_train_negative_label_df : {len(shuffled_train_negative_label_df)}\")"
      ],
      "metadata": {
        "id": "NVH0QTrdQRr6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***2. Obtaining Split Indices***"
      ],
      "metadata": {
        "id": "XdM-BxcWphwU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "split_indices = np.multiply(len(shuffled_train_positive_label_df), split).astype(int)\n",
        "for idx, val in enumerate(split_indices):\n",
        "    #print(idx, val)\n",
        "    if idx > 0:\n",
        "        split_indices[idx] = sum(split_indices[idx - 1 : idx]) + split_indices[idx]\n",
        "print(\"Split indecs : \", split_indices)"
      ],
      "metadata": {
        "id": "PD4Olr8lQCoO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***3. Spliting Data in Train(60%), Validation(20%) and Test(20%) Sets for Both Positive and Negative Images.***\n",
        "To handle data imbalance problem, we will use equal number of positive and negative images. Thus, we will use 30% train positive, 30% train negative, 10% validation postive, 10% validation negative, 10% test positive and 10% test negative images."
      ],
      "metadata": {
        "id": "o0LhPus_qBU1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting data at train, validation and test positions \n",
        "# for both positive and negative imgaes\n",
        "# This process will select the list of ids\n",
        "(X_train_id_positive, \n",
        " X_val_id_positive, \n",
        " X_test_id_positive) = split_data(split_indices = split_indices, \n",
        "                                  df = shuffled_train_positive_label_df[:split_indices[-1]]\n",
        "                                 )\n",
        "(X_train_id_negative, \n",
        " X_val_id_negative, \n",
        " X_test_id_negative) = split_data(split_indices = split_indices, \n",
        "                                  df = shuffled_train_negative_label_df[:split_indices[-1]]\n",
        "                                 )\n",
        " \n",
        "print(f\"Length of X_train_id_positive : {len(X_train_id_positive)}\")\n",
        "print(f\"Length of X_train_id_negative : {len(X_train_id_negative)}\")\n",
        "\n",
        "print(f\"Length of X_val_id_positive : {len(X_val_id_positive)}\")\n",
        "print(f\"Length of X_val_id_negative : {len(X_val_id_negative)}\")\n",
        "\n",
        "print(f\"Length of X_test_id_positive : {len(X_test_id_positive)}\")\n",
        "print(f\"Length of X_test_id_negative : {len(X_test_id_negative)}\")"
      ],
      "metadata": {
        "id": "MArBjOESQW2s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***4. Generating Fully Qualified Image File Name List for Both Positive and Negative Images***"
      ],
      "metadata": {
        "id": "kFsss8sHqUTU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_img_file_positive = generate_fully_qualified_file_name_list(list(np.concatenate(X_train_id_positive[['id']].values.tolist()).flat))\n",
        "X_val_img_file_positive = generate_fully_qualified_file_name_list(list(np.concatenate(X_val_id_positive[['id']].values.tolist()).flat))\n",
        "X_test_img_file_positive = generate_fully_qualified_file_name_list(list(np.concatenate(X_test_id_positive[['id']].values.tolist()).flat))\n",
        "\n",
        "X_train_img_file_negative = generate_fully_qualified_file_name_list(list(np.concatenate(X_train_id_negative[['id']].values.tolist()).flat))\n",
        "X_val_img_file_negative = generate_fully_qualified_file_name_list(list(np.concatenate(X_val_id_negative[['id']].values.tolist()).flat))\n",
        "X_test_img_file_negative = generate_fully_qualified_file_name_list(list(np.concatenate(X_test_id_negative[['id']].values.tolist()).flat))\n",
        "\n",
        "print(f\"Length of X_train_img_file_positive : {len(X_train_img_file_positive)}\")\n",
        "print(f\"Length of X_train_img_file_negative : {len(X_train_img_file_negative)}\")\n",
        "\n",
        "print(f\"Length of X_val_img_file_positive : {len(X_val_img_file_positive)}\")\n",
        "print(f\"Length of X_val_img_file_negative : {len(X_val_img_file_negative)}\")\n",
        "\n",
        "print(f\"Length of X_test_img_file_positive : {len(X_test_img_file_positive)}\")\n",
        "print(f\"Length of X_test_img_file_negative : {len(X_test_img_file_negative)}\")"
      ],
      "metadata": {
        "id": "77ure3cBqvxx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***5. Reading Image File in Numpy Array***"
      ],
      "metadata": {
        "id": "HztMRI45rkoz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This process will read each image file and store them in np array\n",
        "# for both positive and negative images\n",
        "X_train_positive_np = read_image_file_in_np_array(X_train_img_file_positive)\n",
        "X_val_positive_np = read_image_file_in_np_array(X_val_img_file_positive)\n",
        "X_test_positive_np = read_image_file_in_np_array(X_test_img_file_positive)\n",
        "\n",
        "X_train_negative_np = read_image_file_in_np_array(X_train_img_file_negative)\n",
        "X_val_negative_np = read_image_file_in_np_array(X_val_img_file_negative)\n",
        "X_test_negative_np = read_image_file_in_np_array(X_test_img_file_negative)\n",
        "\n",
        "print(f\"Length of X_train_positive_np : {len(X_train_positive_np)}\")\n",
        "print(f\"Length of X_train_negative_np : {len(X_train_negative_np)}\")\n",
        "\n",
        "print(f\"Length of X_val_positive_np : {len(X_val_positive_np)}\")\n",
        "print(f\"Length of X_val_negative_np : {len(X_val_negative_np)}\")\n",
        "\n",
        "print(f\"Length of X_test_positive_np : {len(X_test_positive_np)}\")\n",
        "print(f\"Length of X_test_negative_np : {len(X_test_negative_np)}\")"
      ],
      "metadata": {
        "id": "lx7gVD9uuJGO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***6. Converting Numpy Array to Tensor***"
      ],
      "metadata": {
        "id": "LCr8-chetC-m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This process converts np array to tensor\n",
        "# for both positive and negative images\n",
        "X_train_positive_tf = convert_np_array_to_tensor(X_train_positive_np)\n",
        "X_val_positive_tf = convert_np_array_to_tensor(X_val_positive_np)\n",
        "X_test_positive_tf = convert_np_array_to_tensor(X_test_positive_np)\n",
        "\n",
        "X_train_negative_tf = convert_np_array_to_tensor(X_train_negative_np)\n",
        "X_val_negative_tf = convert_np_array_to_tensor(X_val_negative_np)\n",
        "X_test_negative_tf = convert_np_array_to_tensor(X_test_negative_np)\n",
        "\n",
        "print(f\"Length of X_train_positive_tf : {len(X_train_positive_tf)}\")\n",
        "print(f\"Length of X_train_negative_tf : {len(X_train_negative_tf)}\")\n",
        "\n",
        "print(f\"Length of X_val_positive_tf : {len(X_val_positive_tf)}\")\n",
        "print(f\"Length of X_val_negative_tf : {len(X_val_negative_tf)}\")\n",
        "\n",
        "print(f\"Length of X_test_positive_tf : {len(X_test_positive_tf)}\")\n",
        "print(f\"Length of X_test_negative_tf : {len(X_test_negative_tf)}\")"
      ],
      "metadata": {
        "id": "HMBgWZyvuTz2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***7. Converting Integer TF to Float***"
      ],
      "metadata": {
        "id": "-Xk-gA_rOtc7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Handling int to float conversion for X_train_positive_tf\")\n",
        "for idx in range(0, len(X_train_positive_tf), process_chunk_size):\n",
        "    if idx % 10000 == 0:\n",
        "        print(\"Processing index: \", idx)\n",
        "    X_train_positive_tf[idx : idx + process_chunk_size] = convert_int_tf_to_float(X_train_positive_tf[idx : idx + process_chunk_size])\n",
        "    gc.collect()\n",
        "    tf.keras.backend.clear_session()\n",
        "\n",
        "print(\"Handling int to float conversion for X_val_positive_tf\")\n",
        "for idx in range(0, len(X_val_positive_tf), process_chunk_size):\n",
        "    if idx % 10000 == 0:\n",
        "        print(\"Processing index: \", idx)\n",
        "    X_val_positive_tf[idx : idx + process_chunk_size] = convert_int_tf_to_float(X_val_positive_tf[idx : idx + process_chunk_size])\n",
        "    gc.collect()\n",
        "    tf.keras.backend.clear_session()\n",
        "\n",
        "print(\"Handling int to float conversion for X_test_positive_tf\")\n",
        "for idx in range(0, len(X_test_positive_tf), process_chunk_size):\n",
        "    if idx % 10000 == 0:\n",
        "        print(\"Processing index: \", idx)\n",
        "    X_test_positive_tf[idx : idx + process_chunk_size] = convert_int_tf_to_float(X_test_positive_tf[idx : idx + process_chunk_size])\n",
        "    gc.collect()\n",
        "    tf.keras.backend.clear_session()\n",
        "\n",
        "print(\"Handling int to float conversion for X_train_negative_tf\")\n",
        "for idx in range(0, len(X_train_negative_tf), process_chunk_size):\n",
        "    if idx % 10000 == 0:\n",
        "        print(\"Processing index: \", idx)\n",
        "    X_train_negative_tf[idx : idx + process_chunk_size] = convert_int_tf_to_float(X_train_negative_tf[idx : idx + process_chunk_size])\n",
        "    gc.collect()\n",
        "    tf.keras.backend.clear_session()\n",
        "\n",
        "print(\"Handling int to float conversion for X_val_negative_tf\")\n",
        "for idx in range(0, len(X_val_negative_tf), process_chunk_size):\n",
        "    if idx % 10000 == 0:\n",
        "        print(\"Processing index: \", idx)\n",
        "    X_val_negative_tf[idx : idx + process_chunk_size] = convert_int_tf_to_float(X_val_negative_tf[idx : idx + process_chunk_size])\n",
        "    gc.collect()\n",
        "    tf.keras.backend.clear_session()\n",
        "\n",
        "print(\"Handling int to float conversion for X_test_negative_tf\")\n",
        "for idx in range(0, len(X_test_negative_tf), process_chunk_size):\n",
        "    if idx % 10000 == 0:\n",
        "        print(\"Processing index: \", idx)\n",
        "    X_test_negative_tf[idx : idx + process_chunk_size] = convert_int_tf_to_float(X_test_negative_tf[idx : idx + process_chunk_size])\n",
        "    gc.collect()\n",
        "    tf.keras.backend.clear_session()\n",
        "\n",
        "print(f\"Length of X_train_positive_tf : {len(X_train_positive_tf)}\")\n",
        "print(f\"Length of X_train_negative_tf : {len(X_train_negative_tf)}\")\n",
        "\n",
        "print(f\"Length of X_val_positive_tf : {len(X_val_positive_tf)}\")\n",
        "print(f\"Length of X_val_negative_tf : {len(X_val_negative_tf)}\")\n",
        "\n",
        "print(f\"Length of X_test_positive_tf : {len(X_test_positive_tf)}\")\n",
        "print(f\"Length of X_test_negative_tf : {len(X_test_negative_tf)}\")"
      ],
      "metadata": {
        "id": "--U4zJK5O1Ld"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***8. Creating Labels***"
      ],
      "metadata": {
        "id": "Uy4ydQgKuWfT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ***a. Creating Positive Labels***"
      ],
      "metadata": {
        "id": "5Ey3CdsGukYh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Y_train_positive = create_label(len(X_train_positive_tf))\n",
        "Y_val_positive = create_label(len(X_val_positive_tf))\n",
        "Y_test_positive = create_label(len(X_test_positive_tf))"
      ],
      "metadata": {
        "id": "eci0QLQcuuqn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ***b. Creating Negative Labels***"
      ],
      "metadata": {
        "id": "Hemm2Rp_urG1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Y_train_positive = create_label(len(X_train_negative_tf), 0)\n",
        "Y_val_positive = create_label(len(X_val_negative_tf), 0)\n",
        "Y_test_positive = create_label(len(X_test_negative_tf), 0)"
      ],
      "metadata": {
        "id": "m0hCn-FWxTgB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***H. Image Processing***"
      ],
      "metadata": {
        "id": "7u66w-Rl8JfG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***1. Converting Color Images to Grayscale***"
      ],
      "metadata": {
        "id": "7fRUdUrzpc1x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Handling grayscale conversion for X_train_positive_tf\")\n",
        "for idx in range(0, len(X_train_positive_tf), process_chunk_size):\n",
        "    if idx % 10000 == 0:\n",
        "        print(\"Processing index: \", idx)\n",
        "    X_train_positive_tf[idx : idx + process_chunk_size] = convert_to_grayscale(X_train_positive_tf[idx : idx + process_chunk_size])\n",
        "    gc.collect()\n",
        "    tf.keras.backend.clear_session()\n",
        "\n",
        "print(\"Handling grayscale conversion for X_val_positive_tf\")\n",
        "for idx in range(0, len(X_val_positive_tf), process_chunk_size):\n",
        "    if idx % 10000 == 0:\n",
        "        print(\"Processing index: \", idx)\n",
        "    X_val_positive_tf[idx : idx + process_chunk_size] = convert_to_grayscale(X_val_positive_tf[idx : idx + process_chunk_size])\n",
        "    gc.collect()\n",
        "    tf.keras.backend.clear_session()\n",
        "\n",
        "print(\"Handling grayscale conversion for X_test_positive_tf\")\n",
        "for idx in range(0, len(X_test_positive_tf), process_chunk_size):\n",
        "    if idx % 10000 == 0:\n",
        "        print(\"Processing index: \", idx)\n",
        "    X_test_positive_tf[idx : idx + process_chunk_size] = convert_to_grayscale(X_test_positive_tf[idx : idx + process_chunk_size])\n",
        "    gc.collect()\n",
        "    tf.keras.backend.clear_session()\n",
        "\n",
        "print(\"Handling grayscale conversion for X_train_negative_tf\")\n",
        "for idx in range(0, len(X_train_negative_tf), process_chunk_size):\n",
        "    if idx % 10000 == 0:\n",
        "        print(\"Processing index: \", idx)\n",
        "    X_train_negative_tf[idx : idx + process_chunk_size] = convert_to_grayscale(X_train_negative_tf[idx : idx + process_chunk_size])\n",
        "    gc.collect()\n",
        "    tf.keras.backend.clear_session()\n",
        "\n",
        "print(\"Handling grayscale conversion for X_val_negative_tf\")\n",
        "for idx in range(0, len(X_val_negative_tf), process_chunk_size):\n",
        "    if idx % 10000 == 0:\n",
        "        print(\"Processing index: \", idx)\n",
        "    X_val_negative_tf[idx : idx + process_chunk_size] = convert_to_grayscale(X_val_negative_tf[idx : idx + process_chunk_size])\n",
        "    gc.collect()\n",
        "    tf.keras.backend.clear_session()\n",
        "\n",
        "print(\"Handling grayscale conversion for X_test_negative_tf\")\n",
        "for idx in range(0, len(X_test_negative_tf), process_chunk_size):\n",
        "    if idx % 10000 == 0:\n",
        "        print(\"Processing index: \", idx)\n",
        "    X_test_negative_tf[idx : idx + process_chunk_size] = convert_to_grayscale(X_test_negative_tf[idx : idx + process_chunk_size])\n",
        "    gc.collect()\n",
        "    tf.keras.backend.clear_session()\n",
        "\n",
        "print(f\"Length of X_train_positive_tf : {len(X_train_positive_tf)}\")\n",
        "print(f\"Length of X_train_negative_tf : {len(X_train_negative_tf)}\")\n",
        "\n",
        "print(f\"Length of X_val_positive_tf : {len(X_val_positive_tf)}\")\n",
        "print(f\"Length of X_val_negative_tf : {len(X_val_negative_tf)}\")\n",
        "\n",
        "print(f\"Length of X_test_positive_tf : {len(X_test_positive_tf)}\")\n",
        "print(f\"Length of X_test_negative_tf : {len(X_test_negative_tf)}\")"
      ],
      "metadata": {
        "id": "K3jEN9KeptiC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***2. Adjusting Brightness of the Images***"
      ],
      "metadata": {
        "id": "M6xSb9uu2fFT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Handling brightness adjustment for X_train_positive_tf\")\n",
        "aug_adj_brghtnss_X_train_positive_tf = adjust_brightness(X_train_positive_tf, delta = DELTA)\n",
        "aug_adj_brghtnss_Y_train_positive = create_label(len(aug_adj_brghtnss_X_train_positive_tf))\n",
        "gc.collect()\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "print(\"Handling brightness adjustment for X_train_negative_tf\")\n",
        "aug_adj_brghtnss_X_train_negative_tf = adjust_brightness(X_train_negative_tf, delta=DELTA)\n",
        "aug_adj_brghtnss_Y_train_negative = create_label(len(aug_adj_brghtnss_X_train_negative_tf), 0)\n",
        "gc.collect()\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "print(f\"Length of aug_adj_brghtnss_X_train_positive_tf : {len(aug_adj_brghtnss_X_train_positive_tf)}\")\n",
        "print(f\"Length of aug_adj_brghtnss_X_train_negative_tf : {len(aug_adj_brghtnss_X_train_negative_tf)}\")\n",
        "\n",
        "print(f\"Length of aug_adj_brghtnss_Y_train_positive : {len(aug_adj_brghtnss_Y_train_positive)}\")\n",
        "print(f\"Length of aug_adj_brghtnss_Y_train_negative : {len(aug_adj_brghtnss_Y_train_negative)}\")"
      ],
      "metadata": {
        "id": "uzBBBXv4ATRX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***3. Adjusting Contrast of the Images***"
      ],
      "metadata": {
        "id": "mhOdyca43Lr6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Handling contrast adjustment for X_train_positive_tf\")\n",
        "aug_adj_cntrst_X_train_positive_tf = adjust_contrast(X_train_positive_tf, contrast_factor = CONTRAST_FACTOR)\n",
        "aug_adj_cntrst_Y_train_positive = create_label(len(aug_adj_cntrst_X_train_positive_tf))\n",
        "gc.collect()\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "print(\"Handling contrast adjustment for X_train_negative_tf\")\n",
        "aug_adj_cntrst_X_train_negative_tf = adjust_contrast(X_train_negative_tf, contrast_factor = CONTRAST_FACTOR)\n",
        "aug_adj_cntrst_Y_train_negative = create_label(len(aug_adj_cntrst_X_train_negative_tf), 0)\n",
        "gc.collect()\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "print(f\"Length of aug_adj_cntrst_X_train_positive_tf : {len(aug_adj_cntrst_X_train_positive_tf)}\")\n",
        "print(f\"Length of aug_adj_cntrst_X_train_negative_tf : {len(aug_adj_cntrst_X_train_negative_tf)}\")\n",
        "\n",
        "print(f\"Length of aug_adj_cntrst_Y_train_positive : {len(aug_adj_cntrst_Y_train_positive)}\")\n",
        "print(f\"Length of aug_adj_cntrst_Y_train_negative : {len(aug_adj_cntrst_Y_train_negative)}\")"
      ],
      "metadata": {
        "id": "n5rVu15P_0GX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***4. Random Flip***"
      ],
      "metadata": {
        "id": "J3611ay63aT0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Handling random flip for X_train_positive_tf\")\n",
        "aug_rnd_flip_X_train_positive_tf = random_flip_left_right(X_train_positive_tf)\n",
        "aug_rnd_flip_Y_train_positive = create_label(len(aug_rnd_flip_X_train_positive_tf))\n",
        "gc.collect()\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "print(\"Handling random flip for X_train_negative_tf\")\n",
        "aug_rnd_flip_X_train_negative_tf = random_flip_left_right(X_train_negative_tf)\n",
        "aug_rnd_flip_Y_train_negative = create_label(len(aug_rnd_flip_X_train_negative_tf), 0)\n",
        "gc.collect()\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "print(f\"Length of aug_rnd_flip_X_train_positive_tf : {len(aug_rnd_flip_X_train_positive_tf)}\")\n",
        "print(f\"Length of aug_rnd_flip_X_train_negative_tf : {len(aug_rnd_flip_X_train_negative_tf)}\")\n",
        "\n",
        "print(f\"Length of aug_rnd_flip_Y_train_positive : {len(aug_rnd_flip_Y_train_positive)}\")\n",
        "print(f\"Length of aug_rnd_flip_Y_train_negative : {len(aug_rnd_flip_Y_train_negative)}\")"
      ],
      "metadata": {
        "id": "1DZmP__h3eE-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***5. Rotate***"
      ],
      "metadata": {
        "id": "B4gojx4w3t_8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ***a. Rotate Images by 90 degrees***"
      ],
      "metadata": {
        "id": "xMcjUzaEeOgb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Handling image rotation by 90 degrees for X_train_positive_tf\")\n",
        "aug_rot_90_X_train_positive_tf = rotate_image(X_train_positive_tf)\n",
        "aug_rot_90_Y_train_positive = create_label(len(aug_rot_90_X_train_positive_tf))\n",
        "gc.collect()\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "print(\"Handling image rotation by 90 degrees for X_train_negative_tf\")\n",
        "aug_rot_90_X_train_negative_tf = rotate_image(X_train_negative_tf)\n",
        "aug_rot_90_Y_train_negative = create_label(len(aug_rot_90_X_train_negative_tf), 0)\n",
        "gc.collect()\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "print(f\"Length of aug_rot_90_X_train_positive_tf : {len(aug_rot_90_X_train_positive_tf)}\")\n",
        "print(f\"Length of aug_rot_90_X_train_negative_tf : {len(aug_rot_90_X_train_negative_tf)}\")\n",
        "\n",
        "print(f\"Length of aug_rot_90_Y_train_positive : {len(aug_rot_90_Y_train_positive)}\")\n",
        "print(f\"Length of aug_rot_90_Y_train_negative : {len(aug_rot_90_Y_train_negative)}\")"
      ],
      "metadata": {
        "id": "-2WMR_hjeK6C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ***b. Rotate Images by 180 degrees***"
      ],
      "metadata": {
        "id": "V78fnRZAesf0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Handling image rotation by 180 degrees for X_train_positive_tf\")\n",
        "aug_rot_180_X_train_positive_tf = rotate_image(X_train_positive_tf, k = 2)\n",
        "aug_rot_180_Y_train_positive = create_label(len(aug_rot_180_X_train_positive_tf))\n",
        "gc.collect()\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "print(\"Handling image rotation by 180 degrees for X_train_negative_tf\")\n",
        "aug_rot_180_X_train_negative_tf = rotate_image(X_train_negative_tf, k = 2)\n",
        "aug_rot_180_Y_train_negative = create_label(len(aug_rot_180_X_train_negative_tf), 0)\n",
        "gc.collect()\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "print(f\"Length of aug_rot_180_X_train_positive_tf : {len(aug_rot_180_X_train_positive_tf)}\")\n",
        "print(f\"Length of aug_rot_180_X_train_negative_tf : {len(aug_rot_180_X_train_negative_tf)}\")\n",
        "\n",
        "print(f\"Length of aug_rot_180_Y_train_positive : {len(aug_rot_180_Y_train_positive)}\")\n",
        "print(f\"Length of aug_rot_180_Y_train_negative : {len(aug_rot_180_Y_train_negative)}\")"
      ],
      "metadata": {
        "id": "uTZWbw4Gez4r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ***c. Rotate Images by 270 degrees***"
      ],
      "metadata": {
        "id": "7mNZi4YPe0Zw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Handling image rotation by 270 degrees for X_train_positive_tf\")\n",
        "aug_rot_270_X_train_positive_tf = rotate_image(X_train_positive_tf, k = 3)\n",
        "aug_rot_270_Y_train_positive = create_label(len(aug_rot_270_X_train_positive_tf))\n",
        "gc.collect()\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "print(\"Handling image rotation by 270 degrees for X_train_negative_tf\")\n",
        "aug_rot_270_X_train_negative_tf = rotate_image(X_train_negative_tf, k = 3)\n",
        "aug_rot_270_Y_train_negative = create_label(len(aug_rot_270_X_train_negative_tf), 0)\n",
        "gc.collect()\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "print(f\"Length of aug_rot_270_X_train_positive_tf : {len(aug_rot_270_X_train_positive_tf)}\")\n",
        "print(f\"Length of aug_rot_270_X_train_negative_tf : {len(aug_rot_270_X_train_negative_tf)}\")\n",
        "\n",
        "print(f\"Length of aug_rot_270_Y_train_positive : {len(aug_rot_270_Y_train_positive)}\")\n",
        "print(f\"Length of aug_rot_270_Y_train_negative : {len(aug_rot_270_Y_train_negative)}\")"
      ],
      "metadata": {
        "id": "dPJ_EPamfC3i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***6. Adding Back the Augmented Images***"
      ],
      "metadata": {
        "id": "1jUx5bzd3pQk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_positive_tf = tf.concat([X_train_positive_tf \n",
        "                              , aug_adj_brghtnss_X_train_positive_tf\n",
        "                              , aug_rnd_flip_X_train_positive_tf\n",
        "                              , aug_adj_cntrst_X_train_positive_tf\n",
        "                              , aug_rot_90_X_train_positive_tf\n",
        "                              , aug_rot_180_X_train_positive_tf\n",
        "                              , aug_rot_270_X_train_positive_tf\n",
        "                                ] \n",
        "                              , axis = 0\n",
        "                              )\n",
        "\n",
        "X_train_negative_tf = tf.concat([X_train_negative_tf \n",
        "                              , aug_adj_brghtnss_X_train_negative_tf\n",
        "                              , aug_rnd_flip_X_train_negative_tf\n",
        "                              , aug_adj_cntrst_X_train_negative_tf\n",
        "                              , aug_rot_90_X_train_negative_tf\n",
        "                              , aug_rot_180_X_train_negative_tf\n",
        "                              , aug_rot_270_X_train_negative_tf\n",
        "                                ] \n",
        "                              , axis = 0\n",
        "                              )"
      ],
      "metadata": {
        "id": "rltlhw1e3F_5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MhdePS053GCk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zIMUULkO3GFV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "teUL8Pcm2Z34"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "txl69od8Yqz2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}