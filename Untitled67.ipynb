{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "5dlGr3VX6DyA",
        "UQBd_dFh6S1S",
        "Iv-y8vdS62gV",
        "xM_Fw_tt7EpU",
        "qSyqwXIMIp7t",
        "2C55GxBKnW3V",
        "JLAsViNZnt1V",
        "0mavHZlbpFpR",
        "gmTSA20Vr0Pp"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/srilamaiti/SM_MIDS_W207_HW/blob/main/Untitled67.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***1. Setup***"
      ],
      "metadata": {
        "id": "NUylKvIS6Lsf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***A. Installing New Libraries***"
      ],
      "metadata": {
        "id": "5dlGr3VX6DyA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kAIyFDyH5uLR",
        "outputId": "ae10fdb3-51cd-4a4f-ecf1-2ffff64779d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: imgaug in /usr/local/lib/python3.7/dist-packages (0.4.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from imgaug) (1.7.3)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from imgaug) (4.6.0.66)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.7/dist-packages (from imgaug) (1.8.5.post1)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.7/dist-packages (from imgaug) (2.9.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from imgaug) (7.1.2)\n",
            "Requirement already satisfied: scikit-image>=0.14.2 in /usr/local/lib/python3.7/dist-packages (from imgaug) (0.18.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from imgaug) (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from imgaug) (1.21.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from imgaug) (1.15.0)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.2->imgaug) (2.6.3)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.2->imgaug) (2021.11.2)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.2->imgaug) (1.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug) (0.11.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->imgaug) (4.1.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install imgaug"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install livelossplot"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91Xb-Plzo2E5",
        "outputId": "46bf98f6-cba2-4a61-8a87-a118ccae888a"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: livelossplot in /usr/local/lib/python3.7/dist-packages (0.5.5)\n",
            "Requirement already satisfied: bokeh in /usr/local/lib/python3.7/dist-packages (from livelossplot) (2.3.3)\n",
            "Requirement already satisfied: numpy<1.22 in /usr/local/lib/python3.7/dist-packages (from livelossplot) (1.21.6)\n",
            "Requirement already satisfied: ipython==7.* in /usr/local/lib/python3.7/dist-packages (from livelossplot) (7.9.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from livelossplot) (3.2.2)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython==7.*->livelossplot) (0.2.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython==7.*->livelossplot) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython==7.*->livelossplot) (0.7.5)\n",
            "Requirement already satisfied: jedi>=0.10 in /usr/local/lib/python3.7/dist-packages (from ipython==7.*->livelossplot) (0.18.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython==7.*->livelossplot) (57.4.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython==7.*->livelossplot) (2.6.1)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython==7.*->livelossplot) (5.1.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from ipython==7.*->livelossplot) (2.0.10)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython==7.*->livelossplot) (4.8.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.10->ipython==7.*->livelossplot) (0.8.3)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython==7.*->livelossplot) (1.15.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython==7.*->livelossplot) (0.2.5)\n",
            "Requirement already satisfied: tornado>=5.1 in /usr/local/lib/python3.7/dist-packages (from bokeh->livelossplot) (6.0.4)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from bokeh->livelossplot) (2.8.2)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.7/dist-packages (from bokeh->livelossplot) (6.0)\n",
            "Requirement already satisfied: pillow>=7.1.0 in /usr/local/lib/python3.7/dist-packages (from bokeh->livelossplot) (7.1.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from bokeh->livelossplot) (4.1.1)\n",
            "Requirement already satisfied: Jinja2>=2.9 in /usr/local/lib/python3.7/dist-packages (from bokeh->livelossplot) (2.11.3)\n",
            "Requirement already satisfied: packaging>=16.8 in /usr/local/lib/python3.7/dist-packages (from bokeh->livelossplot) (21.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.9->bokeh->livelossplot) (2.0.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=16.8->bokeh->livelossplot) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->livelossplot) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->livelossplot) (1.4.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython==7.*->livelossplot) (0.7.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***B. Importing Libraries***"
      ],
      "metadata": {
        "id": "UQBd_dFh6S1S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***a. Importing General Purpose Libraries***"
      ],
      "metadata": {
        "id": "Iv-y8vdS62gV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import joblib\n",
        "import glob\n",
        "import random\n",
        "from itertools import product\n",
        "import gc\n",
        "import subprocess"
      ],
      "metadata": {
        "id": "ujHcENda69HI"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***b. Importing Image Processing and Visualization Libraries***"
      ],
      "metadata": {
        "id": "xM_Fw_tt7EpU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from imutils import rotate as rotate\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "import matplotlib.patches as patches\n",
        "from matplotlib.patches import Polygon\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "from skimage.color import gray2rgb\n",
        "import skimage.io as skio\n",
        "from imgaug import augmenters as img_aug\n",
        "import imgaug as iaug"
      ],
      "metadata": {
        "id": "0NV7G1UoIi4I"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***c. Importing Sklearn Functionalities Libraries***"
      ],
      "metadata": {
        "id": "qSyqwXIMIp7t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import shuffle\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.decomposition import IncrementalPCA\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import StratifiedShuffleSplit"
      ],
      "metadata": {
        "id": "fUh7ts6QI8Lx"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***d. Importing Tensorflow Libraries***"
      ],
      "metadata": {
        "id": "2C55GxBKnW3V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from livelossplot import PlotLossesKeras\n",
        "\n",
        "from tensorflow.keras.layers import RandomFlip\n",
        "from tensorflow.keras.layers import RandomZoom\n",
        "from tensorflow.keras.layers import RandomRotation\n",
        "from tensorflow.keras.layers import Conv1D\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import Concatenate\n",
        "from tensorflow.keras.layers import MaxPooling1D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.layers import AveragePooling2D\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import GlobalMaxPooling2D\n",
        "from tensorflow.keras.layers import GlobalAveragePooling1D\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
        "from tensorflow.keras.layers import Lambda\n",
        "from tensorflow.keras.layers import Multiply\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.layers import Bidirectional\n",
        "from tensorflow.keras.layers import PReLU\n",
        "from keras.layers.core import Activation\n",
        "from keras.layers.convolutional import SeparableConv1D\n",
        "from keras.layers.convolutional import SeparableConv2D\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.applications.vgg19 import VGG19\n",
        "from keras.applications.densenet import *\n",
        "from keras.applications.resnet import ResNet152\n",
        "from keras.applications.nasnet import NASNetMobile\n",
        "from keras.applications.nasnet import NASNetLarge\n",
        "from keras.applications.nasnet import preprocess_input\n",
        "from keras.applications import MobileNetV2\n",
        "from keras.applications.xception import Xception\n",
        "from keras.applications.inception_v3 import *\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import array_to_img\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "\n",
        "from tensorflow.python.ops.numpy_ops import np_config\n",
        "\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "\n",
        "from tensorflow.keras.losses import mae\n",
        "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
        "from tensorflow.keras.losses import binary_crossentropy\n",
        "\n",
        "from keras.models import Model\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from keras.models import load_model\n"
      ],
      "metadata": {
        "id": "eUXe1TURnkN5"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***C. Mounting Google Drive***"
      ],
      "metadata": {
        "id": "JLAsViNZnt1V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Required to read the data from Kaggle\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = \"/content/gdrive/MyDrive/Kaggle\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bCewn8D_n4oL",
        "outputId": "31f41dd1-fc73-4a82-d6b0-3e660d4ca93b"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***D. Downloading Data from Kaggle***"
      ],
      "metadata": {
        "id": "0mavHZlbpFpR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!bash /content/gdrive/MyDrive/Kaggle/download_kaggle_data.ksh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2JCPUogkpL3J",
        "outputId": "9a206ea7-5913-4a89-e39d-bb226b8fd103"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading histopathologic-cancer-detection.zip to /content\n",
            "100% 6.30G/6.31G [01:39<00:00, 131MB/s]\n",
            "100% 6.31G/6.31G [01:39<00:00, 67.9MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***E. Creating Directory Structure***"
      ],
      "metadata": {
        "id": "gmTSA20Vr0Pp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!bash /content/gdrive/MyDrive/Kaggle/create_directory_structure.ksh"
      ],
      "metadata": {
        "id": "_-XnL0Ogr_0X"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***F. Defining Vartiables***"
      ],
      "metadata": {
        "id": "aZ9PZBKVtI__"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_size = 75000\n",
        "batch_size = 192\n",
        "image_size = 96\n",
        "\n",
        "transfer_learning_model_list = ['vgg19', 'restnet', 'densenet', 'nasnet', 'xception']\n",
        "learning_rate_list = [.01, .001, .0001, .00001]\n",
        "optimizer_list = ['sgd', 'adam']\n",
        "dropout_list = [.2, .4, .6]\n",
        "kernel_size_list = [(3,3), (4,4), (5,5)]\n",
        "dense_layer_node_list = [512, 256, 128]\n",
        "fully_conneted_layer_list = [1, 2, 3]\n",
        "epoch_list = [5, 10, 15, 20]\n",
        "\n",
        "train_path = os.getcwd() + \"/train/\"\n",
        "test_path = os.getcwd() + \"/test/\"\n",
        "\n",
        "original_input_file_list = train_path + '*.tif'\n",
        "original_output_file_list = test_path + '*.tif'\n",
        "\n",
        "current_working_dir = os.getcwd()\n",
        "\n",
        "train_label_file = 'train_labels.csv'\n",
        "test_label_file = 'sample_submission.csv'\n",
        "\n",
        "image_file_extension = '.tif'\n",
        "\n",
        "train_files_path = os.path.join(current_working_dir, train_path)\n",
        "test_files_path = os.path.join(current_working_dir, test_path)\n",
        "\n",
        "image_processing_train_positive_path = '/content/image_processing/train/positive'\n",
        "image_processing_train_negative_path = '/content/image_processing/train/negative'\n",
        "\n",
        "image_processing_validation_positive_path = '/content/image_processing/validation/positive'\n",
        "image_processing_validation_negative_path = '/content/image_processing/validation/negative'\n",
        "\n",
        "image_processing_test_positive_path = '/content/image_processing/test/positive'\n",
        "image_processing_test_negative_path = '/content/image_processing/test/negative'\n",
        "\n",
        "image_processing_train_path = \"/content/image_processing/train/\"\n",
        "image_processing_validation_path = \"/content/image_processing/validation/\"\n",
        "image_processing_test_path = \"/content/image_processing/test/\"\n",
        "\n",
        "random.seed(1)"
      ],
      "metadata": {
        "id": "e4rSklTftQY-"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***G. Misclenious Processing Class***"
      ],
      "metadata": {
        "id": "m2j3vtPothqH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class misc_processing:\n",
        "    \"\"\"\n",
        "    This class contains methods for misclenious processings.\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        None\n",
        "    \n",
        "    def generate_fully_qualified_file_name_list(self, file_list):\n",
        "        \"\"\"\n",
        "        This function generates a list of fully qualified file names.\n",
        "        \"\"\"\n",
        "        qualified_file_name_list = [os.path.join(current_working_dir, train_path) + \n",
        "                                    img + \n",
        "                                    '.tif' \n",
        "                                    for img in file_list\n",
        "                                   ]\n",
        "        return qualified_file_name_list\n",
        "\n",
        "    def print_image_original(self, image_file_list, label_list):\n",
        "        \"\"\"\n",
        "        This function prints original images.\n",
        "        \"\"\"\n",
        "        nrows, ncols = 1,4 #print first 4 images\n",
        "        f, axs = plt.subplots(nrows, ncols, figsize=(14,12))\n",
        "        for i, image in enumerate(image_file_list):\n",
        "            axs[i].imshow(array_to_img(image))\n",
        "            pf = Polygon(((32, 32), (64, 32), (64, 64), (32, 64)),\n",
        "                         fc=(0.0, 0.0, 0.0, 0.0), \n",
        "                         ec=(0.0, 0.9, 0.0 ,0.9), lw=4, linestyle='--')\n",
        "            pf.set_edgecolor('r')\n",
        "            axs[i].add_patch(pf)\n",
        "            axs[i].set(title=label_list[i])\n",
        "\n",
        "    def print_image_in_diff_orientation(self, image_file):\n",
        "        \"\"\"\n",
        "        This function prints images.\n",
        "        \"\"\"\n",
        "        tf.random.set_seed(1234)\n",
        "        fig = plt.figure(figsize=(14, 12))\n",
        "        #fig = plt.figure()\n",
        "        image = skio.imread(image_file, plugin = \"tifffile\")\n",
        "        \n",
        "        # plot original\n",
        "        ax = fig.add_subplot(1, 5, 1)\n",
        "        ax.imshow(array_to_img(image))\n",
        "        pf = Polygon(((32, 32), (64, 32), (64, 64), (32, 64)),\n",
        "                fc = (0.0, 0.0, 0.0, 0.0), \n",
        "                ec = (0.0, 0.9, 0.0 ,0.9), lw=4, linestyle='--')\n",
        "        pf.set_edgecolor('r')\n",
        "        ax.add_patch(pf)\n",
        "        ax.set_title('Original', size=15);\n",
        "        \n",
        "        # resize\n",
        "        ax = fig.add_subplot(1, 5, 2)\n",
        "        img_resize = tf.image.resize(image, size=(224, 224))\n",
        "        ax.imshow(array_to_img(img_resize))\n",
        "        pf = Polygon(((80, 80), (144, 80), (144, 144), (80, 144)),\n",
        "                fc = (0.0, 0.0, 0.0, 0.0), \n",
        "                ec = (0.0, 0.9, 0.0 ,0.9), lw=4, linestyle='--')\n",
        "        pf.set_edgecolor('r')\n",
        "        ax.add_patch(pf)\n",
        "        ax.set_title('Step 1: Resize', size=15);\n",
        "        \n",
        "        # adjust brightness\n",
        "        ax = fig.add_subplot(1, 5, 3)\n",
        "        img_bright = tf.image.adjust_brightness(img_resize, 0.3)\n",
        "        ax.imshow(array_to_img(img_bright))\n",
        "        pf = Polygon(((80, 80), (144, 80), (144, 144), (80, 144)),\n",
        "                fc = (0.0, 0.0, 0.0, 0.0), \n",
        "                ec = (0.0, 0.9, 0.0 ,0.9), lw=4, linestyle='--')\n",
        "        pf.set_edgecolor('r')\n",
        "        ax.add_patch(pf)\n",
        "        ax.set_title('Step 2: Brightness', size=15);\n",
        "        \n",
        "        # adjust contrast\n",
        "        ax = fig.add_subplot(1, 5, 4)\n",
        "        img_contrast = tf.image.adjust_contrast(img_bright, contrast_factor=3)\n",
        "        ax.imshow(array_to_img(img_contrast))\n",
        "        pf = Polygon(((80, 80), (144, 80), (144, 144), (80, 144)),\n",
        "                fc = (0.0, 0.0, 0.0, 0.0), \n",
        "                ec = (0.0, 0.9, 0.0 ,0.9), lw=4, linestyle='--')\n",
        "        pf.set_edgecolor('r')\n",
        "        ax.add_patch(pf)\n",
        "        ax.set_title('Step 3: Contrast', size=15);\n",
        "        \n",
        "        # flip left right\n",
        "        ax = fig.add_subplot(1, 5, 5)\n",
        "        img_flip = tf.image.flip_left_right(img_contrast)\n",
        "        ax.imshow(array_to_img(img_flip))\n",
        "        pf = Polygon(((80, 80), (144, 80), (144, 144), (80, 144)),\n",
        "                fc = (0.0, 0.0, 0.0, 0.0), \n",
        "                ec = (0.0, 0.9, 0.0 ,0.9), lw=4, linestyle='--')\n",
        "        pf.set_edgecolor('r')\n",
        "        ax.add_patch(pf)\n",
        "        ax.set_title('Step 4: Flip left right');\n",
        "\n",
        "    def split_data(self, split_indices, df):\n",
        "        \"\"\"\n",
        "        This function splits the input dataframe in train, validation and test set.\n",
        "        \"\"\"\n",
        "        X_train = df[: split_indices[0]]\n",
        "        X_val = df[split_indices[0] : split_indices[1]]\n",
        "        X_test = df[split_indices[1]:]\n",
        "        return X_train, X_val, X_test\n",
        "    \n",
        "    def get_id_and_label_list(self, file_path, file_extension):\n",
        "        \"\"\"\n",
        "        This function gets the imgae id and corresponding label.\n",
        "        \"\"\"\n",
        "        return glob.glob(file_path + '*' + file_extension)\n",
        "        '''\n",
        "        file_list = []\n",
        "        for file_name in glob.glob(file_path + '*' + file_extension):\n",
        "            file_list.append(file_name)\n",
        "        return file_list\n",
        "        '''\n",
        "\n",
        "    def create_label(self, shape, label = 1):\n",
        "        \"\"\"\n",
        "        This function creates labels.\n",
        "        \"\"\"\n",
        "        if label == 1:\n",
        "            return np.ones(shape).flatten()\n",
        "        elif label == 0:\n",
        "            return np.zeros(shape).flatten()\n",
        "    \n",
        "    def compute_mean_and_std(self, image_file_list, r_mid_pos = 48, c_mid_pos = 48):\n",
        "        \"\"\"\n",
        "        This function computes mean and std at the center of the image.\n",
        "        \"\"\"\n",
        "        center_pixel_value_list = []\n",
        "        for image_file in image_file_list:\n",
        "            image = skio.imread(image_file, plugin = \"tifffile\")\n",
        "            center_pixel_value_list.append(image[r_mid_pos, c_mid_pos])\n",
        "        np_array_center_pixel_value = np.array(center_pixel_value_list)\n",
        "        return np.mean(np_array_center_pixel_value), np.std(np_array_center_pixel_value)\n",
        "\n",
        "    def copy_file_from_one_to_other(self, file_names, dest_path):\n",
        "        \"This function moves chunks of files in one to other.\"\n",
        "        os.system('cp -r ' + file_names + ' ' + dest_path)\n",
        "\n",
        "    def process_copy_files(self, file_name_list, dest_path):\n",
        "        \"\"\"\"\n",
        "        This function processes moving files from one dir to the other. \n",
        "        This is the master process to run actual moving in chunks.\n",
        "        \"\"\"\n",
        "        process_chunk_size = 100\n",
        "        for idx in range(0, len(file_name_list), process_chunk_size):\n",
        "            if idx % 10000 == 0:\n",
        "                print(\"Processing index: \", idx)\n",
        "            self.copy_file_from_one_to_other(' '.join(file_name_list[idx : idx + process_chunk_size]), dest_path)\n",
        "    \n",
        "    def check_file_count_in_a_directory(self, dir_path):\n",
        "        \"\"\"\n",
        "        This function checks the file count in a directory\n",
        "        \"\"\"\n",
        "        cmd_string = 'ls ' + dir_path + \" | wc -l\"\n",
        "        file_count = int(subprocess.check_output(cmd_string, shell=True, text=True).strip())\n",
        "        return file_count\n",
        "\n",
        "    def get_mini_batch_data(self, image_list, mini_batch_size):\n",
        "        \"\"\"\n",
        "        This function performs as a generator to spit out data in small batches.\n",
        "        \"\"\"\n",
        "        return (image_list[idx : idx + mini_batch_size] for idx in range(0, len(image_list), mini_batch_size))\n",
        "\n",
        "    def get_aug_step_list(self):\n",
        "        \"\"\"\n",
        "        This function executes image augmentation pipeline.\n",
        "        \"\"\"\n",
        "        sometimes = lambda aug: img_aug.Sometimes(0.5, aug)\n",
        "        img_aug_seq = img_aug.Sequential(\n",
        "        [\n",
        "            # apply the following augmenters to most images\n",
        "            img_aug.Fliplr(0.5), # horizontally flip 50% of all images\n",
        "            img_aug.Flipud(0.2), # vertically flip 20% of all images\n",
        "            sometimes(img_aug.Affine(\n",
        "                scale={\"x\": (0.9, 1.1), \"y\": (0.9, 1.1)}, # scale images to 80-120% of their size, individually per axis\n",
        "                translate_percent={\"x\": (-0.1, 0.1), \"y\": (-0.1, 0.1)}, # translate by -20 to +20 percent (per axis)\n",
        "                rotate=(-10, 10), # rotate by -45 to +45 degrees\n",
        "                shear=(-5, 5), # shear by -16 to +16 degrees\n",
        "                order=[0, 1], # use nearest neighbour or bilinear interpolation (fast)\n",
        "                cval=(0, 255), # if mode is constant, use a cval between 0 and 255\n",
        "                mode=iaug.ALL # use any of scikit-image's warping modes (see 2nd image from the top for examples)\n",
        "            )),\n",
        "            # execute 0 to 5 of the following (less important) augmenters per image\n",
        "            # don't execute all of them, as that would often be way too strong\n",
        "            img_aug.SomeOf((0, 5),\n",
        "                [\n",
        "                    sometimes(img_aug.Superpixels(p_replace=(0, 1.0), n_segments=(20, 200))), # convert images into their superpixel representation\n",
        "                    img_aug.OneOf([\n",
        "                        img_aug.GaussianBlur((0, 1.0)), # blur images with a sigma between 0 and 3.0\n",
        "                        img_aug.AverageBlur(k=(3, 5)), # blur image using local means with kernel sizes between 2 and 7\n",
        "                        img_aug.MedianBlur(k=(3, 5)), # blur image using local medians with kernel sizes between 2 and 7\n",
        "                    ]),\n",
        "                    img_aug.Sharpen(alpha=(0, 1.0), lightness=(0.9, 1.1)), # sharpen images\n",
        "                    img_aug.Emboss(alpha=(0, 1.0), strength=(0, 2.0)), # emboss images\n",
        "                    # search either for all edges or for directed edges,\n",
        "                    # blend the result with the original image using a blobby mask\n",
        "                    img_aug.SimplexNoiseAlpha(img_aug.OneOf([\n",
        "                        img_aug.EdgeDetect(alpha=(0.5, 1.0)),\n",
        "                        img_aug.DirectedEdgeDetect(alpha=(0.5, 1.0), direction=(0.0, 1.0)),\n",
        "                    ])),\n",
        "                    img_aug.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.01*255), per_channel=0.5), # add gaussian noise to images\n",
        "                    img_aug.OneOf([\n",
        "                        img_aug.Dropout((0.01, 0.05), per_channel=0.5), # randomly remove up to 10% of the pixels\n",
        "                        img_aug.CoarseDropout((0.01, 0.03), size_percent=(0.01, 0.02), per_channel=0.2),\n",
        "                    ]),\n",
        "                    img_aug.Invert(0.01, per_channel=True), # invert color channels\n",
        "                    img_aug.Add((-2, 2), per_channel=0.5), # change brightness of images (by -10 to 10 of original value)\n",
        "                    img_aug.AddToHueAndSaturation((-1, 1)), # change hue and saturation\n",
        "                    # either change the brightness of the whole image (sometimes\n",
        "                    # per channel) or change the brightness of subareas\n",
        "                    img_aug.OneOf([\n",
        "                        img_aug.Multiply((0.9, 1.1), per_channel=0.5),\n",
        "                        img_aug.FrequencyNoiseAlpha(\n",
        "                            exponent=(-1, 0),\n",
        "                            first=img_aug.Multiply((0.9, 1.1), per_channel=True),\n",
        "                            second=img_aug.ContrastNormalization((0.9, 1.1))\n",
        "                        )\n",
        "                    ]),\n",
        "                    sometimes(img_aug.ElasticTransformation(alpha=(0.5, 3.5), sigma=0.25)), # move pixels locally around (with random strengths)\n",
        "                    sometimes(img_aug.PiecewiseAffine(scale=(0.01, 0.05))), # sometimes move parts of the image around\n",
        "                    sometimes(img_aug.PerspectiveTransform(scale=(0.01, 0.1)))\n",
        "                ],\n",
        "                random_order=True\n",
        "            )\n",
        "        ],\n",
        "        random_order=True\n",
        "        )\n",
        "        return img_aug_seq\n",
        "\n",
        "    def get_id_label_map(self, df, filter_list):\n",
        "        \"\"\"\n",
        "        This function generates the id and label dictionary.\n",
        "        \"\"\"\n",
        "        return {k : v for k, v in zip(df[df.id.isin(filter_list)].id.values, \n",
        "                                      df[df.id.isin(filter_list)].label.values\n",
        "                                     )\n",
        "               }\n",
        "\n",
        "    def image_data_generator(self, list_files, label_list, batch_size, augment=False):\n",
        "        \"\"\"\n",
        "        This function is a generrator function to produce mini batch of data.\n",
        "        \"\"\"\n",
        "        image_augmentation_steps = self.get_aug_step_list()\n",
        "        while True:\n",
        "            shuffle(list_files)\n",
        "            for mini_batch in self.get_mini_batch_data(list_files, batch_size):\n",
        "                X = [cv2.imread(x) for x in mini_batch]\n",
        "                y = label_list\n",
        "                if augment:\n",
        "                    aug_X = image_augmentation_steps.augment_images(X)\n",
        "                    aug_y = y\n",
        "                    X = X + aug_X\n",
        "                X = [preprocess_input(x) for x in X]\n",
        "                \n",
        "        yield np.array(X), np.array(y)\n",
        "\n",
        "misc_proc = misc_processing()"
      ],
      "metadata": {
        "id": "KMaqq9V4toXo"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***H. Plot Processing Class***"
      ],
      "metadata": {
        "id": "jStvd4wGp8Ju"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class plot_processing:\n",
        "    \"\"\"\n",
        "    This class contains methods to display various plots.\n",
        "    \"\"\"\n",
        "    def count_plot(self, data, label_col, title_val):\n",
        "        \"\"\"\n",
        "        This method plots count plot of the input data set.\n",
        "        \"\"\"\n",
        "        sns.countplot(data = data, x = label_col)\n",
        "        plt.title(title_val)\n",
        "        plt.show(block = False)\n",
        "\n",
        "    def pie_chart_plot(self, data, label_col, title_val):\n",
        "        \"\"\"\n",
        "        This method plots pie chart based on the given data.\n",
        "        \"\"\"\n",
        "        fig = px.pie(data, \n",
        "                     values = data[label_col].value_counts().values, \n",
        "                     names = data[label_col].unique())\n",
        "        fig.update_layout(\n",
        "                      title={\n",
        "                             'text'    : title_val,\n",
        "                             'y'       : .99,\n",
        "                             'x'       :  0.5,\n",
        "                             'xanchor' : 'center',\n",
        "                             'yanchor' : 'top'\n",
        "                            }\n",
        "                          )\n",
        "        fig.show()\n",
        "        plt.show(block = False)\n",
        "\n",
        "plot_proc = plot_processing()"
      ],
      "metadata": {
        "id": "myB5dDG2qBTr"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***I. Image Processing Class***"
      ],
      "metadata": {
        "id": "i2353h6hNEnz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class image_processing:\n",
        "    \"\"\"\n",
        "    This class contains methods for image processing.\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        None\n",
        "    \n",
        "    def read_image_file_in_np_array(self, image_list):\n",
        "        \"\"\"\n",
        "        This method reads each image file in a Numpy array and returns it.\n",
        "        \"\"\"\n",
        "        return np.asarray([skio.imread(image_file, plugin = \"tifffile\") for image_file in image_list])\n",
        "    \n",
        "    def convert_np_array_to_tensor(self, np_image_array):\n",
        "        \"\"\"\n",
        "        This method converts the numpy array representation of each image in tensor.\n",
        "        \"\"\"\n",
        "        return tf.convert_to_tensor(np_image_array, dtype = tf.float32)\n",
        "\n",
        "    def convert_int_tf_to_float(self, tf_image_list):\n",
        "        \"\"\"\n",
        "        This method converts integer TF value to float.\n",
        "        \"\"\"\n",
        "        return np.asanyarray([tf.cast(img, tf.float32) for img in tf_image_list])\n",
        "    \n",
        "    def convert_from_rgb_to_grayscale(self, tf_image_list, large_list_ind = False):\n",
        "        \"\"\"\n",
        "        This method converts color image to grayscale.\n",
        "        \"\"\"\n",
        "        if large_list_ind == False:\n",
        "            return tf.image.rgb_to_grayscale(tf_image_list) / 255.0\n",
        "        else:\n",
        "            None\n",
        "    \n",
        "    def combine_train_val(self, x_train, X_val, y_train, y_val):\n",
        "        \"\"\"\n",
        "        This method combines train and validation data, shuffles them and \n",
        "        returns back suffled data for k-fold cross validation.\n",
        "        \"\"\"\n",
        "        X_train_kfold = tf.concat([X_train, X_val] , axis = 0)\n",
        "        y_train_kfold = tf.concat([y_train, y_val] , axis = 0)\n",
        "\n",
        "        print(\"Shuffling the kfold train data...\")\n",
        "        tf.random.set_seed(1234) # for reproducibility\n",
        "    \n",
        "        test_shuffle_indices = tf.random.shuffle(tf.range(tf.shape(X_train_kfold)[0], dtype = tf.int32))\n",
        "        X_train_kfold = tf.gather(X_train_kfold, test_shuffle_indices)\n",
        "        y_train_kfold = tf.gather(y_train_kfold, test_shuffle_indices).numpy()\n",
        "        \n",
        "        print(f\"X_train_kfold shape: {X_train_kfold.shape}\")\n",
        "        print(f\"y_train_kfold shape: {y_train_kfold.shape}\")\n",
        "\n",
        "    def adjust_brightness(self, tf_image_list, delta):\n",
        "        \"\"\"\n",
        "        This method adjusts the image brightness.\n",
        "        \"\"\"\n",
        "        return tf.image.adjust_brightness(tf_image_list, delta = delta)\n",
        "\n",
        "    def adjust_random_brightness(self, tf_image_list, max_delta = .3, seed = (1,2)):\n",
        "        \"\"\"\n",
        "        This method adjusts random image brightness.\n",
        "        \"\"\"\n",
        "        return tf.image.stateless_random_brightness(tf_image_list, max_delta = max_delta, seed = seed)\n",
        "\n",
        "    def adjust_contrast(self, tf_image_list, contrast_factor):\n",
        "        \"\"\"\n",
        "        This method adjusts contrast of the image.\n",
        "        \"\"\"\n",
        "        return tf.image.adjust_contrast(tf_image_list, contrast_factor = contrast_factor)\n",
        "\n",
        "    def adjust_random_contrast(self, contrast_factor, lower = .2, upper = .5, seed = (1,2)):\n",
        "        \"\"\"\n",
        "        This method randomly contrasts images during training.\n",
        "        \"\"\"\n",
        "        return tf.image.stateless_random_contrast(contrast_factor, lower, upper, seed)\n",
        "\n",
        "    def flip_left_right(self, tf_image_list):\n",
        "        \"\"\"\n",
        "        This method applies flips the image from left to right.\n",
        "        \"\"\"\n",
        "        return tf.image.flip_left_right(tf_image_list)\n",
        "\n",
        "    def random_flip_left_right(self, tf_image_list, seed = (1,2)):\n",
        "        \"\"\"\n",
        "        This method randomly flips images left-right during training.\n",
        "        \"\"\"\n",
        "        return tf.image.stateless_random_flip_left_right(tf_image_list, seed)\n",
        "\n",
        "    def flip_up_down(self, tf_image_list):\n",
        "        \"\"\"\n",
        "        This method flips the image up-down.\n",
        "        \"\"\"\n",
        "        return tf.image.flip_up_down(tf_image_list)\n",
        "    \n",
        "    def random_flip_up_down(self, tf_image_list, seed = (1,2)):\n",
        "        \"\"\"\n",
        "        This method flips the image up-down.\n",
        "        \"\"\"\n",
        "        return tf.image.stateless_random_flip_up_down(tf_image_list, seed)\n",
        "\n",
        "    def rotate_image_by_90_or_180_or_270_deg(self, tf_image_list, k = 1):\n",
        "        \"\"\"\n",
        "        This method rotates images by 90/180/270 degrees.\n",
        "        k = 1 : 90 degree rotation\n",
        "        k = 2 : 180 degree rotation\n",
        "        k = 3 : 270 degree rotation\n",
        "        \"\"\"\n",
        "        return tf.image.rot90(tf_image_list, k)\n",
        "\n",
        "    def rotate_image_by_angle(self, tf_image_list, angle = tf.constant(np.pi/8)):\n",
        "        \"\"\"\n",
        "        This method rotates images by a given angle.\n",
        "        \"\"\"\n",
        "        rotate_layer = tf.keras.layers.RandomRotation(0.2)\n",
        "        rotated_image = rotate_layer(tf_image_list) \n",
        "        return rotated_image    \n",
        "    \n",
        "    def random_zoom(self, tf_image_list):\n",
        "        \"\"\"\n",
        "        This method zooms the image.\n",
        "        \"\"\"\n",
        "        zoom_layer = tf.keras.layers.RandomZoom(.5, .2)\n",
        "        zoomed_image = zoom_layer(tf_image_list) \n",
        "        return zoomed_image\n",
        "\n",
        "    def random_crop(self, tf_image_list, crop_height = 16, crop_width = 16):\n",
        "        \"\"\"\n",
        "        This method randomly crops the image.\n",
        "        \"\"\"\n",
        "        crop_layer = tf.keras.layers.RandomCrop(crop_height, crop_width)\n",
        "        cropped_image = crop_layer(tf_image_list) \n",
        "        return cropped_image\n",
        "\n",
        "    def resize_with_crop_or_pad(self, tf_image_list, crop_height = 32, crop_width = 32):\n",
        "        \"\"\"\n",
        "        This method crops and resizes the central part of the image.\n",
        "        \"\"\"\n",
        "        cropped_image = tf.image.resize_with_crop_or_pad(tf_image_list, crop_height, crop_width)\n",
        "        resized_image = tf.image.resize(cropped_image, [96, 96])\n",
        "        return resized_image\n",
        "\n",
        "img_proc = image_processing()"
      ],
      "metadata": {
        "id": "o4VmIP_cNQCS"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***J. Misclenious Metric Reporting and Plotting Class***"
      ],
      "metadata": {
        "id": "GSEWn5BEN1Sz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class misc_model_functionality_processing:\n",
        "    \"\"\"\n",
        "    This class contains misclenious methods, required for model KPI or model plotting.\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        None\n",
        "    \n",
        "    def model_summary_and_display_structure(self, model):\n",
        "        \"\"\"\n",
        "        This method shows model summary and displays the model structure.\n",
        "        \"\"\"\n",
        "        model.summary()\n",
        "        tf.keras.utils.plot_model(model)\n",
        "\n",
        "    def model_save(self, model, model_name):\n",
        "        \"\"\"\n",
        "        This method saves the model in a h5 file.\n",
        "        \"\"\"\n",
        "        tf.keras.backend.clear_session()\n",
        "        model.save(model_name + '.h5')\n",
        "    \n",
        "    def model_evaluation(self, model, X_test, y_test):\n",
        "        \"\"\"\n",
        "        This method evaluates the test data for a given model.\n",
        "        \"\"\"\n",
        "        self.test_results = model.evaluate(X_test, y_test)\n",
        "        print('\\nTest Loss : {:.2f}%'.format(self.test_results[0] * 100))\n",
        "        print('\\nTest Accuracy :  {:.2f}%'.format(self.test_results[1] * 100))\n",
        "\n",
        "    def model_prediction(self, model, X_test):\n",
        "        \"\"\"\n",
        "        This method predicts for a given model.\n",
        "        \"\"\"\n",
        "        # transform logits to probabilities\n",
        "        self.pred_logits = model.predict(X_test)\n",
        "        self.probas = tf.sigmoid(self.pred_logits)\n",
        "        self.probas = self.probas.numpy().flatten() * 100\n",
        "\n",
        "    def plot_model_accuracy_and_loss(self, history, model_name):\n",
        "        \"\"\"\n",
        "        This method plots model training and validation accuracies.\n",
        "        \"\"\"\n",
        "        tf.keras.backend.clear_session()\n",
        "\n",
        "        hist = history.history\n",
        "        x_arr = np.arange(len(hist['loss'])) + 1\n",
        "        \n",
        "        plt.set_title(f\"Training and validation loss and accuracies for model : {model_name}\")\n",
        "        fig = plt.figure(figsize=(12, 4))\n",
        "        ax = fig.add_subplot(1, 2, 1)\n",
        "        ax.plot(x_arr, hist['loss'], '-o', label = 'Train loss')\n",
        "        ax.plot(x_arr, hist['val_loss'], '--<', label = 'Validation loss')\n",
        "        ax.legend(fontsize=15)\n",
        "        ax.set_xlabel('Epoch', size = 15)\n",
        "        ax.set_ylabel('Loss', size = 15)\n",
        "\n",
        "        ax = fig.add_subplot(1, 2, 2)\n",
        "        ax.plot(x_arr, hist['accuracy'], '-o', label = 'Train acc.')\n",
        "        ax.plot(x_arr, hist['val_accuracy'], '--<', label = 'Validation acc.')\n",
        "        ax.legend(fontsize = 15)\n",
        "        ax.set_xlabel('Epoch', size = 15)\n",
        "        ax.set_ylabel('Accuracy', size = 15)\n",
        "        ax.set_ylim(0,1)\n",
        "        plt.show(block = False)\n",
        "\n",
        "    def model_plot_test_vs_predicted(self, X_test, y_test, y_pred):\n",
        "        \"\"\"\n",
        "        This method plots actual vs prected results against each images.\n",
        "        \"\"\"\n",
        "        # plot test data and associated predicred\n",
        "        fig = plt.figure(figsize=(20, 20))\n",
        "        \n",
        "        for j, example in enumerate(X_test[:20]):\n",
        "            ax = fig.add_subplot(8, 4, j+1)\n",
        "            ax.set_xticks([])\n",
        "            ax.set_yticks([])\n",
        "            ax.imshow(array_to_img(example))\n",
        "            if y_test[j]==0:\n",
        "                true_label = 'No Cancer'\n",
        "            else:\n",
        "                true_label = 'Cancer'\n",
        "    \n",
        "        ax.text(\n",
        "                0.5, -0.15, \n",
        "                'True Label: {:s}\\nPr(Cancer)={:.0f}%'.format(y_test, self.probas[j]), \n",
        "                size = 16, \n",
        "                color = 'grey',\n",
        "                horizontalalignment = 'center',\n",
        "                verticalalignment = 'center', \n",
        "                transform = ax.transAxes)\n",
        "    \n",
        "        plt.tight_layout()\n",
        "        plt.show(block = False)\n",
        "    \n",
        "    def plot_model_result_confusion_matrix(self, model, y_test):\n",
        "        \"\"\"\n",
        "        This method plots confusion matrix.\n",
        "        \"\"\"\n",
        "        self.predictions_baseline = [1 if x > 50.0 else 0 for x in self.probas]\n",
        "        confusion_matrix_baseline = confusion_matrix(np.ceil(y_test).astype(int), self.predictions_baseline)\n",
        "        #plot_confusion_matrix(confusion_matrix_baseline, ['Cancer', 'No Cancer'])\n",
        "        print('ROC AUC Score = ', roc_auc_score(np.ceil(y_test).astype(int), self.predictions_baseline))\n",
        "\n",
        "        fig, ax = plot_confusion_matrix(conf_mat = confusion_matrix_baseline,\n",
        "                                       show_absolute = True,\n",
        "                                       show_normed = True,\n",
        "                                       colorbar = True,\n",
        "                                       cmap = 'Dark2')\n",
        "        plt.show(block = False)\n",
        "\n",
        "    def plot_roc_auc_curve(self, model, y_test):\n",
        "        \"\"\"\n",
        "        This method plots ROC AUC Curve.\n",
        "        \"\"\"\n",
        "        fpr_baseline, tpr_baseline, thresholds_baseline = roc_curve(np.ceil(y_test).astype(int), self.predictions_baseline)\n",
        "        auc_baseline = auc(fpr_baseline, tpr_baseline)\n",
        "        \n",
        "        plt.figure(1)\n",
        "        plt.plot([0, 1], [0, 1], 'k--')\n",
        "        plt.plot(fpr_baseline, tpr_baseline, label='area = {:.2f}'.format(auc_baseline))\n",
        "        plt.xlabel('False positive rate')\n",
        "        plt.ylabel('True positive rate')\n",
        "        plt.title('ROC Curve Baseline')\n",
        "        plt.legend(loc = 'best')\n",
        "        plt.show(block = False)\n",
        "\n",
        "    def generate_report(self, y_test):\n",
        "        \"\"\"\n",
        "        This method generates model performance report.\n",
        "        \"\"\"\n",
        "        report_baseline = classification_report(np.ceil(y_test).astype(int), self.predictions_baseline, target_names = ['No Cancer', 'Cancer'])\n",
        "        print(report_baseline)\n",
        "\n",
        "model_proc = misc_model_functionality_processing()"
      ],
      "metadata": {
        "id": "HC8mI7nSOBnZ"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***2. Data Processing***"
      ],
      "metadata": {
        "id": "GMct-xh6t74w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class data_processing:\n",
        "\n",
        "    def __init__(self):\n",
        "        self.train_file_list = []\n",
        "        self.test_file_list = []\n",
        "\n",
        "    def get_file_names_list(self):\n",
        "        \"\"\"\n",
        "    \t  This method builds the list of train and test files.\n",
        "    \t  \"\"\"\n",
        "        print()\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"Starting to build train and test file name lists...\")\n",
        "        self.train_file_list = misc_proc.get_id_and_label_list(train_files_path, image_file_extension)\n",
        "        self.test_file_list = misc_proc.get_id_and_label_list(test_files_path, image_file_extension)\n",
        "        print(f\"Length of train_file_list : {len(self.train_file_list)}\")\n",
        "        print(f\"Length of test_file_list : {len(self.test_file_list)}\")\n",
        "        print(\"Completed building train and test file name lists...\")\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"*****************************************************\")\n",
        "        print()\n",
        "\n",
        "    def get_label_info(self):\n",
        "        \"\"\"\n",
        "    \t  This method reads the train and test label information.\n",
        "    \t  \"\"\"\n",
        "        print()\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"Starting to get label info...\")\n",
        "        self.train_label = pd.read_csv(train_label_file)\n",
        "        self.test_label = pd.read_csv(test_label_file)\n",
        "        print(f\"Number of train labels : {len(self.train_label)}\")\n",
        "        print(f\"Number of test labels : {len(self.test_label)}\")\n",
        "\n",
        "        self.qualified_train_file_names_list = misc_proc.generate_fully_qualified_file_name_list(self.train_label.id.values.tolist())\n",
        "        self.qualified_test_file_names_list = misc_proc.generate_fully_qualified_file_name_list(self.test_label.id.values.tolist())\n",
        "        \n",
        "        self.train_label_positive = self.train_label[self.train_label['label'] == 1]\n",
        "        self.train_label_negative = self.train_label[self.train_label['label'] == 0]\n",
        "        print(\"Completed getting label info...\")\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"*****************************************************\")\n",
        "        print()\n",
        "\n",
        "    def create_labels(self, train_val_test_ind, data):\n",
        "        \"\"\"\n",
        "        This method creates label of given length.\n",
        "        \"\"\"\n",
        "        print()\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"*****************************************************\")\n",
        "        print(f\"Starting to create labels for {train_val_test_ind}...\")\n",
        "        if train_val_test_ind.lower() == 'train':\n",
        "            self.y_train = data['label'].values.tolist()\n",
        "        elif train_val_test_ind.lower() == 'test':\n",
        "            self.y_test = data['label'].values.tolist()\n",
        "        elif train_val_test_ind.lower() == 'validation':\n",
        "            self.y_validation = data['label'].values.tolist()        \n",
        "        print(f\"Completed building labels for {train_val_test_ind}...\")\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"*****************************************************\")\n",
        "        print()\n",
        "\n",
        "    def split_data(self):\n",
        "        \"\"\"\n",
        "    \t  This method uses train data to split into train, validation and test sets.\n",
        "    \t  The reason we are repurposing the train set is because we do not have labels for test data.\n",
        "    \t  We also see data imbalance issue and thus we are undersampling the most populated class (negative images).\n",
        "    \t  \"\"\"\n",
        "        print()\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"Starting to split data...\")\n",
        "        self.train_label_sample_positive = self.train_label_positive.head(sample_size)\n",
        "        self.train_label_sample_negative = self.train_label_negative.head(sample_size)\n",
        "        self.train_label_processed = pd.concat([self.train_label_sample_negative, \n",
        "          \t                                    self.train_label_sample_positive\n",
        "        \t                                     ], \n",
        "        \t                                     axis = 0).reset_index(drop = True)\n",
        "\n",
        "        remaining_length = len(self.train_label_positive) - len(self.train_label_sample_positive)\n",
        "        self.test_positive_df = self.train_label_positive[sample_size:]\n",
        "        self.test_negative_df = self.train_label_negative[sample_size : sample_size + remaining_length]\n",
        "        self.df_test = pd.concat([self.test_positive_df, self.test_negative_df], axis = 0).reset_index(drop = True)\n",
        "        self.df_test = shuffle(self.df_test)\n",
        "        self.create_labels(train_val_test_ind = 'test', data = self.df_test)\n",
        "\n",
        "        # shuffle\n",
        "        self.train_label_processed = shuffle(self.train_label_processed)\n",
        "        label = self.train_label_processed['label']\n",
        "        self.df_train, self.df_validation = train_test_split(self.train_label_processed, \n",
        "          \t                                                 test_size = 0.2, \n",
        "        \t                                                   random_state = 0, \n",
        "        \t                                                   stratify = label\n",
        "        \t                                                  )\n",
        "        self.create_labels(train_val_test_ind = 'train', data = self.df_train)\n",
        "        self.create_labels(train_val_test_ind = 'validation', data = self.df_validation)\n",
        "\n",
        "        print(f\"Length of df_train : {len(self.df_train)}\")\n",
        "        print(f\"Length of df_validation : {len(self.df_validation)}\")\n",
        "        print(f\"Length of df_test : {len(self.df_test)}\")\n",
        "        print(f\"Length of y_train : {len(self.y_train)}\")\n",
        "        print(f\"Length of y_validation : {len(self.y_validation)}\")\n",
        "        print(f\"Length of y_test : {len(self.y_test)}\")\n",
        "\n",
        "        print(\"Positive and negative images distribution in df_train\")\n",
        "        print(self.df_train['label'].value_counts())\n",
        "\n",
        "        print(\"Positive and negative images distribution in df_validation\")\n",
        "        print(self.df_validation['label'].value_counts())\n",
        "        \n",
        "        print(\"Positive and negative images distribution in df_test\")\n",
        "        print(self.df_test['label'].value_counts())\n",
        "\n",
        "        self.sample_positive_label = self.train_label_sample_positive['label'].values.tolist()\n",
        "        self.sample_negative_label = self.train_label_sample_negative['label'].values.tolist()\n",
        "\n",
        "        self.df_train_positive = self.df_train[self.df_train.label == 1]\n",
        "        self.df_train_negative = self.df_train[self.df_train.label == 0]\n",
        "\n",
        "        self.df_validation_positive = self.df_validation[self.df_validation.label == 1]\n",
        "        self.df_validation_negative = self.df_validation[self.df_validation.label == 0]\n",
        "\n",
        "        self.df_test_positive = self.df_test[self.df_test.label == 1]\n",
        "        self.df_test_negative = self.df_test[self.df_test.label == 0]\n",
        "\n",
        "        print(f\"Length of df_train_positive : {len(self.df_train_positive)}\")\n",
        "        print(f\"Length of df_train_positive : {len(self.df_train_positive)}\")\n",
        "\n",
        "        print(f\"Length of df_validation_positive : {len(self.df_validation_positive)}\")\n",
        "        print(f\"Length of df_validation_negative : {len(self.df_validation_negative)}\")\n",
        "\n",
        "        print(f\"Length of df_test_positive : {len(self.df_test_positive)}\")\n",
        "        print(f\"Length of df_test_negative : {len(self.df_test_negative)}\")\n",
        "\n",
        "        self.train_positive_file_list = misc_proc.generate_fully_qualified_file_name_list(self.df_train_positive.id.values.tolist())\n",
        "        self.train_negative_file_list = misc_proc.generate_fully_qualified_file_name_list(self.df_train_negative.id.values.tolist())\n",
        "\n",
        "        self.validation_positive_file_list = misc_proc.generate_fully_qualified_file_name_list(self.df_validation_positive.id.values.tolist())\n",
        "        self.validation_negative_file_list = misc_proc.generate_fully_qualified_file_name_list(self.df_validation_negative.id.values.tolist())\n",
        "\n",
        "        self.test_positive_file_list = misc_proc.generate_fully_qualified_file_name_list(self.df_test_positive.id.tolist())\n",
        "        self.test_negative_file_list = misc_proc.generate_fully_qualified_file_name_list(self.df_test_negative.id.tolist())\n",
        "\n",
        "        print(f\"Length of train_positive_file_list : {len(self.train_positive_file_list)}\")\n",
        "        print(f\"Length of train_negative_file_list : {len(self.train_negative_file_list)}\")\n",
        "\n",
        "        print(f\"Length of validation_positive_file_list : {len(self.validation_positive_file_list)}\")\n",
        "        print(f\"Length of validation_negative_file_list : {len(self.validation_negative_file_list)}\")\n",
        "\n",
        "        print(f\"Length of test_positive_file_list : {len(self.test_positive_file_list)}\")\n",
        "        print(f\"Length of test_negative_file_list : {len(self.test_negative_file_list)}\")\n",
        "\n",
        "        print(\"Completed spliting the data sets...\")\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"*****************************************************\")\n",
        "        print()\n",
        "\n",
        "    def get_data_distribution(self, train_or_test_ind):\n",
        "        \"\"\"\n",
        "     \t  This method shows the distribution of positive and negative images in the data set. \n",
        "     \t  \"\"\"\n",
        "        print()\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"*****************************************************\")\n",
        "        print(f\"Starting to get data distributions for {train_or_test_ind}...\")\n",
        "        if train_or_test_ind.lower() == 'train':\n",
        "            print(\"Data distribution in the train data set\")\n",
        "            print(self.train_label['label'].value_counts())\n",
        "            plot_proc.count_plot(data = self.train_label, \n",
        "                                 label_col = 'label',\n",
        "                                 title_val = \"Distribution of Labels in Train Data\"\n",
        "                                )\n",
        "            plot_proc.pie_chart_plot(data = self.train_label, \n",
        "                                     label_col = 'label',\n",
        "                                     title_val = \"Train Label Percentage Pie Chart\"\n",
        "                                    )\n",
        "        elif train_or_test_ind.lower() == 'test':\n",
        "            print(\"Data distribution in the test data set\")\n",
        "            print(self.test_label['label'].value_counts())  \n",
        "            plot_proc.count_plot(data = self.test_label, \n",
        "                                 label_col = 'label',\n",
        "                                 title_val = \"Distribution of Labels in Test Data\"\n",
        "                                )\n",
        "            plot_proc.pie_chart_plot(data = self.test_label, \n",
        "                                     label_col = 'label',\n",
        "                                     title_val = \"Test Label Percentage Pie Chart\"\n",
        "                                    )\n",
        "        print(f\"Completed getting data distributions for {train_or_test_ind}...\")\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"*****************************************************\")\n",
        "        print()\n",
        "\n",
        "    def check_duplicate_ids(self, train_or_test_ind):\n",
        "        \"\"\"\n",
        "    \t  This method checks if there is any duplicate ids in the data set.\n",
        "    \t  \"\"\"\n",
        "        print()\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"*****************************************************\")\n",
        "        print(f\"Starting to check duplicates for {train_or_test_ind}...\")\n",
        "        if train_or_test_ind.lower() == 'train':\n",
        "            df_train_id_count = pd.DataFrame(self.train_label.groupby(['id'])['id'].count())\n",
        "            df_train_id_count.columns = ['id_count']\n",
        "            df_train_id_count.reset_index(inplace = True)\n",
        "            print(\"Number of train duplicate entries : \", len(df_train_id_count[df_train_id_count.id_count > 1]))\n",
        "        elif train_or_test_ind.lower() == 'test':\n",
        "            df_test_id_count = pd.DataFrame(self.test_label.groupby(['id'])['id'].count())\n",
        "            df_test_id_count.columns = ['id_count']\n",
        "            df_test_id_count.reset_index(inplace = True)\n",
        "            print(\"Number of test duplicate entries : \", len(df_test_id_count[df_test_id_count.id_count > 1]))\n",
        "        print(f\"Completed checking duplicates for {train_or_test_ind}...\")\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"*****************************************************\")\n",
        "        print()\n",
        "\n",
        "    def move_files(self):\n",
        "        \"\"\"\n",
        "        This method moves the identified files to the appropriate directory.\n",
        "        \"\"\"\n",
        "        print()\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"*****************************************************\")\n",
        "        print(f\"Copying train_positive_file_list under {image_processing_train_positive_path}\")\n",
        "        misc_proc.process_copy_files(self.train_positive_file_list, image_processing_train_positive_path)\n",
        "        print(f\"Copying train_negative_file_list under {image_processing_train_negative_path}\")\n",
        "        misc_proc.process_copy_files(self.train_negative_file_list, image_processing_train_negative_path)\n",
        "\n",
        "        print(f\"File count under {image_processing_train_positive_path} is {misc_proc.check_file_count_in_a_directory(image_processing_train_positive_path)}\")\n",
        "        print(f\"File count under {image_processing_train_negative_path} is {misc_proc.check_file_count_in_a_directory(image_processing_train_negative_path)}\")\n",
        "\n",
        "        print(f\"Copying validation_positive_file_list under {image_processing_validation_positive_path}\")\n",
        "        misc_proc.process_copy_files(self.validation_positive_file_list, image_processing_validation_positive_path)\n",
        "        print(f\"Copying validation_negative_file_list under {image_processing_validation_negative_path}\")\n",
        "        misc_proc.process_copy_files(self.validation_negative_file_list, image_processing_validation_negative_path)\n",
        "\n",
        "        print(f\"File count under {image_processing_validation_positive_path} is {misc_proc.check_file_count_in_a_directory(image_processing_validation_positive_path)}\")\n",
        "        print(f\"File count under {image_processing_validation_negative_path} is {misc_proc.check_file_count_in_a_directory(image_processing_validation_negative_path)}\")\n",
        "\n",
        "        print(f\"Copying test_positive_file_list under {image_processing_test_positive_path}\")\n",
        "        misc_proc.process_copy_files(self.test_positive_file_list, image_processing_test_positive_path)\n",
        "        print(f\"Copying test_negative_file_list under {image_processing_test_negative_path}\")\n",
        "        misc_proc.process_copy_files(self.test_negative_file_list, image_processing_test_negative_path)\n",
        "\n",
        "        print(f\"File count under {image_processing_test_positive_path} is {misc_proc.check_file_count_in_a_directory(image_processing_test_positive_path)}\")\n",
        "        print(f\"File count under {image_processing_test_negative_path} is {misc_proc.check_file_count_in_a_directory(image_processing_test_negative_path)}\")\n",
        "\n",
        "        print(f\"Completed file movements...\")\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"*****************************************************\")\n",
        "        print()\n",
        "\n",
        "    def data_visualization(self, train_or_test_ind, positive_or_negative_ind, image_list, number_of_images = 5):\n",
        "        \"\"\"\n",
        "        This method visualizes the data.\n",
        "        \"\"\"\n",
        "        print()\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"*****************************************************\")\n",
        "        print(f\"Starting data visualization for {train_or_test_ind} and {positive_or_negative_ind}...\")\n",
        "        if train_or_test_ind.lower() == 'train':\n",
        "            print(f\"Displaying training {positive_or_negative_ind.lower()} images\")\n",
        "        if train_or_test_ind.lower() == 'test':\n",
        "            print(f\"Displaying test {positive_or_negative_ind.lower()} images\")\n",
        "\n",
        "        for image in image_list[:number_of_images]:\n",
        "            misc_proc.print_image_in_diff_orientation(image)\n",
        "            plt.show(block = False)\n",
        "\n",
        "        print(f\"Completed getting data visualizations for {train_or_test_ind}...\")\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"*****************************************************\")\n",
        "        print()\n",
        "\n",
        "    def get_image_summary_stats(self):\n",
        "        \"\"\"\n",
        "        This method gets positive and negative images summary stats at the picture level and each color (R, G, B) channel level.\n",
        "        \"\"\"\n",
        "        print()\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"Starting to get positive and negative images summary stats...\")\n",
        "        print(\"Mean and standard deviation at center for positive train images: \", misc_proc.compute_mean_and_std(self.train_positive_file_list))\n",
        "        print(\"Mean and standard deviation at center for negative train images: \", misc_proc.compute_mean_and_std(self.train_negative_file_list))\n",
        "\n",
        "        number_of_bins = 64 \n",
        "        fig, ax = plt.subplots(1,2, sharey = True, sharex = True, figsize = (8,2), dpi = 150)\n",
        "        ax[0].hist(img_proc.read_image_file_in_np_array(self.train_positive_file_list)[:,:,:,(0,1,2)].flatten(),\n",
        "                                                        bins = number_of_bins, \n",
        "                                                        density = True);\n",
        "        ax[1].hist(img_proc.read_image_file_in_np_array(self.train_negative_file_list)[:,:,:,(0,1,2)].flatten(),\n",
        "                                                        bins = number_of_bins, \n",
        "                                                        density = True);\n",
        "\n",
        "        ax[0].set_title(\"Train positive images\");\n",
        "        ax[1].set_title(\"Train negative images\");\n",
        "\n",
        "        ax[0].set_xlabel(\"Mean brightness\")\n",
        "        ax[1].set_xlabel(\"Mean brightness\")\n",
        "        ax[0].set_ylabel(\"Relative frequency\")\n",
        "        ax[1].set_ylabel(\"Relative frequency\");\n",
        "\n",
        "        print(\"Average across red, green and blue channels for Train positive images\")\n",
        "        print(np.mean(img_proc.read_image_file_in_np_array(self.train_positive_file_list), axis = (0,1,2)))\n",
        "        print(\"Standard Deviation across red, green and blue channels for Train positive images\")\n",
        "        print(np.std(img_proc.read_image_file_in_np_array(self.train_positive_file_list), axis = (0,1,2)))\n",
        "\n",
        "        print(\"Average across red, green and blue channels for Train X_train_img_file_negative images\")\n",
        "        print(np.mean(img_proc.read_image_file_in_np_array(self.train_negative_file_list), axis = (0,1,2)))\n",
        "        print(\"Standard Deviation across red, green and blue channels for Train X_train_img_file_negative images\")\n",
        "        print(np.std(img_proc.read_image_file_in_np_array(self.train_negative_file_list), axis = (0,1,2)))\n",
        "\n",
        "        print(f\"Completed get positive and negative images summary stats...\")\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"*****************************************************\")\n",
        "        print()\n",
        "\n",
        "    def data_processing_pipeline(self):\n",
        "        \"\"\"\n",
        "        This method performs required data processing steps.\n",
        "        \"\"\"\n",
        "        print()\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"Starting data processing pipeline...\")\n",
        "        self.get_file_names_list()\n",
        "        self.get_label_info()\n",
        "        self.check_duplicate_ids('train')\n",
        "        self.check_duplicate_ids('test')\n",
        "        self.get_data_distribution('train')\n",
        "        self.get_data_distribution('test')\n",
        "        self.split_data()\n",
        "        self.get_image_summary_stats()\n",
        "        #self.move_files()\n",
        "        print(\"Completed data processing pipeline...\")\n",
        "        print()\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"*****************************************************\")\n",
        "\n",
        "data_proc = data_processing()\n",
        "data_proc.data_processing_pipeline()\n",
        "data_proc.data_visualization(train_or_test_ind = 'train', positive_or_negative_ind = 'positive', image_list = data_proc.train_positive_file_list)\n",
        "data_proc.data_visualization(train_or_test_ind = 'train', positive_or_negative_ind = 'negative', image_list = data_proc.train_negative_file_list)\n",
        "\n"
      ],
      "metadata": {
        "id": "9ASpSKwV7EnJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "49484fb3-5ea5-4438-e50c-8bd8152c5146"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "*****************************************************\n",
            "*****************************************************\n",
            "Starting data processing pipeline...\n",
            "\n",
            "*****************************************************\n",
            "*****************************************************\n",
            "Starting to build train and test file name lists...\n",
            "Length of train_file_list : 220025\n",
            "Length of test_file_list : 57458\n",
            "Completed building train and test file name lists...\n",
            "*****************************************************\n",
            "*****************************************************\n",
            "\n",
            "\n",
            "*****************************************************\n",
            "*****************************************************\n",
            "Starting to get label info...\n",
            "Number of train labels : 220025\n",
            "Number of test labels : 57458\n",
            "Completed getting label info...\n",
            "*****************************************************\n",
            "*****************************************************\n",
            "\n",
            "\n",
            "*****************************************************\n",
            "*****************************************************\n",
            "Starting to check duplicates for train...\n",
            "Number of train duplicate entries :  0\n",
            "Completed checking duplicates for train...\n",
            "*****************************************************\n",
            "*****************************************************\n",
            "\n",
            "\n",
            "*****************************************************\n",
            "*****************************************************\n",
            "Starting to check duplicates for test...\n",
            "Number of test duplicate entries :  0\n",
            "Completed checking duplicates for test...\n",
            "*****************************************************\n",
            "*****************************************************\n",
            "\n",
            "\n",
            "*****************************************************\n",
            "*****************************************************\n",
            "Starting to get data distributions for train...\n",
            "Data distribution in the train data set\n",
            "0    130908\n",
            "1     89117\n",
            "Name: label, dtype: int64\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"aa0e0f84-c582-465a-8927-096e312d7d18\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"aa0e0f84-c582-465a-8927-096e312d7d18\")) {                    Plotly.newPlot(                        \"aa0e0f84-c582-465a-8927-096e312d7d18\",                        [{\"domain\":{\"x\":[0.0,1.0],\"y\":[0.0,1.0]},\"hovertemplate\":\"label=%{label}<br>value=%{value}<extra></extra>\",\"labels\":[0,1],\"legendgroup\":\"\",\"name\":\"\",\"showlegend\":true,\"values\":[130908,89117],\"type\":\"pie\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60},\"title\":{\"text\":\"Train Label Percentage Pie Chart\",\"y\":0.99,\"x\":0.5,\"xanchor\":\"center\",\"yanchor\":\"top\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('aa0e0f84-c582-465a-8927-096e312d7d18');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed getting data distributions for train...\n",
            "*****************************************************\n",
            "*****************************************************\n",
            "\n",
            "\n",
            "*****************************************************\n",
            "*****************************************************\n",
            "Starting to get data distributions for test...\n",
            "Data distribution in the test data set\n",
            "0    57458\n",
            "Name: label, dtype: int64\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"35f21724-ba30-4306-91a5-3b9e30db5699\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"35f21724-ba30-4306-91a5-3b9e30db5699\")) {                    Plotly.newPlot(                        \"35f21724-ba30-4306-91a5-3b9e30db5699\",                        [{\"domain\":{\"x\":[0.0,1.0],\"y\":[0.0,1.0]},\"hovertemplate\":\"label=%{label}<br>value=%{value}<extra></extra>\",\"labels\":[0],\"legendgroup\":\"\",\"name\":\"\",\"showlegend\":true,\"values\":[57458],\"type\":\"pie\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60},\"title\":{\"text\":\"Test Label Percentage Pie Chart\",\"y\":0.99,\"x\":0.5,\"xanchor\":\"center\",\"yanchor\":\"top\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('35f21724-ba30-4306-91a5-3b9e30db5699');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed getting data distributions for test...\n",
            "*****************************************************\n",
            "*****************************************************\n",
            "\n",
            "\n",
            "*****************************************************\n",
            "*****************************************************\n",
            "Starting to split data...\n",
            "\n",
            "*****************************************************\n",
            "*****************************************************\n",
            "Starting to create labels for test...\n",
            "Completed building labels for test...\n",
            "*****************************************************\n",
            "*****************************************************\n",
            "\n",
            "\n",
            "*****************************************************\n",
            "*****************************************************\n",
            "Starting to create labels for train...\n",
            "Completed building labels for train...\n",
            "*****************************************************\n",
            "*****************************************************\n",
            "\n",
            "\n",
            "*****************************************************\n",
            "*****************************************************\n",
            "Starting to create labels for validation...\n",
            "Completed building labels for validation...\n",
            "*****************************************************\n",
            "*****************************************************\n",
            "\n",
            "Length of df_train : 120000\n",
            "Length of df_validation : 30000\n",
            "Length of df_test : 28234\n",
            "Length of y_train : 120000\n",
            "Length of y_validation : 30000\n",
            "Length of y_test : 28234\n",
            "Positive and negative images distribution in df_train\n",
            "1    60000\n",
            "0    60000\n",
            "Name: label, dtype: int64\n",
            "Positive and negative images distribution in df_validation\n",
            "1    15000\n",
            "0    15000\n",
            "Name: label, dtype: int64\n",
            "Positive and negative images distribution in df_test\n",
            "0    14117\n",
            "1    14117\n",
            "Name: label, dtype: int64\n",
            "Length of df_train_positive : 60000\n",
            "Length of df_train_positive : 60000\n",
            "Length of df_validation_positive : 15000\n",
            "Length of df_validation_negative : 15000\n",
            "Length of df_test_positive : 14117\n",
            "Length of df_test_negative : 14117\n",
            "Length of train_positive_file_list : 60000\n",
            "Length of train_negative_file_list : 60000\n",
            "Length of validation_positive_file_list : 15000\n",
            "Length of validation_negative_file_list : 15000\n",
            "Length of test_positive_file_list : 14117\n",
            "Length of test_negative_file_list : 14117\n",
            "Completed spliting the data sets...\n",
            "*****************************************************\n",
            "*****************************************************\n",
            "\n",
            "\n",
            "*****************************************************\n",
            "*****************************************************\n",
            "Starting to get positive and negative images summary stats...\n",
            "Mean and standard deviation at center for positive train images:  (160.21068888888888, 58.09088281088225)\n"
          ]
        }
      ]
    }
  ]
}