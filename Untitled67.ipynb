{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "5dlGr3VX6DyA",
        "UQBd_dFh6S1S",
        "Iv-y8vdS62gV",
        "xM_Fw_tt7EpU",
        "qSyqwXIMIp7t",
        "2C55GxBKnW3V",
        "JLAsViNZnt1V",
        "0mavHZlbpFpR",
        "gmTSA20Vr0Pp"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/srilamaiti/SM_MIDS_W207_HW/blob/main/Untitled67.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***1. Setup***"
      ],
      "metadata": {
        "id": "NUylKvIS6Lsf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***A. Installing New Libraries***"
      ],
      "metadata": {
        "id": "5dlGr3VX6DyA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kAIyFDyH5uLR",
        "outputId": "61476185-8922-4bf2-e2fe-0b4d57b4a4d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: imgaug in /usr/local/lib/python3.7/dist-packages (0.4.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from imgaug) (1.15.0)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.7/dist-packages (from imgaug) (2.9.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from imgaug) (1.7.3)\n",
            "Requirement already satisfied: scikit-image>=0.14.2 in /usr/local/lib/python3.7/dist-packages (from imgaug) (0.18.3)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from imgaug) (1.21.6)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from imgaug) (7.1.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from imgaug) (3.2.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from imgaug) (4.6.0.66)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.7/dist-packages (from imgaug) (1.8.5.post1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.2->imgaug) (2.6.3)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.2->imgaug) (2021.11.2)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.2->imgaug) (1.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug) (0.11.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->imgaug) (4.1.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install imgaug"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install livelossplot"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91Xb-Plzo2E5",
        "outputId": "7bd19a96-4cce-4d62-99a2-10ea89a3b33d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: livelossplot in /usr/local/lib/python3.7/dist-packages (0.5.5)\n",
            "Requirement already satisfied: numpy<1.22 in /usr/local/lib/python3.7/dist-packages (from livelossplot) (1.21.6)\n",
            "Requirement already satisfied: bokeh in /usr/local/lib/python3.7/dist-packages (from livelossplot) (2.3.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from livelossplot) (3.2.2)\n",
            "Requirement already satisfied: ipython==7.* in /usr/local/lib/python3.7/dist-packages (from livelossplot) (7.9.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython==7.*->livelossplot) (2.6.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from ipython==7.*->livelossplot) (2.0.10)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython==7.*->livelossplot) (57.4.0)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython==7.*->livelossplot) (5.1.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython==7.*->livelossplot) (4.4.2)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython==7.*->livelossplot) (0.2.0)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython==7.*->livelossplot) (4.8.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython==7.*->livelossplot) (0.7.5)\n",
            "Requirement already satisfied: jedi>=0.10 in /usr/local/lib/python3.7/dist-packages (from ipython==7.*->livelossplot) (0.18.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.10->ipython==7.*->livelossplot) (0.8.3)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython==7.*->livelossplot) (1.15.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython==7.*->livelossplot) (0.2.5)\n",
            "Requirement already satisfied: tornado>=5.1 in /usr/local/lib/python3.7/dist-packages (from bokeh->livelossplot) (6.0.4)\n",
            "Requirement already satisfied: Jinja2>=2.9 in /usr/local/lib/python3.7/dist-packages (from bokeh->livelossplot) (2.11.3)\n",
            "Requirement already satisfied: pillow>=7.1.0 in /usr/local/lib/python3.7/dist-packages (from bokeh->livelossplot) (7.1.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from bokeh->livelossplot) (4.1.1)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.7/dist-packages (from bokeh->livelossplot) (6.0)\n",
            "Requirement already satisfied: packaging>=16.8 in /usr/local/lib/python3.7/dist-packages (from bokeh->livelossplot) (21.3)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from bokeh->livelossplot) (2.8.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.9->bokeh->livelossplot) (2.0.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=16.8->bokeh->livelossplot) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->livelossplot) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->livelossplot) (0.11.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython==7.*->livelossplot) (0.7.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***B. Importing Libraries***"
      ],
      "metadata": {
        "id": "UQBd_dFh6S1S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***a. Importing General Purpose Libraries***"
      ],
      "metadata": {
        "id": "Iv-y8vdS62gV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import joblib\n",
        "import glob\n",
        "import random\n",
        "from itertools import product\n",
        "import gc\n",
        "import subprocess\n",
        "import shutil\n",
        "import copy"
      ],
      "metadata": {
        "id": "ujHcENda69HI"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***b. Importing Image Processing and Visualization Libraries***"
      ],
      "metadata": {
        "id": "xM_Fw_tt7EpU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from imutils import rotate as rotate\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "import matplotlib.patches as patches\n",
        "from matplotlib.patches import Polygon\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "from skimage.color import gray2rgb\n",
        "import skimage.io as skio\n",
        "from imgaug import augmenters as img_aug\n",
        "import imgaug as iaug"
      ],
      "metadata": {
        "id": "0NV7G1UoIi4I"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***c. Importing Sklearn Functionalities***"
      ],
      "metadata": {
        "id": "qSyqwXIMIp7t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import shuffle\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.decomposition import IncrementalPCA\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import auc\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.model_selection import StratifiedShuffleSplit"
      ],
      "metadata": {
        "id": "fUh7ts6QI8Lx"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***d. Importing Tensorflow Libraries***"
      ],
      "metadata": {
        "id": "2C55GxBKnW3V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from livelossplot import PlotLossesKeras\n",
        "\n",
        "from tensorflow.keras.layers import RandomFlip\n",
        "from tensorflow.keras.layers import RandomZoom\n",
        "from tensorflow.keras.layers import RandomRotation\n",
        "from tensorflow.keras.layers import Conv1D\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import Concatenate\n",
        "from tensorflow.keras.layers import MaxPooling1D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.layers import AveragePooling2D\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import GlobalMaxPooling2D\n",
        "from tensorflow.keras.layers import GlobalAveragePooling1D\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
        "from tensorflow.keras.layers import Lambda\n",
        "from tensorflow.keras.layers import Multiply\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.layers import Bidirectional\n",
        "from tensorflow.keras.layers import PReLU\n",
        "from keras.layers.core import Activation\n",
        "from keras.layers.convolutional import SeparableConv1D\n",
        "from keras.layers.convolutional import SeparableConv2D\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.applications.vgg19 import VGG19\n",
        "from keras.applications.densenet import *\n",
        "from keras.applications.resnet import ResNet152\n",
        "from keras.applications.nasnet import NASNetMobile\n",
        "from keras.applications.nasnet import NASNetLarge\n",
        "from keras.applications.nasnet import preprocess_input\n",
        "from keras.applications import MobileNetV2\n",
        "from keras.applications.xception import Xception\n",
        "from keras.applications.inception_v3 import *\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import array_to_img\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.preprocessing.image import save_img\n",
        "\n",
        "from tensorflow.python.ops.numpy_ops import np_config\n",
        "\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "\n",
        "from tensorflow.keras.losses import mae\n",
        "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
        "from tensorflow.keras.losses import binary_crossentropy\n",
        "\n",
        "from keras.models import Model\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from keras.models import load_model\n"
      ],
      "metadata": {
        "id": "eUXe1TURnkN5"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions download -c histopathologic-cancer-detection\n",
        "!unzip -o -qq \\*.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1NmRkYfRQkZL",
        "outputId": "8b3c710b-873e-4eae-bee5-d213e15c1c12"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/kaggle\", line 5, in <module>\n",
            "    from kaggle.cli import main\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/kaggle/__init__.py\", line 23, in <module>\n",
            "    api.authenticate()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/kaggle/api/kaggle_api_extended.py\", line 166, in authenticate\n",
            "    self.config_file, self.config_dir))\n",
            "OSError: Could not find kaggle.json. Make sure it's located in /root/.kaggle. Or use the environment method.\n",
            "unzip:  cannot find or open *.zip, *.zip.zip or *.zip.ZIP.\n",
            "\n",
            "No zipfiles found.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***C. Mounting Google Drive***"
      ],
      "metadata": {
        "id": "JLAsViNZnt1V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Required to read the data from Kaggle\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = \"/content/gdrive/MyDrive/Kaggle\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bCewn8D_n4oL",
        "outputId": "4fee1923-bed3-4945-9445-e304cbe2fd24"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***D. Downloading Data from Kaggle***"
      ],
      "metadata": {
        "id": "0mavHZlbpFpR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!bash /content/gdrive/MyDrive/Kaggle/download_kaggle_data.ksh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qxaSmgjsoxfh",
        "outputId": "a8079dab-d6a3-49fa-8db8-50872b831fa0"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading histopathologic-cancer-detection.zip to /content\n",
            "100% 6.30G/6.31G [00:28<00:00, 298MB/s]\n",
            "100% 6.31G/6.31G [00:28<00:00, 236MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***E. Defining Vartiables***"
      ],
      "metadata": {
        "id": "aZ9PZBKVtI__"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_size = 80000\n",
        "#sample_size = 500\n",
        "batch_size = 192\n",
        "#batch_size = 64\n",
        "\n",
        "image_size = 96\n",
        "number_of_splits = 8\n",
        "#number_of_splits = 5\n",
        "run_mode = ['interim_test', 'final_test']\n",
        "\n",
        "# Transfer learning model list\n",
        "transfer_learning_model_list = ['VGG16', 'VGG19', 'DenseNet201', 'InceptionV3', 'ResNet50', 'EfficientNetB7', 'MobileNet', 'Xception']\n",
        "learning_rate_list = [.01, .001, .0001, .00001]\n",
        "optimizer_list = ['sgd', 'adam']\n",
        "dropout_list = [.2, .4, .6]\n",
        "kernel_size_list = [(3,3), (4,4), (5,5)]\n",
        "dense_layer_node_list = [512, 256, 128]\n",
        "fully_conneted_layer_list = [1, 2, 3]\n",
        "epoch_list = [5, 10, 15, 20]\n",
        "\n",
        "train_path = os.getcwd() + \"/train/\"\n",
        "test_path = os.getcwd() + \"/test/\"\n",
        "\n",
        "original_input_file_list = train_path + '*.tif'\n",
        "original_output_file_list = test_path + '*.tif'\n",
        "\n",
        "current_working_dir = os.getcwd()\n",
        "\n",
        "train_label_file = 'train_labels.csv'\n",
        "test_label_file = 'sample_submission.csv'\n",
        "\n",
        "image_file_extension = '.tif'\n",
        "\n",
        "train_files_path = os.path.join(current_working_dir, train_path)\n",
        "test_files_path = os.path.join(current_working_dir, test_path)\n",
        "\n",
        "image_processing_train_positive_path = '/content/image_processing/train/positive'\n",
        "image_processing_train_negative_path = '/content/image_processing/train/negative'\n",
        "\n",
        "image_processing_validation_positive_path = '/content/image_processing/validation/positive'\n",
        "image_processing_validation_negative_path = '/content/image_processing/validation/negative'\n",
        "\n",
        "image_processing_test_positive_path = '/content/image_processing/test/positive'\n",
        "image_processing_test_negative_path = '/content/image_processing/test/negative'\n",
        "\n",
        "image_processing_train_path = \"/content/image_processing/train/\"\n",
        "image_processing_validation_path = \"/content/image_processing/validation/\"\n",
        "image_processing_test_path = \"/content/image_processing/test/\"\n",
        "\n",
        "random.seed(1)\n",
        "random_state = 1234\n",
        "\n",
        "dropout_rate = .5\n",
        "\n",
        "training_accuracy_col_list   = ['training_accuracy_k' + str(k) + '_fold_accuracy' for k in range(1, number_of_splits + 1)]\n",
        "validation_accuracy_col_list = ['validation_accuracy_k' + str(k) + '_fold_accuracy' for k in range(1, number_of_splits + 1)]\n",
        "training_loss_col_list = ['training_loss_k' + str(k) + '_fold_loss' for k in range(1, number_of_splits + 1)]\n",
        "validation_loss_col_list = ['validation_loss_k' + str(k) + '_fold_loss' for k in range(1, number_of_splits + 1)]\n",
        "consolidated_df_model_kpi = pd.DataFrame()\n",
        "\n",
        "df_model_kfold_epoch_pred_pct = pd.DataFrame()\n",
        "df_model_kfold_epoch_pred_bin = pd.DataFrame()\n",
        "\n",
        "saved_model_names_list = []\n",
        "\n",
        "grayscale_image_augmentation_list = ['adjust_random_brightness',\n",
        "                                     'adjust_random_contrast',\n",
        "                                     'random_flip_left_right',\n",
        "                                     'random_flip_up_down',\n",
        "                                     'rotate_image_by_angle',\n",
        "                                     'rotate_image_by_90_or_180_or_270_deg',\n",
        "                                     'random_zoom',\n",
        "                                     'resize_with_crop_or_pad'\n",
        "                                    ]"
      ],
      "metadata": {
        "id": "e4rSklTftQY-"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***F. Misclenious Processing Class***"
      ],
      "metadata": {
        "id": "m2j3vtPothqH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class misc_processing:\n",
        "    \"\"\"\n",
        "    This class contains methods for misclenious processings.\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        None\n",
        "  \n",
        "    def create_dir_structure(self, root_directory):\n",
        "        \"\"\"\n",
        "        This method creates a directory tree in the form below:-\n",
        "        image_processing--| train         |---positive\n",
        "                          |               |---negative\n",
        "                          |  \n",
        "                          | validation    |---positive\n",
        "                          |               |---negative\n",
        "                          |\n",
        "                          | test          |---positive\n",
        "                          |               |---negative\n",
        "\n",
        "        \"\"\"\n",
        "        os.makedirs(f'{root_directory}', exist_ok = True)\n",
        "        for sub_folder in ['train', 'validation', 'test']:\n",
        "            for grp in ['positive', 'negative']:\n",
        "                os.makedirs(f'{root_directory}/{sub_folder}/{grp}', exist_ok=True)\n",
        "\n",
        "    def remove_files_from_dir(self, path):\n",
        "        \"\"\"\n",
        "        This method deletes all files under a given path.\n",
        "        \"\"\"\n",
        "        print()\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"*****************************************************\")\n",
        "        print(f\"Starting to remove files under {path}...\")\n",
        "        shutil.rmtree(path)\n",
        "        os.mkdir(path)\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"*****************************************************\")\n",
        "        print()\n",
        "    \n",
        "    def generate_fully_qualified_file_name_list(self, file_list):\n",
        "        \"\"\"\n",
        "        This method generates a list of fully qualified file names.\n",
        "        \"\"\"\n",
        "        qualified_file_name_list = [os.path.join(current_working_dir, train_path) + \n",
        "                                    img + \n",
        "                                    '.tif' \n",
        "                                    for img in file_list\n",
        "                                   ]\n",
        "        return qualified_file_name_list\n",
        "\n",
        "    def print_image_original(self, image_file_list, label_list):\n",
        "        \"\"\"\n",
        "        This method prints original images.\n",
        "        \"\"\"\n",
        "        nrows, ncols = 1,4 #print first 4 images\n",
        "        f, axs = plt.subplots(nrows, ncols, figsize=(14,12))\n",
        "        for i, image in enumerate(image_file_list):\n",
        "            axs[i].imshow(array_to_img(image))\n",
        "            pf = Polygon(((32, 32), (64, 32), (64, 64), (32, 64)),\n",
        "                         fc=(0.0, 0.0, 0.0, 0.0), \n",
        "                         ec=(0.0, 0.9, 0.0 ,0.9), lw=4, linestyle='--')\n",
        "            pf.set_edgecolor('r')\n",
        "            axs[i].add_patch(pf)\n",
        "            axs[i].set(title=label_list[i])\n",
        "\n",
        "    def print_image_in_diff_orientation(self, image_file):\n",
        "        \"\"\"\n",
        "        This method prints images.\n",
        "        \"\"\"\n",
        "        tf.random.set_seed(1234)\n",
        "        fig = plt.figure(figsize=(14, 12))\n",
        "        #fig = plt.figure()\n",
        "        image = skio.imread(image_file, plugin = \"tifffile\")\n",
        "        \n",
        "        # plot original\n",
        "        ax = fig.add_subplot(1, 5, 1)\n",
        "        ax.imshow(array_to_img(image))\n",
        "        pf = Polygon(((32, 32), (64, 32), (64, 64), (32, 64)),\n",
        "                fc = (0.0, 0.0, 0.0, 0.0), \n",
        "                ec = (0.0, 0.9, 0.0 ,0.9), lw=4, linestyle='--')\n",
        "        pf.set_edgecolor('r')\n",
        "        ax.add_patch(pf)\n",
        "        ax.set_title('Original', size=15);\n",
        "        \n",
        "        # resize\n",
        "        ax = fig.add_subplot(1, 5, 2)\n",
        "        img_resize = tf.image.resize(image, size=(224, 224))\n",
        "        ax.imshow(array_to_img(img_resize))\n",
        "        pf = Polygon(((80, 80), (144, 80), (144, 144), (80, 144)),\n",
        "                fc = (0.0, 0.0, 0.0, 0.0), \n",
        "                ec = (0.0, 0.9, 0.0 ,0.9), lw=4, linestyle='--')\n",
        "        pf.set_edgecolor('r')\n",
        "        ax.add_patch(pf)\n",
        "        ax.set_title('Step 1: Resize', size=15);\n",
        "        \n",
        "        # adjust brightness\n",
        "        ax = fig.add_subplot(1, 5, 3)\n",
        "        img_bright = tf.image.adjust_brightness(img_resize, 0.3)\n",
        "        ax.imshow(array_to_img(img_bright))\n",
        "        pf = Polygon(((80, 80), (144, 80), (144, 144), (80, 144)),\n",
        "                fc = (0.0, 0.0, 0.0, 0.0), \n",
        "                ec = (0.0, 0.9, 0.0 ,0.9), lw=4, linestyle='--')\n",
        "        pf.set_edgecolor('r')\n",
        "        ax.add_patch(pf)\n",
        "        ax.set_title('Step 2: Brightness', size=15);\n",
        "        \n",
        "        # adjust contrast\n",
        "        ax = fig.add_subplot(1, 5, 4)\n",
        "        img_contrast = tf.image.adjust_contrast(img_bright, contrast_factor=3)\n",
        "        ax.imshow(array_to_img(img_contrast))\n",
        "        pf = Polygon(((80, 80), (144, 80), (144, 144), (80, 144)),\n",
        "                fc = (0.0, 0.0, 0.0, 0.0), \n",
        "                ec = (0.0, 0.9, 0.0 ,0.9), lw=4, linestyle='--')\n",
        "        pf.set_edgecolor('r')\n",
        "        ax.add_patch(pf)\n",
        "        ax.set_title('Step 3: Contrast', size=15);\n",
        "        \n",
        "        # flip left right\n",
        "        ax = fig.add_subplot(1, 5, 5)\n",
        "        img_flip = tf.image.flip_left_right(img_contrast)\n",
        "        ax.imshow(array_to_img(img_flip))\n",
        "        pf = Polygon(((80, 80), (144, 80), (144, 144), (80, 144)),\n",
        "                fc = (0.0, 0.0, 0.0, 0.0), \n",
        "                ec = (0.0, 0.9, 0.0 ,0.9), lw=4, linestyle='--')\n",
        "        pf.set_edgecolor('r')\n",
        "        ax.add_patch(pf)\n",
        "        ax.set_title('Step 4: Flip left right');\n",
        "\n",
        "    def get_id_and_label_list(self, file_path, file_extension):\n",
        "        \"\"\"\n",
        "        This function gets the imgae id and corresponding label.\n",
        "        \"\"\"\n",
        "        file_list = []\n",
        "        for file_name in glob.glob(file_path + '*' + file_extension):\n",
        "            file_list.append(file_name)\n",
        "        return file_list\n",
        "\n",
        "    def compute_mean_and_std(self, image_file_list, r_mid_pos = 48, c_mid_pos = 48):\n",
        "        \"\"\"\n",
        "        This method computes mean and std at the center of the image.\n",
        "        \"\"\"\n",
        "        center_pixel_value_list = []\n",
        "        for image_file in image_file_list:\n",
        "            image = skio.imread(image_file, plugin = \"tifffile\")\n",
        "            center_pixel_value_list.append(image[r_mid_pos, c_mid_pos])\n",
        "        np_array_center_pixel_value = np.array(center_pixel_value_list)\n",
        "        return np.mean(np_array_center_pixel_value), np.std(np_array_center_pixel_value)\n",
        "\n",
        "    def copy_file_from_one_to_other(self, file_names, dest_path):\n",
        "        \"This method moves chunks of files in one to other.\"\n",
        "        os.system('cp -r ' + file_names + ' ' + dest_path)\n",
        "\n",
        "    def process_copy_files(self, file_name_list, dest_path):\n",
        "        \"\"\"\"\n",
        "        This method processes moving files from one dir to the other. \n",
        "        This is the master process to run actual moving in chunks.\n",
        "        \"\"\"\n",
        "        '''\n",
        "        process_chunk_size = 100\n",
        "        for idx in range(0, len(file_name_list), process_chunk_size):\n",
        "            if idx % 10000 == 0:\n",
        "                print(\"Processing index: \", idx)\n",
        "            self.copy_file_from_one_to_other(' '.join(file_name_list[idx : idx + process_chunk_size]), dest_path)\n",
        "        '''\n",
        "        for file in file_name_list:\n",
        "            shutil.copy(file, dest_path)\n",
        "    \n",
        "    def check_file_count_in_a_directory(self, dir_path):\n",
        "        \"\"\"\n",
        "        This method checks the file count in a directory\n",
        "        \"\"\"\n",
        "        cmd_string = 'ls ' + dir_path + \" | wc -l\"\n",
        "        file_count = int(subprocess.check_output(cmd_string, shell=True, text=True).strip())\n",
        "        return file_count\n",
        "\n",
        "    def get_mini_batch_data(self, image_list, mini_batch_size):\n",
        "        \"\"\"\n",
        "        This method performs as a generator to spit out data in small batches.\n",
        "        \"\"\"\n",
        "        return (image_list[idx : idx + mini_batch_size] for idx in range(0, len(image_list), mini_batch_size))\n",
        "\n",
        "    def get_aug_step_list(self):\n",
        "        \"\"\"\n",
        "        This method executes image augmentation pipeline.\n",
        "        \"\"\"\n",
        "        sometimes = lambda aug: img_aug.Sometimes(0.5, aug)\n",
        "        img_aug_seq = img_aug.Sequential(\n",
        "        [\n",
        "            # apply the following augmenters to most images\n",
        "            img_aug.Fliplr(0.5), # horizontally flip 50% of all images\n",
        "            img_aug.Flipud(0.2), # vertically flip 20% of all images\n",
        "            sometimes(img_aug.Affine(\n",
        "                scale={\"x\": (0.9, 1.1), \"y\": (0.9, 1.1)}, # scale images to 80-120% of their size, individually per axis\n",
        "                translate_percent={\"x\": (-0.1, 0.1), \"y\": (-0.1, 0.1)}, # translate by -20 to +20 percent (per axis)\n",
        "                rotate=(-10, 10), # rotate by -45 to +45 degrees\n",
        "                shear=(-5, 5), # shear by -16 to +16 degrees\n",
        "                order=[0, 1], # use nearest neighbour or bilinear interpolation (fast)\n",
        "                cval=(0, 255), # if mode is constant, use a cval between 0 and 255\n",
        "                mode=iaug.ALL # use any of scikit-image's warping modes (see 2nd image from the top for examples)\n",
        "            )),\n",
        "            # execute 0 to 5 of the following (less important) augmenters per image\n",
        "            # don't execute all of them, as that would often be way too strong\n",
        "            img_aug.SomeOf((0, 5),\n",
        "                [\n",
        "                    sometimes(img_aug.Superpixels(p_replace=(0, 1.0), n_segments=(20, 200))), # convert images into their superpixel representation\n",
        "                    img_aug.OneOf([\n",
        "                        img_aug.GaussianBlur((0, 1.0)), # blur images with a sigma between 0 and 3.0\n",
        "                        img_aug.AverageBlur(k=(3, 5)), # blur image using local means with kernel sizes between 2 and 7\n",
        "                        img_aug.MedianBlur(k=(3, 5)), # blur image using local medians with kernel sizes between 2 and 7\n",
        "                    ]),\n",
        "                    img_aug.Sharpen(alpha=(0, 1.0), lightness=(0.9, 1.1)), # sharpen images\n",
        "                    img_aug.Emboss(alpha=(0, 1.0), strength=(0, 2.0)), # emboss images\n",
        "                    # search either for all edges or for directed edges,\n",
        "                    # blend the result with the original image using a blobby mask\n",
        "                    img_aug.SimplexNoiseAlpha(img_aug.OneOf([\n",
        "                        img_aug.EdgeDetect(alpha=(0.5, 1.0)),\n",
        "                        img_aug.DirectedEdgeDetect(alpha=(0.5, 1.0), direction=(0.0, 1.0)),\n",
        "                    ])),\n",
        "                    img_aug.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.01*255), per_channel=0.5), # add gaussian noise to images\n",
        "                    img_aug.OneOf([\n",
        "                        img_aug.Dropout((0.01, 0.05), per_channel=0.5), # randomly remove up to 10% of the pixels\n",
        "                        img_aug.CoarseDropout((0.01, 0.03), size_percent=(0.01, 0.02), per_channel=0.2),\n",
        "                    ]),\n",
        "                    img_aug.Invert(0.01, per_channel=True), # invert color channels\n",
        "                    img_aug.Add((-2, 2), per_channel=0.5), # change brightness of images (by -10 to 10 of original value)\n",
        "                    img_aug.AddToHueAndSaturation((-1, 1)), # change hue and saturation\n",
        "                    # either change the brightness of the whole image (sometimes\n",
        "                    # per channel) or change the brightness of subareas\n",
        "                    img_aug.OneOf([\n",
        "                        img_aug.Multiply((0.9, 1.1), per_channel=0.5),\n",
        "                        img_aug.FrequencyNoiseAlpha(\n",
        "                            exponent=(-1, 0),\n",
        "                            first=img_aug.Multiply((0.9, 1.1), per_channel=True),\n",
        "                            second=img_aug.ContrastNormalization((0.9, 1.1))\n",
        "                        )\n",
        "                    ]),\n",
        "                    sometimes(img_aug.ElasticTransformation(alpha=(0.5, 3.5), sigma=0.25)), # move pixels locally around (with random strengths)\n",
        "                    sometimes(img_aug.PiecewiseAffine(scale=(0.01, 0.05))), # sometimes move parts of the image around\n",
        "                    sometimes(img_aug.PerspectiveTransform(scale=(0.01, 0.1)))\n",
        "                ],\n",
        "                random_order=True\n",
        "            )\n",
        "        ],\n",
        "        random_order=True\n",
        "        )\n",
        "        return img_aug_seq\n",
        "\n",
        "    def get_id_label_map(self, df, filter_list):\n",
        "        \"\"\"\n",
        "        This method generates the id and label dictionary.\n",
        "        \"\"\"\n",
        "        return {k : v for k, v in zip(df[df.id.isin(filter_list)].id.values, \n",
        "                                      df[df.id.isin(filter_list)].label.values\n",
        "                                     )\n",
        "               }\n",
        "\n",
        "    def image_data_generator(self, list_files, label_list, batch_size, augment=False):\n",
        "        \"\"\"\n",
        "        This method is a generrator function to produce mini batch of data.\n",
        "        \"\"\"\n",
        "        image_augmentation_steps = self.get_aug_step_list()\n",
        "        while True:\n",
        "            shuffle(list_files)\n",
        "            for mini_batch in self.get_mini_batch_data(list_files, batch_size):\n",
        "                X = [cv2.imread(x) for x in mini_batch]\n",
        "                y = label_list\n",
        "                if augment:\n",
        "                    aug_X = image_augmentation_steps.augment_images(X)\n",
        "                    aug_y = y\n",
        "                    X = X + aug_X\n",
        "                X = [preprocess_input(x) for x in X]\n",
        "                \n",
        "        yield np.array(X), np.array(y)\n",
        "\n",
        "misc_proc = misc_processing()\n",
        "misc_proc.create_dir_structure(root_directory = '/content/image_processing')"
      ],
      "metadata": {
        "id": "KMaqq9V4toXo"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***G. Visualization Processing Class***"
      ],
      "metadata": {
        "id": "jStvd4wGp8Ju"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class data_viz_processing:\n",
        "    \"\"\"\n",
        "    This class contains methods to display various plots.\n",
        "    \"\"\"\n",
        "    def count_plot(self, data, label_col, title_val):\n",
        "        \"\"\"\n",
        "        This method plots count plot of the input data set.\n",
        "        \"\"\"\n",
        "        sns.countplot(data = data, x = label_col)\n",
        "        plt.title(title_val)\n",
        "        plt.show(block = False)\n",
        "\n",
        "    def pie_chart_plot(self, data, label_col, title_val):\n",
        "        \"\"\"\n",
        "        This method plots pie chart based on the given data.\n",
        "        \"\"\"\n",
        "        fig = px.pie(data, \n",
        "                     values = data[label_col].value_counts().values, \n",
        "                     names = data[label_col].unique())\n",
        "        fig.update_layout(\n",
        "                      title={\n",
        "                             'text'    : title_val,\n",
        "                             'y'       : .99,\n",
        "                             'x'       :  0.5,\n",
        "                             'xanchor' : 'center',\n",
        "                             'yanchor' : 'top'\n",
        "                            }\n",
        "                          )\n",
        "        fig.show()\n",
        "        plt.show(block = False)\n",
        "\n",
        "data_viz = data_viz_processing()"
      ],
      "metadata": {
        "id": "myB5dDG2qBTr"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***H. Image Processing Class***"
      ],
      "metadata": {
        "id": "i2353h6hNEnz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class image_processing:\n",
        "    \"\"\"\n",
        "    This class contains methods for image processing.\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        None\n",
        "    \n",
        "    def read_image_file_in_np_array(self, image_list):\n",
        "        \"\"\"\n",
        "        This method reads each image file in a Numpy array and returns it.\n",
        "        \"\"\"\n",
        "        return np.asarray([skio.imread(image_file, plugin = \"tifffile\") for image_file in image_list])\n",
        "    \n",
        "    def convert_np_array_to_tensor(self, np_image_array):\n",
        "        \"\"\"\n",
        "        This method converts the numpy array representation of each image in tensor.\n",
        "        \"\"\"\n",
        "        return tf.convert_to_tensor(np_image_array, dtype = tf.float32)\n",
        "\n",
        "    def convert_int_tf_to_float(self, tf_image_list):\n",
        "        \"\"\"\n",
        "        This method converts integer TF value to float.\n",
        "        \"\"\"\n",
        "        return np.asanyarray([tf.cast(img, tf.float32) for img in tf_image_list])\n",
        "    \n",
        "    def convert_from_rgb_to_grayscale(self, tf_image_list, large_list_ind = False):\n",
        "        \"\"\"\n",
        "        This method converts color image to grayscale.\n",
        "        \"\"\"\n",
        "        if large_list_ind == False:\n",
        "            return tf.image.rgb_to_grayscale(tf_image_list) / 255.0\n",
        "        else:\n",
        "            None\n",
        "    \n",
        "    def combine_train_val(self, x_train, X_val, y_train, y_val):\n",
        "        \"\"\"\n",
        "        This method combines train and validation data, shuffles them and \n",
        "        returns back suffled data for k-fold cross validation.\n",
        "        \"\"\"\n",
        "        X_train_kfold = tf.concat([X_train, X_val] , axis = 0)\n",
        "        y_train_kfold = tf.concat([y_train, y_val] , axis = 0)\n",
        "\n",
        "        print(\"Shuffling the kfold train data...\")\n",
        "        tf.random.set_seed(1234) # for reproducibility\n",
        "    \n",
        "        test_shuffle_indices = tf.random.shuffle(tf.range(tf.shape(X_train_kfold)[0], dtype = tf.int32))\n",
        "        X_train_kfold = tf.gather(X_train_kfold, test_shuffle_indices)\n",
        "        y_train_kfold = tf.gather(y_train_kfold, test_shuffle_indices).numpy()\n",
        "        \n",
        "        print(f\"X_train_kfold shape: {X_train_kfold.shape}\")\n",
        "        print(f\"y_train_kfold shape: {y_train_kfold.shape}\")\n",
        "\n",
        "    def adjust_brightness(self, tf_image_list, delta):\n",
        "        \"\"\"\n",
        "        This method adjusts the image brightness.\n",
        "        \"\"\"\n",
        "        return tf.image.adjust_brightness(tf_image_list, delta = delta)\n",
        "\n",
        "    def adjust_random_brightness(self, tf_image_list, max_delta = .3, seed = (1,2)):\n",
        "        \"\"\"\n",
        "        This method adjusts random image brightness.\n",
        "        \"\"\"\n",
        "        return tf.image.stateless_random_brightness(tf_image_list, max_delta = max_delta, seed = seed)\n",
        "\n",
        "    def adjust_contrast(self, tf_image_list, contrast_factor):\n",
        "        \"\"\"\n",
        "        This method adjusts contrast of the image.\n",
        "        \"\"\"\n",
        "        return tf.image.adjust_contrast(tf_image_list, contrast_factor = contrast_factor)\n",
        "\n",
        "    def adjust_random_contrast(self, contrast_factor, lower = .2, upper = .5, seed = (1,2)):\n",
        "        \"\"\"\n",
        "        This method randomly contrasts images during training.\n",
        "        \"\"\"\n",
        "        return tf.image.stateless_random_contrast(contrast_factor, lower, upper, seed)\n",
        "\n",
        "    def flip_left_right(self, tf_image_list):\n",
        "        \"\"\"\n",
        "        This method applies flips the image from left to right.\n",
        "        \"\"\"\n",
        "        return tf.image.flip_left_right(tf_image_list)\n",
        "\n",
        "    def random_flip_left_right(self, tf_image_list, seed = (1,2)):\n",
        "        \"\"\"\n",
        "        This method randomly flips images left-right during training.\n",
        "        \"\"\"\n",
        "        return tf.image.stateless_random_flip_left_right(tf_image_list, seed)\n",
        "\n",
        "    def flip_up_down(self, tf_image_list):\n",
        "        \"\"\"\n",
        "        This method flips the image up-down.\n",
        "        \"\"\"\n",
        "        return tf.image.flip_up_down(tf_image_list)\n",
        "    \n",
        "    def random_flip_up_down(self, tf_image_list, seed = (1,2)):\n",
        "        \"\"\"\n",
        "        This method flips the image up-down.\n",
        "        \"\"\"\n",
        "        return tf.image.stateless_random_flip_up_down(tf_image_list, seed)\n",
        "\n",
        "    def rotate_image_by_90_or_180_or_270_deg(self, tf_image_list, k = 1):\n",
        "        \"\"\"\n",
        "        This method rotates images by 90/180/270 degrees.\n",
        "        k = 1 : 90 degree rotation\n",
        "        k = 2 : 180 degree rotation\n",
        "        k = 3 : 270 degree rotation\n",
        "        \"\"\"\n",
        "        return tf.image.rot90(tf_image_list, k)\n",
        "\n",
        "    def rotate_image_by_angle(self, tf_image_list, angle = tf.constant(np.pi/8)):\n",
        "        \"\"\"\n",
        "        This method rotates images by a given angle.\n",
        "        \"\"\"\n",
        "        rotate_layer = tf.keras.layers.RandomRotation(0.2)\n",
        "        rotated_image = rotate_layer(tf_image_list) \n",
        "        return rotated_image    \n",
        "    \n",
        "    def random_zoom(self, tf_image_list):\n",
        "        \"\"\"\n",
        "        This method zooms the image.\n",
        "        \"\"\"\n",
        "        zoom_layer = tf.keras.layers.RandomZoom(.5, .2)\n",
        "        zoomed_image = zoom_layer(tf_image_list) \n",
        "        return zoomed_image\n",
        "\n",
        "    def random_crop(self, tf_image_list, crop_height = 16, crop_width = 16):\n",
        "        \"\"\"\n",
        "        This method randomly crops the image.\n",
        "        \"\"\"\n",
        "        crop_layer = tf.keras.layers.RandomCrop(crop_height, crop_width)\n",
        "        cropped_image = crop_layer(tf_image_list) \n",
        "        return cropped_image\n",
        "\n",
        "    def resize_with_crop_or_pad(self, tf_image_list, crop_height = 32, crop_width = 32):\n",
        "        \"\"\"\n",
        "        This method crops and resizes the central part of the image.\n",
        "        \"\"\"\n",
        "        cropped_image = tf.image.resize_with_crop_or_pad(tf_image_list, crop_height, crop_width)\n",
        "        resized_image = tf.image.resize(cropped_image, [96, 96])\n",
        "        return resized_image\n",
        "\n",
        "    def image_augmentation_pipeline(self, train_image_list, test_image_list, validation_image_list):\n",
        "        \"\"\"\n",
        "        This method executes image augmentation tasks.\n",
        "        \"\"\"\n",
        "        for img_aug_func in grayscale_image_augmentation_list:\n",
        "            \n",
        "            print(\"Image augmentation function : \", img_aug_func)\n",
        "            \n",
        "            if img_aug_func == 'adjust_random_brightness':\n",
        "      \n",
        "                print(\"Handling random brightness adjustment for train_image_list\")\n",
        "                train_image_aug_list = self.adjust_random_brightness(tf_image_list = train_image_list, \n",
        "                                                                     max_delta = np.round(random.uniform(.1, .5),1)\n",
        "                                                                    )\n",
        "                gc.collect()\n",
        "                tf.keras.backend.clear_session()\n",
        "                print(f\"Shape of train_image_aug_list : {train_image_aug_list.shape}\")\n",
        "\n",
        "            elif img_aug_func == 'adjust_random_contrast':\n",
        "      \n",
        "                print(\"Handling contrast adjustment for X_train_positive_aug_tf\")\n",
        "                train_image_aug_list = self.adjust_random_contrast(tf_image_list = train_image_aug_list, \n",
        "                                                                   lower = np.round(random.uniform(.1, .3),1), \n",
        "                                                                   upper = np.round(random.uniform(.4, .6),1)\n",
        "                                                                  )\n",
        "                gc.collect()\n",
        "                tf.keras.backend.clear_session()\n",
        "                print(f\"Shape of train_image_aug_list : {train_image_aug_list.shape}\")\n",
        "\n",
        "            elif img_aug_func == 'random_flip_left_right':\n",
        "                \n",
        "                print(\"Handling random flip left and right for train_image_list\")\n",
        "                train_image_aug_list = self.random_flip_left_right(tf_image_list = train_image_aug_list)\n",
        "                gc.collect()\n",
        "                print(f\"Shape of X_train_positive_aug_tf : {train_image_aug_list.shape}\")\n",
        "\n",
        "            elif img_aug_func == 'random_flip_up_down':\n",
        "\n",
        "                print(\"Handling random flip up and down for train_image_list\")\n",
        "                train_image_aug_list = self.random_flip_up_down(tf_image_list = train_image_aug_list)\n",
        "                gc.collect()\n",
        "                tf.keras.backend.clear_session()\n",
        "                print(f\"Shape of X_train_positive_aug_tf : {train_image_aug_list.shape}\")\n",
        "\n",
        "            elif img_aug_func == 'rotate_image_by_angle':\n",
        "                \n",
        "                print(\"Handling image rotation by an angle for train_image_list\")\n",
        "                train_image_aug_list = self.rotate_image_by_angle(tf_image_list = train_image_aug_list)\n",
        "                gc.collect()\n",
        "                tf.keras.backend.clear_session()\n",
        "                print(f\"Shape of X_train_positive_aug_tf : {train_image_aug_list.shape}\")\n",
        "            \n",
        "            elif img_aug_func == 'rotate_image_by_90_or_180_or_270_deg':\n",
        "\n",
        "                print(\"Handling image rotation by 90 deg angle for train_image_list\")\n",
        "                train_image_aug_list = self.rotate_image_by_90_or_180_or_270_deg(tf_image_list = train_image_aug_list, \n",
        "                                                                                 k = random.randrange(1, 3)\n",
        "                                                                                )\n",
        "                gc.collect()\n",
        "                print(f\"Shape of X_train_positive_aug_tf : {train_image_aug_list.shape}\")\n",
        "\n",
        "            elif img_aug_func == 'random_zoom':\n",
        "\n",
        "                print(\"Handling random zoom for X_train_positive_aug_tf\")\n",
        "                train_image_aug_list = self.random_zoom(tf_image_list = train_image_aug_list)\n",
        "                gc.collect()\n",
        "                tf.keras.backend.clear_session()\n",
        "                print(f\"Shape of X_train_positive_aug_tf : {train_image_aug_list.shape}\")\n",
        "        \n",
        "            elif img_aug_func == 'resize_with_crop_or_pad':\n",
        "\n",
        "                print(\"Handling resize with crop or pad for train_image_list\")\n",
        "                train_image_aug_list = self.resize_with_crop_or_pad(tf_image_list = train_image_aug_list)\n",
        "                gc.collect()\n",
        "                print(f\"Shape of X_train_positive_aug_tf : {train_image_aug_list.shape}\")\n",
        "        \n",
        "        return train_image_aug_list\n",
        "\n",
        "img_proc = image_processing()"
      ],
      "metadata": {
        "id": "o4VmIP_cNQCS"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***I. Misclenious Model Building, Metric Reporting and Plotting Class***"
      ],
      "metadata": {
        "id": "GSEWn5BEN1Sz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class misc_model_functionality_processing:\n",
        "    \"\"\"\n",
        "    This class contains misclenious methods, required for model KPI or model plotting.\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        tf.random.set_seed(random_state)\n",
        "        np.random.seed(random_state)\n",
        "        tf.keras.backend.clear_session()\n",
        "\n",
        "    def model_summary_and_display_structure(self, model):\n",
        "        \"\"\"\n",
        "        This method shows model summary and displays the model structure.\n",
        "        \"\"\"\n",
        "        model.summary()\n",
        "        tf.keras.utils.plot_model(model)\n",
        "        plt.show(block = False)\n",
        "\n",
        "    def model_save(self, model, model_name):\n",
        "        \"\"\"\n",
        "        This method saves the model in a h5 file.\n",
        "        \"\"\"\n",
        "        tf.keras.backend.clear_session()\n",
        "        model.save(model_name + '.h5')\n",
        "    \n",
        "    def model_evaluation(self, model, X_test, y_test):\n",
        "        \"\"\"\n",
        "        This method evaluates the test data for a given model.\n",
        "        \"\"\"\n",
        "        self.test_results = model.evaluate(X_test, y_test)\n",
        "        print('\\nTest Loss : {:.2f}%'.format(self.test_results[0] * 100))\n",
        "        print('\\nTest Accuracy :  {:.2f}%'.format(self.test_results[1] * 100))\n",
        "\n",
        "    def model_prediction(self, model, X_test):\n",
        "        \"\"\"\n",
        "        This method predicts for a given model.\n",
        "        \"\"\"\n",
        "        # transform logits to probabilities\n",
        "        self.pred_logits = model.predict(X_test)\n",
        "        self.probas = tf.sigmoid(self.pred_logits)\n",
        "        self.probas = self.probas.numpy().flatten() * 100\n",
        "\n",
        "    def plot_model_accuracy_and_loss(self, history, model_name):\n",
        "        \"\"\"\n",
        "        This method plots model training and validation accuracies.\n",
        "        \"\"\"\n",
        "        tf.keras.backend.clear_session()\n",
        "\n",
        "        hist = history.history\n",
        "        x_arr = np.arange(len(hist['loss'])) + 1\n",
        "        \n",
        "        fig = plt.figure(figsize=(12, 4))\n",
        "        ax = fig.add_subplot(1, 2, 1)\n",
        "        ax.plot(x_arr, hist['loss'], '-o', label = 'Train loss')\n",
        "        ax.plot(x_arr, hist['val_loss'], '--<', label = 'Validation loss')\n",
        "        ax.legend(fontsize=15)\n",
        "        ax.set_xlabel('Epoch', size = 15)\n",
        "        ax.set_ylabel('Loss', size = 15)\n",
        "\n",
        "        ax = fig.add_subplot(1, 2, 2)\n",
        "        ax.plot(x_arr, hist['accuracy'], '-o', label = 'Train acc.')\n",
        "        ax.plot(x_arr, hist['val_accuracy'], '--<', label = 'Validation acc.')\n",
        "        ax.legend(fontsize = 15)\n",
        "        ax.set_xlabel('Epoch', size = 15)\n",
        "        ax.set_ylabel('Accuracy', size = 15)\n",
        "        ax.set_ylim(0,1)\n",
        "        plt.title(f\"Training and validation loss and accuracies for model : {model_name}\")\n",
        "        plt.show(block = False)\n",
        "\n",
        "    def build_pretained_model(self, model_name):\n",
        "        \"\"\"\n",
        "        This function utilizes transfer learning of a given model.\n",
        "        \"\"\"\n",
        "        tf.random.set_seed(random_state)\n",
        "        np.random.seed(random_state)\n",
        "        tf.keras.backend.clear_session()\n",
        "        input_shape = (image_size, image_size, 3)\n",
        "        if model_name == 'VGG19':\n",
        "            pretrained_model = VGG19(weights = 'imagenet', include_top = False, input_shape = input_shape)\n",
        "        elif model_name == 'DenseNet201':\n",
        "            pretrained_model = tf.keras.applications.densenet.DenseNet201(weights = 'imagenet', include_top = False, input_shape = input_shape)\n",
        "        elif model_name == 'ResNet50':\n",
        "            pretrained_model = tf.keras.applications.resnet50.ResNet50(weights = 'imagenet', include_top = False, input_shape = input_shape)\n",
        "        elif model_name == 'VGG16':\n",
        "            pretrained_model = VGG16(weights = 'imagenet', include_top = False, input_shape = input_shape)\n",
        "        elif model_name == 'EfficientNetB7':\n",
        "            pretrained_model = tf.keras.applications.efficientnet.EfficientNetB7(weights = 'imagenet', include_top = False, input_shape = input_shape)\n",
        "        elif model_name == 'MobileNet':\n",
        "            pretrained_model = tf.keras.applications.MobileNet(weights = 'imagenet', include_top = False, input_shape = input_shape)\n",
        "        elif model_name == 'Xception':\n",
        "            pretrained_model = tf.keras.applications.Xception(weights = 'imagenet', include_top = False, input_shape = input_shape)\n",
        "        elif model_name == 'InceptionV3':\n",
        "            pretrained_model = tf.keras.applications.InceptionV3(weights = 'imagenet', include_top = False, input_shape = input_shape)\n",
        "        self.model_summary_and_display_structure(pretrained_model)\n",
        "        return pretrained_model\n",
        "\n",
        "    def model_plot_test_vs_predicted(self, X_test, y_test, y_pred):\n",
        "        \"\"\"\n",
        "        This method plots actual vs prected results against each images.\n",
        "        \"\"\"\n",
        "        # plot test data and associated predicred\n",
        "        fig = plt.figure(figsize=(20, 20))\n",
        "        \n",
        "        for j, example in enumerate(X_test[:20]):\n",
        "            ax = fig.add_subplot(8, 4, j+1)\n",
        "            ax.set_xticks([])\n",
        "            ax.set_yticks([])\n",
        "            ax.imshow(array_to_img(example))\n",
        "            if y_test[j]==0:\n",
        "                true_label = 'No Cancer'\n",
        "            else:\n",
        "                true_label = 'Cancer'\n",
        "    \n",
        "            ax.text(\n",
        "                0.5, -0.15, \n",
        "                'True Label: {:s}\\nPr(Cancer)={:.0f}%'.format(y_test, self.probas[j]), \n",
        "                size = 16, \n",
        "                color = 'grey',\n",
        "                horizontalalignment = 'center',\n",
        "                verticalalignment = 'center', \n",
        "                transform = ax.transAxes)\n",
        "    \n",
        "        plt.tight_layout()\n",
        "        plt.show(block = False)\n",
        "    \n",
        "    def plot_model_result_confusion_matrix(self, model, y_test):\n",
        "        \"\"\"\n",
        "        This method plots confusion matrix.\n",
        "        \"\"\"\n",
        "        self.predictions_baseline = [1 if x > 50.0 else 0 for x in self.probas]\n",
        "        confusion_matrix_baseline = confusion_matrix(np.ceil(y_test).astype(int), self.predictions_baseline)\n",
        "        #plot_confusion_matrix(confusion_matrix_baseline, ['Cancer', 'No Cancer'])\n",
        "        print('ROC AUC Score = ', roc_auc_score(np.ceil(y_test).astype(int), self.predictions_baseline))\n",
        "\n",
        "        fig, ax = plot_confusion_matrix(conf_mat = confusion_matrix_baseline,\n",
        "                                       show_absolute = True,\n",
        "                                       show_normed = True,\n",
        "                                       colorbar = True,\n",
        "                                       cmap = 'Dark2')\n",
        "        plt.show(block = False)\n",
        "\n",
        "    def plot_roc_auc_curve(self, model, y_test):\n",
        "        \"\"\"\n",
        "        This method plots ROC AUC Curve.\n",
        "        \"\"\"\n",
        "        fpr_baseline, tpr_baseline, thresholds_baseline = roc_curve(np.ceil(y_test).astype(int), self.predictions_baseline)\n",
        "        auc_baseline = auc(fpr_baseline, tpr_baseline)\n",
        "        \n",
        "        plt.figure(1)\n",
        "        plt.plot([0, 1], [0, 1], 'k--')\n",
        "        plt.plot(fpr_baseline, tpr_baseline, label='area = {:.2f}'.format(auc_baseline))\n",
        "        plt.xlabel('False positive rate')\n",
        "        plt.ylabel('True positive rate')\n",
        "        plt.title('ROC Curve Baseline')\n",
        "        plt.legend(loc = 'best')\n",
        "        plt.show(block = False)\n",
        "\n",
        "    def generate_report(self, y_test):\n",
        "        \"\"\"\n",
        "        This method generates model performance report.\n",
        "        \"\"\"\n",
        "        report_baseline = classification_report(np.ceil(y_test).astype(int), self.predictions_baseline, target_names = ['No Cancer', 'Cancer'])\n",
        "        print(report_baseline)\n",
        "\n",
        "model_proc = misc_model_functionality_processing()"
      ],
      "metadata": {
        "id": "HC8mI7nSOBnZ"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***2. Data Processing***"
      ],
      "metadata": {
        "id": "GMct-xh6t74w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class data_processing:\n",
        "\n",
        "    def __init__(self, run_mode):\n",
        "        self.train_file_list = []\n",
        "        self.test_file_list = []\n",
        "        self.run_mode = run_mode\n",
        "        np.random.seed(random_state)\n",
        "                \n",
        "    def get_file_names_list(self):\n",
        "        \"\"\"\n",
        "    \t  This method builds the list of train and test files.\n",
        "        It also reads the original color images and save them with _gs extension \n",
        "        in the same path as the original image. The grayscale images will be \n",
        "        used for modeling whereas the color images are used for data \n",
        "        visualization purposes.\n",
        "    \t  \"\"\"\n",
        "        print()\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"Starting to build fully qualified train and test file name lists...\")\n",
        "        # Original input images are color which we will later convert to grascale.\n",
        "        self.train_file_color_list = misc_proc.get_id_and_label_list(train_files_path, image_file_extension)\n",
        "        self.test_file_color_list = misc_proc.get_id_and_label_list(test_files_path, image_file_extension)\n",
        "        self.train_file_list = []\n",
        "\n",
        "        # Loading the input images as grayscale images and saving them back with \n",
        "        # \"_gs\" extension to distinguish.\n",
        "        # For modeling purpose, we will use the grayscale images and \n",
        "        # for visualization purposes we will use the original color images.\n",
        "        for image_file in self.train_file_color_list:\n",
        "            img_gs = load_img(image_file, color_mode = \"grayscale\")\n",
        "            img_array_gs = img_to_array(img_gs)\n",
        "            save_img(image_file.split(\".\")[0] + '_gs' + image_file_extension, img_array_gs)\n",
        "            self.train_file_list.append(image_file.split(\".\")[0] + '_gs' + image_file_extension)\n",
        "        \n",
        "        if self.run_mode == 'interim_test':\n",
        "            print(f\"Length of train_file_list : {len(self.train_file_list)}\")\n",
        "            print(f\"Length of test_file_list : {len(self.test_file_list)}\")\n",
        "        print(\"Completed building train and test file name lists...\")\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"*****************************************************\")\n",
        "        print()\n",
        "\n",
        "    def get_label_info(self):\n",
        "        \"\"\"\n",
        "    \t  This method reads the train and test label information from \n",
        "        train_labels.csv and sample_submission.csv.\n",
        "        These files have the below structure:-\n",
        "        id and label.\n",
        "        Corresponding to the train or test id, there will be an image file \n",
        "        prssent in the respective train oo test folder.\n",
        "    \t  \"\"\"\n",
        "        print()\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"Starting to get label info...\")\n",
        "        self.train_label = pd.read_csv(train_label_file)\n",
        "        self.test_label = pd.read_csv(test_label_file)\n",
        "        if self.run_mode == 'interim_test':\n",
        "            print(f\"Number of train labels : {len(self.train_label)}\")\n",
        "            print(f\"Number of test labels : {len(self.test_label)}\")\n",
        "\n",
        "        self.qualified_train_file_names_list = misc_proc.generate_fully_qualified_file_name_list(self.train_label.id.values.tolist())\n",
        "        self.qualified_test_file_names_list = misc_proc.generate_fully_qualified_file_name_list(self.test_label.id.values.tolist())\n",
        "        \n",
        "        self.train_label_positive = self.train_label[self.train_label['label'] == 1]\n",
        "        self.train_label_negative = self.train_label[self.train_label['label'] == 0]\n",
        "        \n",
        "        print(\"Completed getting label info...\")\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"*****************************************************\")\n",
        "        print()\n",
        "\n",
        "    def create_labels(self, train_val_test_ind, data):\n",
        "        \"\"\"\n",
        "        This method creates label of given length.\n",
        "        \"\"\"\n",
        "        print()\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"*****************************************************\")\n",
        "        print(f\"Starting to create labels for {train_val_test_ind}...\")\n",
        "        if train_val_test_ind.lower() == 'train':\n",
        "            self.y_train = np.asarray(data['label'].values.tolist())\n",
        "        elif train_val_test_ind.lower() == 'test':\n",
        "            self.y_test = np.asarray(data['label'].values.tolist())\n",
        "        elif train_val_test_ind.lower() == 'validation':\n",
        "            self.y_validation = np.asarray(data['label'].values.tolist())    \n",
        "        print(f\"Completed building labels for {train_val_test_ind}...\")\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"*****************************************************\")\n",
        "        print()\n",
        "\n",
        "    def split_data_based_on_indices(self, train_indices, validation_indices):\n",
        "        \"\"\"\n",
        "        This method splits data based on indices.\n",
        "        \"\"\"\n",
        "        print()\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"Starting to split data based on indices...\")\n",
        "        # New train and validation set and corresponding labels based on the kfold split process generated indices.\n",
        "        self.df_train = self.df_train_original.iloc[train_indices]\n",
        "        self.df_validation = self.df_train_original.iloc[validation_indices]\n",
        "        self.create_labels(train_val_test_ind = 'train', data = self.df_train)\n",
        "        self.create_labels(train_val_test_ind = 'validation', data = self.df_validation)\n",
        "        \n",
        "        if self.run_mode == 'interim_test':\n",
        "            print(f\"Length of train data : {len(self.df_train)}, length of validation data : {len(self.df_validation)}, length of test data : {len(self.df_test)}\")\n",
        "            print(f\"Length of train positive data : {len(self.df_train[self.df_train.label == 1])}, length of validation positive data : {len(self.df_validation[self.df_validation.label == 1])}, length of test positive data : {len(self.df_test[self.df_test.label == 1])}\")\n",
        "            print(f\"Length of train negative data : {len(self.df_train[self.df_train.label == 0])}, length of validation negative data : {len(self.df_validation[self.df_validation.label == 0])}, length of test negative data : {len(self.df_test[self.df_test.label == 0])}\")\n",
        "        \n",
        "        \"\"\"\n",
        "        Both df_train and df_validation have three columns id, id_gs and label.\n",
        "        id is the original color file name without extension and id_gs is the\n",
        "        grayscale file name, derived off id column along with a \"_gs\" suffix.\n",
        "        For modeling purpose, we will use the _gs file and for data visulaization\n",
        "        purposes, we will use the original color images.\n",
        "        Thus, to move the files in a different directory, we will move the \n",
        "        grayscale images.\n",
        "        \"\"\"\n",
        "        misc_proc.remove_files_from_dir(image_processing_train_positive_path)\n",
        "        misc_proc.remove_files_from_dir(image_processing_train_negative_path)\n",
        "        self.train_positive_file_list = misc_proc.generate_fully_qualified_file_name_list(self.df_train[self.df_train.label == 1].id_gs.values.tolist())\n",
        "        self.train_negative_file_list = misc_proc.generate_fully_qualified_file_name_list(self.df_train[self.df_train.label == 0].id_gs.values.tolist())\n",
        "        print(f\"Copying test_positive_file_list under {image_processing_train_positive_path}\")\n",
        "        misc_proc.process_copy_files(self.train_positive_file_list, image_processing_train_positive_path)\n",
        "        print(f\"Copying test_negative_file_list under {image_processing_train_negative_path}\")\n",
        "        misc_proc.process_copy_files(self.train_negative_file_list, image_processing_train_negative_path)\n",
        "        print(f\"File count under {image_processing_train_positive_path} after moving new files is: {misc_proc.check_file_count_in_a_directory(image_processing_train_positive_path)}\")\n",
        "        print(f\"File count under {image_processing_train_negative_path} after moving new files is : {misc_proc.check_file_count_in_a_directory(image_processing_train_negative_path)}\")\n",
        "        \n",
        "        misc_proc.remove_files_from_dir(image_processing_validation_positive_path)\n",
        "        misc_proc.remove_files_from_dir(image_processing_validation_negative_path)\n",
        "        self.validation_positive_file_list = misc_proc.generate_fully_qualified_file_name_list(self.df_validation[self.df_validation.label == 1].id_gs.values.tolist())\n",
        "        self.validation_negative_file_list = misc_proc.generate_fully_qualified_file_name_list(self.df_validation[self.df_validation.label == 0].id_gs.values.tolist())\n",
        "        print(f\"Copying test_positive_file_list under {image_processing_validation_positive_path}\")\n",
        "        misc_proc.process_copy_files(self.validation_positive_file_list, image_processing_validation_positive_path)\n",
        "        print(f\"Copying test_negative_file_list under {image_processing_validation_negative_path}\")\n",
        "        misc_proc.process_copy_files(self.validation_negative_file_list, image_processing_validation_negative_path)\n",
        "        print(f\"File count under {image_processing_validation_positive_path} after moving new files is: {misc_proc.check_file_count_in_a_directory(image_processing_validation_positive_path)}\")\n",
        "        print(f\"File count under {image_processing_validation_negative_path} after moving new files is : {misc_proc.check_file_count_in_a_directory(image_processing_validation_negative_path)}\")\n",
        "            \n",
        "        print(\"Completed spliting the data sets based on indices...\")\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"*****************************************************\")\n",
        "        print()\n",
        "\n",
        "    def initial_split_data(self):\n",
        "        \"\"\"\n",
        "    \t  This method uses train data to split into train, validation and test sets.\n",
        "    \t  The reason we are repurposing the train set is because we do not have labels for test data.\n",
        "    \t  We also see data imbalance issue and thus we are undersampling the most populated class (negative images).\n",
        "    \t  \"\"\"\n",
        "        print()\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"Starting to split data...\")\n",
        "\n",
        "        \"\"\"\n",
        "        Extracting top sample_size records from train_label_positive and \n",
        "        train_label_negative seperately and then combine them together so \n",
        "        that distribution is uniform.\n",
        "        \"\"\"\n",
        "        self.train_label_sample_positive = self.train_label_positive.head(sample_size)\n",
        "        self.train_label_sample_negative = self.train_label_negative.head(sample_size)\n",
        "        self.train_label_processed = pd.concat([self.train_label_sample_negative, \n",
        "          \t                                    self.train_label_sample_positive\n",
        "        \t                                     ], \n",
        "        \t                                     axis = 0).reset_index(drop = True)\n",
        "\n",
        "        \"\"\"\n",
        "        Getting the remaining records (length of uiverse - sample size) serves\n",
        "        as test data set. We have also made sure distribution is uniform here.\n",
        "        \"\"\"\n",
        "        '''\n",
        "        remaining_length = 50 #len(self.train_label_positive) - len(self.train_label_sample_positive)\n",
        "        self.test_positive_df = self.train_label_positive[sample_size : sample_size + remaining_length]\n",
        "        self.test_negative_df = self.train_label_negative[sample_size : sample_size + remaining_length]\n",
        "        self.df_test = pd.concat([self.test_positive_df, self.test_negative_df], axis = 0).reset_index(drop = True)\n",
        "        self.df_test = shuffle(self.df_test, random_state = random_state)\n",
        "        self.create_labels(train_val_test_ind = 'test', data = self.df_test)\n",
        "        '''\n",
        "\n",
        "        # shuffle\n",
        "        self.train_label_processed = shuffle(self.train_label_processed, random_state = random_state)\n",
        "        label = self.train_label_processed['label']\n",
        "        self.df_train, self.df_test = train_test_split(self.train_label_processed, \n",
        "          \t                                                 test_size = 0.1, \n",
        "        \t                                                   random_state = random_state, \n",
        "        \t                                                   stratify = label\n",
        "        \t                                                  )\n",
        "        self.create_labels(train_val_test_ind = 'train', data = self.df_train)\n",
        "        self.create_labels(train_val_test_ind = 'test', data = self.df_test)\n",
        "        self.df_train['id_gs'] = self.df_train['id'].apply(lambda x : x + '_gs')\n",
        "        self.df_test['id_gs']  = self.df_test['id'].apply(lambda x : x + '_gs')\n",
        "        self.df_train_original = copy.deepcopy(self.df_train)\n",
        "\n",
        "        \"\"\"\n",
        "        At this point, df_test has three columns id, id_gs and label.\n",
        "        id denotes original color image name without extension and id_gs is the\n",
        "        grayscale image name derived off id column data, suffixed with '_gs'\n",
        "        extension.\n",
        "        We will use grayscale images for all our training, so while moving the\n",
        "        images to appropriate directory, we need to move the grayscale images.\n",
        "        \"\"\"\n",
        "        self.test_positive_file_list = misc_proc.generate_fully_qualified_file_name_list(self.df_test[self.df_test.label == 1].id_gs.values.tolist())\n",
        "        self.test_negative_file_list = misc_proc.generate_fully_qualified_file_name_list(self.df_test[self.df_test.label == 0].id_gs.values.tolist())\n",
        "        print(f\"Copying test_positive_file_list under {image_processing_test_positive_path}\")\n",
        "        misc_proc.process_copy_files(self.test_positive_file_list, image_processing_test_positive_path)\n",
        "        print(f\"Copying test_negative_file_list under {image_processing_test_negative_path}\")\n",
        "        misc_proc.process_copy_files(self.test_negative_file_list, image_processing_test_negative_path)\n",
        "        print(f\"File count under {image_processing_test_positive_path} is {misc_proc.check_file_count_in_a_directory(image_processing_test_positive_path)}\")\n",
        "        print(f\"File count under {image_processing_test_negative_path} is {misc_proc.check_file_count_in_a_directory(image_processing_test_negative_path)}\")\n",
        "\n",
        "        self.sample_positive_label = self.train_label_sample_positive['label'].values.tolist()\n",
        "        self.sample_negative_label = self.train_label_sample_negative['label'].values.tolist()\n",
        "\n",
        "        self.df_train_positive = self.df_train[self.df_train.label == 1]\n",
        "        self.df_train_negative = self.df_train[self.df_train.label == 0]\n",
        "\n",
        "        self.df_test_positive = self.df_test[self.df_test.label == 1]\n",
        "        self.df_test_negative = self.df_test[self.df_test.label == 0]\n",
        "\n",
        "        # Train color files\n",
        "        self.train_positive_color_file_list = misc_proc.generate_fully_qualified_file_name_list(self.df_train_positive.id.values.tolist())\n",
        "        self.train_negative_color_file_list = misc_proc.generate_fully_qualified_file_name_list(self.df_train_negative.id.values.tolist())\n",
        "\n",
        "        # Test color files\n",
        "        self.test_positive_color_file_list = misc_proc.generate_fully_qualified_file_name_list(self.df_test_positive.id.tolist())\n",
        "        self.test_negative_color_file_list = misc_proc.generate_fully_qualified_file_name_list(self.df_test_negative.id.tolist())\n",
        "\n",
        "        # Train grayscale files\n",
        "        self.train_positive_file_list = misc_proc.generate_fully_qualified_file_name_list(self.df_train_positive.id_gs.values.tolist())\n",
        "        self.train_negative_file_list = misc_proc.generate_fully_qualified_file_name_list(self.df_train_negative.id_gs.values.tolist())\n",
        "\n",
        "        # Test grayscale files\n",
        "        self.test_positive_file_list = misc_proc.generate_fully_qualified_file_name_list(self.df_test_positive.id_gs.tolist())\n",
        "        self.test_negative_file_list = misc_proc.generate_fully_qualified_file_name_list(self.df_test_negative.id_gs.tolist())\n",
        "\n",
        "        if self.run_mode == 'interim_test':\n",
        "            \n",
        "            print(f\"Length of df_train : {len(self.df_train)}\")\n",
        "            print(f\"Length of df_test : {len(self.df_test)}\")\n",
        "            print(f\"Length of y_train : {len(self.y_train)}\")\n",
        "            print(f\"Length of y_test : {len(self.y_test)}\")\n",
        "\n",
        "            print(\"Positive and negative images distribution in df_train\")\n",
        "            print(self.df_train['label'].value_counts())\n",
        "\n",
        "            print(\"Positive and negative images distribution in df_test\")\n",
        "            print(self.df_test['label'].value_counts())\n",
        "\n",
        "            print(f\"Length of df_train_positive : {len(self.df_train_positive)}\")\n",
        "            print(f\"Length of df_train_positive : {len(self.df_train_positive)}\")\n",
        "\n",
        "            print(f\"Length of df_test_positive : {len(self.df_test_positive)}\")\n",
        "            print(f\"Length of df_test_negative : {len(self.df_test_negative)}\")\n",
        "\n",
        "            print(f\"Length of train_positive_file_list : {len(self.train_positive_file_list)}\")\n",
        "            print(f\"Length of train_negative_file_list : {len(self.train_negative_file_list)}\")\n",
        "\n",
        "            print(f\"Length of test_positive_file_list : {len(self.test_positive_file_list)}\")\n",
        "            print(f\"Length of test_negative_file_list : {len(self.test_negative_file_list)}\")\n",
        "\n",
        "        print(\"Completed spliting the data sets...\")\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"*****************************************************\")\n",
        "        print()\n",
        "\n",
        "    def get_data_distribution(self, train_or_test_ind):\n",
        "        \"\"\"\n",
        "     \t  This method shows the distribution of positive and negative images in the data set. \n",
        "     \t  \"\"\"\n",
        "        print()\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"*****************************************************\")\n",
        "        print(f\"Starting to get data distributions for {train_or_test_ind}...\")\n",
        "        if train_or_test_ind.lower() == 'train':\n",
        "            print(\"Data distribution in the train data set\")\n",
        "            print(self.train_label['label'].value_counts())\n",
        "            data_viz.count_plot(data = self.train_label, \n",
        "                                 label_col = 'label',\n",
        "                                 title_val = \"Distribution of Labels in Train Data\"\n",
        "                                )\n",
        "            data_viz.pie_chart_plot(data = self.train_label, \n",
        "                                     label_col = 'label',\n",
        "                                     title_val = \"Train Label Percentage Pie Chart\"\n",
        "                                    )\n",
        "        elif train_or_test_ind.lower() == 'test':\n",
        "            print(\"Data distribution in the test data set\")\n",
        "            print(self.test_label['label'].value_counts())  \n",
        "            data_viz.count_plot(data = self.test_label, \n",
        "                                 label_col = 'label',\n",
        "                                 title_val = \"Distribution of Labels in Test Data\"\n",
        "                                )\n",
        "            data_viz.pie_chart_plot(data = self.test_label, \n",
        "                                     label_col = 'label',\n",
        "                                     title_val = \"Test Label Percentage Pie Chart\"\n",
        "                                    )\n",
        "        print(f\"Completed getting data distributions for {train_or_test_ind}...\")\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"*****************************************************\")\n",
        "        print()\n",
        "\n",
        "    def check_duplicate_ids(self, train_or_test_ind):\n",
        "        \"\"\"\n",
        "    \t  This method checks if there is any duplicate ids in the data set.\n",
        "    \t  \"\"\"\n",
        "        print()\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"*****************************************************\")\n",
        "        print(f\"Starting to check duplicates for {train_or_test_ind}...\")\n",
        "        if train_or_test_ind.lower() == 'train':\n",
        "            df_train_id_count = pd.DataFrame(self.train_label.groupby(['id'])['id'].count())\n",
        "            df_train_id_count.columns = ['id_count']\n",
        "            df_train_id_count.reset_index(inplace = True)\n",
        "            print(\"Number of train duplicate entries : \", len(df_train_id_count[df_train_id_count.id_count > 1]))\n",
        "        elif train_or_test_ind.lower() == 'test':\n",
        "            df_test_id_count = pd.DataFrame(self.test_label.groupby(['id'])['id'].count())\n",
        "            df_test_id_count.columns = ['id_count']\n",
        "            df_test_id_count.reset_index(inplace = True)\n",
        "            print(\"Number of test duplicate entries : \", len(df_test_id_count[df_test_id_count.id_count > 1]))\n",
        "        print(f\"Completed checking duplicates for {train_or_test_ind}...\")\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"*****************************************************\")\n",
        "        print()\n",
        "\n",
        "    def data_visualization(self, train_or_test_ind, positive_or_negative_ind, image_list, number_of_images = 5):\n",
        "        \"\"\"\n",
        "        This method visualizes the data.\n",
        "        \"\"\"\n",
        "        print()\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"*****************************************************\")\n",
        "        print(f\"Starting data visualization for {train_or_test_ind} and {positive_or_negative_ind}...\")\n",
        "        if train_or_test_ind.lower() == 'train':\n",
        "            print(f\"Displaying training {positive_or_negative_ind.lower()} images\")\n",
        "        if train_or_test_ind.lower() == 'test':\n",
        "            print(f\"Displaying test {positive_or_negative_ind.lower()} images\")\n",
        "\n",
        "        for image in image_list[:number_of_images]:\n",
        "            misc_proc.print_image_in_diff_orientation(image)\n",
        "            plt.show(block = False)\n",
        "\n",
        "        print(f\"Completed getting data visualizations for {train_or_test_ind}...\")\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"*****************************************************\")\n",
        "        print()\n",
        "\n",
        "    def get_image_summary_stats(self):\n",
        "        \"\"\"\n",
        "        This method gets positive and negative images summary stats at the picture level and each color (R, G, B) channel level.\n",
        "        \"\"\"\n",
        "        print()\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"Starting to get positive and negative images summary stats...\")\n",
        "\n",
        "        # Whole image wise stats\n",
        "        print(\"Mean and standard deviation at center for positive train images: \", misc_proc.compute_mean_and_std(self.train_positive_color_file_list))\n",
        "        print(\"Mean and standard deviation at center for negative train images: \", misc_proc.compute_mean_and_std(self.train_negative_color_file_list))\n",
        "\n",
        "        number_of_bins = 64 \n",
        "        figw, axw = plt.subplots(1,2, sharey = True, sharex = True, figsize = (8,2), dpi = 150)\n",
        "        axw[0].hist(img_proc.read_image_file_in_np_array(self.train_positive_color_file_list)[:,:,:,(0,1,2)].flatten(),\n",
        "                                                        bins = number_of_bins, \n",
        "                                                        density = True);\n",
        "        axw[1].hist(img_proc.read_image_file_in_np_array(self.train_negative_color_file_list)[:,:,:,(0,1,2)].flatten(),\n",
        "                                                        bins = number_of_bins, \n",
        "                                                        density = True);\n",
        "\n",
        "        axw[0].set_title(\"Train positive images\");\n",
        "        axw[1].set_title(\"Train negative images\");\n",
        "\n",
        "        axw[0].set_xlabel(\"Mean brightness\")\n",
        "        axw[1].set_xlabel(\"Mean brightness\")\n",
        "        axw[0].set_ylabel(\"Relative frequency\")\n",
        "        axw[1].set_ylabel(\"Relative frequency\")\n",
        "        plt.show(block = False);\n",
        "\n",
        "        # Channel wise stats\n",
        "        print(\"Average across red, green and blue channels for train positive images\")\n",
        "        print(np.mean(img_proc.read_image_file_in_np_array(self.train_positive_color_file_list), axis = (0,1,2)))\n",
        "        print(\"Standard Deviation across red, green and blue channels for Train positive images\")\n",
        "        print(np.std(img_proc.read_image_file_in_np_array(self.train_positive_color_file_list), axis = (0,1,2)))\n",
        "\n",
        "        print(\"Average across red, green and blue channels for train X_train_img_file_negative images\")\n",
        "        print(np.mean(img_proc.read_image_file_in_np_array(self.train_negative_color_file_list), axis = (0,1,2)))\n",
        "        print(\"Standard Deviation across red, green and blue channels for train X_train_img_file_negative images\")\n",
        "        print(np.std(img_proc.read_image_file_in_np_array(self.train_negative_color_file_list), axis = (0,1,2)))\n",
        "\n",
        "        # Red Channel\n",
        "        figr, axr = plt.subplots(1,2, sharey = True, sharex = True, figsize = (8,2), dpi = 150)\n",
        "        axr[0].hist(img_proc.read_image_file_in_np_array(self.train_positive_color_file_list)[:,:,:,(0)].flatten(),\n",
        "                                                        bins = number_of_bins, \n",
        "                                                        density = True);\n",
        "        axr[1].hist(img_proc.read_image_file_in_np_array(self.train_negative_color_file_list)[:,:,:,(0)].flatten(),\n",
        "                                                        bins = number_of_bins, \n",
        "                                                        density = True);\n",
        "\n",
        "        axr[0].set_title(\"Train positive images\");\n",
        "        axr[1].set_title(\"Train negative images\");\n",
        "\n",
        "        axr[0].set_xlabel(\"Mean red brightness\")\n",
        "        axr[1].set_xlabel(\"Mean red brightness\")\n",
        "        axr[0].set_ylabel(\"Relative frequency\")\n",
        "        axr[1].set_ylabel(\"Relative frequency\")\n",
        "        plt.show(block = False);\n",
        "\n",
        "        # Green Channel\n",
        "        figg, axg = plt.subplots(1,2, sharey = True, sharex = True, figsize = (8,2), dpi = 150)\n",
        "        axg[0].hist(img_proc.read_image_file_in_np_array(self.train_positive_color_file_list)[:,:,:,(1)].flatten(),\n",
        "                                                        bins = number_of_bins, \n",
        "                                                        density = True);\n",
        "        axg[1].hist(img_proc.read_image_file_in_np_array(self.train_negative_color_file_list)[:,:,:,(1)].flatten(),\n",
        "                                                        bins = number_of_bins, \n",
        "                                                        density = True);\n",
        "\n",
        "        axg[0].set_title(\"Train positive images\");\n",
        "        axg[1].set_title(\"Train negative images\");\n",
        "\n",
        "        axg[0].set_xlabel(\"Mean green brightness\")\n",
        "        axg[1].set_xlabel(\"Mean green brightness\")\n",
        "        axg[0].set_ylabel(\"Relative frequency\")\n",
        "        axg[1].set_ylabel(\"Relative frequency\")\n",
        "        plt.show(block = False);\n",
        "\n",
        "        # Blue Channel\n",
        "        figb, axb = plt.subplots(1,2, sharey = True, sharex = True, figsize = (8,2), dpi = 150)\n",
        "        axb[0].hist(img_proc.read_image_file_in_np_array(self.train_positive_color_file_list)[:,:,:,(2)].flatten(),\n",
        "                                                        bins = number_of_bins, \n",
        "                                                        density = True);\n",
        "        axb[1].hist(img_proc.read_image_file_in_np_array(self.train_negative_color_file_list)[:,:,:,(2)].flatten(),\n",
        "                                                        bins = number_of_bins, \n",
        "                                                        density = True);\n",
        "\n",
        "        axb[0].set_title(\"Train positive images\");\n",
        "        axb[1].set_title(\"Train negative images\");\n",
        "\n",
        "        axb[0].set_xlabel(\"Mean blue brightness\")\n",
        "        axb[1].set_xlabel(\"Mean blue brightness\")\n",
        "        axb[0].set_ylabel(\"Relative frequency\")\n",
        "        axb[1].set_ylabel(\"Relative frequency\")\n",
        "        plt.show(block = False);\n",
        "\n",
        "        print(f\"Completed get positive and negative images summary stats...\")\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"*****************************************************\")\n",
        "        print()\n",
        "\n",
        "    def data_processing_pipeline(self):\n",
        "        \"\"\"\n",
        "        This method performs required data processing steps.\n",
        "        \"\"\"\n",
        "        print()\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"Starting data processing pipeline...\")\n",
        "        self.get_file_names_list()\n",
        "        self.get_label_info()\n",
        "        self.initial_split_data()\n",
        "        \n",
        "        if self.run_mode == 'interim_test':\n",
        "            self.check_duplicate_ids('train')\n",
        "            self.check_duplicate_ids('test')\n",
        "            self.get_data_distribution('train')\n",
        "            self.get_data_distribution('test')\n",
        "            self.get_image_summary_stats()\n",
        "            \n",
        "        #self.move_files()\n",
        "        print(\"Completed data processing pipeline...\")\n",
        "        print()\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"*****************************************************\")\n",
        "\n",
        "'''\n",
        "data_proc = data_processing(run_mode = 'final_test')\n",
        "'''\n",
        "# Used for testing\n",
        "data_proc = data_processing(run_mode = 'interim_test') \n",
        "data_proc.data_processing_pipeline()\n",
        "\n",
        "# Data visualizations\n",
        "data_proc.data_visualization(train_or_test_ind = 'train', positive_or_negative_ind = 'positive', image_list = data_proc.train_positive_color_file_list)\n",
        "data_proc.data_visualization(train_or_test_ind = 'train', positive_or_negative_ind = 'negative', image_list = data_proc.train_positive_color_file_list)"
      ],
      "metadata": {
        "id": "9ASpSKwV7EnJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8168320-220d-448a-ac9f-a71d4175ea9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "*****************************************************\n",
            "*****************************************************\n",
            "Starting data processing pipeline...\n",
            "\n",
            "*****************************************************\n",
            "*****************************************************\n",
            "Starting to build fully qualified train and test file name lists...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***3. Model Building***"
      ],
      "metadata": {
        "id": "ISUTBnGe72tT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class image_data_generator:\n",
        "    \"\"\"\n",
        "    This class defines the train, validation and test data generator functions,\n",
        "    which we will use while training and evaluating the models.\n",
        "    \"\"\"\n",
        "    def rotate_img(image):\n",
        "        return np.rot90(image, np.random.choice([-1, 0, 1, 2]))\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        This constructor class initializes the train, validation and test \n",
        "        image generators.\n",
        "        Train data generators include data augmentation functionalities.\n",
        "        Test and validation data generators are just normalized.\n",
        "        \"\"\"\n",
        "        tf.keras.backend.clear_session()\n",
        "        gc.collect()\n",
        "        # Train data generator\n",
        "        self.train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "                        rescale = 1./255,\n",
        "                        zoom_range = 0.1,\n",
        "                        horizontal_flip = True,\n",
        "                        vertical_flip = True,\n",
        "                        preprocessing_function = self.rotate_img,\n",
        "                        brightness_range = [0.4, 1.2]\n",
        "                       )\n",
        "        # Validation data generator\n",
        "        self.val_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "        # Test data generator\n",
        "        self.test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "img_data_gen = image_data_generator()"
      ],
      "metadata": {
        "id": "fMFcUaFNIuky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "tf.keras.backend.clear_session()\n",
        "gc.collect()\n",
        "\n",
        "def rotate_img(image):\n",
        "    return np.rot90(image, np.random.choice([-1, 0, 1, 2]))\n",
        "\n",
        "# Generators\n",
        "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    rescale = 1./255,\n",
        "    zoom_range = 0.1,\n",
        "    horizontal_flip = True,\n",
        "    vertical_flip = True,\n",
        "    rotation_range = 180,\n",
        "    width_shift_range = 0.3,\n",
        "    height_shift_range = 0.3,\n",
        "    shear_range = 0.3,\n",
        "    brightness_range = [0.4, 1.2],\n",
        "    preprocessing_function=lambda x: x[..., np.random.permutation([1, 2, 3, 4, 5, 6, 7, 8])]\n",
        ")\n",
        "\n",
        "'''\n",
        "(rescale = 1./255,\n",
        "                                       horizontal_flip = True,\n",
        "                                       vertical_flip = True,\n",
        "                                       rotation_range = 180,\n",
        "                                       zoom_range = 0.4, \n",
        "                                       width_shift_range = 0.3,\n",
        "                                       height_shift_range = 0.3,\n",
        "                                       shear_range = 0.3,\n",
        "                                       channel_shift_range = 0.3\n",
        "                                      )\n",
        "'''\n",
        "\n",
        "val_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale = 1./255)\n",
        "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale = 1./255)\n"
      ],
      "metadata": {
        "id": "2L3l2U-LhC1-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "class custom_generator(tf.keras.utils.Sequence) :\n",
        "  \n",
        "    def __init__(self, images, labels, batch_size) :\n",
        "        self.images = images\n",
        "        self.labels = labels\n",
        "        self.batch_size = batch_size\n",
        "    \n",
        "    \n",
        "    def __len__(self) :\n",
        "        return (np.ceil(len(self.images) / float(self.batch_size))).astype(np.int)\n",
        "  \n",
        "  \n",
        "    def __getitem__(self, idx) :\n",
        "        with tf.device('/cpu:0'): \n",
        "            batch_x = self.images[idx * self.batch_size : (idx+1) * self.batch_size]\n",
        "            batch_y = self.labels[idx * self.batch_size : (idx+1) * self.batch_size]\n",
        "    \n",
        "        return batch_x, batch_y\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "gaahAuOELfQH",
        "outputId": "c8d598e6-d7db-472d-bb2f-61c91ec33f20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nclass custom_generator(tf.keras.utils.Sequence) :\\n  \\n    def __init__(self, images, labels, batch_size) :\\n        self.images = images\\n        self.labels = labels\\n        self.batch_size = batch_size\\n    \\n    \\n    def __len__(self) :\\n        return (np.ceil(len(self.images) / float(self.batch_size))).astype(np.int)\\n  \\n  \\n    def __getitem__(self, idx) :\\n        with tf.device('/cpu:0'): \\n            batch_x = self.images[idx * self.batch_size : (idx+1) * self.batch_size]\\n            batch_y = self.labels[idx * self.batch_size : (idx+1) * self.batch_size]\\n    \\n        return batch_x, batch_y\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temp_df_model_kfold_epoch_train_accuracy = pd.DataFrame()\n",
        "temp_df_model_kfold_epoch_train_loss = pd.DataFrame()\n",
        "temp_df_model_kfold_epoch_validation_accuracy = pd.DataFrame()\n",
        "temp_df_model_kfold_epoch_validation_loss = pd.DataFrame()\n",
        "temp_consolidated_df_model_kpi = pd.DataFrame()\n",
        "consolidated_df_model_kpi = pd.DataFrame()\n",
        "temp_df_acttual_vs_pred_bin_pred_pct = pd.DataFrame()\n",
        "df_actual_vs_pred_bin_pred_pct = pd.DataFrame()\n",
        "\n",
        "temp_list_prob_logits_and_bin = []\n",
        "\n",
        "epochs = 10\n",
        "for model_name in transfer_learning_model_list:\n",
        "\n",
        "    temp_df_model_kfold_epoch_train_accuracy = pd.DataFrame()\n",
        "    temp_df_model_kfold_epoch_train_loss = pd.DataFrame()\n",
        "    temp_df_model_kfold_epoch_validation_accuracy = pd.DataFrame()\n",
        "    temp_df_model_kfold_epoch_validation_loss = pd.DataFrame()\n",
        "    temp_consolidated_df_model_kpi = pd.DataFrame()\n",
        "    for kfold, (train_indices, validation_indices) in enumerate(StratifiedKFold(n_splits =  number_of_splits, \n",
        "                                                                                shuffle = True, \n",
        "                                                                                random_state = random_state\n",
        "                                                                               ).split(data_proc.df_train_original['label'].values.tolist(), \n",
        "                                                                                       data_proc.df_train_original['label'].values.tolist()\n",
        "                                                                                      )):\n",
        "        print(f\"Model : {model_name}, k-fold : {kfold + 1}, length of train data : {len(train_indices)}, length of validation data : {len(validation_indices)}\")\n",
        "        data_proc.split_data_based_on_indices(train_indices = train_indices, validation_indices = validation_indices)\n",
        "\n",
        "        train_dataset_from_data_generator = train_datagen.flow_from_directory(image_processing_train_path,\n",
        "                                                                     target_size = (image_size, image_size),\n",
        "                                                                     class_mode = 'binary',\n",
        "                                                                     batch_size = batch_size,\n",
        "                                                                     color_mode = 'rgb',\n",
        "                                                                     shuffle = True,\n",
        "                                                                     seed = random_state\n",
        "                                                                    )\n",
        "        validation_dataset_from_data_generator = val_datagen.flow_from_directory(image_processing_validation_path,\n",
        "                                                                 target_size = (image_size, image_size),\n",
        "                                                                 class_mode = 'binary',\n",
        "                                                                 batch_size = batch_size,\n",
        "                                                                 color_mode = 'rgb',\n",
        "                                                                 shuffle = True,\n",
        "                                                                 seed = random_state\n",
        "                                                                )\n",
        "        test_dataset_from_data_generator = test_datagen.flow_from_directory(image_processing_test_path,\n",
        "                                                                   target_size = (image_size, image_size),\n",
        "                                                                   batch_size = batch_size,\n",
        "                                                                   class_mode = 'binary',\n",
        "                                                                   color_mode = 'rgb',\n",
        "                                                                   shuffle = False,\n",
        "                                                                   seed = random_state\n",
        "                                                                  )\n",
        "        \n",
        "        tf.random.set_seed(random_state)\n",
        "        np.random.seed(random_state)\n",
        "\n",
        "        # Pre-trained model build\n",
        "        print(f\"Building pretainined model for {model_name}\")\n",
        "        try:\n",
        "            del pretrained_model\n",
        "        except:\n",
        "            None\n",
        "        pretrained_model = model_proc.build_pretained_model(model_name = model_name)\n",
        "        pretrained_model.trainable = False\n",
        "        \n",
        "        # Plug the pre-trained model to custom model\n",
        "        print(f\"Plugging in the pretainined model for {model_name} to custom model\")\n",
        "        try:\n",
        "            del model\n",
        "        except:\n",
        "            None\n",
        "        input_shape = (image_size, image_size, 3)\n",
        "        inputs = tf.keras.Input(input_shape)\n",
        "        m2 = tf.keras.layers.GlobalAveragePooling2D()(pretrained_model(inputs))\n",
        "        m2 = tf.keras.layers.Dropout(dropout_rate)(m2)\n",
        "        m2 = tf.keras.layers.Dense(256, activation = 'relu')(m2)\n",
        "        m2 = tf.keras.layers.BatchNormalization()(m2)\n",
        "        m2 = tf.keras.layers.Dropout(dropout_rate)(m2)\n",
        "        m2 = tf.keras.layers.Flatten()(m2)\n",
        "        m2 = tf.keras.layers.Dense(1, activation = None)(m2)\n",
        "        model = tf.keras.Model(inputs = inputs, outputs = m2)\n",
        "        \n",
        "        # Model compile\n",
        "        print(\"Compiling the model...\")\n",
        "        model.compile(optimizer = 'adam',\n",
        "                      loss = tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "                      metrics = ['accuracy']) \n",
        "\n",
        "        # Model fit\n",
        "        print(\"Model fit...\")\n",
        "        es = EarlyStopping(monitor = 'val_loss', mode = 'min', verbose = 1, min_delta = 1)\n",
        "        history = model.fit(train_dataset_from_data_generator,\n",
        "                            epochs = epochs,\n",
        "                            steps_per_epoch = len(train_dataset_from_data_generator),\n",
        "                            validation_data = validation_dataset_from_data_generator,\n",
        "                            validation_steps = len(validation_dataset_from_data_generator),\n",
        "                            verbose = 1,\n",
        "                            callbacks = [es]\n",
        "                           )\n",
        "\n",
        "        # Model save\n",
        "        print(\"Saving model...\")\n",
        "        tf.keras.backend.clear_session()\n",
        "        gc.collect()\n",
        "        model.save('tumor_detection_' + model_name + '_k' + str(kfold) + '.h5')\n",
        "        #tf.saved_model.save(model, os.getcwd())\n",
        "        saved_model_names_list.append('tumor_detection_' + model_name + '_k' + str(kfold))\n",
        "        \n",
        "        # Append the final train and validation accuracy and loss.\n",
        "        print(f\"Storing train and validation accuracy and loss for model {model_name}, fold {kfold}\")\n",
        "        temp_df_model_kfold_epoch_train_accuracy =  pd.DataFrame({\"model\": model_name, \n",
        "                                                                  \"epoch\" : range(1, epochs + 1), \n",
        "                                                                  \"kfold\": kfold + 1, \n",
        "                                                                  \"train_accuracy\": history.history['accuracy']})\n",
        "        temp_df_model_kfold_epoch_train_loss =  pd.DataFrame({\"train_loss\" : history.history['loss']})\n",
        "        temp_df_model_kfold_epoch_validation_accuracy =  pd.DataFrame({\"validation_accuracy\" : history.history['val_accuracy']})\n",
        "        temp_df_model_kfold_epoch_validation_loss =  pd.DataFrame({\"validation_loss\" : history.history['val_loss']})\n",
        "        temp_consolidated_df_model_kpi = pd.concat([temp_df_model_kfold_epoch_train_accuracy,\n",
        "                                                    temp_df_model_kfold_epoch_train_loss,\n",
        "                                                    temp_df_model_kfold_epoch_validation_accuracy,\n",
        "                                                    temp_df_model_kfold_epoch_validation_loss\n",
        "                                                   ], axis = 1)\n",
        "        # Consolidating training and validation accuracies in single data frame \n",
        "        # along with model name, epoch, kfold number.\n",
        "        consolidated_df_model_kpi = pd.concat([temp_consolidated_df_model_kpi, consolidated_df_model_kpi], axis = 0)\n",
        "        \n",
        "        # Plot train and val accuracy and loss\n",
        "        print(f\"Plotting train and validation accuracy and loss for model {model_name}, fold {kfold}\")\n",
        "        model_proc.plot_model_accuracy_and_loss(history = history, model_name = model_name)\n",
        "\n",
        "        # Model Predict, transform logits to probabilities\n",
        "        step_size_test = np.ceil(test_dataset_from_data_generator.n / test_dataset_from_data_generator.batch_size)\n",
        "        test_dataset_from_data_generator.reset()\n",
        "        pred_logits = model.predict_generator(test_dataset_from_data_generator, steps = step_size_test, verbose = 1)\n",
        "        probas_sigmoid = tf.sigmoid(pred_logits)\n",
        "        probas_sigmoid = probas_sigmoid.numpy().flatten() * 100\n",
        "        predictions_binary = [1 if x > 50.0 else 0 for x in probas_sigmoid]\n",
        "\n",
        "        temp_df_actual_vs_pred_bin_pred_pct = pd.DataFrame({\"model\"    : model_name, \n",
        "                                                            \"kfold\"    : kfold + 1, \n",
        "                                                            \"actual\"   : data_proc.y_test, \n",
        "                                                            \"pred_pct\" : probas_sigmoid, \n",
        "                                                            \"pred_bin\" : predictions_binary\n",
        "                                                           }\n",
        "                                                          )\n",
        "        df_actual_vs_pred_bin_pred_pct = pd.concat([temp_df_actual_vs_pred_bin_pred_pct, \n",
        "                                                    df_actual_vs_pred_bin_pred_pct], \n",
        "                                                   axis = 0)\n",
        "\n",
        "        #total_probas.append(probas_sigmoid)\n",
        "        #total_votes.append(predictions_binary)\n",
        "        #temp_list_prob_logits_and_bin.append((model_name, kfold, data_proc.y_test, probas_sigmoid, predictions_binary))\n",
        "\n",
        "# voting across kfold\n",
        "# voting across ensemble models        \n",
        "# kpi print\n"
      ],
      "metadata": {
        "id": "10lQvL9Y78jH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "consolidated_df_model_kpi.to_csv('consolidated_df_model_kpi.csv', index = False)\n",
        "df_actual_vs_pred_bin_pred_pct.to_csv('actual_vs_pred_bin_pred_pct.csv', index = False)"
      ],
      "metadata": {
        "id": "mQ3TVgyF3yCX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_consolidated_df_model_kpi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "FC1o2fSra6YK",
        "outputId": "2c1482d0-d186-44ee-f8bd-abe7b52e2ccf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Model  epoch  kfold  train_accuracy  train_loss  validation_accuracy  \\\n",
              "0  MobileNet      1      2        0.620000    0.813912             0.723333   \n",
              "1  MobileNet      2      2        0.680000    0.750776             0.770000   \n",
              "2  MobileNet      3      2        0.686667    0.693884             0.780000   \n",
              "3  MobileNet      4      2        0.731667    0.663158             0.800000   \n",
              "4  MobileNet      5      2        0.715000    0.678024             0.816667   \n",
              "5  MobileNet      6      2        0.755000    0.544642             0.796667   \n",
              "6  MobileNet      7      2        0.726667    0.606768             0.783333   \n",
              "7  MobileNet      8      2        0.738333    0.565250             0.786667   \n",
              "8  MobileNet      9      2        0.721667    0.615989             0.796667   \n",
              "9  MobileNet     10      2        0.706667    0.606732             0.776667   \n",
              "\n",
              "   validation_loss  \n",
              "0         0.661691  \n",
              "1         0.532801  \n",
              "2         0.523295  \n",
              "3         0.490008  \n",
              "4         0.465862  \n",
              "5         0.465026  \n",
              "6         0.488508  \n",
              "7         0.514052  \n",
              "8         0.480295  \n",
              "9         0.479577  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f4c2fa3e-7595-4690-914b-e0ca764a0934\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>epoch</th>\n",
              "      <th>kfold</th>\n",
              "      <th>train_accuracy</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>validation_accuracy</th>\n",
              "      <th>validation_loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>MobileNet</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0.620000</td>\n",
              "      <td>0.813912</td>\n",
              "      <td>0.723333</td>\n",
              "      <td>0.661691</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>MobileNet</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0.680000</td>\n",
              "      <td>0.750776</td>\n",
              "      <td>0.770000</td>\n",
              "      <td>0.532801</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>MobileNet</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0.686667</td>\n",
              "      <td>0.693884</td>\n",
              "      <td>0.780000</td>\n",
              "      <td>0.523295</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>MobileNet</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0.731667</td>\n",
              "      <td>0.663158</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.490008</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>MobileNet</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>0.715000</td>\n",
              "      <td>0.678024</td>\n",
              "      <td>0.816667</td>\n",
              "      <td>0.465862</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>MobileNet</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>0.755000</td>\n",
              "      <td>0.544642</td>\n",
              "      <td>0.796667</td>\n",
              "      <td>0.465026</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>MobileNet</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>0.726667</td>\n",
              "      <td>0.606768</td>\n",
              "      <td>0.783333</td>\n",
              "      <td>0.488508</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>MobileNet</td>\n",
              "      <td>8</td>\n",
              "      <td>2</td>\n",
              "      <td>0.738333</td>\n",
              "      <td>0.565250</td>\n",
              "      <td>0.786667</td>\n",
              "      <td>0.514052</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>MobileNet</td>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "      <td>0.721667</td>\n",
              "      <td>0.615989</td>\n",
              "      <td>0.796667</td>\n",
              "      <td>0.480295</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>MobileNet</td>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>0.706667</td>\n",
              "      <td>0.606732</td>\n",
              "      <td>0.776667</td>\n",
              "      <td>0.479577</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f4c2fa3e-7595-4690-914b-e0ca764a0934')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f4c2fa3e-7595-4690-914b-e0ca764a0934 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f4c2fa3e-7595-4690-914b-e0ca764a0934');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "consolidated_df_model_kpi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "id": "0Ntl4zfOasQs",
        "outputId": "18fa0034-783e-4ee1-c366-58071dc4e21f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: []\n",
              "Index: []"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cea28b6c-7737-41c4-8e4d-f050f5abefb2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cea28b6c-7737-41c4-8e4d-f050f5abefb2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cea28b6c-7737-41c4-8e4d-f050f5abefb2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cea28b6c-7737-41c4-8e4d-f050f5abefb2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history.history['accuracy'][-1], model_name, model.layers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dof5JBQBnJC9",
        "outputId": "8fa9e820-57c4-4948-d3fc-5687cff09e90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.7200000286102295,\n",
              " 'ResNet50',\n",
              " [<keras.layers.reshaping.zero_padding2d.ZeroPadding2D at 0x7fedc019e790>,\n",
              "  <keras.layers.convolutional.conv2d.Conv2D at 0x7fedcb717d90>,\n",
              "  <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7fedd00ee1d0>,\n",
              "  <keras.layers.core.activation.Activation at 0x7fedcaa17610>,\n",
              "  <keras.layers.reshaping.zero_padding2d.ZeroPadding2D at 0x7fec68578450>,\n",
              "  <keras.layers.pooling.max_pooling2d.MaxPooling2D at 0x7fedcac8ec10>,\n",
              "  <keras.layers.convolutional.conv2d.Conv2D at 0x7fedcacd0190>,\n",
              "  <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7fedd062b790>,\n",
              "  <keras.layers.core.activation.Activation at 0x7fec684eea50>,\n",
              "  <keras.layers.convolutional.conv2d.Conv2D at 0x7fedca08acd0>,\n",
              "  <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7fedca08af50>,\n",
              "  <keras.layers.core.activation.Activation at 0x7fedca0b92d0>,\n",
              "  <keras.layers.convolutional.conv2d.Conv2D at 0x7fedc00ee2d0>,\n",
              "  <keras.layers.convolutional.conv2d.Conv2D at 0x7fed7610ac90>,\n",
              "  <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7fedcac8e7d0>,\n",
              "  <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7fed7610a5d0>])"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temp_list_prob_logits_and_bin"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cILah4LM3k_G",
        "outputId": "822aaa96-5240-4abc-868e-18bfbf235c52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('VGG19',\n",
              "  0,\n",
              "  array([0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
              "         1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1,\n",
              "         1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0,\n",
              "         1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1]),\n",
              "  array([48.05063  , 47.389744 , 22.572712 , 85.73469  , 34.331547 ,\n",
              "         75.56823  , 86.46646  , 73.52185  ,  5.7347608, 16.077538 ,\n",
              "         19.457882 , 61.17448  , 31.436836 , 76.51586  , 70.27448  ,\n",
              "         49.60244  , 61.09548  , 13.916016 , 83.727516 , 19.798729 ,\n",
              "         16.244715 , 89.44317  , 37.01599  , 78.96583  , 45.712322 ,\n",
              "         89.16941  , 80.9362   , 24.726233 , 86.466515 , 19.26561  ,\n",
              "         32.943897 , 88.44037  , 39.473797 , 76.06881  , 47.10745  ,\n",
              "         66.46906  , 19.6394   ,  9.7881365, 76.64213  , 95.53778  ,\n",
              "         33.069965 , 55.554592 , 86.50181  , 81.18079  ,  4.989494 ,\n",
              "         10.595455 , 34.5515   , 17.932182 , 24.575756 , 12.497286 ,\n",
              "         31.601408 , 73.9109   , 39.001255 , 44.84428  , 70.445885 ,\n",
              "         19.548494 , 58.400475 , 24.312656 , 31.153275 , 18.909098 ,\n",
              "         96.95525  , 22.997675 , 44.091328 , 48.657932 ,  9.893101 ,\n",
              "         37.58786  , 75.11158  , 15.988641 , 56.896614 , 15.712322 ,\n",
              "         28.606888 , 31.821808 , 15.049997 ,  9.77613  , 31.732193 ,\n",
              "         65.32558  , 51.50921  , 39.71848  ,  8.31834  , 74.3101   ,\n",
              "         10.316734 , 83.003044 ,  8.326267 , 82.17456  , 39.485764 ,\n",
              "         90.564865 , 45.695873 , 65.8709   ,  6.050696 , 22.032837 ,\n",
              "         43.639637 , 47.5905   , 18.609577 , 17.75153  , 42.464317 ,\n",
              "         54.16056  , 60.8567   , 34.249504 , 25.226906 , 54.28362  ],\n",
              "        dtype=float32),\n",
              "  [0,\n",
              "   0,\n",
              "   0,\n",
              "   1,\n",
              "   0,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   1,\n",
              "   0,\n",
              "   1,\n",
              "   1,\n",
              "   0,\n",
              "   1,\n",
              "   0,\n",
              "   1,\n",
              "   0,\n",
              "   0,\n",
              "   1,\n",
              "   0,\n",
              "   1,\n",
              "   0,\n",
              "   1,\n",
              "   1,\n",
              "   0,\n",
              "   1,\n",
              "   0,\n",
              "   0,\n",
              "   1,\n",
              "   0,\n",
              "   1,\n",
              "   0,\n",
              "   1,\n",
              "   0,\n",
              "   0,\n",
              "   1,\n",
              "   1,\n",
              "   0,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   1,\n",
              "   0,\n",
              "   0,\n",
              "   1,\n",
              "   0,\n",
              "   1,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   1,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   1,\n",
              "   0,\n",
              "   1,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   1,\n",
              "   1,\n",
              "   0,\n",
              "   0,\n",
              "   1,\n",
              "   0,\n",
              "   1,\n",
              "   0,\n",
              "   1,\n",
              "   0,\n",
              "   1,\n",
              "   0,\n",
              "   1,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   1,\n",
              "   1,\n",
              "   0,\n",
              "   0,\n",
              "   1]),\n",
              " ('VGG19',\n",
              "  1,\n",
              "  array([0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
              "         1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1,\n",
              "         1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0,\n",
              "         1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1]),\n",
              "  array([48.287468 , 48.877205 , 21.66864  , 80.80532  , 38.46425  ,\n",
              "         70.54272  , 80.737976 , 70.37867  ,  7.192364 , 18.404768 ,\n",
              "         23.238752 , 60.945137 , 34.207474 , 68.4169   , 67.43704  ,\n",
              "         51.90101  , 56.88643  , 21.59494  , 77.78965  , 17.529213 ,\n",
              "         12.305136 , 87.43622  , 28.057215 , 71.650444 , 47.2031   ,\n",
              "         84.68632  , 72.21272  , 16.806269 , 83.66026  , 27.487198 ,\n",
              "         23.110693 , 86.89941  , 45.73135  , 73.732796 , 39.13013  ,\n",
              "         39.180206 , 24.515953 , 12.407619 , 63.287216 , 93.90816  ,\n",
              "         33.153515 , 46.76719  , 81.66608  , 76.67535  ,  4.649738 ,\n",
              "         18.066439 , 33.27434  , 26.543436 , 18.865168 , 19.512217 ,\n",
              "         29.46051  , 66.279495 , 22.593157 , 49.847816 , 44.88306  ,\n",
              "         25.162693 , 50.86704  , 29.564053 , 31.81026  , 23.210762 ,\n",
              "         93.829704 , 22.373186 , 45.666035 , 49.7836   , 11.332082 ,\n",
              "         27.367231 , 70.77899  , 12.431761 , 57.634567 , 14.489627 ,\n",
              "         31.484703 , 27.749336 , 17.780758 , 12.4737425, 20.301567 ,\n",
              "         67.914825 , 53.73407  , 25.280745 , 13.3833065, 72.20831  ,\n",
              "         14.460272 , 71.54107  , 12.826058 , 75.319534 , 39.764786 ,\n",
              "         87.456474 , 44.425056 , 61.381523 ,  9.14427  , 10.209845 ,\n",
              "         22.922878 , 47.4828   , 25.874535 , 20.327816 , 48.62114  ,\n",
              "         56.401165 , 55.354588 , 33.479454 ,  9.739092 , 59.307583 ],\n",
              "        dtype=float32),\n",
              "  [0,\n",
              "   0,\n",
              "   0,\n",
              "   1,\n",
              "   0,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   1,\n",
              "   0,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   0,\n",
              "   1,\n",
              "   0,\n",
              "   0,\n",
              "   1,\n",
              "   0,\n",
              "   1,\n",
              "   0,\n",
              "   1,\n",
              "   1,\n",
              "   0,\n",
              "   1,\n",
              "   0,\n",
              "   0,\n",
              "   1,\n",
              "   0,\n",
              "   1,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   1,\n",
              "   1,\n",
              "   0,\n",
              "   0,\n",
              "   1,\n",
              "   1,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   1,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   1,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   1,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   1,\n",
              "   0,\n",
              "   1,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   1,\n",
              "   1,\n",
              "   0,\n",
              "   0,\n",
              "   1,\n",
              "   0,\n",
              "   1,\n",
              "   0,\n",
              "   1,\n",
              "   0,\n",
              "   1,\n",
              "   0,\n",
              "   1,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   1,\n",
              "   1,\n",
              "   0,\n",
              "   0,\n",
              "   1]),\n",
              " ('VGG19',\n",
              "  2,\n",
              "  array([0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
              "         1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0,\n",
              "         1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1,\n",
              "         1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0,\n",
              "         1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1]),\n",
              "  array([50.520603 , 45.209965 , 11.970262 , 78.66364  , 38.578407 ,\n",
              "         73.26383  , 83.77357  , 66.771034 ,  6.685873 , 16.067583 ,\n",
              "         23.099731 , 59.19517  , 33.561092 , 68.02727  , 64.157776 ,\n",
              "         49.455032 , 53.98639  , 15.839057 , 77.49203  , 10.802904 ,\n",
              "          8.062048 , 83.65782  , 22.3837   , 65.13318  , 38.549976 ,\n",
              "         84.76436  , 59.516758 ,  9.931957 , 81.60565  , 12.84145  ,\n",
              "         10.516551 , 83.19118  , 45.02034  , 73.65077  , 26.879288 ,\n",
              "         32.53304  , 16.092308 , 12.8629055, 62.773777 , 93.47182  ,\n",
              "         31.802893 , 41.285446 , 83.07126  , 75.90132  ,  3.925231 ,\n",
              "         11.218799 , 36.43721  , 18.97883  , 16.926561 , 13.207239 ,\n",
              "         23.643229 , 69.82246  , 14.06739  , 37.13645  , 44.913223 ,\n",
              "         20.59215  , 40.71599  , 22.72925  , 30.143633 , 19.673502 ,\n",
              "         93.97484  , 22.641352 , 48.236103 , 50.28358  ,  9.311956 ,\n",
              "         31.627972 , 71.339485 , 11.666058 , 60.48019  , 11.351141 ,\n",
              "         26.858837 , 22.891443 , 19.775192 , 12.7717495, 10.019853 ,\n",
              "         55.974304 , 46.13952  , 24.83559  , 11.601992 , 73.54685  ,\n",
              "         10.151709 , 68.848946 , 10.952063 , 76.36973  , 35.406933 ,\n",
              "         85.61152  , 45.59938  , 65.19995  ,  5.9155726,  3.456609 ,\n",
              "         17.729633 , 49.35413  , 13.744341 , 24.797684 , 41.557453 ,\n",
              "         55.387753 , 60.133476 , 37.022774 ,  4.456131 , 58.13676  ],\n",
              "        dtype=float32),\n",
              "  [1,\n",
              "   0,\n",
              "   0,\n",
              "   1,\n",
              "   0,\n",
              "   1,\n",
              "   1,\n",
              "   1,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   1,\n",
              "   0,\n",
              "   1,\n",
              "   1,\n",
              "   0,\n",
              "   1,\n",
              "   0,\n",
              "   1,\n",
              "   0,\n",
              "   0,\n",
              "   1,\n",
              "   0,\n",
              "   1,\n",
              "   0,\n",
              "   1,\n",
              "   1,\n",
              "   0,\n",
              "   1,\n",
              "   0,\n",
              "   0,\n",
              "   1,\n",
              "   0,\n",
              "   1,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   1,\n",
              "   1,\n",
              "   0,\n",
              "   0,\n",
              "   1,\n",
              "   1,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   1,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   1,\n",
              "   0,\n",
              "   0,\n",
              "   1,\n",
              "   0,\n",
              "   0,\n",
              "   1,\n",
              "   0,\n",
              "   1,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   1,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   1,\n",
              "   0,\n",
              "   1,\n",
              "   0,\n",
              "   1,\n",
              "   0,\n",
              "   1,\n",
              "   0,\n",
              "   1,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   1,\n",
              "   1,\n",
              "   0,\n",
              "   0,\n",
              "   1])]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "probas_sigmoid"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BeLUZw5Pf8Fw",
        "outputId": "71bf5dbd-9384-4f7e-ed9c-dca4c932ad45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([26.759811 , 21.000294 , 69.220764 , 37.908928 , 44.423885 ,\n",
              "       21.487764 , 92.56546  , 50.90136  , 20.919725 , 10.942429 ,\n",
              "       14.997794 , 76.72939  , 75.06709  , 85.167    , 72.80903  ,\n",
              "       60.90873  , 62.78906  , 35.16518  , 85.5758   , 60.69565  ,\n",
              "       17.786324 , 71.44436  , 50.48705  , 70.66738  , 68.51311  ,\n",
              "       59.037487 , 24.281233 , 55.78431  , 58.00105  , 53.781544 ,\n",
              "       29.1357   , 57.95767  , 10.526545 , 14.541383 , 84.44711  ,\n",
              "       75.05674  , 27.387657 , 24.222921 , 84.257545 , 72.80864  ,\n",
              "       22.332218 , 60.64878  , 65.33443  , 64.6207   , 19.10183  ,\n",
              "       44.14553  , 13.264269 , 40.007    , 53.606636 , 22.870125 ,\n",
              "       57.078827 , 14.474447 , 10.136927 , 78.876564 , 68.93493  ,\n",
              "       24.610926 , 52.05474  , 27.00921  , 80.50887  , 13.675712 ,\n",
              "       75.85295  ,  8.540578 , 28.045856 , 18.632477 , 23.916872 ,\n",
              "       23.784115 , 88.80971  , 16.072195 , 78.99193  , 18.763142 ,\n",
              "       45.700687 , 20.79987  , 26.802326 , 37.212433 , 25.094086 ,\n",
              "       74.47401  , 53.36006  , 42.98667  , 63.963146 , 37.494305 ,\n",
              "       66.47862  , 19.829422 , 58.151405 , 83.742256 , 90.183685 ,\n",
              "       93.096504 , 92.32488  , 24.999472 , 18.913967 , 26.649904 ,\n",
              "       21.949879 , 24.951103 , 37.0492   , 46.958057 , 39.50288  ,\n",
              "       66.69964  , 68.35858  ,  2.7027209, 74.97378  , 18.051935 ],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_probas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zyl5XD8TfcLW",
        "outputId": "4929c171-6fa2-478c-b88d-529f735e0b84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([16.28261  ,  9.988834 , 56.692665 , 22.139416 , 32.229694 ,\n",
              "         9.644326 , 89.73247  , 37.793327 , 22.064075 , 11.527203 ,\n",
              "        21.337826 , 68.689445 , 70.888756 , 82.30195  , 57.358772 ,\n",
              "        64.73564  , 59.21045  , 19.741268 , 78.289856 , 47.168064 ,\n",
              "        12.228358 , 70.35827  , 44.446003 , 63.149464 , 62.631798 ,\n",
              "        42.209934 , 12.690844 , 56.914284 , 50.090973 , 45.38556  ,\n",
              "        14.704679 , 42.083004 ,  6.859979 , 25.206589 , 84.20685  ,\n",
              "        72.856544 , 19.80084  , 20.00012  , 81.21279  , 70.99147  ,\n",
              "        19.491486 , 47.077415 , 60.207916 , 48.360737 , 20.94985  ,\n",
              "        32.18368  , 18.013186 , 33.02866  , 44.74133  , 11.848454 ,\n",
              "        41.99236  ,  6.322144 , 12.501532 , 79.628624 , 63.109547 ,\n",
              "        11.991962 , 36.156067 , 50.38272  , 77.100685 , 34.397194 ,\n",
              "        70.74703  ,  7.673559 , 35.381157 , 28.664928 , 11.380238 ,\n",
              "        47.77349  , 85.71648  ,  7.956951 , 69.19596  , 11.375313 ,\n",
              "        32.076572 ,  9.799742 , 14.161517 , 20.48347  , 11.934661 ,\n",
              "        70.55228  , 35.932316 , 28.966892 , 53.328514 , 19.281963 ,\n",
              "        52.59005  , 11.776578 , 53.056152 , 79.66594  , 87.11924  ,\n",
              "        90.6271   , 84.961525 , 25.889338 , 26.46017  , 17.859621 ,\n",
              "        24.543495 , 25.795492 , 24.275393 , 29.270136 , 30.461285 ,\n",
              "        58.76463  , 60.517532 ,  1.4701769, 70.16892  , 23.039785 ],\n",
              "       dtype=float32),\n",
              " array([31.736683, 21.143013, 70.833725, 39.906227, 45.448597, 20.16592 ,\n",
              "        92.96833 , 55.990376, 31.948345, 17.01808 , 25.68272 , 80.1862  ,\n",
              "        78.696815, 87.96105 , 74.17372 , 76.7902  , 70.13292 , 37.394695,\n",
              "        88.389084, 63.300777, 20.517977, 80.39465 , 57.60283 , 73.34702 ,\n",
              "        75.58507 , 61.405807, 25.192776, 62.69383 , 62.28469 , 54.975826,\n",
              "        27.632576, 64.260124, 13.336569, 31.096184, 87.57619 , 80.778046,\n",
              "        35.013447, 36.075897, 87.65786 , 77.57832 , 27.936548, 61.070717,\n",
              "        72.886185, 64.936844, 28.478394, 48.66248 , 24.743078, 52.682663,\n",
              "        59.39437 , 24.759275, 60.02564 , 14.382395, 16.22465 , 83.34415 ,\n",
              "        71.92828 , 23.52749 , 53.168213, 35.859524, 85.46386 , 25.58859 ,\n",
              "        79.149086, 14.565876, 47.71642 , 29.909119, 23.668633, 42.73144 ,\n",
              "        89.93741 , 18.61916 , 79.124535, 22.168587, 47.73345 , 19.553427,\n",
              "        27.119604, 38.068314, 24.182772, 77.38384 , 55.048996, 45.615204,\n",
              "        66.8823  , 38.081257, 70.178154, 24.006462, 66.13731 , 85.64144 ,\n",
              "        91.99739 , 93.856995, 91.7896  , 42.20404 , 30.663517, 33.678608,\n",
              "        28.76022 , 35.98677 , 39.91976 , 47.064598, 46.141518, 73.29381 ,\n",
              "        71.63164 ,  4.402436, 73.435814, 30.65694 ], dtype=float32),\n",
              " array([21.469769 , 15.7289505, 67.95808  , 32.225586 , 44.122772 ,\n",
              "        14.534346 , 92.83601  , 34.40025  , 21.695913 ,  6.3811636,\n",
              "        12.910475 , 74.83224  , 75.09754  , 86.032936 , 67.98718  ,\n",
              "        69.514725 , 66.44843  , 28.076849 , 83.51688  , 53.829903 ,\n",
              "        14.707353 , 77.59772  , 54.815437 , 63.77981  , 59.103817 ,\n",
              "        55.09885  , 18.598484 , 52.11627  , 53.37445  , 52.877884 ,\n",
              "        19.495409 , 50.771088 ,  9.334387 , 12.738079 , 85.96722  ,\n",
              "        78.61016  , 16.881361 , 23.450827 , 86.242935 , 74.63192  ,\n",
              "        18.611998 , 57.017853 , 69.416534 , 50.918324 , 18.477297 ,\n",
              "        36.039425 , 11.197031 , 39.446728 , 46.709217 , 19.525948 ,\n",
              "        51.14097  , 11.162906 ,  8.451758 , 77.491745 , 61.423195 ,\n",
              "        17.660452 , 44.21254  , 23.440783 , 80.79593  , 18.311533 ,\n",
              "        74.79101  ,  7.1331954, 29.236904 , 20.661955 , 17.144276 ,\n",
              "        40.143696 , 89.960846 , 11.389679 , 74.17456  , 15.214547 ,\n",
              "        42.480602 , 15.283603 , 21.141169 , 18.248447 , 20.533531 ,\n",
              "        71.995636 , 42.75834  , 35.90406  , 54.443844 , 29.10643  ,\n",
              "        65.56684  , 12.071088 , 56.58632  , 74.052124 , 90.016594 ,\n",
              "        93.60019  , 90.60469  , 24.911577 , 16.967497 , 18.158897 ,\n",
              "        17.291985 , 28.346619 , 22.916468 , 36.009296 , 30.881    ,\n",
              "        59.68352  , 66.638794 ,  1.9908346, 68.9132   , 22.409897 ],\n",
              "       dtype=float32),\n",
              " array([18.331764, 13.97181 , 60.974377, 30.401867, 36.93172 , 12.367117,\n",
              "        89.80971 , 39.120197, 26.001501,  8.935368, 19.553085, 72.212906,\n",
              "        72.58044 , 82.31761 , 59.39498 , 67.57762 , 65.63686 , 25.663237,\n",
              "        80.86489 , 59.43589 , 19.970669, 75.51384 , 46.819256, 62.902554,\n",
              "        58.65888 , 48.501705, 17.89608 , 56.820423, 55.759174, 47.871174,\n",
              "        17.76109 , 51.30558 , 10.618808, 10.282944, 82.12265 , 71.26807 ,\n",
              "        18.185884, 30.424885, 83.95707 , 68.72408 , 22.757084, 52.904892,\n",
              "        65.78297 , 55.20599 , 21.930819, 39.176056, 10.157307, 47.550026,\n",
              "        47.93171 , 20.094913, 46.25223 ,  8.736109, 11.357176, 65.90289 ,\n",
              "        63.34112 , 15.737809, 39.744804, 19.59639 , 78.76387 , 16.520788,\n",
              "        68.288124, 10.323581, 36.716297, 19.845413, 16.159819, 33.49677 ,\n",
              "        84.97981 , 10.431666, 70.99216 , 17.97622 , 38.46918 , 14.418748,\n",
              "        20.771328, 23.936527, 18.809563, 70.235344, 41.66546 , 34.51686 ,\n",
              "        54.47556 , 24.819838, 59.96698 , 12.011965, 54.304058, 76.1635  ,\n",
              "        87.988205, 90.61766 , 86.34272 , 26.955948, 18.523436, 20.76268 ,\n",
              "        21.868523, 18.534536, 27.378946, 41.631023, 31.992262, 55.783142,\n",
              "        61.425434,  2.580018, 58.760704, 24.720406], dtype=float32),\n",
              " array([26.759811 , 21.000294 , 69.220764 , 37.908928 , 44.423885 ,\n",
              "        21.487764 , 92.56546  , 50.90136  , 20.919725 , 10.942429 ,\n",
              "        14.997794 , 76.72939  , 75.06709  , 85.167    , 72.80903  ,\n",
              "        60.90873  , 62.78906  , 35.16518  , 85.5758   , 60.69565  ,\n",
              "        17.786324 , 71.44436  , 50.48705  , 70.66738  , 68.51311  ,\n",
              "        59.037487 , 24.281233 , 55.78431  , 58.00105  , 53.781544 ,\n",
              "        29.1357   , 57.95767  , 10.526545 , 14.541383 , 84.44711  ,\n",
              "        75.05674  , 27.387657 , 24.222921 , 84.257545 , 72.80864  ,\n",
              "        22.332218 , 60.64878  , 65.33443  , 64.6207   , 19.10183  ,\n",
              "        44.14553  , 13.264269 , 40.007    , 53.606636 , 22.870125 ,\n",
              "        57.078827 , 14.474447 , 10.136927 , 78.876564 , 68.93493  ,\n",
              "        24.610926 , 52.05474  , 27.00921  , 80.50887  , 13.675712 ,\n",
              "        75.85295  ,  8.540578 , 28.045856 , 18.632477 , 23.916872 ,\n",
              "        23.784115 , 88.80971  , 16.072195 , 78.99193  , 18.763142 ,\n",
              "        45.700687 , 20.79987  , 26.802326 , 37.212433 , 25.094086 ,\n",
              "        74.47401  , 53.36006  , 42.98667  , 63.963146 , 37.494305 ,\n",
              "        66.47862  , 19.829422 , 58.151405 , 83.742256 , 90.183685 ,\n",
              "        93.096504 , 92.32488  , 24.999472 , 18.913967 , 26.649904 ,\n",
              "        21.949879 , 24.951103 , 37.0492   , 46.958057 , 39.50288  ,\n",
              "        66.69964  , 68.35858  ,  2.7027209, 74.97378  , 18.051935 ],\n",
              "       dtype=float32)]"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_votes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xBK9rE7xfhwy",
        "outputId": "1edc72e8-8c86-42d3-f63f-6073e98f4773"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[-1.63734913e+00],\n",
              "        [-2.19846582e+00],\n",
              "        [ 2.69322932e-01],\n",
              "        [-1.25756025e+00],\n",
              "        [-7.43235946e-01],\n",
              "        [-2.23738408e+00],\n",
              "        [ 2.16784596e+00],\n",
              "        [-4.98329669e-01],\n",
              "        [-1.26193619e+00],\n",
              "        [-2.03798556e+00],\n",
              "        [-1.30468106e+00],\n",
              "        [ 7.85640359e-01],\n",
              "        [ 8.89987588e-01],\n",
              "        [ 1.53694022e+00],\n",
              "        [ 2.96504378e-01],\n",
              "        [ 6.07439101e-01],\n",
              "        [ 3.72672021e-01],\n",
              "        [-1.40254426e+00],\n",
              "        [ 1.28263807e+00],\n",
              "        [-1.13398820e-01],\n",
              "        [-1.97098076e+00],\n",
              "        [ 8.64417195e-01],\n",
              "        [-2.23080471e-01],\n",
              "        [ 5.38634121e-01],\n",
              "        [ 5.16452789e-01],\n",
              "        [-3.14161181e-01],\n",
              "        [-1.92857456e+00],\n",
              "        [ 2.78354526e-01],\n",
              "        [ 3.63890361e-03],\n",
              "        [-1.85104221e-01],\n",
              "        [-1.75795388e+00],\n",
              "        [-3.19366992e-01],\n",
              "        [-2.60839963e+00],\n",
              "        [-1.08762431e+00],\n",
              "        [ 1.67369986e+00],\n",
              "        [ 9.87356484e-01],\n",
              "        [-1.39878869e+00],\n",
              "        [-1.38628685e+00],\n",
              "        [ 1.46389651e+00],\n",
              "        [ 8.94969642e-01],\n",
              "        [-1.41838515e+00],\n",
              "        [-1.17036715e-01],\n",
              "        [ 4.14135873e-01],\n",
              "        [-6.55941516e-02],\n",
              "        [-1.32795095e+00],\n",
              "        [-7.45343328e-01],\n",
              "        [-1.51545441e+00],\n",
              "        [-7.06889153e-01],\n",
              "        [-2.11127520e-01],\n",
              "        [-2.00686002e+00],\n",
              "        [-3.23087096e-01],\n",
              "        [-2.69580340e+00],\n",
              "        [-1.94577014e+00],\n",
              "        [ 1.36324310e+00],\n",
              "        [ 5.36919236e-01],\n",
              "        [-1.99319148e+00],\n",
              "        [-5.68596900e-01],\n",
              "        [ 1.53089901e-02],\n",
              "        [ 1.21400535e+00],\n",
              "        [-6.45643473e-01],\n",
              "        [ 8.83129597e-01],\n",
              "        [-2.48755002e+00],\n",
              "        [-6.02326751e-01],\n",
              "        [-9.11713719e-01],\n",
              "        [-2.05247664e+00],\n",
              "        [-8.91192406e-02],\n",
              "        [ 1.79193807e+00],\n",
              "        [-2.44821048e+00],\n",
              "        [ 8.09296787e-01],\n",
              "        [-2.05296493e+00],\n",
              "        [-7.50254989e-01],\n",
              "        [-2.21967626e+00],\n",
              "        [-1.80193925e+00],\n",
              "        [-1.35634673e+00],\n",
              "        [-1.99863219e+00],\n",
              "        [ 8.73737454e-01],\n",
              "        [-5.78303099e-01],\n",
              "        [-8.96992564e-01],\n",
              "        [ 1.33337721e-01],\n",
              "        [-1.43179190e+00],\n",
              "        [ 1.03694558e-01],\n",
              "        [-2.01375985e+00],\n",
              "        [ 1.22398525e-01],\n",
              "        [ 1.36554468e+00],\n",
              "        [ 1.91154301e+00],\n",
              "        [ 2.26893044e+00],\n",
              "        [ 1.73158646e+00],\n",
              "        [-1.05172825e+00],\n",
              "        [-1.02218652e+00],\n",
              "        [-1.52588737e+00],\n",
              "        [-1.12310946e+00],\n",
              "        [-1.05662513e+00],\n",
              "        [-1.13764000e+00],\n",
              "        [-8.82300138e-01],\n",
              "        [-8.25427115e-01],\n",
              "        [ 3.54243636e-01],\n",
              "        [ 4.27076340e-01],\n",
              "        [-4.20497656e+00],\n",
              "        [ 8.55354846e-01],\n",
              "        [-1.20606613e+00]], dtype=float32), array([[-0.7658993 ],\n",
              "        [-1.3163265 ],\n",
              "        [ 0.8873223 ],\n",
              "        [-0.4093737 ],\n",
              "        [-0.18256147],\n",
              "        [-1.3759565 ],\n",
              "        [ 2.5818343 ],\n",
              "        [ 0.24077144],\n",
              "        [-0.7561466 ],\n",
              "        [-1.5843465 ],\n",
              "        [-1.062525  ],\n",
              "        [ 1.397973  ],\n",
              "        [ 1.3067461 ],\n",
              "        [ 1.9887474 ],\n",
              "        [ 1.0550177 ],\n",
              "        [ 1.1965021 ],\n",
              "        [ 0.85363555],\n",
              "        [-0.51532114],\n",
              "        [ 2.0298023 ],\n",
              "        [ 0.54514194],\n",
              "        [-1.3542295 ],\n",
              "        [ 1.411145  ],\n",
              "        [ 0.30648997],\n",
              "        [ 1.0123008 ],\n",
              "        [ 1.1300639 ],\n",
              "        [ 0.4644024 ],\n",
              "        [-1.0883571 ],\n",
              "        [ 0.51910424],\n",
              "        [ 0.5016497 ],\n",
              "        [ 0.19969404],\n",
              "        [-0.962761  ],\n",
              "        [ 0.58667225],\n",
              "        [-1.8715223 ],\n",
              "        [-0.7956264 ],\n",
              "        [ 1.9528943 ],\n",
              "        [ 1.4356521 ],\n",
              "        [-0.61844814],\n",
              "        [-0.57207143],\n",
              "        [ 1.9604224 ],\n",
              "        [ 1.24126   ],\n",
              "        [-0.9476113 ],\n",
              "        [ 0.4502855 ],\n",
              "        [ 0.98885566],\n",
              "        [ 0.6162641 ],\n",
              "        [-0.920854  ],\n",
              "        [-0.05351367],\n",
              "        [-1.112362  ],\n",
              "        [ 0.1074097 ],\n",
              "        [ 0.38029274],\n",
              "        [-1.1114925 ],\n",
              "        [ 0.40653354],\n",
              "        [-1.783886  ],\n",
              "        [-1.6416072 ],\n",
              "        [ 1.6102167 ],\n",
              "        [ 0.9409072 ],\n",
              "        [-1.1787617 ],\n",
              "        [ 0.12689847],\n",
              "        [-0.5814664 ],\n",
              "        [ 1.7714554 ],\n",
              "        [-1.0674628 ],\n",
              "        [ 1.3339353 ],\n",
              "        [-1.7690641 ],\n",
              "        [-0.09140672],\n",
              "        [-0.8516293 ],\n",
              "        [-1.1709332 ],\n",
              "        [-0.2928168 ],\n",
              "        [ 2.190289  ],\n",
              "        [-1.4749486 ],\n",
              "        [ 1.3324485 ],\n",
              "        [-1.2558688 ],\n",
              "        [-0.09072405],\n",
              "        [-1.4144428 ],\n",
              "        [-0.9885628 ],\n",
              "        [-0.4866498 ],\n",
              "        [-1.1426852 ],\n",
              "        [ 1.2301136 ],\n",
              "        [ 0.20265065],\n",
              "        [-0.17584355],\n",
              "        [ 0.70286655],\n",
              "        [-0.4861008 ],\n",
              "        [ 0.855796  ],\n",
              "        [-1.1523253 ],\n",
              "        [ 0.6694191 ],\n",
              "        [ 1.785823  ],\n",
              "        [ 2.4419928 ],\n",
              "        [ 2.7264593 ],\n",
              "        [ 2.4140973 ],\n",
              "        [-0.3144031 ],\n",
              "        [-0.81589764],\n",
              "        [-0.6776497 ],\n",
              "        [-0.90705824],\n",
              "        [-0.57593846],\n",
              "        [-0.40880957],\n",
              "        [-0.11755122],\n",
              "        [-0.15464684],\n",
              "        [ 1.0095809 ],\n",
              "        [ 0.9262624 ],\n",
              "        [-3.0779893 ],\n",
              "        [ 1.0168478 ],\n",
              "        [-0.81620705]], dtype=float32), array([[-1.2968378 ],\n",
              "        [-1.6785353 ],\n",
              "        [ 0.7518458 ],\n",
              "        [-0.74342406],\n",
              "        [-0.2361809 ],\n",
              "        [-1.7716001 ],\n",
              "        [ 2.561768  ],\n",
              "        [-0.6455081 ],\n",
              "        [-1.2834759 ],\n",
              "        [-2.6858811 ],\n",
              "        [-1.9088976 ],\n",
              "        [ 1.089685  ],\n",
              "        [ 1.1038215 ],\n",
              "        [ 1.8180282 ],\n",
              "        [ 0.7531828 ],\n",
              "        [ 0.8242945 ],\n",
              "        [ 0.6833425 ],\n",
              "        [-0.94065285],\n",
              "        [ 1.6227118 ],\n",
              "        [ 0.15349677],\n",
              "        [-1.7577407 ],\n",
              "        [ 1.2423749 ],\n",
              "        [ 0.19321635],\n",
              "        [ 0.56582016],\n",
              "        [ 0.3682587 ],\n",
              "        [ 0.20466559],\n",
              "        [-1.4763138 ],\n",
              "        [ 0.08470135],\n",
              "        [ 0.13518372],\n",
              "        [ 0.1152427 ],\n",
              "        [-1.4181352 ],\n",
              "        [ 0.03084578],\n",
              "        [-2.273473  ],\n",
              "        [-1.9243183 ],\n",
              "        [ 1.8125699 ],\n",
              "        [ 1.3015847 ],\n",
              "        [-1.5940589 ],\n",
              "        [-1.1830275 ],\n",
              "        [ 1.8356153 ],\n",
              "        [ 1.0790769 ],\n",
              "        [-1.4754215 ],\n",
              "        [ 0.28257942],\n",
              "        [ 0.8196657 ],\n",
              "        [ 0.03673708],\n",
              "        [-1.4843388 ],\n",
              "        [-0.5736534 ],\n",
              "        [-2.0707715 ],\n",
              "        [-0.4285724 ],\n",
              "        [-0.1318218 ],\n",
              "        [-1.4161906 ],\n",
              "        [ 0.04564681],\n",
              "        [-2.074208  ],\n",
              "        [-2.3824916 ],\n",
              "        [ 1.2362893 ],\n",
              "        [ 0.46513617],\n",
              "        [-1.5395237 ],\n",
              "        [-0.23254071],\n",
              "        [-1.1835872 ],\n",
              "        [ 1.4368043 ],\n",
              "        [-1.4953817 ],\n",
              "        [ 1.087497  ],\n",
              "        [-2.566407  ],\n",
              "        [-0.88390577],\n",
              "        [-1.3454237 ],\n",
              "        [-1.5754366 ],\n",
              "        [-0.39948142],\n",
              "        [ 2.192882  ],\n",
              "        [-2.0515409 ],\n",
              "        [ 1.0550612 ],\n",
              "        [-1.7178719 ],\n",
              "        [-0.30307463],\n",
              "        [-1.7125287 ],\n",
              "        [-1.316437  ],\n",
              "        [-1.4996048 ],\n",
              "        [-1.3532759 ],\n",
              "        [ 0.94424516],\n",
              "        [-0.29171762],\n",
              "        [-0.57953066],\n",
              "        [ 0.17822382],\n",
              "        [-0.8902207 ],\n",
              "        [ 0.64405   ],\n",
              "        [-1.9857155 ],\n",
              "        [ 0.2649925 ],\n",
              "        [ 1.0486796 ],\n",
              "        [ 2.1990695 ],\n",
              "        [ 2.6827638 ],\n",
              "        [ 2.2662954 ],\n",
              "        [-1.1033337 ],\n",
              "        [-1.5879326 ],\n",
              "        [-1.5056189 ],\n",
              "        [-1.5650734 ],\n",
              "        [-0.9273326 ],\n",
              "        [-1.2130339 ],\n",
              "        [-0.5749607 ],\n",
              "        [-0.8056885 ],\n",
              "        [ 0.39229536],\n",
              "        [ 0.6918933 ],\n",
              "        [-3.896507  ],\n",
              "        [ 0.7960646 ],\n",
              "        [-1.2419373 ]], dtype=float32), array([[-1.4940298 ],\n",
              "        [-1.8176334 ],\n",
              "        [ 0.44623527],\n",
              "        [-0.8282337 ],\n",
              "        [-0.53514713],\n",
              "        [-1.9581152 ],\n",
              "        [ 2.176258  ],\n",
              "        [-0.4422626 ],\n",
              "        [-1.0458906 ],\n",
              "        [-2.3215523 ],\n",
              "        [-1.4144644 ],\n",
              "        [ 0.9550472 ],\n",
              "        [ 0.9734387 ],\n",
              "        [ 1.5380163 ],\n",
              "        [ 0.38031793],\n",
              "        [ 0.73442775],\n",
              "        [ 0.64715326],\n",
              "        [-1.0635462 ],\n",
              "        [ 1.4412553 ],\n",
              "        [ 0.3820146 ],\n",
              "        [-1.3881285 ],\n",
              "        [ 1.1262078 ],\n",
              "        [-0.12740189],\n",
              "        [ 0.5280386 ],\n",
              "        [ 0.3498813 ],\n",
              "        [-0.05994976],\n",
              "        [-1.5234041 ],\n",
              "        [ 0.27452824],\n",
              "        [ 0.2313939 ],\n",
              "        [-0.08520473],\n",
              "        [-1.5326185 ],\n",
              "        [ 0.05223504],\n",
              "        [-2.1302836 ],\n",
              "        [-2.1661744 ],\n",
              "        [ 1.5246794 ],\n",
              "        [ 0.90843904],\n",
              "        [-1.503804  ],\n",
              "        [-0.8271462 ],\n",
              "        [ 1.6550375 ],\n",
              "        [ 0.7872514 ],\n",
              "        [-1.2220787 ],\n",
              "        [ 0.11632687],\n",
              "        [ 0.6536376 ],\n",
              "        [ 0.20899674],\n",
              "        [-1.2697026 ],\n",
              "        [-0.43991783],\n",
              "        [-2.179867  ],\n",
              "        [-0.09807742],\n",
              "        [-0.0827788 ],\n",
              "        [-1.3803728 ],\n",
              "        [-0.15019241],\n",
              "        [-2.3462903 ],\n",
              "        [-2.0547652 ],\n",
              "        [ 0.65897   ],\n",
              "        [ 0.54687923],\n",
              "        [-1.6778672 ],\n",
              "        [-0.4161095 ],\n",
              "        [-1.4117137 ],\n",
              "        [ 1.3107508 ],\n",
              "        [-1.6199782 ],\n",
              "        [ 0.7670445 ],\n",
              "        [-2.1617773 ],\n",
              "        [-0.5444072 ],\n",
              "        [-1.3959842 ],\n",
              "        [-1.6463846 ],\n",
              "        [-0.68580174],\n",
              "        [ 1.7330189 ],\n",
              "        [-2.1501558 ],\n",
              "        [ 0.89500314],\n",
              "        [-1.5179594 ],\n",
              "        [-0.46968064],\n",
              "        [-1.7809371 ],\n",
              "        [-1.3387647 ],\n",
              "        [-1.1561626 ],\n",
              "        [-1.462432  ],\n",
              "        [ 0.85852975],\n",
              "        [-0.33652186],\n",
              "        [-0.64034474],\n",
              "        [ 0.17950283],\n",
              "        [-1.1082442 ],\n",
              "        [ 0.4040893 ],\n",
              "        [-1.9912977 ],\n",
              "        [ 0.17258951],\n",
              "        [ 1.1616642 ],\n",
              "        [ 1.9913143 ],\n",
              "        [ 2.2678201 ],\n",
              "        [ 1.844052  ],\n",
              "        [-0.99685866],\n",
              "        [-1.4812788 ],\n",
              "        [-1.3392903 ],\n",
              "        [-1.2733448 ],\n",
              "        [-1.4805434 ],\n",
              "        [-0.9754805 ],\n",
              "        [-0.33793887],\n",
              "        [-0.75412744],\n",
              "        [ 0.2323655 ],\n",
              "        [ 0.46523094],\n",
              "        [-3.631235  ],\n",
              "        [ 0.35408157],\n",
              "        [-1.11358   ]], dtype=float32), array([[-1.0068431 ],\n",
              "        [-1.3249077 ],\n",
              "        [ 0.8104606 ],\n",
              "        [-0.49341565],\n",
              "        [-0.2239761 ],\n",
              "        [-1.2957708 ],\n",
              "        [ 2.5217788 ],\n",
              "        [ 0.03605814],\n",
              "        [-1.3297709 ],\n",
              "        [-2.0966353 ],\n",
              "        [-1.7347741 ],\n",
              "        [ 1.1930934 ],\n",
              "        [ 1.1021937 ],\n",
              "        [ 1.7477592 ],\n",
              "        [ 0.98495495],\n",
              "        [ 0.44347742],\n",
              "        [ 0.5231779 ],\n",
              "        [-0.6117865 ],\n",
              "        [ 1.7804954 ],\n",
              "        [ 0.43453673],\n",
              "        [-1.5308918 ],\n",
              "        [ 0.91706425],\n",
              "        [ 0.01948258],\n",
              "        [ 0.87928385],\n",
              "        [ 0.77745366],\n",
              "        [ 0.36551562],\n",
              "        [-1.1373223 ],\n",
              "        [ 0.23241296],\n",
              "        [ 0.32281625],\n",
              "        [ 0.15155119],\n",
              "        [-0.88880247],\n",
              "        [ 0.32103586],\n",
              "        [-2.1400418 ],\n",
              "        [-1.7710338 ],\n",
              "        [ 1.6918794 ],\n",
              "        [ 1.1016406 ],\n",
              "        [-0.97504234],\n",
              "        [-1.1404966 ],\n",
              "        [ 1.6775168 ],\n",
              "        [ 0.9849356 ],\n",
              "        [-1.2464101 ],\n",
              "        [ 0.43257284],\n",
              "        [ 0.6337719 ],\n",
              "        [ 0.6024077 ],\n",
              "        [-1.443407  ],\n",
              "        [-0.23525801],\n",
              "        [-1.8777921 ],\n",
              "        [-0.40517342],\n",
              "        [ 0.14451644],\n",
              "        [-1.2156593 ],\n",
              "        [ 0.285068  ],\n",
              "        [-1.7764304 ],\n",
              "        [-2.1821022 ],\n",
              "        [ 1.3175012 ],\n",
              "        [ 0.7970789 ],\n",
              "        [-1.1194718 ],\n",
              "        [ 0.08223594],\n",
              "        [-0.99415535],\n",
              "        [ 1.418408  ],\n",
              "        [-1.8424896 ],\n",
              "        [ 1.1446342 ],\n",
              "        [-2.3710668 ],\n",
              "        [-0.942188  ],\n",
              "        [-1.4740702 ],\n",
              "        [-1.1572424 ],\n",
              "        [-1.1645521 ],\n",
              "        [ 2.0714495 ],\n",
              "        [-1.6528661 ],\n",
              "        [ 1.3244389 ],\n",
              "        [-1.4654747 ],\n",
              "        [-0.17239821],\n",
              "        [-1.3370312 ],\n",
              "        [-1.004675  ],\n",
              "        [-0.52311426],\n",
              "        [-1.0936006 ],\n",
              "        [ 1.070753  ],\n",
              "        [ 0.13460532],\n",
              "        [-0.28239486],\n",
              "        [ 0.57376486],\n",
              "        [-0.5110685 ],\n",
              "        [ 0.684697  ],\n",
              "        [-1.3969897 ],\n",
              "        [ 0.3289918 ],\n",
              "        [ 1.6391741 ],\n",
              "        [ 2.2178028 ],\n",
              "        [ 2.6016078 ],\n",
              "        [ 2.4873302 ],\n",
              "        [-1.0986404 ],\n",
              "        [-1.45561   ],\n",
              "        [-1.0124582 ],\n",
              "        [-1.2685896 ],\n",
              "        [-1.1012219 ],\n",
              "        [-0.53010666],\n",
              "        [-0.12182824],\n",
              "        [-0.42622218],\n",
              "        [ 0.6946314 ],\n",
              "        [ 0.7703003 ],\n",
              "        [-3.583512  ],\n",
              "        [ 1.0972142 ],\n",
              "        [-1.5128328 ]], dtype=float32)]"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z3kInNxTfKz7",
        "outputId": "e2f7bbf3-da59-4700-f075-9dc0469fcc12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-1.0068431 ],\n",
              "       [-1.3249077 ],\n",
              "       [ 0.8104606 ],\n",
              "       [-0.49341565],\n",
              "       [-0.2239761 ],\n",
              "       [-1.2957708 ],\n",
              "       [ 2.5217788 ],\n",
              "       [ 0.03605814],\n",
              "       [-1.3297709 ],\n",
              "       [-2.0966353 ],\n",
              "       [-1.7347741 ],\n",
              "       [ 1.1930934 ],\n",
              "       [ 1.1021937 ],\n",
              "       [ 1.7477592 ],\n",
              "       [ 0.98495495],\n",
              "       [ 0.44347742],\n",
              "       [ 0.5231779 ],\n",
              "       [-0.6117865 ],\n",
              "       [ 1.7804954 ],\n",
              "       [ 0.43453673],\n",
              "       [-1.5308918 ],\n",
              "       [ 0.91706425],\n",
              "       [ 0.01948258],\n",
              "       [ 0.87928385],\n",
              "       [ 0.77745366],\n",
              "       [ 0.36551562],\n",
              "       [-1.1373223 ],\n",
              "       [ 0.23241296],\n",
              "       [ 0.32281625],\n",
              "       [ 0.15155119],\n",
              "       [-0.88880247],\n",
              "       [ 0.32103586],\n",
              "       [-2.1400418 ],\n",
              "       [-1.7710338 ],\n",
              "       [ 1.6918794 ],\n",
              "       [ 1.1016406 ],\n",
              "       [-0.97504234],\n",
              "       [-1.1404966 ],\n",
              "       [ 1.6775168 ],\n",
              "       [ 0.9849356 ],\n",
              "       [-1.2464101 ],\n",
              "       [ 0.43257284],\n",
              "       [ 0.6337719 ],\n",
              "       [ 0.6024077 ],\n",
              "       [-1.443407  ],\n",
              "       [-0.23525801],\n",
              "       [-1.8777921 ],\n",
              "       [-0.40517342],\n",
              "       [ 0.14451644],\n",
              "       [-1.2156593 ],\n",
              "       [ 0.285068  ],\n",
              "       [-1.7764304 ],\n",
              "       [-2.1821022 ],\n",
              "       [ 1.3175012 ],\n",
              "       [ 0.7970789 ],\n",
              "       [-1.1194718 ],\n",
              "       [ 0.08223594],\n",
              "       [-0.99415535],\n",
              "       [ 1.418408  ],\n",
              "       [-1.8424896 ],\n",
              "       [ 1.1446342 ],\n",
              "       [-2.3710668 ],\n",
              "       [-0.942188  ],\n",
              "       [-1.4740702 ],\n",
              "       [-1.1572424 ],\n",
              "       [-1.1645521 ],\n",
              "       [ 2.0714495 ],\n",
              "       [-1.6528661 ],\n",
              "       [ 1.3244389 ],\n",
              "       [-1.4654747 ],\n",
              "       [-0.17239821],\n",
              "       [-1.3370312 ],\n",
              "       [-1.004675  ],\n",
              "       [-0.52311426],\n",
              "       [-1.0936006 ],\n",
              "       [ 1.070753  ],\n",
              "       [ 0.13460532],\n",
              "       [-0.28239486],\n",
              "       [ 0.57376486],\n",
              "       [-0.5110685 ],\n",
              "       [ 0.684697  ],\n",
              "       [-1.3969897 ],\n",
              "       [ 0.3289918 ],\n",
              "       [ 1.6391741 ],\n",
              "       [ 2.2178028 ],\n",
              "       [ 2.6016078 ],\n",
              "       [ 2.4873302 ],\n",
              "       [-1.0986404 ],\n",
              "       [-1.45561   ],\n",
              "       [-1.0124582 ],\n",
              "       [-1.2685896 ],\n",
              "       [-1.1012219 ],\n",
              "       [-0.53010666],\n",
              "       [-0.12182824],\n",
              "       [-0.42622218],\n",
              "       [ 0.6946314 ],\n",
              "       [ 0.7703003 ],\n",
              "       [-3.583512  ],\n",
              "       [ 1.0972142 ],\n",
              "       [-1.5128328 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_proc.train_file_list[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DsXHEJw6l4Bi",
        "outputId": "8a98fd00-5ba9-4564-e3cf-0d3dc9861ed6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/train/c9f789088c8a1c0d69173d158b583aff5ecc922c.tif',\n",
              " '/content/train/aeb2af70be779226eba2169a669de684085be8aa.tif',\n",
              " '/content/train/d76b0ca11c461a573916c4ed8a017bbab7d899d7.tif',\n",
              " '/content/train/15617b722dd2033247d022b21bfb7b030035e7af.tif',\n",
              " '/content/train/50229a4804af7a78a2a7f79a991f82beffdd033a.tif']"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_img = load_img(data_proc.train_file_list[0], color_mode =\"grayscale\")\n",
        "test_img_arry = img_to_array(test_img)\n",
        "print(type(test_img))\n",
        "print(test_img.format)\n",
        "print(test_img.mode)\n",
        "print(test_img.size)\n",
        "print(test_img.getbands())\n",
        "print(test_img_arry.shape)\n",
        "\n",
        "test_img1 = load_img(data_proc.train_file_list[0])\n",
        "test_img1_arry = img_to_array(test_img1)\n",
        "print(test_img1_arry.shape)\n",
        "print(test_img1.getbands())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F-_a0JOfmzX3",
        "outputId": "d4f1da0d-f031-487e-d6d9-d47b47318bfb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'PIL.TiffImagePlugin.TiffImageFile'>\n",
            "TIFF\n",
            "L\n",
            "(96, 96)\n",
            "('L',)\n",
            "(96, 96, 1)\n",
            "(96, 96, 3)\n",
            "('R', 'G', 'B')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "misc_proc.print_image_in_diff_orientation(data_proc.train_file_list[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-EkTzqZYl7Ap",
        "outputId": "cbb68732-7fb3-4197-ed97-499c91193876"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/utils/image_utils.py:382: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n",
            "  warnings.warn('grayscale is deprecated. Please use '\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-d6c407692e05>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmisc_proc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_image_in_diff_orientation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_proc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_file_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-36-80a125a92d07>\u001b[0m in \u001b[0;36mprint_image_in_diff_orientation\u001b[0;34m(self, image_file)\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;31m# plot original\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_subplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray_to_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m         pf = Polygon(((32, 32), (64, 32), (64, 64), (32, 64)),\n\u001b[1;32m     79\u001b[0m                 \u001b[0mfc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/image_utils.py\u001b[0m in \u001b[0;36marray_to_img\u001b[0;34m(x, data_format, scale, dtype)\u001b[0m\n\u001b[1;32m    224\u001b[0m   \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m     raise ValueError('Expected image array to have rank 3 (single image). '\n\u001b[0m\u001b[1;32m    227\u001b[0m                      f'Got array with shape: {x.shape}')\n\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Expected image array to have rank 3 (single image). Got array with shape: (96, 96)"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1008x864 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}