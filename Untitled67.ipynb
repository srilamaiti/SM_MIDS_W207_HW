{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "5dlGr3VX6DyA",
        "UQBd_dFh6S1S",
        "Iv-y8vdS62gV",
        "xM_Fw_tt7EpU",
        "qSyqwXIMIp7t",
        "2C55GxBKnW3V",
        "JLAsViNZnt1V",
        "0mavHZlbpFpR",
        "gmTSA20Vr0Pp"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/srilamaiti/SM_MIDS_W207_HW/blob/main/Untitled67.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***1. Setup***"
      ],
      "metadata": {
        "id": "NUylKvIS6Lsf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***A. Installing New Libraries***"
      ],
      "metadata": {
        "id": "5dlGr3VX6DyA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kAIyFDyH5uLR",
        "outputId": "4f52af3e-058d-4b7f-abc5-bf0bd02c6d01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: imgaug in /usr/local/lib/python3.7/dist-packages (0.4.0)\n",
            "Requirement already satisfied: scikit-image>=0.14.2 in /usr/local/lib/python3.7/dist-packages (from imgaug) (0.18.3)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.7/dist-packages (from imgaug) (1.8.5.post1)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.7/dist-packages (from imgaug) (2.9.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from imgaug) (1.7.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from imgaug) (3.2.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from imgaug) (4.6.0.66)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from imgaug) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from imgaug) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from imgaug) (1.21.6)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.2->imgaug) (2021.11.2)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.2->imgaug) (2.6.3)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.2->imgaug) (1.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug) (1.4.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->imgaug) (4.1.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install imgaug"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install livelossplot"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91Xb-Plzo2E5",
        "outputId": "a4a18e6a-74e0-42f8-9bf1-6a20f2e853ec"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting livelossplot\n",
            "  Downloading livelossplot-0.5.5-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from livelossplot) (3.2.2)\n",
            "Requirement already satisfied: ipython==7.* in /usr/local/lib/python3.7/dist-packages (from livelossplot) (7.9.0)\n",
            "Requirement already satisfied: numpy<1.22 in /usr/local/lib/python3.7/dist-packages (from livelossplot) (1.21.6)\n",
            "Requirement already satisfied: bokeh in /usr/local/lib/python3.7/dist-packages (from livelossplot) (2.3.3)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython==7.*->livelossplot) (57.4.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython==7.*->livelossplot) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from ipython==7.*->livelossplot) (2.0.10)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython==7.*->livelossplot) (5.1.1)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython==7.*->livelossplot) (2.6.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython==7.*->livelossplot) (4.4.2)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython==7.*->livelossplot) (0.2.0)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython==7.*->livelossplot) (4.8.0)\n",
            "Collecting jedi>=0.10\n",
            "  Downloading jedi-0.18.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 6.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.10->ipython==7.*->livelossplot) (0.8.3)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython==7.*->livelossplot) (1.15.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython==7.*->livelossplot) (0.2.5)\n",
            "Requirement already satisfied: tornado>=5.1 in /usr/local/lib/python3.7/dist-packages (from bokeh->livelossplot) (6.0.4)\n",
            "Requirement already satisfied: pillow>=7.1.0 in /usr/local/lib/python3.7/dist-packages (from bokeh->livelossplot) (7.1.2)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.7/dist-packages (from bokeh->livelossplot) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from bokeh->livelossplot) (4.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from bokeh->livelossplot) (2.8.2)\n",
            "Requirement already satisfied: Jinja2>=2.9 in /usr/local/lib/python3.7/dist-packages (from bokeh->livelossplot) (2.11.3)\n",
            "Requirement already satisfied: packaging>=16.8 in /usr/local/lib/python3.7/dist-packages (from bokeh->livelossplot) (21.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.9->bokeh->livelossplot) (2.0.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=16.8->bokeh->livelossplot) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->livelossplot) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->livelossplot) (0.11.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython==7.*->livelossplot) (0.7.0)\n",
            "Installing collected packages: jedi, livelossplot\n",
            "Successfully installed jedi-0.18.1 livelossplot-0.5.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***B. Importing Libraries***"
      ],
      "metadata": {
        "id": "UQBd_dFh6S1S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***a. Importing General Purpose Libraries***"
      ],
      "metadata": {
        "id": "Iv-y8vdS62gV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import joblib\n",
        "import glob\n",
        "import random\n",
        "from itertools import product\n",
        "import gc\n",
        "import subprocess\n",
        "import shutil\n",
        "import copy"
      ],
      "metadata": {
        "id": "ujHcENda69HI"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***b. Importing Image Processing and Visualization Libraries***"
      ],
      "metadata": {
        "id": "xM_Fw_tt7EpU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from imutils import rotate as rotate\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "import matplotlib.patches as patches\n",
        "from matplotlib.patches import Polygon\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "from skimage.color import gray2rgb\n",
        "import skimage.io as skio\n",
        "from imgaug import augmenters as img_aug\n",
        "import imgaug as iaug"
      ],
      "metadata": {
        "id": "0NV7G1UoIi4I"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***c. Importing Sklearn Functionalities***"
      ],
      "metadata": {
        "id": "qSyqwXIMIp7t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import shuffle\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.decomposition import IncrementalPCA\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import auc\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.model_selection import StratifiedShuffleSplit"
      ],
      "metadata": {
        "id": "fUh7ts6QI8Lx"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***d. Importing Tensorflow Libraries***"
      ],
      "metadata": {
        "id": "2C55GxBKnW3V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from livelossplot import PlotLossesKeras\n",
        "\n",
        "from tensorflow.keras.layers import RandomFlip\n",
        "from tensorflow.keras.layers import RandomZoom\n",
        "from tensorflow.keras.layers import RandomRotation\n",
        "from tensorflow.keras.layers import Conv1D\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import Concatenate\n",
        "from tensorflow.keras.layers import MaxPooling1D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.layers import AveragePooling2D\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import GlobalMaxPooling2D\n",
        "from tensorflow.keras.layers import GlobalAveragePooling1D\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
        "from tensorflow.keras.layers import Lambda\n",
        "from tensorflow.keras.layers import Multiply\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.layers import Bidirectional\n",
        "from tensorflow.keras.layers import PReLU\n",
        "from keras.layers.core import Activation\n",
        "from keras.layers.convolutional import SeparableConv1D\n",
        "from keras.layers.convolutional import SeparableConv2D\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.applications.vgg19 import VGG19\n",
        "from keras.applications.densenet import *\n",
        "from keras.applications.resnet import ResNet152\n",
        "from keras.applications.nasnet import NASNetMobile\n",
        "from keras.applications.nasnet import NASNetLarge\n",
        "from keras.applications.nasnet import preprocess_input\n",
        "from keras.applications import MobileNetV2\n",
        "from keras.applications.xception import Xception\n",
        "from keras.applications.inception_v3 import *\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import array_to_img\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.preprocessing.image import save_img\n",
        "\n",
        "from tensorflow.python.ops.numpy_ops import np_config\n",
        "\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "\n",
        "from tensorflow.keras.losses import mae\n",
        "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
        "from tensorflow.keras.losses import binary_crossentropy\n",
        "\n",
        "from keras.models import Model\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from keras.models import load_model\n"
      ],
      "metadata": {
        "id": "eUXe1TURnkN5"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions download -c histopathologic-cancer-detection\n",
        "#unzip -o -qq \\*.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1NmRkYfRQkZL",
        "outputId": "ba8a63ac-f4ad-4fa2-c4f4-b22f71037388"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/kaggle\", line 5, in <module>\n",
            "    from kaggle.cli import main\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/kaggle/__init__.py\", line 23, in <module>\n",
            "    api.authenticate()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/kaggle/api/kaggle_api_extended.py\", line 166, in authenticate\n",
            "    self.config_file, self.config_dir))\n",
            "OSError: Could not find kaggle.json. Make sure it's located in /root/.kaggle. Or use the environment method.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***C. Mounting Google Drive***"
      ],
      "metadata": {
        "id": "JLAsViNZnt1V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Required to read the data from Kaggle\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = \"/content/gdrive/MyDrive/Kaggle\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bCewn8D_n4oL",
        "outputId": "8355419a-b916-45ed-db1e-df079b0e0cf6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***D. Downloading Data from Kaggle***"
      ],
      "metadata": {
        "id": "0mavHZlbpFpR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!bash /content/gdrive/MyDrive/Kaggle/download_kaggle_data.ksh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qxaSmgjsoxfh",
        "outputId": "62e71f55-165c-459e-c922-42dd8cf6fd1a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading histopathologic-cancer-detection.zip to /content\n",
            "100% 6.30G/6.31G [01:02<00:00, 95.3MB/s]\n",
            "100% 6.31G/6.31G [01:02<00:00, 108MB/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***E. Defining Vartiables***"
      ],
      "metadata": {
        "id": "aZ9PZBKVtI__"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#sample_size = 80000\n",
        "sample_size = 500\n",
        "#batch_size = 192\n",
        "batch_size = 64\n",
        "image_size = 96\n",
        "#number_of_splits = 8\n",
        "number_of_splits = 5\n",
        "run_mode = ['interim_test', 'final_test']\n",
        "\n",
        "transfer_learning_model_list = ['VGG19', 'DenseNet201', 'ResNet50', 'VGG16', 'EfficientNetB7']\n",
        "learning_rate_list = [.01, .001, .0001, .00001]\n",
        "optimizer_list = ['sgd', 'adam']\n",
        "dropout_list = [.2, .4, .6]\n",
        "kernel_size_list = [(3,3), (4,4), (5,5)]\n",
        "dense_layer_node_list = [512, 256, 128]\n",
        "fully_conneted_layer_list = [1, 2, 3]\n",
        "epoch_list = [5, 10, 15, 20]\n",
        "\n",
        "train_path = os.getcwd() + \"/train/\"\n",
        "test_path = os.getcwd() + \"/test/\"\n",
        "\n",
        "original_input_file_list = train_path + '*.tif'\n",
        "original_output_file_list = test_path + '*.tif'\n",
        "\n",
        "current_working_dir = os.getcwd()\n",
        "\n",
        "train_label_file = 'train_labels.csv'\n",
        "test_label_file = 'sample_submission.csv'\n",
        "\n",
        "image_file_extension = '.tif'\n",
        "\n",
        "train_files_path = os.path.join(current_working_dir, train_path)\n",
        "test_files_path = os.path.join(current_working_dir, test_path)\n",
        "\n",
        "image_processing_train_positive_path = '/content/image_processing/train/positive'\n",
        "image_processing_train_negative_path = '/content/image_processing/train/negative'\n",
        "\n",
        "image_processing_validation_positive_path = '/content/image_processing/validation/positive'\n",
        "image_processing_validation_negative_path = '/content/image_processing/validation/negative'\n",
        "\n",
        "image_processing_test_positive_path = '/content/image_processing/test/positive'\n",
        "image_processing_test_negative_path = '/content/image_processing/test/negative'\n",
        "\n",
        "image_processing_train_path = \"/content/image_processing/train/\"\n",
        "image_processing_validation_path = \"/content/image_processing/validation/\"\n",
        "image_processing_test_path = \"/content/image_processing/test/\"\n",
        "\n",
        "random.seed(1)\n",
        "random_state = 1234\n",
        "\n",
        "dropout_layer = .5\n",
        "\n",
        "training_accuracy_col_list   = ['training_accuracy_k' + str(k) + '_fold_accuracy' for k in range(1, number_of_splits + 1)]\n",
        "validation_accuracy_col_list = ['validation_accuracy_k' + str(k) + '_fold_accuracy' for k in range(1, number_of_splits + 1)]\n",
        "training_loss_col_list = ['training_loss_k' + str(k) + '_fold_loss' for k in range(1, number_of_splits + 1)]\n",
        "validation_loss_col_list = ['validation_loss_k' + str(k) + '_fold_loss' for k in range(1, number_of_splits + 1)]\n",
        "consolidated_df_model_kpi = pd.DataFrame()\n",
        "\n",
        "saved_model_names_list = []\n",
        "\n",
        "grayscale_image_augmentation_list = ['adjust_random_brightness',\n",
        "                                     'adjust_random_contrast',\n",
        "                                     'random_flip_left_right',\n",
        "                                     'random_flip_up_down',\n",
        "                                     'rotate_image_by_angle',\n",
        "                                     'rotate_image_by_90_or_180_or_270_deg',\n",
        "                                     'random_zoom',\n",
        "                                     'resize_with_crop_or_pad'\n",
        "                                    ]"
      ],
      "metadata": {
        "id": "e4rSklTftQY-"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***F. Misclenious Processing Class***"
      ],
      "metadata": {
        "id": "m2j3vtPothqH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class misc_processing:\n",
        "    \"\"\"\n",
        "    This class contains methods for misclenious processings.\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        None\n",
        "  \n",
        "    def create_dir_structure(self, root_directory):\n",
        "        \"\"\"\n",
        "        This method creates a directory tree in the form below:-\n",
        "        image_processing--| train         |---positive\n",
        "                          |               |---negative\n",
        "                          |  \n",
        "                          | validation    |---positive\n",
        "                          |               |---negative\n",
        "                          |\n",
        "                          | test          |---positive\n",
        "                          |               |---negative\n",
        "\n",
        "        \"\"\"\n",
        "        os.makedirs(f'{root_directory}', exist_ok = True)\n",
        "        for sub_folder in ['train', 'validation', 'test']:\n",
        "            for grp in ['positive', 'negative']:\n",
        "                os.makedirs(f'{root_directory}/{sub_folder}/{grp}', exist_ok=True)\n",
        "\n",
        "    def remove_files_from_dir(self, path):\n",
        "        \"\"\"\n",
        "        This method deletes all files under a given path.\n",
        "        \"\"\"\n",
        "        print()\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"*****************************************************\")\n",
        "        print(f\"Starting to remove files under {path}...\")\n",
        "        shutil.rmtree(path)\n",
        "        os.mkdir(path)\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"*****************************************************\")\n",
        "        print()\n",
        "    \n",
        "    def generate_fully_qualified_file_name_list(self, file_list):\n",
        "        \"\"\"\n",
        "        This method generates a list of fully qualified file names.\n",
        "        \"\"\"\n",
        "        qualified_file_name_list = [os.path.join(current_working_dir, train_path) + \n",
        "                                    img + \n",
        "                                    '.tif' \n",
        "                                    for img in file_list\n",
        "                                   ]\n",
        "        return qualified_file_name_list\n",
        "\n",
        "    def print_image_original(self, image_file_list, label_list):\n",
        "        \"\"\"\n",
        "        This method prints original images.\n",
        "        \"\"\"\n",
        "        nrows, ncols = 1,4 #print first 4 images\n",
        "        f, axs = plt.subplots(nrows, ncols, figsize=(14,12))\n",
        "        for i, image in enumerate(image_file_list):\n",
        "            axs[i].imshow(array_to_img(image))\n",
        "            pf = Polygon(((32, 32), (64, 32), (64, 64), (32, 64)),\n",
        "                         fc=(0.0, 0.0, 0.0, 0.0), \n",
        "                         ec=(0.0, 0.9, 0.0 ,0.9), lw=4, linestyle='--')\n",
        "            pf.set_edgecolor('r')\n",
        "            axs[i].add_patch(pf)\n",
        "            axs[i].set(title=label_list[i])\n",
        "\n",
        "    def print_image_in_diff_orientation(self, image_file):\n",
        "        \"\"\"\n",
        "        This method prints images.\n",
        "        \"\"\"\n",
        "        tf.random.set_seed(1234)\n",
        "        fig = plt.figure(figsize=(14, 12))\n",
        "        #fig = plt.figure()\n",
        "        image = skio.imread(image_file, plugin = \"tifffile\")\n",
        "        \n",
        "        # plot original\n",
        "        ax = fig.add_subplot(1, 5, 1)\n",
        "        ax.imshow(array_to_img(image))\n",
        "        pf = Polygon(((32, 32), (64, 32), (64, 64), (32, 64)),\n",
        "                fc = (0.0, 0.0, 0.0, 0.0), \n",
        "                ec = (0.0, 0.9, 0.0 ,0.9), lw=4, linestyle='--')\n",
        "        pf.set_edgecolor('r')\n",
        "        ax.add_patch(pf)\n",
        "        ax.set_title('Original', size=15);\n",
        "        \n",
        "        # resize\n",
        "        ax = fig.add_subplot(1, 5, 2)\n",
        "        img_resize = tf.image.resize(image, size=(224, 224))\n",
        "        ax.imshow(array_to_img(img_resize))\n",
        "        pf = Polygon(((80, 80), (144, 80), (144, 144), (80, 144)),\n",
        "                fc = (0.0, 0.0, 0.0, 0.0), \n",
        "                ec = (0.0, 0.9, 0.0 ,0.9), lw=4, linestyle='--')\n",
        "        pf.set_edgecolor('r')\n",
        "        ax.add_patch(pf)\n",
        "        ax.set_title('Step 1: Resize', size=15);\n",
        "        \n",
        "        # adjust brightness\n",
        "        ax = fig.add_subplot(1, 5, 3)\n",
        "        img_bright = tf.image.adjust_brightness(img_resize, 0.3)\n",
        "        ax.imshow(array_to_img(img_bright))\n",
        "        pf = Polygon(((80, 80), (144, 80), (144, 144), (80, 144)),\n",
        "                fc = (0.0, 0.0, 0.0, 0.0), \n",
        "                ec = (0.0, 0.9, 0.0 ,0.9), lw=4, linestyle='--')\n",
        "        pf.set_edgecolor('r')\n",
        "        ax.add_patch(pf)\n",
        "        ax.set_title('Step 2: Brightness', size=15);\n",
        "        \n",
        "        # adjust contrast\n",
        "        ax = fig.add_subplot(1, 5, 4)\n",
        "        img_contrast = tf.image.adjust_contrast(img_bright, contrast_factor=3)\n",
        "        ax.imshow(array_to_img(img_contrast))\n",
        "        pf = Polygon(((80, 80), (144, 80), (144, 144), (80, 144)),\n",
        "                fc = (0.0, 0.0, 0.0, 0.0), \n",
        "                ec = (0.0, 0.9, 0.0 ,0.9), lw=4, linestyle='--')\n",
        "        pf.set_edgecolor('r')\n",
        "        ax.add_patch(pf)\n",
        "        ax.set_title('Step 3: Contrast', size=15);\n",
        "        \n",
        "        # flip left right\n",
        "        ax = fig.add_subplot(1, 5, 5)\n",
        "        img_flip = tf.image.flip_left_right(img_contrast)\n",
        "        ax.imshow(array_to_img(img_flip))\n",
        "        pf = Polygon(((80, 80), (144, 80), (144, 144), (80, 144)),\n",
        "                fc = (0.0, 0.0, 0.0, 0.0), \n",
        "                ec = (0.0, 0.9, 0.0 ,0.9), lw=4, linestyle='--')\n",
        "        pf.set_edgecolor('r')\n",
        "        ax.add_patch(pf)\n",
        "        ax.set_title('Step 4: Flip left right');\n",
        "\n",
        "    def get_id_and_label_list(self, file_path, file_extension):\n",
        "        \"\"\"\n",
        "        This function gets the imgae id and corresponding label.\n",
        "        \"\"\"\n",
        "        file_list = []\n",
        "        for file_name in glob.glob(file_path + '*' + file_extension):\n",
        "            file_list.append(file_name)\n",
        "        return file_list\n",
        "\n",
        "    def compute_mean_and_std(self, image_file_list, r_mid_pos = 48, c_mid_pos = 48):\n",
        "        \"\"\"\n",
        "        This method computes mean and std at the center of the image.\n",
        "        \"\"\"\n",
        "        center_pixel_value_list = []\n",
        "        for image_file in image_file_list:\n",
        "            image = skio.imread(image_file, plugin = \"tifffile\")\n",
        "            center_pixel_value_list.append(image[r_mid_pos, c_mid_pos])\n",
        "        np_array_center_pixel_value = np.array(center_pixel_value_list)\n",
        "        return np.mean(np_array_center_pixel_value), np.std(np_array_center_pixel_value)\n",
        "\n",
        "    def copy_file_from_one_to_other(self, file_names, dest_path):\n",
        "        \"This method moves chunks of files in one to other.\"\n",
        "        os.system('cp -r ' + file_names + ' ' + dest_path)\n",
        "\n",
        "    def process_copy_files(self, file_name_list, dest_path):\n",
        "        \"\"\"\"\n",
        "        This method processes moving files from one dir to the other. \n",
        "        This is the master process to run actual moving in chunks.\n",
        "        \"\"\"\n",
        "        '''\n",
        "        process_chunk_size = 100\n",
        "        for idx in range(0, len(file_name_list), process_chunk_size):\n",
        "            if idx % 10000 == 0:\n",
        "                print(\"Processing index: \", idx)\n",
        "            self.copy_file_from_one_to_other(' '.join(file_name_list[idx : idx + process_chunk_size]), dest_path)\n",
        "        '''\n",
        "        for file in file_name_list:\n",
        "            shutil.copy(file, dest_path)\n",
        "    \n",
        "    def check_file_count_in_a_directory(self, dir_path):\n",
        "        \"\"\"\n",
        "        This method checks the file count in a directory\n",
        "        \"\"\"\n",
        "        cmd_string = 'ls ' + dir_path + \" | wc -l\"\n",
        "        file_count = int(subprocess.check_output(cmd_string, shell=True, text=True).strip())\n",
        "        return file_count\n",
        "\n",
        "    def get_mini_batch_data(self, image_list, mini_batch_size):\n",
        "        \"\"\"\n",
        "        This method performs as a generator to spit out data in small batches.\n",
        "        \"\"\"\n",
        "        return (image_list[idx : idx + mini_batch_size] for idx in range(0, len(image_list), mini_batch_size))\n",
        "\n",
        "    def get_aug_step_list(self):\n",
        "        \"\"\"\n",
        "        This method executes image augmentation pipeline.\n",
        "        \"\"\"\n",
        "        sometimes = lambda aug: img_aug.Sometimes(0.5, aug)\n",
        "        img_aug_seq = img_aug.Sequential(\n",
        "        [\n",
        "            # apply the following augmenters to most images\n",
        "            img_aug.Fliplr(0.5), # horizontally flip 50% of all images\n",
        "            img_aug.Flipud(0.2), # vertically flip 20% of all images\n",
        "            sometimes(img_aug.Affine(\n",
        "                scale={\"x\": (0.9, 1.1), \"y\": (0.9, 1.1)}, # scale images to 80-120% of their size, individually per axis\n",
        "                translate_percent={\"x\": (-0.1, 0.1), \"y\": (-0.1, 0.1)}, # translate by -20 to +20 percent (per axis)\n",
        "                rotate=(-10, 10), # rotate by -45 to +45 degrees\n",
        "                shear=(-5, 5), # shear by -16 to +16 degrees\n",
        "                order=[0, 1], # use nearest neighbour or bilinear interpolation (fast)\n",
        "                cval=(0, 255), # if mode is constant, use a cval between 0 and 255\n",
        "                mode=iaug.ALL # use any of scikit-image's warping modes (see 2nd image from the top for examples)\n",
        "            )),\n",
        "            # execute 0 to 5 of the following (less important) augmenters per image\n",
        "            # don't execute all of them, as that would often be way too strong\n",
        "            img_aug.SomeOf((0, 5),\n",
        "                [\n",
        "                    sometimes(img_aug.Superpixels(p_replace=(0, 1.0), n_segments=(20, 200))), # convert images into their superpixel representation\n",
        "                    img_aug.OneOf([\n",
        "                        img_aug.GaussianBlur((0, 1.0)), # blur images with a sigma between 0 and 3.0\n",
        "                        img_aug.AverageBlur(k=(3, 5)), # blur image using local means with kernel sizes between 2 and 7\n",
        "                        img_aug.MedianBlur(k=(3, 5)), # blur image using local medians with kernel sizes between 2 and 7\n",
        "                    ]),\n",
        "                    img_aug.Sharpen(alpha=(0, 1.0), lightness=(0.9, 1.1)), # sharpen images\n",
        "                    img_aug.Emboss(alpha=(0, 1.0), strength=(0, 2.0)), # emboss images\n",
        "                    # search either for all edges or for directed edges,\n",
        "                    # blend the result with the original image using a blobby mask\n",
        "                    img_aug.SimplexNoiseAlpha(img_aug.OneOf([\n",
        "                        img_aug.EdgeDetect(alpha=(0.5, 1.0)),\n",
        "                        img_aug.DirectedEdgeDetect(alpha=(0.5, 1.0), direction=(0.0, 1.0)),\n",
        "                    ])),\n",
        "                    img_aug.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.01*255), per_channel=0.5), # add gaussian noise to images\n",
        "                    img_aug.OneOf([\n",
        "                        img_aug.Dropout((0.01, 0.05), per_channel=0.5), # randomly remove up to 10% of the pixels\n",
        "                        img_aug.CoarseDropout((0.01, 0.03), size_percent=(0.01, 0.02), per_channel=0.2),\n",
        "                    ]),\n",
        "                    img_aug.Invert(0.01, per_channel=True), # invert color channels\n",
        "                    img_aug.Add((-2, 2), per_channel=0.5), # change brightness of images (by -10 to 10 of original value)\n",
        "                    img_aug.AddToHueAndSaturation((-1, 1)), # change hue and saturation\n",
        "                    # either change the brightness of the whole image (sometimes\n",
        "                    # per channel) or change the brightness of subareas\n",
        "                    img_aug.OneOf([\n",
        "                        img_aug.Multiply((0.9, 1.1), per_channel=0.5),\n",
        "                        img_aug.FrequencyNoiseAlpha(\n",
        "                            exponent=(-1, 0),\n",
        "                            first=img_aug.Multiply((0.9, 1.1), per_channel=True),\n",
        "                            second=img_aug.ContrastNormalization((0.9, 1.1))\n",
        "                        )\n",
        "                    ]),\n",
        "                    sometimes(img_aug.ElasticTransformation(alpha=(0.5, 3.5), sigma=0.25)), # move pixels locally around (with random strengths)\n",
        "                    sometimes(img_aug.PiecewiseAffine(scale=(0.01, 0.05))), # sometimes move parts of the image around\n",
        "                    sometimes(img_aug.PerspectiveTransform(scale=(0.01, 0.1)))\n",
        "                ],\n",
        "                random_order=True\n",
        "            )\n",
        "        ],\n",
        "        random_order=True\n",
        "        )\n",
        "        return img_aug_seq\n",
        "\n",
        "    def get_id_label_map(self, df, filter_list):\n",
        "        \"\"\"\n",
        "        This method generates the id and label dictionary.\n",
        "        \"\"\"\n",
        "        return {k : v for k, v in zip(df[df.id.isin(filter_list)].id.values, \n",
        "                                      df[df.id.isin(filter_list)].label.values\n",
        "                                     )\n",
        "               }\n",
        "\n",
        "    def image_data_generator(self, list_files, label_list, batch_size, augment=False):\n",
        "        \"\"\"\n",
        "        This method is a generrator function to produce mini batch of data.\n",
        "        \"\"\"\n",
        "        image_augmentation_steps = self.get_aug_step_list()\n",
        "        while True:\n",
        "            shuffle(list_files)\n",
        "            for mini_batch in self.get_mini_batch_data(list_files, batch_size):\n",
        "                X = [cv2.imread(x) for x in mini_batch]\n",
        "                y = label_list\n",
        "                if augment:\n",
        "                    aug_X = image_augmentation_steps.augment_images(X)\n",
        "                    aug_y = y\n",
        "                    X = X + aug_X\n",
        "                X = [preprocess_input(x) for x in X]\n",
        "                \n",
        "        yield np.array(X), np.array(y)\n",
        "\n",
        "misc_proc = misc_processing()\n",
        "misc_proc.create_dir_structure(root_directory = '/content/image_processing')"
      ],
      "metadata": {
        "id": "KMaqq9V4toXo"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***G. Visualization Processing Class***"
      ],
      "metadata": {
        "id": "jStvd4wGp8Ju"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class data_viz_processing:\n",
        "    \"\"\"\n",
        "    This class contains methods to display various plots.\n",
        "    \"\"\"\n",
        "    def count_plot(self, data, label_col, title_val):\n",
        "        \"\"\"\n",
        "        This method plots count plot of the input data set.\n",
        "        \"\"\"\n",
        "        sns.countplot(data = data, x = label_col)\n",
        "        plt.title(title_val)\n",
        "        plt.show(block = False)\n",
        "\n",
        "    def pie_chart_plot(self, data, label_col, title_val):\n",
        "        \"\"\"\n",
        "        This method plots pie chart based on the given data.\n",
        "        \"\"\"\n",
        "        fig = px.pie(data, \n",
        "                     values = data[label_col].value_counts().values, \n",
        "                     names = data[label_col].unique())\n",
        "        fig.update_layout(\n",
        "                      title={\n",
        "                             'text'    : title_val,\n",
        "                             'y'       : .99,\n",
        "                             'x'       :  0.5,\n",
        "                             'xanchor' : 'center',\n",
        "                             'yanchor' : 'top'\n",
        "                            }\n",
        "                          )\n",
        "        fig.show()\n",
        "        plt.show(block = False)\n",
        "\n",
        "data_viz = data_viz_processing()"
      ],
      "metadata": {
        "id": "myB5dDG2qBTr"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***H. Image Processing Class***"
      ],
      "metadata": {
        "id": "i2353h6hNEnz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class image_processing:\n",
        "    \"\"\"\n",
        "    This class contains methods for image processing.\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        None\n",
        "    \n",
        "    def read_image_file_in_np_array(self, image_list):\n",
        "        \"\"\"\n",
        "        This method reads each image file in a Numpy array and returns it.\n",
        "        \"\"\"\n",
        "        return np.asarray([skio.imread(image_file, plugin = \"tifffile\") for image_file in image_list])\n",
        "    \n",
        "    def convert_np_array_to_tensor(self, np_image_array):\n",
        "        \"\"\"\n",
        "        This method converts the numpy array representation of each image in tensor.\n",
        "        \"\"\"\n",
        "        return tf.convert_to_tensor(np_image_array, dtype = tf.float32)\n",
        "\n",
        "    def convert_int_tf_to_float(self, tf_image_list):\n",
        "        \"\"\"\n",
        "        This method converts integer TF value to float.\n",
        "        \"\"\"\n",
        "        return np.asanyarray([tf.cast(img, tf.float32) for img in tf_image_list])\n",
        "    \n",
        "    def convert_from_rgb_to_grayscale(self, tf_image_list, large_list_ind = False):\n",
        "        \"\"\"\n",
        "        This method converts color image to grayscale.\n",
        "        \"\"\"\n",
        "        if large_list_ind == False:\n",
        "            return tf.image.rgb_to_grayscale(tf_image_list) / 255.0\n",
        "        else:\n",
        "            None\n",
        "    \n",
        "    def combine_train_val(self, x_train, X_val, y_train, y_val):\n",
        "        \"\"\"\n",
        "        This method combines train and validation data, shuffles them and \n",
        "        returns back suffled data for k-fold cross validation.\n",
        "        \"\"\"\n",
        "        X_train_kfold = tf.concat([X_train, X_val] , axis = 0)\n",
        "        y_train_kfold = tf.concat([y_train, y_val] , axis = 0)\n",
        "\n",
        "        print(\"Shuffling the kfold train data...\")\n",
        "        tf.random.set_seed(1234) # for reproducibility\n",
        "    \n",
        "        test_shuffle_indices = tf.random.shuffle(tf.range(tf.shape(X_train_kfold)[0], dtype = tf.int32))\n",
        "        X_train_kfold = tf.gather(X_train_kfold, test_shuffle_indices)\n",
        "        y_train_kfold = tf.gather(y_train_kfold, test_shuffle_indices).numpy()\n",
        "        \n",
        "        print(f\"X_train_kfold shape: {X_train_kfold.shape}\")\n",
        "        print(f\"y_train_kfold shape: {y_train_kfold.shape}\")\n",
        "\n",
        "    def adjust_brightness(self, tf_image_list, delta):\n",
        "        \"\"\"\n",
        "        This method adjusts the image brightness.\n",
        "        \"\"\"\n",
        "        return tf.image.adjust_brightness(tf_image_list, delta = delta)\n",
        "\n",
        "    def adjust_random_brightness(self, tf_image_list, max_delta = .3, seed = (1,2)):\n",
        "        \"\"\"\n",
        "        This method adjusts random image brightness.\n",
        "        \"\"\"\n",
        "        return tf.image.stateless_random_brightness(tf_image_list, max_delta = max_delta, seed = seed)\n",
        "\n",
        "    def adjust_contrast(self, tf_image_list, contrast_factor):\n",
        "        \"\"\"\n",
        "        This method adjusts contrast of the image.\n",
        "        \"\"\"\n",
        "        return tf.image.adjust_contrast(tf_image_list, contrast_factor = contrast_factor)\n",
        "\n",
        "    def adjust_random_contrast(self, contrast_factor, lower = .2, upper = .5, seed = (1,2)):\n",
        "        \"\"\"\n",
        "        This method randomly contrasts images during training.\n",
        "        \"\"\"\n",
        "        return tf.image.stateless_random_contrast(contrast_factor, lower, upper, seed)\n",
        "\n",
        "    def flip_left_right(self, tf_image_list):\n",
        "        \"\"\"\n",
        "        This method applies flips the image from left to right.\n",
        "        \"\"\"\n",
        "        return tf.image.flip_left_right(tf_image_list)\n",
        "\n",
        "    def random_flip_left_right(self, tf_image_list, seed = (1,2)):\n",
        "        \"\"\"\n",
        "        This method randomly flips images left-right during training.\n",
        "        \"\"\"\n",
        "        return tf.image.stateless_random_flip_left_right(tf_image_list, seed)\n",
        "\n",
        "    def flip_up_down(self, tf_image_list):\n",
        "        \"\"\"\n",
        "        This method flips the image up-down.\n",
        "        \"\"\"\n",
        "        return tf.image.flip_up_down(tf_image_list)\n",
        "    \n",
        "    def random_flip_up_down(self, tf_image_list, seed = (1,2)):\n",
        "        \"\"\"\n",
        "        This method flips the image up-down.\n",
        "        \"\"\"\n",
        "        return tf.image.stateless_random_flip_up_down(tf_image_list, seed)\n",
        "\n",
        "    def rotate_image_by_90_or_180_or_270_deg(self, tf_image_list, k = 1):\n",
        "        \"\"\"\n",
        "        This method rotates images by 90/180/270 degrees.\n",
        "        k = 1 : 90 degree rotation\n",
        "        k = 2 : 180 degree rotation\n",
        "        k = 3 : 270 degree rotation\n",
        "        \"\"\"\n",
        "        return tf.image.rot90(tf_image_list, k)\n",
        "\n",
        "    def rotate_image_by_angle(self, tf_image_list, angle = tf.constant(np.pi/8)):\n",
        "        \"\"\"\n",
        "        This method rotates images by a given angle.\n",
        "        \"\"\"\n",
        "        rotate_layer = tf.keras.layers.RandomRotation(0.2)\n",
        "        rotated_image = rotate_layer(tf_image_list) \n",
        "        return rotated_image    \n",
        "    \n",
        "    def random_zoom(self, tf_image_list):\n",
        "        \"\"\"\n",
        "        This method zooms the image.\n",
        "        \"\"\"\n",
        "        zoom_layer = tf.keras.layers.RandomZoom(.5, .2)\n",
        "        zoomed_image = zoom_layer(tf_image_list) \n",
        "        return zoomed_image\n",
        "\n",
        "    def random_crop(self, tf_image_list, crop_height = 16, crop_width = 16):\n",
        "        \"\"\"\n",
        "        This method randomly crops the image.\n",
        "        \"\"\"\n",
        "        crop_layer = tf.keras.layers.RandomCrop(crop_height, crop_width)\n",
        "        cropped_image = crop_layer(tf_image_list) \n",
        "        return cropped_image\n",
        "\n",
        "    def resize_with_crop_or_pad(self, tf_image_list, crop_height = 32, crop_width = 32):\n",
        "        \"\"\"\n",
        "        This method crops and resizes the central part of the image.\n",
        "        \"\"\"\n",
        "        cropped_image = tf.image.resize_with_crop_or_pad(tf_image_list, crop_height, crop_width)\n",
        "        resized_image = tf.image.resize(cropped_image, [96, 96])\n",
        "        return resized_image\n",
        "\n",
        "    def image_augmentation_pipeline(self, train_image_list, test_image_list, validation_image_list):\n",
        "        \"\"\"\n",
        "        This method executes image augmentation tasks.\n",
        "        \"\"\"\n",
        "        for img_aug_func in grayscale_image_augmentation_list:\n",
        "            \n",
        "            print(\"Image augmentation function : \", img_aug_func)\n",
        "            \n",
        "            if img_aug_func == 'adjust_random_brightness':\n",
        "      \n",
        "                print(\"Handling random brightness adjustment for train_image_list\")\n",
        "                train_image_aug_list = self.adjust_random_brightness(tf_image_list = train_image_list, \n",
        "                                                                     max_delta = np.round(random.uniform(.1, .5),1)\n",
        "                                                                    )\n",
        "                gc.collect()\n",
        "                tf.keras.backend.clear_session()\n",
        "                print(f\"Shape of train_image_aug_list : {train_image_aug_list.shape}\")\n",
        "\n",
        "            elif img_aug_func == 'adjust_random_contrast':\n",
        "      \n",
        "                print(\"Handling contrast adjustment for X_train_positive_aug_tf\")\n",
        "                train_image_aug_list = self.adjust_random_contrast(tf_image_list = train_image_aug_list, \n",
        "                                                                   lower = np.round(random.uniform(.1, .3),1), \n",
        "                                                                   upper = np.round(random.uniform(.4, .6),1)\n",
        "                                                                  )\n",
        "                gc.collect()\n",
        "                tf.keras.backend.clear_session()\n",
        "                print(f\"Shape of train_image_aug_list : {train_image_aug_list.shape}\")\n",
        "\n",
        "            elif img_aug_func == 'random_flip_left_right':\n",
        "                \n",
        "                print(\"Handling random flip left and right for train_image_list\")\n",
        "                train_image_aug_list = self.random_flip_left_right(tf_image_list = train_image_aug_list)\n",
        "                gc.collect()\n",
        "                print(f\"Shape of X_train_positive_aug_tf : {train_image_aug_list.shape}\")\n",
        "\n",
        "            elif img_aug_func == 'random_flip_up_down':\n",
        "\n",
        "                print(\"Handling random flip up and down for train_image_list\")\n",
        "                train_image_aug_list = self.random_flip_up_down(tf_image_list = train_image_aug_list)\n",
        "                gc.collect()\n",
        "                tf.keras.backend.clear_session()\n",
        "                print(f\"Shape of X_train_positive_aug_tf : {train_image_aug_list.shape}\")\n",
        "\n",
        "            elif img_aug_func == 'rotate_image_by_angle':\n",
        "                \n",
        "                print(\"Handling image rotation by an angle for train_image_list\")\n",
        "                train_image_aug_list = self.rotate_image_by_angle(tf_image_list = train_image_aug_list)\n",
        "                gc.collect()\n",
        "                tf.keras.backend.clear_session()\n",
        "                print(f\"Shape of X_train_positive_aug_tf : {train_image_aug_list.shape}\")\n",
        "            \n",
        "            elif img_aug_func == 'rotate_image_by_90_or_180_or_270_deg':\n",
        "\n",
        "                print(\"Handling image rotation by 90 deg angle for train_image_list\")\n",
        "                train_image_aug_list = self.rotate_image_by_90_or_180_or_270_deg(tf_image_list = train_image_aug_list, \n",
        "                                                                                 k = random.randrange(1, 3)\n",
        "                                                                                )\n",
        "                gc.collect()\n",
        "                print(f\"Shape of X_train_positive_aug_tf : {train_image_aug_list.shape}\")\n",
        "\n",
        "            elif img_aug_func == 'random_zoom':\n",
        "\n",
        "                print(\"Handling random zoom for X_train_positive_aug_tf\")\n",
        "                train_image_aug_list = self.random_zoom(tf_image_list = train_image_aug_list)\n",
        "                gc.collect()\n",
        "                tf.keras.backend.clear_session()\n",
        "                print(f\"Shape of X_train_positive_aug_tf : {train_image_aug_list.shape}\")\n",
        "        \n",
        "            elif img_aug_func == 'resize_with_crop_or_pad':\n",
        "\n",
        "                print(\"Handling resize with crop or pad for train_image_list\")\n",
        "                train_image_aug_list = self.resize_with_crop_or_pad(tf_image_list = train_image_aug_list)\n",
        "                gc.collect()\n",
        "                print(f\"Shape of X_train_positive_aug_tf : {train_image_aug_list.shape}\")\n",
        "        \n",
        "        return train_image_aug_list\n",
        "\n",
        "img_proc = image_processing()"
      ],
      "metadata": {
        "id": "o4VmIP_cNQCS"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***I. Misclenious Model Building, Metric Reporting and Plotting Class***"
      ],
      "metadata": {
        "id": "GSEWn5BEN1Sz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class misc_model_functionality_processing:\n",
        "    \"\"\"\n",
        "    This class contains misclenious methods, required for model KPI or model plotting.\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        tf.random.set_seed(random_state)\n",
        "        np.random.seed(random_state)\n",
        "        tf.keras.backend.clear_session()\n",
        "\n",
        "    def model_summary_and_display_structure(self, model):\n",
        "        \"\"\"\n",
        "        This method shows model summary and displays the model structure.\n",
        "        \"\"\"\n",
        "        model.summary()\n",
        "        tf.keras.utils.plot_model(model)\n",
        "        plt.show(block = False)\n",
        "\n",
        "    def model_save(self, model, model_name):\n",
        "        \"\"\"\n",
        "        This method saves the model in a h5 file.\n",
        "        \"\"\"\n",
        "        tf.keras.backend.clear_session()\n",
        "        model.save(model_name + '.h5')\n",
        "    \n",
        "    def model_evaluation(self, model, X_test, y_test):\n",
        "        \"\"\"\n",
        "        This method evaluates the test data for a given model.\n",
        "        \"\"\"\n",
        "        self.test_results = model.evaluate(X_test, y_test)\n",
        "        print('\\nTest Loss : {:.2f}%'.format(self.test_results[0] * 100))\n",
        "        print('\\nTest Accuracy :  {:.2f}%'.format(self.test_results[1] * 100))\n",
        "\n",
        "    def model_prediction(self, model, X_test):\n",
        "        \"\"\"\n",
        "        This method predicts for a given model.\n",
        "        \"\"\"\n",
        "        # transform logits to probabilities\n",
        "        self.pred_logits = model.predict(X_test)\n",
        "        self.probas = tf.sigmoid(self.pred_logits)\n",
        "        self.probas = self.probas.numpy().flatten() * 100\n",
        "\n",
        "    def plot_model_accuracy_and_loss(self, history, model_name):\n",
        "        \"\"\"\n",
        "        This method plots model training and validation accuracies.\n",
        "        \"\"\"\n",
        "        tf.keras.backend.clear_session()\n",
        "\n",
        "        hist = history.history\n",
        "        x_arr = np.arange(len(hist['loss'])) + 1\n",
        "        \n",
        "        fig = plt.figure(figsize=(12, 4))\n",
        "        ax = fig.add_subplot(1, 2, 1)\n",
        "        ax.plot(x_arr, hist['loss'], '-o', label = 'Train loss')\n",
        "        ax.plot(x_arr, hist['val_loss'], '--<', label = 'Validation loss')\n",
        "        ax.legend(fontsize=15)\n",
        "        ax.set_xlabel('Epoch', size = 15)\n",
        "        ax.set_ylabel('Loss', size = 15)\n",
        "\n",
        "        ax = fig.add_subplot(1, 2, 2)\n",
        "        ax.plot(x_arr, hist['accuracy'], '-o', label = 'Train acc.')\n",
        "        ax.plot(x_arr, hist['val_accuracy'], '--<', label = 'Validation acc.')\n",
        "        ax.legend(fontsize = 15)\n",
        "        ax.set_xlabel('Epoch', size = 15)\n",
        "        ax.set_ylabel('Accuracy', size = 15)\n",
        "        ax.set_ylim(0,1)\n",
        "        plt.title(f\"Training and validation loss and accuracies for model : {model_name}\")\n",
        "        plt.show(block = False)\n",
        "\n",
        "    def build_pretained_model(self, model_name):\n",
        "        \"\"\"\n",
        "        This function utilizes transfer learning of a given model.\n",
        "        \"\"\"\n",
        "        tf.random.set_seed(random_state)\n",
        "        np.random.seed(random_state)\n",
        "        tf.keras.backend.clear_session()\n",
        "        input_shape = (image_size, image_size, 3)\n",
        "        if model_name == 'VGG19':\n",
        "            pretrained_model = VGG19(weights = 'imagenet', include_top = False, input_shape = input_shape)\n",
        "        elif model_name == 'DenseNet201':\n",
        "            pretrained_model = tf.keras.applications.densenet.DenseNet201(weights = 'imagenet', include_top = False, input_shape = input_shape)\n",
        "        elif model_name == 'ResNet50':\n",
        "            pretrained_model = tf.keras.applications.resnet50.ResNet50(weights = 'imagenet', include_top = False, input_shape = input_shape)\n",
        "        elif model_name == 'VGG16':\n",
        "            pretrained_model = VGG16(weights = 'imagenet', include_top = False, input_shape = input_shape)\n",
        "        elif model_name == 'EfficientNetB7':\n",
        "            pretrained_model = tf.keras.applications.efficientnet.EfficientNetB7(weights = 'imagenet', include_top = False, input_shape = input_shape)\n",
        "        self.model_summary_and_display_structure(pretrained_model)\n",
        "        return pretrained_model\n",
        "\n",
        "    def model_plot_test_vs_predicted(self, X_test, y_test, y_pred):\n",
        "        \"\"\"\n",
        "        This method plots actual vs prected results against each images.\n",
        "        \"\"\"\n",
        "        # plot test data and associated predicred\n",
        "        fig = plt.figure(figsize=(20, 20))\n",
        "        \n",
        "        for j, example in enumerate(X_test[:20]):\n",
        "            ax = fig.add_subplot(8, 4, j+1)\n",
        "            ax.set_xticks([])\n",
        "            ax.set_yticks([])\n",
        "            ax.imshow(array_to_img(example))\n",
        "            if y_test[j]==0:\n",
        "                true_label = 'No Cancer'\n",
        "            else:\n",
        "                true_label = 'Cancer'\n",
        "    \n",
        "            ax.text(\n",
        "                0.5, -0.15, \n",
        "                'True Label: {:s}\\nPr(Cancer)={:.0f}%'.format(y_test, self.probas[j]), \n",
        "                size = 16, \n",
        "                color = 'grey',\n",
        "                horizontalalignment = 'center',\n",
        "                verticalalignment = 'center', \n",
        "                transform = ax.transAxes)\n",
        "    \n",
        "        plt.tight_layout()\n",
        "        plt.show(block = False)\n",
        "    \n",
        "    def plot_model_result_confusion_matrix(self, model, y_test):\n",
        "        \"\"\"\n",
        "        This method plots confusion matrix.\n",
        "        \"\"\"\n",
        "        self.predictions_baseline = [1 if x > 50.0 else 0 for x in self.probas]\n",
        "        confusion_matrix_baseline = confusion_matrix(np.ceil(y_test).astype(int), self.predictions_baseline)\n",
        "        #plot_confusion_matrix(confusion_matrix_baseline, ['Cancer', 'No Cancer'])\n",
        "        print('ROC AUC Score = ', roc_auc_score(np.ceil(y_test).astype(int), self.predictions_baseline))\n",
        "\n",
        "        fig, ax = plot_confusion_matrix(conf_mat = confusion_matrix_baseline,\n",
        "                                       show_absolute = True,\n",
        "                                       show_normed = True,\n",
        "                                       colorbar = True,\n",
        "                                       cmap = 'Dark2')\n",
        "        plt.show(block = False)\n",
        "\n",
        "    def plot_roc_auc_curve(self, model, y_test):\n",
        "        \"\"\"\n",
        "        This method plots ROC AUC Curve.\n",
        "        \"\"\"\n",
        "        fpr_baseline, tpr_baseline, thresholds_baseline = roc_curve(np.ceil(y_test).astype(int), self.predictions_baseline)\n",
        "        auc_baseline = auc(fpr_baseline, tpr_baseline)\n",
        "        \n",
        "        plt.figure(1)\n",
        "        plt.plot([0, 1], [0, 1], 'k--')\n",
        "        plt.plot(fpr_baseline, tpr_baseline, label='area = {:.2f}'.format(auc_baseline))\n",
        "        plt.xlabel('False positive rate')\n",
        "        plt.ylabel('True positive rate')\n",
        "        plt.title('ROC Curve Baseline')\n",
        "        plt.legend(loc = 'best')\n",
        "        plt.show(block = False)\n",
        "\n",
        "    def generate_report(self, y_test):\n",
        "        \"\"\"\n",
        "        This method generates model performance report.\n",
        "        \"\"\"\n",
        "        report_baseline = classification_report(np.ceil(y_test).astype(int), self.predictions_baseline, target_names = ['No Cancer', 'Cancer'])\n",
        "        print(report_baseline)\n",
        "\n",
        "model_proc = misc_model_functionality_processing()"
      ],
      "metadata": {
        "id": "HC8mI7nSOBnZ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***2. Data Processing***"
      ],
      "metadata": {
        "id": "GMct-xh6t74w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class data_processing:\n",
        "\n",
        "    def __init__(self, run_mode):\n",
        "        self.train_file_list = []\n",
        "        self.test_file_list = []\n",
        "        self.run_mode = run_mode\n",
        "        np.random.seed(random_state)\n",
        "                \n",
        "    def get_file_names_list(self):\n",
        "        \"\"\"\n",
        "    \t  This method builds the list of train and test files.\n",
        "    \t  \"\"\"\n",
        "        print()\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"Starting to build train and test file name lists...\")\n",
        "        self.train_file_list = misc_proc.get_id_and_label_list(train_files_path, image_file_extension)\n",
        "        self.test_file_list = misc_proc.get_id_and_label_list(test_files_path, image_file_extension)\n",
        "        for image_file in self.train_file_list:\n",
        "            img_gs = load_img(image_file, grayscale=True)\n",
        "            img_array_gs = img_to_array(img_gs)\n",
        "            save_img(image_file, img_array_gs)\n",
        "        \n",
        "        if self.run_mode == 'interim_test':\n",
        "            print(f\"Length of train_file_list : {len(self.train_file_list)}\")\n",
        "            print(f\"Length of test_file_list : {len(self.test_file_list)}\")\n",
        "        print(\"Completed building train and test file name lists...\")\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"*****************************************************\")\n",
        "        print()\n",
        "\n",
        "    def get_label_info(self):\n",
        "        \"\"\"\n",
        "    \t  This method reads the train and test label information.\n",
        "    \t  \"\"\"\n",
        "        print()\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"Starting to get label info...\")\n",
        "        self.train_label = pd.read_csv(train_label_file)\n",
        "        self.test_label = pd.read_csv(test_label_file)\n",
        "        if self.run_mode == 'interim_test':\n",
        "            print(f\"Number of train labels : {len(self.train_label)}\")\n",
        "            print(f\"Number of test labels : {len(self.test_label)}\")\n",
        "\n",
        "        self.qualified_train_file_names_list = misc_proc.generate_fully_qualified_file_name_list(self.train_label.id.values.tolist())\n",
        "        self.qualified_test_file_names_list = misc_proc.generate_fully_qualified_file_name_list(self.test_label.id.values.tolist())\n",
        "        \n",
        "        self.train_label_positive = self.train_label[self.train_label['label'] == 1]\n",
        "        self.train_label_negative = self.train_label[self.train_label['label'] == 0]\n",
        "        print(\"Completed getting label info...\")\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"*****************************************************\")\n",
        "        print()\n",
        "\n",
        "    def create_labels(self, train_val_test_ind, data):\n",
        "        \"\"\"\n",
        "        This method creates label of given length.\n",
        "        \"\"\"\n",
        "        print()\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"*****************************************************\")\n",
        "        print(f\"Starting to create labels for {train_val_test_ind}...\")\n",
        "        if train_val_test_ind.lower() == 'train':\n",
        "            self.y_train = np.asarray(data['label'].values.tolist())\n",
        "        elif train_val_test_ind.lower() == 'test':\n",
        "            self.y_test = np.asarray(data['label'].values.tolist())\n",
        "        elif train_val_test_ind.lower() == 'validation':\n",
        "            self.y_validation = np.asarray(data['label'].values.tolist())    \n",
        "        print(f\"Completed building labels for {train_val_test_ind}...\")\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"*****************************************************\")\n",
        "        print()\n",
        "\n",
        "    def split_data_based_on_indices(self, train_indices, validation_indices):\n",
        "        \"\"\"\n",
        "        This method splits data based on indices.\n",
        "        \"\"\"\n",
        "        print()\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"Starting to split data based on indices...\")\n",
        "        # New train and validation set and corresponding labels based on the kfold split process generated indices.\n",
        "        self.df_train = self.df_train_original.iloc[train_indices]\n",
        "        self.df_validation = self.df_train_original.iloc[validation_indices]\n",
        "        self.create_labels(train_val_test_ind = 'train', data = self.df_train)\n",
        "        self.create_labels(train_val_test_ind = 'validation', data = self.df_validation)\n",
        "        \n",
        "        if self.run_mode == 'interim_test':\n",
        "            print(f\"Length of train data : {len(self.df_train)}, length of validation data : {len(self.df_validation)}, length of test data : {len(self.df_test)}\")\n",
        "            print(f\"Length of train positive data : {len(self.df_train[self.df_train.label == 1])}, length of validation positive data : {len(self.df_validation[self.df_validation.label == 1])}, length of test positive data : {len(self.df_test[self.df_test.label == 1])}\")\n",
        "            print(f\"Length of train negative data : {len(self.df_train[self.df_train.label == 0])}, length of validation negative data : {len(self.df_validation[self.df_validation.label == 0])}, length of test negative data : {len(self.df_test[self.df_test.label == 0])}\")\n",
        "        \n",
        "        misc_proc.remove_files_from_dir(image_processing_train_positive_path)\n",
        "        misc_proc.remove_files_from_dir(image_processing_train_negative_path)\n",
        "        self.train_positive_file_list = misc_proc.generate_fully_qualified_file_name_list(self.df_train[self.df_train.label == 1].id.values.tolist())\n",
        "        self.train_negative_file_list = misc_proc.generate_fully_qualified_file_name_list(self.df_train[self.df_train.label == 0].id.values.tolist())\n",
        "        print(f\"Copying test_positive_file_list under {image_processing_train_positive_path}\")\n",
        "        misc_proc.process_copy_files(self.train_positive_file_list, image_processing_train_positive_path)\n",
        "        print(f\"Copying test_negative_file_list under {image_processing_train_negative_path}\")\n",
        "        misc_proc.process_copy_files(self.train_negative_file_list, image_processing_train_negative_path)\n",
        "        print(f\"File count under {image_processing_train_positive_path} after moving new files is: {misc_proc.check_file_count_in_a_directory(image_processing_train_positive_path)}\")\n",
        "        print(f\"File count under {image_processing_train_negative_path} after moving new files is : {misc_proc.check_file_count_in_a_directory(image_processing_train_negative_path)}\")\n",
        "        \n",
        "        misc_proc.remove_files_from_dir(image_processing_validation_positive_path)\n",
        "        misc_proc.remove_files_from_dir(image_processing_validation_negative_path)\n",
        "        self.validation_positive_file_list = misc_proc.generate_fully_qualified_file_name_list(self.df_validation[self.df_validation.label == 1].id.values.tolist())\n",
        "        self.validation_negative_file_list = misc_proc.generate_fully_qualified_file_name_list(self.df_validation[self.df_validation.label == 0].id.values.tolist())\n",
        "        print(f\"Copying test_positive_file_list under {image_processing_validation_positive_path}\")\n",
        "        misc_proc.process_copy_files(self.validation_positive_file_list, image_processing_validation_positive_path)\n",
        "        print(f\"Copying test_negative_file_list under {image_processing_validation_negative_path}\")\n",
        "        misc_proc.process_copy_files(self.validation_negative_file_list, image_processing_validation_negative_path)\n",
        "        print(f\"File count under {image_processing_validation_positive_path} after moving new files is: {misc_proc.check_file_count_in_a_directory(image_processing_validation_positive_path)}\")\n",
        "        print(f\"File count under {image_processing_validation_negative_path} after moving new files is : {misc_proc.check_file_count_in_a_directory(image_processing_validation_negative_path)}\")\n",
        "            \n",
        "        print(\"Completed spliting the data sets based on indices...\")\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"*****************************************************\")\n",
        "        print()\n",
        "\n",
        "    def initial_split_data(self):\n",
        "        \"\"\"\n",
        "    \t  This method uses train data to split into train, validation and test sets.\n",
        "    \t  The reason we are repurposing the train set is because we do not have labels for test data.\n",
        "    \t  We also see data imbalance issue and thus we are undersampling the most populated class (negative images).\n",
        "    \t  \"\"\"\n",
        "        print()\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"Starting to split data...\")\n",
        "        self.train_label_sample_positive = self.train_label_positive.head(sample_size)\n",
        "        self.train_label_sample_negative = self.train_label_negative.head(sample_size)\n",
        "        self.train_label_processed = pd.concat([self.train_label_sample_negative, \n",
        "          \t                                    self.train_label_sample_positive\n",
        "        \t                                     ], \n",
        "        \t                                     axis = 0).reset_index(drop = True)\n",
        "\n",
        "        remaining_length = 50 #len(self.train_label_positive) - len(self.train_label_sample_positive)\n",
        "        self.test_positive_df = self.train_label_positive[sample_size : sample_size + remaining_length]\n",
        "        self.test_negative_df = self.train_label_negative[sample_size : sample_size + remaining_length]\n",
        "        self.df_test = pd.concat([self.test_positive_df, self.test_negative_df], axis = 0).reset_index(drop = True)\n",
        "        self.df_test = shuffle(self.df_test, random_state = random_state)\n",
        "        self.create_labels(train_val_test_ind = 'test', data = self.df_test)\n",
        "\n",
        "        self.test_positive_file_list = misc_proc.generate_fully_qualified_file_name_list(self.df_test[self.df_test.label == 1].id.values.tolist())\n",
        "        self.test_negative_file_list = misc_proc.generate_fully_qualified_file_name_list(self.df_test[self.df_test.label == 0].id.values.tolist())\n",
        "        print(f\"Copying test_positive_file_list under {image_processing_test_positive_path}\")\n",
        "        misc_proc.process_copy_files(self.test_positive_file_list, image_processing_test_positive_path)\n",
        "        print(f\"Copying test_negative_file_list under {image_processing_test_negative_path}\")\n",
        "        misc_proc.process_copy_files(self.test_negative_file_list, image_processing_test_negative_path)\n",
        "        print(f\"File count under {image_processing_test_positive_path} is {misc_proc.check_file_count_in_a_directory(image_processing_test_positive_path)}\")\n",
        "        print(f\"File count under {image_processing_test_negative_path} is {misc_proc.check_file_count_in_a_directory(image_processing_test_negative_path)}\")\n",
        "\n",
        "        # shuffle\n",
        "        self.train_label_processed = shuffle(self.train_label_processed, random_state = random_state)\n",
        "        label = self.train_label_processed['label']\n",
        "        self.df_train, self.df_test = train_test_split(self.train_label_processed, \n",
        "          \t                                                 test_size = 0.1, \n",
        "        \t                                                   random_state = random_state, \n",
        "        \t                                                   stratify = label\n",
        "        \t                                                  )\n",
        "        self.create_labels(train_val_test_ind = 'train', data = self.df_train)\n",
        "        self.create_labels(train_val_test_ind = 'test', data = self.df_test)\n",
        "        self.df_train_original = copy.deepcopy(self.df_train)\n",
        "\n",
        "        self.sample_positive_label = self.train_label_sample_positive['label'].values.tolist()\n",
        "        self.sample_negative_label = self.train_label_sample_negative['label'].values.tolist()\n",
        "\n",
        "        self.df_train_positive = self.df_train[self.df_train.label == 1]\n",
        "        self.df_train_negative = self.df_train[self.df_train.label == 0]\n",
        "\n",
        "        self.df_test_positive = self.df_test[self.df_test.label == 1]\n",
        "        self.df_test_negative = self.df_test[self.df_test.label == 0]\n",
        "\n",
        "        self.train_positive_file_list = misc_proc.generate_fully_qualified_file_name_list(self.df_train_positive.id.values.tolist())\n",
        "        self.train_negative_file_list = misc_proc.generate_fully_qualified_file_name_list(self.df_train_negative.id.values.tolist())\n",
        "\n",
        "        self.test_positive_file_list = misc_proc.generate_fully_qualified_file_name_list(self.df_test_positive.id.tolist())\n",
        "        self.test_negative_file_list = misc_proc.generate_fully_qualified_file_name_list(self.df_test_negative.id.tolist())\n",
        "\n",
        "        if self.run_mode == 'interim_test':\n",
        "            \n",
        "            print(f\"Length of df_train : {len(self.df_train)}\")\n",
        "            print(f\"Length of df_test : {len(self.df_test)}\")\n",
        "            print(f\"Length of y_train : {len(self.y_train)}\")\n",
        "            print(f\"Length of y_test : {len(self.y_test)}\")\n",
        "\n",
        "            print(\"Positive and negative images distribution in df_train\")\n",
        "            print(self.df_train['label'].value_counts())\n",
        "\n",
        "            print(\"Positive and negative images distribution in df_test\")\n",
        "            print(self.df_test['label'].value_counts())\n",
        "\n",
        "            print(f\"Length of df_train_positive : {len(self.df_train_positive)}\")\n",
        "            print(f\"Length of df_train_positive : {len(self.df_train_positive)}\")\n",
        "\n",
        "            print(f\"Length of df_test_positive : {len(self.df_test_positive)}\")\n",
        "            print(f\"Length of df_test_negative : {len(self.df_test_negative)}\")\n",
        "\n",
        "            print(f\"Length of train_positive_file_list : {len(self.train_positive_file_list)}\")\n",
        "            print(f\"Length of train_negative_file_list : {len(self.train_negative_file_list)}\")\n",
        "\n",
        "            print(f\"Length of test_positive_file_list : {len(self.test_positive_file_list)}\")\n",
        "            print(f\"Length of test_negative_file_list : {len(self.test_negative_file_list)}\")\n",
        "\n",
        "        print(\"Completed spliting the data sets...\")\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"*****************************************************\")\n",
        "        print()\n",
        "\n",
        "    def get_data_distribution(self, train_or_test_ind):\n",
        "        \"\"\"\n",
        "     \t  This method shows the distribution of positive and negative images in the data set. \n",
        "     \t  \"\"\"\n",
        "        print()\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"*****************************************************\")\n",
        "        print(f\"Starting to get data distributions for {train_or_test_ind}...\")\n",
        "        if train_or_test_ind.lower() == 'train':\n",
        "            print(\"Data distribution in the train data set\")\n",
        "            print(self.train_label['label'].value_counts())\n",
        "            data_viz.count_plot(data = self.train_label, \n",
        "                                 label_col = 'label',\n",
        "                                 title_val = \"Distribution of Labels in Train Data\"\n",
        "                                )\n",
        "            data_viz.pie_chart_plot(data = self.train_label, \n",
        "                                     label_col = 'label',\n",
        "                                     title_val = \"Train Label Percentage Pie Chart\"\n",
        "                                    )\n",
        "        elif train_or_test_ind.lower() == 'test':\n",
        "            print(\"Data distribution in the test data set\")\n",
        "            print(self.test_label['label'].value_counts())  \n",
        "            data_viz.count_plot(data = self.test_label, \n",
        "                                 label_col = 'label',\n",
        "                                 title_val = \"Distribution of Labels in Test Data\"\n",
        "                                )\n",
        "            data_viz.pie_chart_plot(data = self.test_label, \n",
        "                                     label_col = 'label',\n",
        "                                     title_val = \"Test Label Percentage Pie Chart\"\n",
        "                                    )\n",
        "        print(f\"Completed getting data distributions for {train_or_test_ind}...\")\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"*****************************************************\")\n",
        "        print()\n",
        "\n",
        "    def check_duplicate_ids(self, train_or_test_ind):\n",
        "        \"\"\"\n",
        "    \t  This method checks if there is any duplicate ids in the data set.\n",
        "    \t  \"\"\"\n",
        "        print()\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"*****************************************************\")\n",
        "        print(f\"Starting to check duplicates for {train_or_test_ind}...\")\n",
        "        if train_or_test_ind.lower() == 'train':\n",
        "            df_train_id_count = pd.DataFrame(self.train_label.groupby(['id'])['id'].count())\n",
        "            df_train_id_count.columns = ['id_count']\n",
        "            df_train_id_count.reset_index(inplace = True)\n",
        "            print(\"Number of train duplicate entries : \", len(df_train_id_count[df_train_id_count.id_count > 1]))\n",
        "        elif train_or_test_ind.lower() == 'test':\n",
        "            df_test_id_count = pd.DataFrame(self.test_label.groupby(['id'])['id'].count())\n",
        "            df_test_id_count.columns = ['id_count']\n",
        "            df_test_id_count.reset_index(inplace = True)\n",
        "            print(\"Number of test duplicate entries : \", len(df_test_id_count[df_test_id_count.id_count > 1]))\n",
        "        print(f\"Completed checking duplicates for {train_or_test_ind}...\")\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"*****************************************************\")\n",
        "        print()\n",
        "\n",
        "    def move_files(self):\n",
        "        \"\"\"\n",
        "        This method moves the identified files to the appropriate directory.\n",
        "        \"\"\"\n",
        "        print()\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"*****************************************************\")\n",
        "        print(f\"Copying train_positive_file_list under {image_processing_train_positive_path}\")\n",
        "        misc_proc.process_copy_files(self.train_positive_file_list, image_processing_train_positive_path)\n",
        "        print(f\"Copying train_negative_file_list under {image_processing_train_negative_path}\")\n",
        "        misc_proc.process_copy_files(self.train_negative_file_list, image_processing_train_negative_path)\n",
        "\n",
        "        print(f\"File count under {image_processing_train_positive_path} is {misc_proc.check_file_count_in_a_directory(image_processing_train_positive_path)}\")\n",
        "        print(f\"File count under {image_processing_train_negative_path} is {misc_proc.check_file_count_in_a_directory(image_processing_train_negative_path)}\")\n",
        "\n",
        "        print(f\"Copying validation_positive_file_list under {image_processing_validation_positive_path}\")\n",
        "        misc_proc.process_copy_files(self.validation_positive_file_list, image_processing_validation_positive_path)\n",
        "        print(f\"Copying validation_negative_file_list under {image_processing_validation_negative_path}\")\n",
        "        misc_proc.process_copy_files(self.validation_negative_file_list, image_processing_validation_negative_path)\n",
        "\n",
        "        print(f\"File count under {image_processing_validation_positive_path} is {misc_proc.check_file_count_in_a_directory(image_processing_validation_positive_path)}\")\n",
        "        print(f\"File count under {image_processing_validation_negative_path} is {misc_proc.check_file_count_in_a_directory(image_processing_validation_negative_path)}\")\n",
        "\n",
        "        print(f\"Copying test_positive_file_list under {image_processing_test_positive_path}\")\n",
        "        misc_proc.process_copy_files(self.test_positive_file_list, image_processing_test_positive_path)\n",
        "        print(f\"Copying test_negative_file_list under {image_processing_test_negative_path}\")\n",
        "        misc_proc.process_copy_files(self.test_negative_file_list, image_processing_test_negative_path)\n",
        "\n",
        "        print(f\"File count under {image_processing_test_positive_path} is {misc_proc.check_file_count_in_a_directory(image_processing_test_positive_path)}\")\n",
        "        print(f\"File count under {image_processing_test_negative_path} is {misc_proc.check_file_count_in_a_directory(image_processing_test_negative_path)}\")\n",
        "\n",
        "        print(f\"Completed file movements...\")\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"*****************************************************\")\n",
        "        print()\n",
        "\n",
        "    def data_visualization(self, train_or_test_ind, positive_or_negative_ind, image_list, number_of_images = 5):\n",
        "        \"\"\"\n",
        "        This method visualizes the data.\n",
        "        \"\"\"\n",
        "        print()\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"*****************************************************\")\n",
        "        print(f\"Starting data visualization for {train_or_test_ind} and {positive_or_negative_ind}...\")\n",
        "        if train_or_test_ind.lower() == 'train':\n",
        "            print(f\"Displaying training {positive_or_negative_ind.lower()} images\")\n",
        "        if train_or_test_ind.lower() == 'test':\n",
        "            print(f\"Displaying test {positive_or_negative_ind.lower()} images\")\n",
        "\n",
        "        for image in image_list[:number_of_images]:\n",
        "            misc_proc.print_image_in_diff_orientation(image)\n",
        "            plt.show(block = False)\n",
        "\n",
        "        print(f\"Completed getting data visualizations for {train_or_test_ind}...\")\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"*****************************************************\")\n",
        "        print()\n",
        "\n",
        "    def get_image_summary_stats(self):\n",
        "        \"\"\"\n",
        "        This method gets positive and negative images summary stats at the picture level and each color (R, G, B) channel level.\n",
        "        \"\"\"\n",
        "        print()\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"Starting to get positive and negative images summary stats...\")\n",
        "\n",
        "        # Whole image wise stats\n",
        "        print(\"Mean and standard deviation at center for positive train images: \", misc_proc.compute_mean_and_std(self.train_positive_file_list))\n",
        "        print(\"Mean and standard deviation at center for negative train images: \", misc_proc.compute_mean_and_std(self.train_negative_file_list))\n",
        "\n",
        "        number_of_bins = 64 \n",
        "        figw, axw = plt.subplots(1,2, sharey = True, sharex = True, figsize = (8,2), dpi = 150)\n",
        "        axw[0].hist(img_proc.read_image_file_in_np_array(self.train_positive_file_list)[:,:,:,(0,1,2)].flatten(),\n",
        "                                                        bins = number_of_bins, \n",
        "                                                        density = True);\n",
        "        axw[1].hist(img_proc.read_image_file_in_np_array(self.train_negative_file_list)[:,:,:,(0,1,2)].flatten(),\n",
        "                                                        bins = number_of_bins, \n",
        "                                                        density = True);\n",
        "\n",
        "        axw[0].set_title(\"Train positive images\");\n",
        "        axw[1].set_title(\"Train negative images\");\n",
        "\n",
        "        axw[0].set_xlabel(\"Mean brightness\")\n",
        "        axw[1].set_xlabel(\"Mean brightness\")\n",
        "        axw[0].set_ylabel(\"Relative frequency\")\n",
        "        axw[1].set_ylabel(\"Relative frequency\")\n",
        "        plt.show(block = False);\n",
        "\n",
        "        # Channel wise stats\n",
        "        print(\"Average across red, green and blue channels for train positive images\")\n",
        "        print(np.mean(img_proc.read_image_file_in_np_array(self.train_positive_file_list), axis = (0,1,2)))\n",
        "        print(\"Standard Deviation across red, green and blue channels for Train positive images\")\n",
        "        print(np.std(img_proc.read_image_file_in_np_array(self.train_positive_file_list), axis = (0,1,2)))\n",
        "\n",
        "        print(\"Average across red, green and blue channels for train X_train_img_file_negative images\")\n",
        "        print(np.mean(img_proc.read_image_file_in_np_array(self.train_negative_file_list), axis = (0,1,2)))\n",
        "        print(\"Standard Deviation across red, green and blue channels for train X_train_img_file_negative images\")\n",
        "        print(np.std(img_proc.read_image_file_in_np_array(self.train_negative_file_list), axis = (0,1,2)))\n",
        "\n",
        "        # Red Channel\n",
        "        figr, axr = plt.subplots(1,2, sharey = True, sharex = True, figsize = (8,2), dpi = 150)\n",
        "        axr[0].hist(img_proc.read_image_file_in_np_array(self.train_positive_file_list)[:,:,:,(0)].flatten(),\n",
        "                                                        bins = number_of_bins, \n",
        "                                                        density = True);\n",
        "        axr[1].hist(img_proc.read_image_file_in_np_array(self.train_negative_file_list)[:,:,:,(0)].flatten(),\n",
        "                                                        bins = number_of_bins, \n",
        "                                                        density = True);\n",
        "\n",
        "        axr[0].set_title(\"Train positive images\");\n",
        "        axr[1].set_title(\"Train negative images\");\n",
        "\n",
        "        axr[0].set_xlabel(\"Mean red brightness\")\n",
        "        axr[1].set_xlabel(\"Mean red brightness\")\n",
        "        axr[0].set_ylabel(\"Relative frequency\")\n",
        "        axr[1].set_ylabel(\"Relative frequency\")\n",
        "        plt.show(block = False);\n",
        "\n",
        "        # Green Channel\n",
        "        figg, axg = plt.subplots(1,2, sharey = True, sharex = True, figsize = (8,2), dpi = 150)\n",
        "        axg[0].hist(img_proc.read_image_file_in_np_array(self.train_positive_file_list)[:,:,:,(1)].flatten(),\n",
        "                                                        bins = number_of_bins, \n",
        "                                                        density = True);\n",
        "        axg[1].hist(img_proc.read_image_file_in_np_array(self.train_negative_file_list)[:,:,:,(1)].flatten(),\n",
        "                                                        bins = number_of_bins, \n",
        "                                                        density = True);\n",
        "\n",
        "        axg[0].set_title(\"Train positive images\");\n",
        "        axg[1].set_title(\"Train negative images\");\n",
        "\n",
        "        axg[0].set_xlabel(\"Mean green brightness\")\n",
        "        axg[1].set_xlabel(\"Mean green brightness\")\n",
        "        axg[0].set_ylabel(\"Relative frequency\")\n",
        "        axg[1].set_ylabel(\"Relative frequency\")\n",
        "        plt.show(block = False);\n",
        "\n",
        "        # Blue Channel\n",
        "        figb, axb = plt.subplots(1,2, sharey = True, sharex = True, figsize = (8,2), dpi = 150)\n",
        "        axb[0].hist(img_proc.read_image_file_in_np_array(self.train_positive_file_list)[:,:,:,(2)].flatten(),\n",
        "                                                        bins = number_of_bins, \n",
        "                                                        density = True);\n",
        "        axb[1].hist(img_proc.read_image_file_in_np_array(self.train_negative_file_list)[:,:,:,(2)].flatten(),\n",
        "                                                        bins = number_of_bins, \n",
        "                                                        density = True);\n",
        "\n",
        "        axb[0].set_title(\"Train positive images\");\n",
        "        axb[1].set_title(\"Train negative images\");\n",
        "\n",
        "        axb[0].set_xlabel(\"Mean blue brightness\")\n",
        "        axb[1].set_xlabel(\"Mean blue brightness\")\n",
        "        axb[0].set_ylabel(\"Relative frequency\")\n",
        "        axb[1].set_ylabel(\"Relative frequency\")\n",
        "        plt.show(block = False);\n",
        "\n",
        "        print(f\"Completed get positive and negative images summary stats...\")\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"*****************************************************\")\n",
        "        print()\n",
        "\n",
        "    def data_processing_pipeline(self):\n",
        "        \"\"\"\n",
        "        This method performs required data processing steps.\n",
        "        \"\"\"\n",
        "        print()\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"Starting data processing pipeline...\")\n",
        "        self.get_file_names_list()\n",
        "        self.get_label_info()\n",
        "        if self.run_mode == 'interim_test':\n",
        "            self.check_duplicate_ids('train')\n",
        "            self.check_duplicate_ids('test')\n",
        "            self.get_data_distribution('train')\n",
        "            self.get_data_distribution('test')\n",
        "        \n",
        "        self.initial_split_data()\n",
        "        \n",
        "        if self.run_mode == 'interim_test':\n",
        "            self.get_image_summary_stats()\n",
        "        \n",
        "        #self.move_files()\n",
        "        print(\"Completed data processing pipeline...\")\n",
        "        print()\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"*****************************************************\")\n",
        "\n",
        "data_proc = data_processing(run_mode = 'final_test')\n",
        "data_proc.data_processing_pipeline()\n",
        "data_proc.data_visualization(train_or_test_ind = 'train', positive_or_negative_ind = 'positive', image_list = data_proc.train_positive_file_list)\n",
        "data_proc.data_visualization(train_or_test_ind = 'train', positive_or_negative_ind = 'negative', image_list = data_proc.train_negative_file_list)"
      ],
      "metadata": {
        "id": "9ASpSKwV7EnJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0839c7e-ce2d-41c9-8a4b-b2937b9a91bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "*****************************************************\n",
            "*****************************************************\n",
            "Starting data processing pipeline...\n",
            "\n",
            "*****************************************************\n",
            "*****************************************************\n",
            "Starting to build train and test file name lists...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/utils/image_utils.py:382: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n",
            "  warnings.warn('grayscale is deprecated. Please use '\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_proc.train_file_list"
      ],
      "metadata": {
        "id": "tq8G3f3yjEcU",
        "outputId": "a328126e-83a9-4874-bb60-da11efdf0915",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/train/c9f789088c8a1c0d69173d158b583aff5ecc922c.tif',\n",
              " '/content/train/aeb2af70be779226eba2169a669de684085be8aa.tif',\n",
              " '/content/train/d76b0ca11c461a573916c4ed8a017bbab7d899d7.tif',\n",
              " '/content/train/15617b722dd2033247d022b21bfb7b030035e7af.tif',\n",
              " '/content/train/50229a4804af7a78a2a7f79a991f82beffdd033a.tif',\n",
              " '/content/train/dc8d5b6d994a1b4ced8c61b1e0768bc19428b8ce.tif',\n",
              " '/content/train/e820872c708ca22338ca1dad627472b3a9fd58ec.tif',\n",
              " '/content/train/6ff7b333d0270886191790b3452109a3ce9b34af.tif',\n",
              " '/content/train/eb984401cc5ed38dd236e4ce28dcad7a55be76ab.tif',\n",
              " '/content/train/afecdd26162645696bd062efe10c5fc15e38cb1d.tif',\n",
              " '/content/train/c8eebe94d72b4bad076a374edbbb6ad3fd641074.tif',\n",
              " '/content/train/567a53d7ffa35bf53cb4890289c51d38e0c98950.tif',\n",
              " '/content/train/3a100a933f3463224fc492408326cc1ec5f9aab8.tif',\n",
              " '/content/train/dd8404b6c6787680432efbb267e7cfe99927385e.tif',\n",
              " '/content/train/8f1dac582d484031994064faac6aeece8f502696.tif',\n",
              " '/content/train/98c370ded3c55a4f3b689117a70a2959d07b55d1.tif',\n",
              " '/content/train/8eb3b36387e3cb9ac17d83e824810e32e577a500.tif',\n",
              " '/content/train/440504f6c734ce59cc1735c981724741913503ff.tif',\n",
              " '/content/train/33ee7bacbb9022c0944ad2968c41847e3afd14c2.tif',\n",
              " '/content/train/6e623ea9c7c07817d6445cb0240d2c3795ae23a8.tif',\n",
              " '/content/train/5506e73f3b1d6b74631112af1cb9a0a8efed099f.tif',\n",
              " '/content/train/4ac149d04481612513e4828e2267050c6be7d59f.tif',\n",
              " '/content/train/2e3885a6c07100d3d2b2562ddce6fe05917977e8.tif',\n",
              " '/content/train/86076dc1c6534d09b322b6532649fd163a40dd4e.tif',\n",
              " '/content/train/e0162f760716c1d3ca22f1c397970f4d0b745256.tif',\n",
              " '/content/train/8db784155e6d6386f0261ed4f66101e9a7817546.tif',\n",
              " '/content/train/d3a81813aaf7db0ee0489762f241e976d7f7a8a0.tif',\n",
              " '/content/train/1538ce02ec196287323b0c92192e97ecb5e694b4.tif',\n",
              " '/content/train/eecf4638d8669e07b710201094971e3bcb20a735.tif',\n",
              " '/content/train/5253b9f05f0e8569901fda4ac382b2d071430700.tif',\n",
              " '/content/train/aef26a113773a066ce469695c43716b463478e1a.tif',\n",
              " '/content/train/cc0be17e21acf4bb2589b04136f5050687b18006.tif',\n",
              " '/content/train/2870bb607aa89201e3818459f524c2e75582224b.tif',\n",
              " '/content/train/d8573e7daa0f456f6a69c3c6313df9e1160d8728.tif',\n",
              " '/content/train/edfc5247005ef5ce8b8fb26db897194e7a5def79.tif',\n",
              " '/content/train/8c3b6fa2806c75d8456224946e425a0bb310dccb.tif',\n",
              " '/content/train/903269bf37a6fde53fb09f29218920240613042b.tif',\n",
              " '/content/train/ccd03d18d4c9f15c039695da47ec2ae0efb60b26.tif',\n",
              " '/content/train/79304ca47d21192e16b34972af45e990463ffb27.tif',\n",
              " '/content/train/cd1e2b4d2734f6035fecb5828342bb1d7ad5c5c9.tif',\n",
              " '/content/train/85fe2adb720db66d358a86eeb99be4738ed8bd16.tif',\n",
              " '/content/train/16c015cbee202cae0a47c42b293037b7aebf9165.tif',\n",
              " '/content/train/3e9c762c2bb54e6d102e3698887234dcbb061f40.tif',\n",
              " '/content/train/ea643019e85426aee650b7482dd3c70d3fe270fa.tif',\n",
              " '/content/train/f72409e56e737cf6d0add85c733b27d2346651e1.tif',\n",
              " '/content/train/c48f2478ab2acade431d1006ac2c321319dea80f.tif',\n",
              " '/content/train/91a385c3683e9fa50cb35a5549d3fe59042d2b70.tif',\n",
              " '/content/train/5845d1c0664671ab96cc81c15a2e0c6565d9b559.tif',\n",
              " '/content/train/cb1187986bf9f34d469b3cad6db6bed09ff0c4bf.tif',\n",
              " '/content/train/932c3f5f8f547c3b65fe71bbc5e51c11bef38e52.tif',\n",
              " '/content/train/7d776c979e7435cd6d5ce4b47fe9471e33267516.tif',\n",
              " '/content/train/b517da0bb74eac5ef340f9a96f2d3e406be96538.tif',\n",
              " '/content/train/65b55a33f738a63f3cf241a8ab5909e75a8e8559.tif',\n",
              " '/content/train/d619251713182928fc50e33eb3f0fb542581a7ac.tif',\n",
              " '/content/train/20a60120fe2b6a3d5c210e6deec92bd98ab0aa7a.tif',\n",
              " '/content/train/858d6d318e5f446ef4b185a983e02d472a7a5acc.tif',\n",
              " '/content/train/1847e94d1130a48af43d06a12fadd86834c2a32d.tif',\n",
              " '/content/train/7bbe5dbb480a8587bf5418a95d4571b566c8c25c.tif',\n",
              " '/content/train/8b4c0afa78bb11b7a54b46f269510197331d0232.tif',\n",
              " '/content/train/26184622a467fd05bebef6026b2d662827e3390b.tif',\n",
              " '/content/train/cb7cae32af00520eddc6e5c5535a7f8148e60a9d.tif',\n",
              " '/content/train/06f7fe9af4034ae7312b10a4e8569c7108c4dff0.tif',\n",
              " '/content/train/87c3e827acc27b6b024b08de70afff4dcfa862cd.tif',\n",
              " '/content/train/1823a650def2754a3d3e861a7d90cb32904b7f91.tif',\n",
              " '/content/train/eb706e1890f3529454bbcfae414536ec292f1bac.tif',\n",
              " '/content/train/d885a89386b9fe43166db37e8c0ed8543f36c66e.tif',\n",
              " '/content/train/f44df5e5519a497514a1eddd9c0a9bb383f2df5c.tif',\n",
              " '/content/train/de27a17b1cbccff33fef7ca7ab173070cfab9703.tif',\n",
              " '/content/train/d6517dc6a4e1a8bf46e7e93301a2e7ee4712e532.tif',\n",
              " '/content/train/3f9b75c3b6bd3cd57b8fc0487c301ef2e7438da3.tif',\n",
              " '/content/train/83626c671c956dc386706976d5825769c0b0a0bb.tif',\n",
              " '/content/train/1b631d1cc642fc7d8c4d7b626d44ca3b7ee4d4b2.tif',\n",
              " '/content/train/5c8875fc9cf94cc9e73966fe0ce75394c2f38428.tif',\n",
              " '/content/train/ddb3465692275bd640bc75da1f86cb06628d971b.tif',\n",
              " '/content/train/d4ba1b179fea3771a4ddf2be024f92425379e5f4.tif',\n",
              " '/content/train/1ae2bed260bae68fcbb47f9c8e5046690e761e65.tif',\n",
              " '/content/train/6e33da51ec8db3cb3ab821a3931669470950078c.tif',\n",
              " '/content/train/f45c195f14c75e5f24c15f92ef253b20639da12d.tif',\n",
              " '/content/train/f1480ec7eb921b1ae8f03c4172715dfd61a60a48.tif',\n",
              " '/content/train/c2488676db3cc94b552ca7dca81a17b4a44a120a.tif',\n",
              " '/content/train/c12f8c0a581154f46a43ce866d8dfa291b1d31a3.tif',\n",
              " '/content/train/f84be44eab9ae067958c8818d2010dde58a87e09.tif',\n",
              " '/content/train/390b3731072b5bd2f731e7e5f696a390d23aac31.tif',\n",
              " '/content/train/f0aa6bd46e519585bd638831e25167193a54e287.tif',\n",
              " '/content/train/49318079c3f8bfe99ef4411fc3b00311a1f497ea.tif',\n",
              " '/content/train/d90f7ccd6e00245d93b031fb59d9ca690c1c288a.tif',\n",
              " '/content/train/4c4658e1559f37796b689afb4b616a34866f8952.tif',\n",
              " '/content/train/c2598d721db2ae00008e84da4cbdeb0cc349d52a.tif',\n",
              " '/content/train/e16932cccb53d38a32e4ca841acfaafc6d608a9b.tif',\n",
              " '/content/train/a415bdbcba3321ff72a16cc8ce35adae2431ae9a.tif',\n",
              " '/content/train/d8b8f8017d91108ad949eccef22ebddfaf386863.tif',\n",
              " '/content/train/2c627d9bbf09622f3f820fc3a1c89ec05b531de8.tif',\n",
              " '/content/train/dda572cc563b808b324a45aa823cc2775b2d419d.tif',\n",
              " '/content/train/4754d3bdaa137f543aafaac935cb4e8970265062.tif',\n",
              " '/content/train/f2848765798fb6be2d25844f2cd7fc06b0021721.tif',\n",
              " '/content/train/65c5e67a26314f584672dabc910c73574ffede59.tif',\n",
              " '/content/train/53d572bdcd43df96127239d79a635a9ca1e02a76.tif',\n",
              " '/content/train/1a124e5c762aaa7389fa7747094b703dc5e43f99.tif',\n",
              " '/content/train/92f8c5bf9fdf595c2a46bc061d1294413aedd440.tif',\n",
              " '/content/train/5848984c46fa3093192dbf732fee2a519c9445cb.tif',\n",
              " '/content/train/4358a9029e5035a248b72143c2e36e4b193925e8.tif',\n",
              " '/content/train/a014d697bbd2061f309d4f38b471e77f126d15fe.tif',\n",
              " '/content/train/b1de09a15b9885c14dede844e891ea0340f4de94.tif',\n",
              " '/content/train/dd82cfeac2f01e97da925f29054a406a7ebb56c4.tif',\n",
              " '/content/train/621ebe4993210f0234f75d70a171b343a89db94a.tif',\n",
              " '/content/train/7d6e8e47de2fac0483509a9802a35a9fb80b027b.tif',\n",
              " '/content/train/768db832e1d4c23b7c7a0941dce6054a490d8ca7.tif',\n",
              " '/content/train/4eece62abc261252b2a8f94266cf2ed9d3a45e57.tif',\n",
              " '/content/train/6c26ba7e8ac36f070c852b77004978b5a8fefdc0.tif',\n",
              " '/content/train/c20b38a5e70b056d2d9e0fe2d7ccbf65ad88d091.tif',\n",
              " '/content/train/7a7076a7c59f0d88ee2386416a67713a8d272861.tif',\n",
              " '/content/train/f2c02de45267dab34d11c3d6c82b512389b057be.tif',\n",
              " '/content/train/11b4c937582776bf27fb266954dd1184fae7e2b7.tif',\n",
              " '/content/train/01d32ad216935be1c6b9a61b5bcc930133079a26.tif',\n",
              " '/content/train/632ff4d765b792d20e44cbbdeb6f731e2cbbf048.tif',\n",
              " '/content/train/6c0cb65fdf7a83b23f85f3d7bf7d412b6d0fcc38.tif',\n",
              " '/content/train/a5bc0bb9b9870ad0ce83d4e38ceb4e7bbedd2f67.tif',\n",
              " '/content/train/c5d8ff1e6931cee1390e797947cc02059ba53b55.tif',\n",
              " '/content/train/8d2b7ffc07c9331369e28161b15fc0c797c7e1df.tif',\n",
              " '/content/train/33662966dbd5c8fcd9ccd344ac72a1dea09aff31.tif',\n",
              " '/content/train/236014bd9629cddad6bbc9368d0108433367a823.tif',\n",
              " '/content/train/38fcf4beafabfaedb910b063e94a61425a5b52b8.tif',\n",
              " '/content/train/f5f44eb421df346a230b624ff3b26815b1c5b7d2.tif',\n",
              " '/content/train/d5675363d65e8e5cfd5fafcf072946756a4cf86c.tif',\n",
              " '/content/train/08846e01e87151bda07cb62d32447b6aa6df91b4.tif',\n",
              " '/content/train/fa43aacc6aabdaffd7249dcd28ae2b8ea8d34955.tif',\n",
              " '/content/train/8e02244431bf6404950bad92126a4c61ca50f6dc.tif',\n",
              " '/content/train/20afbb6eece5be8b76033f23ed355d91a60cb490.tif',\n",
              " '/content/train/d4dab875f161219d3cb68f04d570082202a9b6df.tif',\n",
              " '/content/train/51751facf173b0ebec55b664a5ac07f4bf32e53d.tif',\n",
              " '/content/train/8d9ec67e72b8251ed8862d3569ae154e6c2dfe1f.tif',\n",
              " '/content/train/9577eebf7a2f605210a99d93d460e5c8e3a8efcb.tif',\n",
              " '/content/train/e12052c528e37450622087ca5a50761a3373643f.tif',\n",
              " '/content/train/efa9114780969bf223ccd97a0555d4e9bfe8f416.tif',\n",
              " '/content/train/68127ad64b461f51d4a4cca0f2bc83360760c864.tif',\n",
              " '/content/train/12b7f780db7f31e909f1d94e89592643204ca948.tif',\n",
              " '/content/train/d228887c6ff9ecfb3b8693ec615da74447267bf5.tif',\n",
              " '/content/train/ff2d4b0acd4118ceb5619a61925e8f746562c969.tif',\n",
              " '/content/train/0a11a034444056631ea1f1c4ccafb2a0eb049691.tif',\n",
              " '/content/train/352fc147ad67e4b6cd4d91ee3576ddf349193f56.tif',\n",
              " '/content/train/3e63928d1f0ec7a05377e7ccd407a4ff66c4067a.tif',\n",
              " '/content/train/93df359e7ba95a4b37f0fd2b9fe2db36cbb4ce9e.tif',\n",
              " '/content/train/b4c3477a94e6763fa4728c7bb98b634111e39eae.tif',\n",
              " '/content/train/01c89e96028a1f40bac43367ceb89dfaec681180.tif',\n",
              " '/content/train/eca525ea2c2cc48684c429524a9f23e757e45cd4.tif',\n",
              " '/content/train/bbc2f2449ccb18f983aad79a8985d288e136ef00.tif',\n",
              " '/content/train/73ca3b2d3d8627f4fd0ea0e6046efd8247a56e48.tif',\n",
              " '/content/train/09b7e0f7f15a83cb46be0d6e3e726827177bfb03.tif',\n",
              " '/content/train/f3ac928c7a95e3ea04826c6d39af23b3b956ace3.tif',\n",
              " '/content/train/3abca167b8a2af81451ad4305a7cf5cdbe3533ca.tif',\n",
              " '/content/train/04286a1f3e5e27e7eb24cfa59add41b38d772cb2.tif',\n",
              " '/content/train/28361da0ee257d975e6f5d62bd20d71b3ca65049.tif',\n",
              " '/content/train/c08952a432172588dda5fb68bc199d30e271b916.tif',\n",
              " '/content/train/714ab80018af9752336e929b8201e35634683109.tif',\n",
              " '/content/train/6fa32a7069d658b82f38da1636e2b92f0cb6f67f.tif',\n",
              " '/content/train/45e0809d3a0c51c8f6d3fd7c4fd39560d0e94131.tif',\n",
              " '/content/train/756fc0539578a236c3cead0c7713b4e030fb696b.tif',\n",
              " '/content/train/3fdb24f63161030ecb08a2d1f996e514805a226e.tif',\n",
              " '/content/train/66b23ee6915f8a917ccf39d83de5f6da7106db9f.tif',\n",
              " '/content/train/449cd6ac87e4c5dcf8473b5935d0a07322976e0e.tif',\n",
              " '/content/train/a3d58b35b8a88a2616c2c580cdfe5b1ac9b58350.tif',\n",
              " '/content/train/8db459f229d914d4ada493febe6367e6e86de92c.tif',\n",
              " '/content/train/6128d340b10a7ea6991e56f95e31e61372a3488a.tif',\n",
              " '/content/train/77ae94877dc2cddb8eff036e42fbb0bebbf90fb3.tif',\n",
              " '/content/train/f6ded758cc1745e5fdde8f66c58f6a4a418588cb.tif',\n",
              " '/content/train/db580e988038d686aac112f348b0fd8729d9ad5e.tif',\n",
              " '/content/train/6c299effa0f13a695379635025deab367773f619.tif',\n",
              " '/content/train/363c66a04266577793a37d1ca1a3889bf93b2796.tif',\n",
              " '/content/train/6e239e4c4ea571134d158478066c9c2e009ec167.tif',\n",
              " '/content/train/9f816aaa3dbea57d81c9408e79b762c757904626.tif',\n",
              " '/content/train/c80db45eac0d6bf6684e1c39d475b9175e8be116.tif',\n",
              " '/content/train/28c54f9aa76e534de34446def2185d7b150ea240.tif',\n",
              " '/content/train/d0c78d04475702e50bb0775c82082b299c2ff429.tif',\n",
              " '/content/train/09dd3f240da8e771e9f130c1d40e63fe16df7fad.tif',\n",
              " '/content/train/eaba58f4bc0e30aee97cc49fed3dd529dcf672d5.tif',\n",
              " '/content/train/66492ac13c13decf76860b43f1dbe17b18434820.tif',\n",
              " '/content/train/f6c153c0281b380ded90a0fffe059f863d5cd036.tif',\n",
              " '/content/train/4274c81baa7188c0f7d8f9e6d41688a31c313ce5.tif',\n",
              " '/content/train/7ca31d9db7e17421cb3ec2bd0d9f42c53385dfd7.tif',\n",
              " '/content/train/e9c60ed1312e823bfc32626955e455686447f36c.tif',\n",
              " '/content/train/fa042411e7c0a686c324ea2502c7d63786396f35.tif',\n",
              " '/content/train/13f009fe415ccd4dd88b0fa7f9cbce850697b39e.tif',\n",
              " '/content/train/411c6b2a1e1a851679057ba19b28f67816dced1e.tif',\n",
              " '/content/train/1ddd20238481b81fd37a2e2250abe8f55d927e11.tif',\n",
              " '/content/train/cdf32a9857eaa91b0018a9e6c7d1c51957ff4e86.tif',\n",
              " '/content/train/69ad87af91af78f0624d5c550bc1e073fa206f60.tif',\n",
              " '/content/train/edf3e0282305c6e48052efd5646498640024ef0f.tif',\n",
              " '/content/train/0b30b1fae7934389aeaf7392996a681f789cd975.tif',\n",
              " '/content/train/ec692c53de625c93eb2e77e48b31c9f2d97b0d04.tif',\n",
              " '/content/train/9fa6e6a902e8003aae7d4b051147804f8df6638f.tif',\n",
              " '/content/train/5631e21a3e56d4defba4a7824c870263b6790a96.tif',\n",
              " '/content/train/7e2302ca6ea486a114f5ee4fd297f1d2613cce1c.tif',\n",
              " '/content/train/fbac83c2c21c53d11714e8ca46021ced5f7336ff.tif',\n",
              " '/content/train/21138e34656748fac240965a7649ab5ac5ad4296.tif',\n",
              " '/content/train/a2735ce25b29e82b10af4cb016de7e2f5d614331.tif',\n",
              " '/content/train/4eb632d0550416e7d330ec24dfb14ca275d73147.tif',\n",
              " '/content/train/78ff44528982bacea0a212b5878e65e8b89606c0.tif',\n",
              " '/content/train/52ae953eddec74f7f36dbecc31968f4ec2a7df79.tif',\n",
              " '/content/train/55620bfc7bbd4753296c2be17e54b604eac3967b.tif',\n",
              " '/content/train/335c317cdb1e8eba3e55638a44978fb0bc97c425.tif',\n",
              " '/content/train/1e60c0ee571d5f3f861e9ca83c86f52a71f7e5d0.tif',\n",
              " '/content/train/6dd5cd6a4cd7bc562ffd2fcecc7eb689bdee68ff.tif',\n",
              " '/content/train/055534835204a62763f7b2dde1d86bbf77120f99.tif',\n",
              " '/content/train/917f850d583911dd237c17842b0d118bab16e2fe.tif',\n",
              " '/content/train/d429e7e3c3c72ca153948cdab66f2f546ae6b844.tif',\n",
              " '/content/train/1e122acdc5c4a1fae58e64951e5bb5bdd12d45e7.tif',\n",
              " '/content/train/e4c16f9753e4e20a92851278ed5219a8001a3092.tif',\n",
              " '/content/train/ba3bdd2d74ea78253ccc63420ded6b17092a6ff9.tif',\n",
              " '/content/train/039ec704fe602093e5148627277455a64276065d.tif',\n",
              " '/content/train/a522063e8b2e83edd13f7f848005d02d44681c57.tif',\n",
              " '/content/train/d6a9f75dc15d345bb4e223271b225be281b00fc6.tif',\n",
              " '/content/train/09961219482ae95d4b5ec175f4fbf7c073e0d651.tif',\n",
              " '/content/train/7c4ec673a8940fb85f59e4c7baa9d765eca65099.tif',\n",
              " '/content/train/59b470291335a3e7ba9d2feaf33f101238402f7b.tif',\n",
              " '/content/train/aca90a12a39389d242e1f03d6dbeb17cf0094fe8.tif',\n",
              " '/content/train/5c9cfc7d61e99692be473d7a39f1d112b3d8a50c.tif',\n",
              " '/content/train/ff87e1d4d67ef29d43efd007372fde67a50762e5.tif',\n",
              " '/content/train/2697494b3d70b8a275725cae2ece1c5fbba09f47.tif',\n",
              " '/content/train/7a48d661315b7e71472c35b8b8a9612c3ba2f806.tif',\n",
              " '/content/train/4da0f96268be0329560d07f0915e0d713c3a3f44.tif',\n",
              " '/content/train/b33b70db924d98b1fb1ba5ff6cd01e8355800cec.tif',\n",
              " '/content/train/25dbe5ff2db959970936e1ff8fea0309b0168988.tif',\n",
              " '/content/train/1fbd170b081bd6727d84f27194cf108835f89dde.tif',\n",
              " '/content/train/b6d732c3579cc82fe27df18d89c3f0a8dadd89ef.tif',\n",
              " '/content/train/f84fe99c8211bdc5c0647fc1218851c86b9813a4.tif',\n",
              " '/content/train/60fcdf7e8de9ffb6ef3df2c34c35c173da032a24.tif',\n",
              " '/content/train/2bfbf54081a874c0c13f0d7c7206afb1ee8fee2f.tif',\n",
              " '/content/train/427c6b854c81dfe5eda23f4cfd24caa89b16d82a.tif',\n",
              " '/content/train/37fd905eda50287fb292bb540a01a91be035f1d2.tif',\n",
              " '/content/train/0dfcdc41ef73ce68dcd8feadba8e31c5df6d7ee2.tif',\n",
              " '/content/train/ee4fa5ffd8d2b742e8fdd41829d632157270ee52.tif',\n",
              " '/content/train/760902b99434d6ad6b44a19d3753bf624007be90.tif',\n",
              " '/content/train/a1766f97d9fa34ac9af58f3b31db33e8a15152a0.tif',\n",
              " '/content/train/2f3f104bec161250305641a941fd07942c814904.tif',\n",
              " '/content/train/16080f539b8ca6ad2a3e29763422656be77b8299.tif',\n",
              " '/content/train/abd077848344d930586dac5f3731de548a85d8c8.tif',\n",
              " '/content/train/5f6eb54cfa3368686904b390cc3c96f8953662c5.tif',\n",
              " '/content/train/c70f36f85a420430f24e21b09bdf01d8669b98bd.tif',\n",
              " '/content/train/beb74df5c168945ba9e4e6a4bb7c56d009aeb514.tif',\n",
              " '/content/train/12f6dce133312875eb390bbed39f066611ab1f38.tif',\n",
              " '/content/train/d5e3e9dccd94bbab3a670796b036cd98d77e9264.tif',\n",
              " '/content/train/a55928ea6286a76d1856920480b09d0f85f2942e.tif',\n",
              " '/content/train/1c4023598d525b61aca14406c015cee892bbb35a.tif',\n",
              " '/content/train/03d6fca7a63011a8e8adc5127b64590c692e6424.tif',\n",
              " '/content/train/8821837c8cc7475dcd7bb6dd2a16dbac548c83f0.tif',\n",
              " '/content/train/082b565e40778d48a9ea0b35d18a431cba3d9c23.tif',\n",
              " '/content/train/014ea34b68e1e5b66d6492d2e6018227e1eaf701.tif',\n",
              " '/content/train/4ab5c345a69b3ec02e4dd2bc0846659cb2f4ffab.tif',\n",
              " '/content/train/e17a05a885feaee1198cf0255575aea8399bb454.tif',\n",
              " '/content/train/a32efe27ddfcac05af227164b05f20d2b40c6574.tif',\n",
              " '/content/train/1aab1098ecbd0d2b943e60d027d8e5882778d818.tif',\n",
              " '/content/train/d64ce96c1a80e52829e9449013b1df8b0d42227c.tif',\n",
              " '/content/train/37037a2b5bd8f03436ff55e59839585b44d249bd.tif',\n",
              " '/content/train/3f27c0a9680cd63bc32fd9bbd033512de333f02e.tif',\n",
              " '/content/train/0474c9cb441f13895189fd5be3e27804e979a927.tif',\n",
              " '/content/train/c167de1834b62ba7230c3df13be604c1d89caec8.tif',\n",
              " '/content/train/2a6e9047eed31fcefc986bee7c1fa6097925750c.tif',\n",
              " '/content/train/7324e1db33d4988e75bd4c09e14ee82cdcbf7273.tif',\n",
              " '/content/train/b6ac72a0e83a6ab3bd4c5aed47097cdb78cc0bab.tif',\n",
              " '/content/train/018c7ed453a2da7e16a92b4bfdc300b410084c41.tif',\n",
              " '/content/train/9c909120ea50a1e168af3208e6fb654ea2ccf358.tif',\n",
              " '/content/train/f2de2ce5f5de6aeef40b543b762e6d1a7eabaa12.tif',\n",
              " '/content/train/a5c00fefae5d7417b06ed3070cf39f99b06a9dd8.tif',\n",
              " '/content/train/e895ac46235bbcd7be1924009b7cd8141e970b0c.tif',\n",
              " '/content/train/3fbf9e13f02f2a119015d8b2cef7acc036d8c64a.tif',\n",
              " '/content/train/7af0d6d89649d0656ce84eade6558bad0bc05d6f.tif',\n",
              " '/content/train/a903ee8f1e4bec1a9280cf98d2897cbfa0f20979.tif',\n",
              " '/content/train/12f2aedc37cb6754a64abf80d72054223a9fc375.tif',\n",
              " '/content/train/a9c00a1be54859ac151130b43a4c9ae4cab0816c.tif',\n",
              " '/content/train/738de5ca94cea470d3c486dc1ceae38b6e632253.tif',\n",
              " '/content/train/3ce050cabb6a1fdc5b69ecdd40df6d1252fb7e7c.tif',\n",
              " '/content/train/df49d3208581dcf3431f4799c577eec97e020f1c.tif',\n",
              " '/content/train/0bdad0055b3da36654388a7978a653d4903d29aa.tif',\n",
              " '/content/train/96dca60d4ab43ec030c423ca7e05275305329d9c.tif',\n",
              " '/content/train/a2c064d205d168eabd7ad219a8ba76b2ec4e699b.tif',\n",
              " '/content/train/91e6b11fa8d94e351bc2156974f310645761ed67.tif',\n",
              " '/content/train/402b2dfba46c0a2e51ecd54283b35762e139866c.tif',\n",
              " '/content/train/cd38743ef9df8e2d7328af4e86cd867f1a87305d.tif',\n",
              " '/content/train/904fd13f7412886eabb9b0a71b0451796faf88d2.tif',\n",
              " '/content/train/b857d62baaad6e1c3b27c4c2727effe3b4ead1a0.tif',\n",
              " '/content/train/ca8cfee5298870f545a6b55d946707523a9152f0.tif',\n",
              " '/content/train/e454d105924ce2aa10a371d3e76a8dcbc0b8d03a.tif',\n",
              " '/content/train/5fb502bdbe548ff00626457cabc3aeeb4ba74525.tif',\n",
              " '/content/train/a2f9ed456f6591ed91692ce4cc2819e871109bf3.tif',\n",
              " '/content/train/8a39e07e1fd837ae004ab8c5ac891ad0c98dd324.tif',\n",
              " '/content/train/0d0f82b024bf31839bf65a7cade0191e97c58863.tif',\n",
              " '/content/train/60572826afc873bfee8e61ec18149f54c2d9ac1b.tif',\n",
              " '/content/train/8da8173b06cf0e69fce93e86c77a2a55a5d37562.tif',\n",
              " '/content/train/34caf67c2c4ff7d04a05dcef6dd54d33246dbf0b.tif',\n",
              " '/content/train/8745c3d775a01485329b374bbeef13c16ecb755a.tif',\n",
              " '/content/train/46ff88bae682ec1991129145e92c8b32fc9c64aa.tif',\n",
              " '/content/train/3c510fb1016fccf50ef6b5d56702c44540b7e288.tif',\n",
              " '/content/train/557d9dce8ab5d0a2c91fd608eb1f5256763e1cad.tif',\n",
              " '/content/train/9559b53f116b58217a0c772f4b121627242e0a21.tif',\n",
              " '/content/train/7d5acd45055f3e709f88245bec01a815041b0388.tif',\n",
              " '/content/train/174a92c0e90ffc2aadf90042aff3f28a17db6399.tif',\n",
              " '/content/train/993ecda49d42ba3f06ef10071e4228c911a05a5e.tif',\n",
              " '/content/train/50c06580494c5b5aa4f3852f5139d8ee91c29559.tif',\n",
              " '/content/train/3045abc92365636e2058d15713e8408bf2476b0d.tif',\n",
              " '/content/train/5c7505524ff4645d6baa2ea7fea5f32b99b35be4.tif',\n",
              " '/content/train/1440174f1260ae560ab52776a214f4ffc31d2bab.tif',\n",
              " '/content/train/bcf3cd97c1f99e93a4ebae07f81ab64e83b3eedc.tif',\n",
              " '/content/train/f55759cfe9425925a488e002ba6595e413c6e7cd.tif',\n",
              " '/content/train/b58f9d34a6775f514301d446d5f5a12630351628.tif',\n",
              " '/content/train/61e0f9c9749d24de32400a04b3d2c6db23dc514a.tif',\n",
              " '/content/train/8f1a6ef6a4a225b50d59a1a91da66141246db07a.tif',\n",
              " '/content/train/40fde80828f851c17dae6fce70a8ae3c44a9034d.tif',\n",
              " '/content/train/45ebd6e2c8a74d14a57942b82081bde9af2a2938.tif',\n",
              " '/content/train/72dcdaf2fae08943bbdd94dd3a288bb10b360b51.tif',\n",
              " '/content/train/009e2a357597b732a9ce1f4f247fa0e8af4d71af.tif',\n",
              " '/content/train/0ce9140b2421ee0e8f9c7ceaaa20b757938a40fb.tif',\n",
              " '/content/train/132ceb1d45f4fd338806a3d647fe6f5a61a378c0.tif',\n",
              " '/content/train/765426ebf72c6b2e4ec3ccd1789a231edeac1248.tif',\n",
              " '/content/train/91fad4c1d514351b06ab39b45d2b62dc76011b8c.tif',\n",
              " '/content/train/4ddcea96976b11b434de7a0bce33d87f712cd2b6.tif',\n",
              " '/content/train/be8f3d94ba1b5dfb33956495d15ce23b6aa66047.tif',\n",
              " '/content/train/be7ace00ffcce39f298c0e5b60947bf627a5005c.tif',\n",
              " '/content/train/6de941d2091a337029376aa60e2805569493f890.tif',\n",
              " '/content/train/a9fd06ddda821f2024c047a9cb82634bab0b07fc.tif',\n",
              " '/content/train/b3beea07d55cf5f5a08f9424dea8b94ccd8c09db.tif',\n",
              " '/content/train/99b4c5c3e967cf356eb7940f5051f4267a00a727.tif',\n",
              " '/content/train/2a3fa67e4abbdfb95084e7845eea3814d08c2dbe.tif',\n",
              " '/content/train/e999ec145baffa72a74f9f40c428cbf3a1a82c26.tif',\n",
              " '/content/train/2e4bad76ad22d5204bbc477eb85bee70fb61f380.tif',\n",
              " '/content/train/3cb5099bf01c5b48daea6edcbeccaaaf8abd31bf.tif',\n",
              " '/content/train/7eed450cdd8ac47352c5c8b26510d5cc10d55786.tif',\n",
              " '/content/train/127bb8040c8d2ee2f01674deaa716b50c42b89a5.tif',\n",
              " '/content/train/1b98f3f82ef4890df66093adfdb8b62682d94c7b.tif',\n",
              " '/content/train/ab8afd9a06fcdacd738fa3147df4a5d2eb91edaa.tif',\n",
              " '/content/train/eb2c6faacdbd5b3f2d89a889a56e0958add7e7b2.tif',\n",
              " '/content/train/05e3ff2144c6da94ddbcfc0f089e5e0f99dc7a4b.tif',\n",
              " '/content/train/06ce1fe0607d5b3a0d6d4940ec8b14021794371d.tif',\n",
              " '/content/train/1694de177337a2ed2c47745ee4f1898b87f1951e.tif',\n",
              " '/content/train/3c5c9f426373fd0890498b0c206c2823445b80d4.tif',\n",
              " '/content/train/edaa94742d4b26e63f5da14ddbacb81a2dbaa3bb.tif',\n",
              " '/content/train/3c303409c7e56ce45a84b23417488781b72ae1c0.tif',\n",
              " '/content/train/f8fa0a52a30ccd730719abcf05465e8324b5d187.tif',\n",
              " '/content/train/9bce95e0a74081031d38eb993b351d949a2bc433.tif',\n",
              " '/content/train/a13df7ce0f340e65ccec20c881b8ce05608a3b44.tif',\n",
              " '/content/train/a73bf4777a6b6a9bf1bb79c1d7231c1897687406.tif',\n",
              " '/content/train/0cacbb244e6c2cd9d438fce1d5552cfd57e6ab05.tif',\n",
              " '/content/train/ec7a068a8b95d3888a1eda94df4826c83a8f7850.tif',\n",
              " '/content/train/e75967c75098c1b0c4742d69a959098a9f7d28b7.tif',\n",
              " '/content/train/ed6c3e3913f48e9be8c959eb4f77e5f0dcf100db.tif',\n",
              " '/content/train/64ca1ab5adb002e7dbd7af3715772297f7e12146.tif',\n",
              " '/content/train/f0edf6e2c44d54a42d08c64510415909e05908ae.tif',\n",
              " '/content/train/30cafa54571dd4c581380cc96ee83d3c3040b19a.tif',\n",
              " '/content/train/78934e73fd5b037f0de8b7984dd8f9a9e6d4ff48.tif',\n",
              " '/content/train/67b8ac56b6dd7b6de70423e5433787a17360445a.tif',\n",
              " '/content/train/46f1dc5c1f5f83f099bcfa4d7f5cff8304969262.tif',\n",
              " '/content/train/f97f9c5f98bcd2b23a5f618599aa9cc55edf925e.tif',\n",
              " '/content/train/900e19ce013bc62e9ce863d324f0cdcbbdde68cd.tif',\n",
              " '/content/train/d5e707d9222fbf631b8aa0306ab94217128fae5e.tif',\n",
              " '/content/train/18c8cef4fb97c5bca95c69638c6233804f1c93d7.tif',\n",
              " '/content/train/4a5a49b1a8d78c049e9341a7948eab85fb34019e.tif',\n",
              " '/content/train/f43831b9ede828ebd2d15b565b76664ff575cede.tif',\n",
              " '/content/train/84dcc74b7db1c018d95e293320f908a89239148d.tif',\n",
              " '/content/train/0fb3f85acdcb19475ce1b590170d6671658f9cda.tif',\n",
              " '/content/train/d502c54b06d17cba80952b908d189485aba24872.tif',\n",
              " '/content/train/9019f65ba55197494381d59c6b5da29791921e3b.tif',\n",
              " '/content/train/a87b226e5d08619164206f06232755834fc76834.tif',\n",
              " '/content/train/79f5284a0a2fe2e3a18c775e27487ad0f20b33aa.tif',\n",
              " '/content/train/6695c4730dc2eccce2b2a16309a2e1b6ddeb313c.tif',\n",
              " '/content/train/b46cd933ff6168f689c76042979e087682607f66.tif',\n",
              " '/content/train/ea3adf3696343a49136bdb009c6c41b82af50ca0.tif',\n",
              " '/content/train/bebaea0ec1ee278fb9e2c6af02b037afad8ea1db.tif',\n",
              " '/content/train/860f9bfa741f789ddff353d8d854052df66a58d9.tif',\n",
              " '/content/train/d807179b7e5fd349ccae582901f9ba2b67c7a626.tif',\n",
              " '/content/train/e018a760b3bb5e1b34a3743ed78841477ff189bf.tif',\n",
              " '/content/train/660a4cbab088d96b42e703caab7469d5585fdae6.tif',\n",
              " '/content/train/eb94ec631151fd8bbc4d4060f646acb51a4e2320.tif',\n",
              " '/content/train/53ba93143c8265f6ed739114cc378bfd7bc969a4.tif',\n",
              " '/content/train/00c534adb44ee0457e675339ed9945651e897925.tif',\n",
              " '/content/train/a6f1f55f2c70be757f00267eba4855923860bafb.tif',\n",
              " '/content/train/8519324d1a4bfadd9b337bfe42a170068ed0a4fd.tif',\n",
              " '/content/train/005f4f493ec7f9f506f7435c173a4f31097f977c.tif',\n",
              " '/content/train/bee5e6a352919db73e4fab3e7fbc734ea4c99544.tif',\n",
              " '/content/train/9b091e3a80cabab5332d2b2e342a6e8ff3f27c27.tif',\n",
              " '/content/train/1813d08aa821c372b739c4b8ac16c5c947963b7d.tif',\n",
              " '/content/train/67cba89086cecd29c772b42af678c24bb741fe57.tif',\n",
              " '/content/train/49f179f70ec80f1a63380a8426d1a29db9a28528.tif',\n",
              " '/content/train/46003310823ba032669c1adf5a0985aefffae4ea.tif',\n",
              " '/content/train/ef7f580d891649ce35e77b87de4e63349f51b8b8.tif',\n",
              " '/content/train/dc9861c880aee784b05e4b6ae7744f5af6db7237.tif',\n",
              " '/content/train/7239496a24ab0c2ed8ca2e4a3e00868d280e9431.tif',\n",
              " '/content/train/aadeffd8e6336a1d21a0244a7df2c7bddec61a1c.tif',\n",
              " '/content/train/76d6ffebf6f1bad04515b9fe9330124ebd03cf57.tif',\n",
              " '/content/train/8ec224ea1262fb61f23576d8c6c92fa80481afd8.tif',\n",
              " '/content/train/b74969591152c38f715211eed7951e4c1d3dfa1e.tif',\n",
              " '/content/train/f2af52ec3420f9e901dfa9bd77cc6f4bea3debc4.tif',\n",
              " '/content/train/50dd94dede27fdd68bd123307e984b86b2aafbb4.tif',\n",
              " '/content/train/92dd48ad05248b35fbced60c6fdbf03142134f86.tif',\n",
              " '/content/train/dab22cdffb3746909e2f8388f70773581d4a75e3.tif',\n",
              " '/content/train/72f0ae5d50cf201c5c01e92165038f887ebd488a.tif',\n",
              " '/content/train/3a8b108f68a43823bb52b6f4e2fab17bbc5a71c1.tif',\n",
              " '/content/train/f1231c106b70edaa90ffd4852dab59d804dbfd02.tif',\n",
              " '/content/train/f90e8467ea3bc4320bbe22fed28f3cd68d73cf8e.tif',\n",
              " '/content/train/c2f0e01346f5771c191f0bcaf69950e4c7140875.tif',\n",
              " '/content/train/c1bab4a4a14f59e257d4517a6482ce71cee5050c.tif',\n",
              " '/content/train/29107f56944fa6974d8e5c9cbb0858487b412492.tif',\n",
              " '/content/train/78cb5075e2d5fce9d126506fdd008d749b272404.tif',\n",
              " '/content/train/855f5c7d452ffee2648f512f8364bf3b5b1dc916.tif',\n",
              " '/content/train/953ff665fd1ab2dadc9c7893d0374b2494f57824.tif',\n",
              " '/content/train/a683e6810007d3584b17b10d5533abf691df91fc.tif',\n",
              " '/content/train/7edcca4b8bd7b6a76a57d04e22b47745017d8a33.tif',\n",
              " '/content/train/b84c1606c9cdac59f92b7f53353b822e32fc3466.tif',\n",
              " '/content/train/6f5a73e0fc81c623385d472dcfa40a89488a644f.tif',\n",
              " '/content/train/b612359c87cc8a12d0d83577be2af49ea66c3473.tif',\n",
              " '/content/train/4701a2ca988425ea5ad754f63ffd5da1733824c4.tif',\n",
              " '/content/train/033cd8496d8c07a09dc9636727709a15009c93bd.tif',\n",
              " '/content/train/5ef919b061150740a34c94792bd4954905994ed7.tif',\n",
              " '/content/train/2da45714de94e894ad7811426192d4d0e71508f7.tif',\n",
              " '/content/train/b829927d998ccaa0d0f55244c9e84ae4f0f0b0be.tif',\n",
              " '/content/train/57d3d479abe6b214bd832f6e7f7bb5d017d78f4e.tif',\n",
              " '/content/train/865391517e026a56aee898b8a10c2e167ad15886.tif',\n",
              " '/content/train/426f0d52bb7b8b65ab4c58582532638a5aa16de9.tif',\n",
              " '/content/train/68dc3380b82c957437c001c9e1d33d5e9c9b7c44.tif',\n",
              " '/content/train/a0061323e393e87464a41011e8db1eae4a455ef6.tif',\n",
              " '/content/train/e22fbc8757837de2420d9c81d9a02effc3a231c0.tif',\n",
              " '/content/train/e388fa6c0d19289f4ffd7fd7f28730e90e657873.tif',\n",
              " '/content/train/a7a6311e1b8866be095643ecc730f3cb91423d17.tif',\n",
              " '/content/train/ac3f664fe871431db335cc6d90268313eb59d66f.tif',\n",
              " '/content/train/628c0ddd6851a8083fa0a7132289690b2e1ed696.tif',\n",
              " '/content/train/9faec07d096d03c4864e47334d32ce6bc448676c.tif',\n",
              " '/content/train/e9a773f584a74a1ef0622976b70109747894cad2.tif',\n",
              " '/content/train/44aa323d948b5a282e880a17e5bb648afad8e2b8.tif',\n",
              " '/content/train/2e627fbad9b85c401e24d6fbee425c571a3f8e90.tif',\n",
              " '/content/train/56b6cc6c231b4919181b5a97f369dcc11d6c9555.tif',\n",
              " '/content/train/be05a68a0dea172a5fec606d185ab89e0312df2b.tif',\n",
              " '/content/train/2c2289ba1a9d91c19306cd484701069b67a87c14.tif',\n",
              " '/content/train/f8f34053bc37a175068fbffa90803c993a43ee88.tif',\n",
              " '/content/train/0cde89d21026a3a7667d4112dc88e2c535f802eb.tif',\n",
              " '/content/train/af383ee212ccae78bd957eb407a2c0a14f72c7ee.tif',\n",
              " '/content/train/17097012c30ed5fff6d88c7c25d94891519be15b.tif',\n",
              " '/content/train/2ca5010638505579692f33762767adf8a6887474.tif',\n",
              " '/content/train/a167b811828f1509991e9fe4c0f12e9dae680201.tif',\n",
              " '/content/train/f4ce2082239dc5ee816e370748da9ff5572321e0.tif',\n",
              " '/content/train/58de2aad157c05fe85ea9bac22fce5001e68053e.tif',\n",
              " '/content/train/0466930457e74c0f5a493a6a47f50a3249b31d30.tif',\n",
              " '/content/train/b8bd5a580746eb62180bf6baaec75d9ee203043f.tif',\n",
              " '/content/train/ee6f2a730135040852c867350f6626358a0ecc21.tif',\n",
              " '/content/train/ed5274af53cebd0337a308df4c2cc80fc99055e8.tif',\n",
              " '/content/train/48866bca5be173b30217e231a592c720489af6a7.tif',\n",
              " '/content/train/d9c6ba485c944dcc2ef8f7f143366c1b0f078074.tif',\n",
              " '/content/train/113aa6ab3bd3e74614ffbf6b4fd4e1aee9437d66.tif',\n",
              " '/content/train/9bcd683b32bcf386e441f1b602ccf8ec389b260f.tif',\n",
              " '/content/train/72fc6113a642e05355a4495a7e32aab6ce7e8de1.tif',\n",
              " '/content/train/49ea662feafac4e65d250571e03042c40dd2c0cf.tif',\n",
              " '/content/train/100fd458b7bb93437669118b6968ea45d63211e6.tif',\n",
              " '/content/train/3d06d26e67239d966497d1b696a1d11360946339.tif',\n",
              " '/content/train/e1fcb10adbdb82712d079bc0cf3a44bf6c098309.tif',\n",
              " '/content/train/0139083665d6c7b51369a3a51bcd94d65c085b2b.tif',\n",
              " '/content/train/7c519431708c57c229fa55b1f676ad9c132dfda6.tif',\n",
              " '/content/train/ec45c35fbcf0b1d03d1be5f2c1f869c16b5e91b5.tif',\n",
              " '/content/train/7f9372ad9f43281767d979627644595cae624863.tif',\n",
              " '/content/train/7ffbcea9f548123743604a4c141eb46ea12a9b54.tif',\n",
              " '/content/train/455eead8a2b7cd06469bb67ea258cc684444e75b.tif',\n",
              " '/content/train/231ad69cdf2b5de76d11542057e0e9b06efeaf43.tif',\n",
              " '/content/train/9d5a174acfab6502e66863ce1c70c6fe180add42.tif',\n",
              " '/content/train/1808ab9f3119eace5e2fbb806589c05d55f7f6a6.tif',\n",
              " '/content/train/bae0b636fe249d7913198c2f4468809a0b8affee.tif',\n",
              " '/content/train/d2d2e85959122b5c04b43df12ceb0779249e8c4b.tif',\n",
              " '/content/train/a10871a892456516cc0091c4353581b7033afa8c.tif',\n",
              " '/content/train/00dea83eb4b643ee12912311ddda8d6fdd71e0bd.tif',\n",
              " '/content/train/7c163b2aecc21a435d58c45dc391362611c131b0.tif',\n",
              " '/content/train/68569ac76cda8842cf4da93728c31972068c82dd.tif',\n",
              " '/content/train/2f78fd941eb22de8cbfd7a071b994e74065f6754.tif',\n",
              " '/content/train/c7941cbb46c61c75aa1d0c7e45d0d8b2676a145a.tif',\n",
              " '/content/train/c9317d6140ddc335f1e72556755643e2c0f47891.tif',\n",
              " '/content/train/9738da7e5a879eae324992c0dc601b3a1ce27236.tif',\n",
              " '/content/train/8584c5b9292c856e896c740f6fac7044c44b3059.tif',\n",
              " '/content/train/f33945170658b81fdaa099de11b649b31b3a3c68.tif',\n",
              " '/content/train/c8d0a30bec66f18ba584c29489074027aab1192d.tif',\n",
              " '/content/train/d982241ece1b2cdf940934fb3c984070c3fab9fb.tif',\n",
              " '/content/train/610692f697010b4a58a9dfa39a9b1162ca5ff817.tif',\n",
              " '/content/train/dad9d52162a0c23524733f840742ebc860c21f77.tif',\n",
              " '/content/train/8cefa15b84cfc1ceb44d4033046b0a67e5ff6ae1.tif',\n",
              " '/content/train/3764f914a95291928e03fdeaddb2fde9b809a556.tif',\n",
              " '/content/train/de8460c2b47235d7a0db6a9dbbc9e3e5677973e7.tif',\n",
              " '/content/train/4e298e6366600422e5b75858ae318922d90a8566.tif',\n",
              " '/content/train/c119b76a75ab51fdbbe5f43782e56136c9575ac6.tif',\n",
              " '/content/train/bd6f1cc1f53723c21124cf2ed42d1d4bfa5d4e2f.tif',\n",
              " '/content/train/d09d1100d084f21458162b008b969fe8651d00be.tif',\n",
              " '/content/train/3622b48f65d8f58c357c52d0a1df88c695e46229.tif',\n",
              " '/content/train/47d24040d8ebc43edf267badc5130bd3d727b37b.tif',\n",
              " '/content/train/36a38cc2e1170f705be9425376a6cb9d3e38e4cf.tif',\n",
              " '/content/train/6be71357f685d006688b24cedc0d86fa5d5afe65.tif',\n",
              " '/content/train/dda5fa2b8c63bfc8be0265632a4d0dd436f87a1c.tif',\n",
              " '/content/train/99d842c229902a3e8e01d0a85d10b57fee05eedc.tif',\n",
              " '/content/train/82e36214c4a643bc8f306f6449fedf9f1e02e643.tif',\n",
              " '/content/train/63fd70c28e9f86d24fcdce31d0c4f50b44e116b5.tif',\n",
              " '/content/train/bcc2a58c2e804c554f374cd5074c710e35bc7020.tif',\n",
              " '/content/train/687d94c9b64b01f83cf12586afae16f89cd4419b.tif',\n",
              " '/content/train/94a8be33dff278008b6cb878649c08563d75af72.tif',\n",
              " '/content/train/ad33a16e3c6753ba07320e2acf9e3be0630aa70f.tif',\n",
              " '/content/train/3db0ef0c70ba6e80b1779c7fc94b683090cd1f7f.tif',\n",
              " '/content/train/f76638856a636bd4b0590726d7838566fab9c933.tif',\n",
              " '/content/train/0360dc9f9b4becbc25389b72af35e4f15c3bcf34.tif',\n",
              " '/content/train/7ea8cb644685e4f1829d7fa55ada72f7f0939572.tif',\n",
              " '/content/train/7c4c6b871fbf45c2cd06eef42e8b44b0ca91681c.tif',\n",
              " '/content/train/fa76b1bdc9de5f76869fbc60c297600a048f6eb7.tif',\n",
              " '/content/train/fae57a7675e0eaecd542fd528a0678fee9966e77.tif',\n",
              " '/content/train/34ba87fc0f680e40f1549c7a73b79ec78f0ff57b.tif',\n",
              " '/content/train/01cb72c08c721841f7a0ba70c1b75a1cd85bb795.tif',\n",
              " '/content/train/8610338348e40fe155b939f5500b8115057e0049.tif',\n",
              " '/content/train/595f8c6fbef57ffe4d1c7b57b52410617b24fbad.tif',\n",
              " '/content/train/1ca27aa1bb88efe90765c108bda7a5566c75485d.tif',\n",
              " '/content/train/4918ecfc3d4096f1ae389123e4772dc37a1f79a7.tif',\n",
              " '/content/train/fc89a29eccdec9056a638664c3dff1b22bd3139f.tif',\n",
              " '/content/train/d03abdfdb77064b57ba11e43bbb74ada5a9307df.tif',\n",
              " '/content/train/013991cf272f049971dc4dbe1e5ffd98fa3ee87b.tif',\n",
              " '/content/train/779d5dc7c21d703cc446214f9f66f319d4230021.tif',\n",
              " '/content/train/1be11030332674783f86c1a4e200a19cb5da0bce.tif',\n",
              " '/content/train/236064e482ee1a5a35b539b7c53f559ee3b94f4b.tif',\n",
              " '/content/train/e388fbbb0db66bd4036ae3ec11c191bdee753820.tif',\n",
              " '/content/train/b0594fb1ba56103b1e829cfcf0274adea692f97f.tif',\n",
              " '/content/train/3616a762b65b66129942136d5585785a4ad0d2bf.tif',\n",
              " '/content/train/961a0cbec7ca0cace1b71fd09e941343fbf7d37f.tif',\n",
              " '/content/train/fe4d41b5db6a0f1e9b9357bc7b748523c28ddf0f.tif',\n",
              " '/content/train/95beebf5b0707ac5c3246603a79b7cf234c0cdba.tif',\n",
              " '/content/train/44b598396581a794c90f09b54a6f6e4f8ab840d0.tif',\n",
              " '/content/train/9d62858cdefe17c1867e32347e4f520b035882d6.tif',\n",
              " '/content/train/516fa096300959bbccd9643e1ac496dc25883e50.tif',\n",
              " '/content/train/f437e6897e2291e23cf585a71cb8fa33f75241f7.tif',\n",
              " '/content/train/398f068c9a6ac50c00591e5f747f7e882c80b1ed.tif',\n",
              " '/content/train/54c4bc41e39c6fe6e6dbdcc8846837f02073e00a.tif',\n",
              " '/content/train/f6e604c9fa1b1d11024dadfed01b1e3899fe63fc.tif',\n",
              " '/content/train/b9bc090b1535f564fedf97cf0e7ed2f62f1ba111.tif',\n",
              " '/content/train/8cba62afdb2f0e4444bcafd6305b17566eb87746.tif',\n",
              " '/content/train/f6699444d431c706321e3be254140265e397b66e.tif',\n",
              " '/content/train/d586851436612091c58374f6e6dc3d18f4fdf151.tif',\n",
              " '/content/train/88eaa52af88150b97dec40c89ad08e5c93af1928.tif',\n",
              " '/content/train/4f55e4409e9f5b2efea602e7b69e443660a742e9.tif',\n",
              " '/content/train/a69fd6f83f8e432fb61f04df428a7a424cd673d8.tif',\n",
              " '/content/train/4be82ced7c7ff554d9a5bd933c67024bb4534fd7.tif',\n",
              " '/content/train/1b6640e769035560c9e13d2913ad3accc4d67a3e.tif',\n",
              " '/content/train/eb21c9badcddcf15d673716be48b2e870f3169e4.tif',\n",
              " '/content/train/381520ce75ae4bcd0c2a3d8dde32e9abf352632e.tif',\n",
              " '/content/train/49ea626c53a1f64a4d6d9c6db8b076d06693bfd2.tif',\n",
              " '/content/train/2ced370dcf2859bea1b1286b3d27361827a6a802.tif',\n",
              " '/content/train/150cfcbe08538b5d3e9235af48970c9c2e9811f4.tif',\n",
              " '/content/train/67a04d0850a71c11208cc2af46f3a4de5dd69766.tif',\n",
              " '/content/train/110f50e11a51561a83c6f62c3c474a9dbfb49dd3.tif',\n",
              " '/content/train/3a4af24db904bd09e5b44836bb28f9589ec0a2fc.tif',\n",
              " '/content/train/50a085cc53afda609e827df07f834ebb44938253.tif',\n",
              " '/content/train/cf82961c951d7e71b94d9753b0ea13bbe4486854.tif',\n",
              " '/content/train/ff88b39693a45beed791243a5c2b077cdb7f2e1f.tif',\n",
              " '/content/train/d55d441f685e6e5ee496f651b09585c6861c7546.tif',\n",
              " '/content/train/72c8130daac6c163c88668b7fb62b8ea75978276.tif',\n",
              " '/content/train/9733ae099323fc1faf27127deedd7bad3445c161.tif',\n",
              " '/content/train/24efd07a4c675fd11bad955d06240f229b6d5766.tif',\n",
              " '/content/train/1006debb2133c09e17cd68d29ae013fb0d83180e.tif',\n",
              " '/content/train/98bce707a50e72f82469ba33f77bc85f53e52617.tif',\n",
              " '/content/train/5a6750b6d815883b527935ffc82378a620ebfa6f.tif',\n",
              " '/content/train/539e0893f35c91a973420c7102d573ead200d4af.tif',\n",
              " '/content/train/ec8f014905e7812f74ed954b77067fc129ba99bd.tif',\n",
              " '/content/train/6d9de7e1520706c7853667db9ef95065ad77934d.tif',\n",
              " '/content/train/ac7ddaa02b889ece51593c84deb14f7f9c1c035c.tif',\n",
              " '/content/train/274300e0d1fbf786f6787e4a01cbee71ccb1fc43.tif',\n",
              " '/content/train/aeedc8fc3187da51588e2205ba0739c14badf28d.tif',\n",
              " '/content/train/db6cc0c6f98f0c21f6c5632742a3f4c8294f940c.tif',\n",
              " '/content/train/503839acc10651917424cc13b239e698c9936fe7.tif',\n",
              " '/content/train/a3e3b638e3aabd347caaf6f7ac16d739461f8fa1.tif',\n",
              " '/content/train/7969f9cf3da98fd9f20713e497f85aaaae3b1c07.tif',\n",
              " '/content/train/c4477b92ed6b69efd974d08c30bff0c5aa88bb6d.tif',\n",
              " '/content/train/de34ca58069c1bb1a4d8ac034680a8587dbae279.tif',\n",
              " '/content/train/3487c818a82d41a856349ba86423d2362732bf38.tif',\n",
              " '/content/train/8cffd2f605b73169e55884a105718869027c8ce1.tif',\n",
              " '/content/train/d1dddef19cfca626936a8f619ec20e24c8804ad8.tif',\n",
              " '/content/train/979eee166daa9430f17dc514bdfff57ba127ef14.tif',\n",
              " '/content/train/b47a737fbd5daf5919cd2900c390685ca3b0daca.tif',\n",
              " '/content/train/1294b0cbf244ca4106cabac80acf8c8e83c4a849.tif',\n",
              " '/content/train/e1d0c312cc1ccc9827e94d22fc0dfd0e23302122.tif',\n",
              " '/content/train/ae364e85df637888d04d496870fae04a9b210111.tif',\n",
              " '/content/train/12ed69186f76e1e577266a3c99c862544fada916.tif',\n",
              " '/content/train/9a7db3728671d1b492b81e9dd5d31232a6036e2a.tif',\n",
              " '/content/train/0dc08c551ece1d8b55d70731c99be68c4fc03344.tif',\n",
              " '/content/train/643884a4c389bcf87e33f9ce825f1c3658012870.tif',\n",
              " '/content/train/84d4a8fbcc8088556b74c8068261ad1be2c64567.tif',\n",
              " '/content/train/08e8f74cd4dfdff555647bb1b27474c16836e564.tif',\n",
              " '/content/train/ad7dfd5220dfc73e123452e4b1323e7a637ee8e0.tif',\n",
              " '/content/train/28fc7b98bc79790421516ff43d3984ae0840351f.tif',\n",
              " '/content/train/ac098438c275b6903992bf473158f486718c99c2.tif',\n",
              " '/content/train/c92ae68cdafb642162df2603c7355844b38f05d1.tif',\n",
              " '/content/train/6b2a98064d1017a82127b64ec88f9cc51a86303f.tif',\n",
              " '/content/train/4e17fc9b90df19cbab0e08b5832481deaa7cb00c.tif',\n",
              " '/content/train/348bac69446b14431a5b0996327e7dd2d9374dec.tif',\n",
              " '/content/train/d12b8979f8d1d2d5539426b9c25d77bfe83001ef.tif',\n",
              " '/content/train/353e716bae93a6626b69dd434411fa534a523af9.tif',\n",
              " '/content/train/672589dae03c12452de8cc78824d5ab248ed0ff5.tif',\n",
              " '/content/train/ec0d7a434a5e32dc4a0f3a0dd2564967fe4618d9.tif',\n",
              " '/content/train/614346ce25d559ff144cbf4b374d134d3be32f42.tif',\n",
              " '/content/train/225f15f00be23678f2ed89fba4de953f8ded9476.tif',\n",
              " '/content/train/d55163ab9581ba2ea1f8a240a147b3e6557b7f9a.tif',\n",
              " '/content/train/7ce43c1253d3f2bd0a2fd9dc20fdc30588d3de43.tif',\n",
              " '/content/train/8f267af0b622c9226f105645e987cd9858b2ceef.tif',\n",
              " '/content/train/9b05e85e66e9dfd2521b795185f754b2ef8f75bc.tif',\n",
              " '/content/train/fb25199f3169e0ec77698ab789fd225e85ec226e.tif',\n",
              " '/content/train/ae9ac702d7195d14e77b88e0645eb0d0f563519f.tif',\n",
              " '/content/train/ef0ce2639a316d66f14d3315b5e88ab1bde4533d.tif',\n",
              " '/content/train/65042efa13b6b0a2477383263daa052f041ae123.tif',\n",
              " '/content/train/2283fb348873b85521e2a26317ce95241245e36b.tif',\n",
              " '/content/train/61b4be70797dfb945ee674143841426178aff47d.tif',\n",
              " '/content/train/ffa94a6e0a962fc89a8c3a6c562becf0a6501642.tif',\n",
              " '/content/train/409c12019d28146028d2abf130054b04c8c6aad2.tif',\n",
              " '/content/train/ac877cea66b9059f6a6888bc186c616cd9fafb11.tif',\n",
              " '/content/train/3b0eb53644258371d99f0863e09f9c06bd975b2e.tif',\n",
              " '/content/train/c91f5a9b946b921ca051912e7949297fdcdb0a3e.tif',\n",
              " '/content/train/0a9cf40db6cd64aa761002c7d5e8a9ed4669b094.tif',\n",
              " '/content/train/3a6168ee3ba1d801fa1a5c9cbca1178da397abe9.tif',\n",
              " '/content/train/38d90131e71731c97049aa87bb73e8db4edc68a1.tif',\n",
              " '/content/train/a3724bf99f2c63f583ad77331f56ae65f1707177.tif',\n",
              " '/content/train/4ed0c945cac477bf58a254a665a9fcff2249afd5.tif',\n",
              " '/content/train/1db279dd51c85c82824a4c79d92c03f563542031.tif',\n",
              " '/content/train/f1cbb02d101558b0c2ffe10152ff6a1fca88c018.tif',\n",
              " '/content/train/2549d7f6bea1884c56a9020d545b27e9a321ffc5.tif',\n",
              " '/content/train/cd295f266208f176bfbbac4934c193c2b96a8a4f.tif',\n",
              " '/content/train/9c0433b980367f99a4fc69d35d6a4ba15f16d814.tif',\n",
              " '/content/train/d6ccfe7aab69c599b0ec0d68fa1fe018c733ae53.tif',\n",
              " '/content/train/578414add78d927f4bf6a762b86792d42a454649.tif',\n",
              " '/content/train/dc5336fff4b415743a33541aa04325ab9c5344e2.tif',\n",
              " '/content/train/6dc8e7a1f03f0b26de61b3e87a2252cbfc8a2505.tif',\n",
              " '/content/train/801d290d1cf567ecaea55d6e0aa0f8f73ee85c6f.tif',\n",
              " '/content/train/b3a3ac7f65229d625773ba9606b2dc286322caac.tif',\n",
              " '/content/train/a5511f99a08d142cf3192d2be4655c40c34b1b25.tif',\n",
              " '/content/train/6571164612ed654a17243f38bff6fc3a86c6e009.tif',\n",
              " '/content/train/449fc953f2507750d51a00f1e31f0603ecabd9ef.tif',\n",
              " '/content/train/3093877856c48109fa1edc5a49a174012404bef6.tif',\n",
              " '/content/train/8fcee8447306f3ce298fdf18eb0ed61f764c841d.tif',\n",
              " '/content/train/ed8a72b5179451826f166b541df94889289e1480.tif',\n",
              " '/content/train/06447048e4f972f0e2f366c35e01aeb32eaf55c1.tif',\n",
              " '/content/train/cd53b0364e4c625164ae930069dc335d688fadb2.tif',\n",
              " '/content/train/1074fafec166b82c8c62e23815463bf406a98a28.tif',\n",
              " '/content/train/b5a8d878db54624bb4432b5597c76799f2c61949.tif',\n",
              " '/content/train/cb898787d6aba8e711ac2f66552cfcb97cfdbf1c.tif',\n",
              " '/content/train/1f4fdc9dc6035ebaba2d5c05158a2a3a678d259f.tif',\n",
              " '/content/train/d4a613d7d1ac8f61edd03ac9b67e8fe82850c67b.tif',\n",
              " '/content/train/3f0a6c083fe38070561b6715829cffeea7d955ae.tif',\n",
              " '/content/train/9d79bafa638b85f079d9fd78c4514e80f2d33db8.tif',\n",
              " '/content/train/ad0b40673b4e4b18940b0c9a7ff1089901c36d19.tif',\n",
              " '/content/train/b12fd5a883c9aa2ac5cf1dd9cda8a6f7d852dd62.tif',\n",
              " '/content/train/632042c2b4c28537092c748320d93ef8943fd0cc.tif',\n",
              " '/content/train/3deff87a222fe58cc7fc4f18167c1ea9539a50de.tif',\n",
              " '/content/train/e089179849a07f52d0433c57e62f35721723fa0e.tif',\n",
              " '/content/train/7e13fde636fa5105bc166e7b530cad451fe4a1a1.tif',\n",
              " '/content/train/f7b06463a59e428b03ca71d834bc2c94866567b2.tif',\n",
              " '/content/train/14e2e535e700ebd5bf4aa2ca932e834d7bb78e63.tif',\n",
              " '/content/train/78d09a3c34356406e49257903b6f26c1a7319058.tif',\n",
              " '/content/train/adfcea770e626bde4b3b8187091e0f9c4e2a300f.tif',\n",
              " '/content/train/9221735638aa885f949c0b0c8e2d320f70f6db63.tif',\n",
              " '/content/train/ee6aecbddd92c6293a9276eaff74cfb9b9ac6b15.tif',\n",
              " '/content/train/8652568820d62d84fd5f1c4d7c213130b814c0ca.tif',\n",
              " '/content/train/add7ac6ab0a2c4352afad58116d90863b84c7536.tif',\n",
              " '/content/train/d4afcef4b1516ceff5ae09d79df742224905f5b6.tif',\n",
              " '/content/train/ed813084c84e74e46012df7febd231087021e552.tif',\n",
              " '/content/train/a4fcb14e2b2b15ffcb25ee38b5659480405d65e3.tif',\n",
              " '/content/train/ae202a267da97d71f0ee442ef78b07e8620788f0.tif',\n",
              " '/content/train/bfa4c7038c0f0da7e76117a2b8b91a8d87f21fc1.tif',\n",
              " '/content/train/e1548d5ee2b3498e1bb5f0aab3043385f5409aa5.tif',\n",
              " '/content/train/72025fe8002c6c6116bebe97d2228c426002a767.tif',\n",
              " '/content/train/42cd3e28f9f0d3e04c7f1bd29dd3d8cdc5176cb3.tif',\n",
              " '/content/train/60262ac882f9c47fdb0ea650cfddfe9d4d0e3e27.tif',\n",
              " '/content/train/5a79573eab48b9c0ac517e61658cb534caac286e.tif',\n",
              " '/content/train/d52ae3247ec13f7b183cf3dc0c4ce5398e5cf392.tif',\n",
              " '/content/train/c6a82c2f6bbfca09e6a533c94a4aace7abf29ec1.tif',\n",
              " '/content/train/242c655eec086d3b31f0dbe816e2d34912644518.tif',\n",
              " '/content/train/b5724202dcea2d09931dbc254dbae8bef8357806.tif',\n",
              " '/content/train/0ecea9840398303d9c8a5f18ef06f3eab67d4fa6.tif',\n",
              " '/content/train/c25f03e032aede04c53f96e0d7f8e1aac0313e2e.tif',\n",
              " '/content/train/28ed803ec51334d23378a779ebd25997dc704e5e.tif',\n",
              " '/content/train/60b405a65d35af1c8db374be532e9e92deee7ba4.tif',\n",
              " '/content/train/70c0c9eecf85a6b0727bd56fd3e1108fb0403554.tif',\n",
              " '/content/train/022bcfab6c912bb00138fbac5c58d7d3f19f0e39.tif',\n",
              " '/content/train/ac4e5365aefc3373deb30d6f14b2a64cd6cdb215.tif',\n",
              " '/content/train/6ad5c2f8cb9c7b2a68142ee268caab8ef71353e9.tif',\n",
              " '/content/train/502ba38aab9dbb8bc474579cef51e86034349d04.tif',\n",
              " '/content/train/19688317964f803104e5db81f4c36aa365c604f2.tif',\n",
              " '/content/train/0f668f5b5953f1c70bd6d73c7e2378b41f739158.tif',\n",
              " '/content/train/4ba925defda39e4927db6831dc73ca2aff1e33ba.tif',\n",
              " '/content/train/00ced350a65abf89cc00d780260578d84de59c9b.tif',\n",
              " '/content/train/19a8370b6bdcbe6abdb10eb054a5f3b2b4db5f23.tif',\n",
              " '/content/train/2173e3e895257df04ce364cbde878d050abb5aee.tif',\n",
              " '/content/train/13b5d3503836795059010dd080b2ee0403b02871.tif',\n",
              " '/content/train/1138115b2b9b4e8c284c5243ce0279a4f7a8afbb.tif',\n",
              " '/content/train/1cfd534771e0df7f76185d99b3ed75601e6f20b6.tif',\n",
              " '/content/train/e7e86bcbe35c6ec92df4ea6af27f369e05226e3d.tif',\n",
              " '/content/train/6c3f435d40a24a02edfed800067317aec5320eb7.tif',\n",
              " '/content/train/b3958e69f46f07d85355366b3ba84d19df7979f2.tif',\n",
              " '/content/train/45223d32f1e3cf6d767eff0c3a886d160e1c62c1.tif',\n",
              " '/content/train/005e7fb8cbb3ac1b0f6a2eec45674ad5f2410f07.tif',\n",
              " '/content/train/d07ca1c99bafda737855b382cd57ad6fa5c75a5e.tif',\n",
              " '/content/train/309b94e391fb9e72526d3d9e4e128440e00278ba.tif',\n",
              " '/content/train/5df24a9be4a31af71d8b971a5bd71b2ccecaf524.tif',\n",
              " '/content/train/fa4f6ac7adfea91c09e9a4197597c8c4b8b95d2c.tif',\n",
              " '/content/train/8c6523e0d606bab7ccbda074b43a40bea44492b0.tif',\n",
              " '/content/train/c938933cb306c8fbc13b2394841b0aee4dc60b91.tif',\n",
              " '/content/train/d9f7d63edaa9e611f3fc99c7f61fedb4abc548e6.tif',\n",
              " '/content/train/e027b02a26a07fefffe035fb48836b30a749661e.tif',\n",
              " '/content/train/4d3f968184c71dbc0d6d8e0f31e5744ac76039fe.tif',\n",
              " '/content/train/c1444648d3e983011ee50338653c7e7825671542.tif',\n",
              " '/content/train/f632db778a8a3a3d84165a2335a19b005fa765c9.tif',\n",
              " '/content/train/0193cfa4c1ca497b5e7c434ec3d10f6164d18525.tif',\n",
              " '/content/train/4a75265b0834e86ebb474ac27f2907a37aaa45b9.tif',\n",
              " '/content/train/b7952cfec43de8806f4d2e60ae91010bade9a784.tif',\n",
              " '/content/train/7b86829e8b788329cd1e129b0cae45c4f0613556.tif',\n",
              " '/content/train/755556897a72c2da8fe01d37ee2e27d064e65835.tif',\n",
              " '/content/train/9d867d7ee2601ebaf206ac2d6df52d1bffec9fe1.tif',\n",
              " '/content/train/7887735562407e036ec3818e1aafa19908cb19b8.tif',\n",
              " '/content/train/780d10232d78136847c999726a8f44bb1366c204.tif',\n",
              " '/content/train/1033fcfcc4fbe4650da7f653f7ccba2c60a6c2c5.tif',\n",
              " '/content/train/281643deb9a3d0fed96301577336bf5eccf9099b.tif',\n",
              " '/content/train/00de7a20909c09f439608b5cced934f27cb47d98.tif',\n",
              " '/content/train/bcb01025795f05217f6564e2f632c0b53552899a.tif',\n",
              " '/content/train/22be268685a9ed1540dd8e77201d7ac7f6d49e9b.tif',\n",
              " '/content/train/8d95173474a53a2427067f3e0e0d012630fcc2fc.tif',\n",
              " '/content/train/40f88d27b526c55367cfd359a66e448297478cc8.tif',\n",
              " '/content/train/922204d612f47defef899b4a9ab56719d8d1f01a.tif',\n",
              " '/content/train/ec83a2e69eb9efb13be07ce7cab12c821f3c22f3.tif',\n",
              " '/content/train/69355919e720b5f1a975a3aebb15b0a67138e7cd.tif',\n",
              " '/content/train/2f837deb159337ee3ca98437fbd879431bb94147.tif',\n",
              " '/content/train/c1551ec18bc2f565f5fe3afeb929f13aedb1af73.tif',\n",
              " '/content/train/614a0779b582099837bfabd6937e04190afe8404.tif',\n",
              " '/content/train/ac2a768b3de83eb850a7227fd3755d3597e1cd77.tif',\n",
              " '/content/train/9d89a51429c437f0f3055b807ba0f6fc4ce8bd80.tif',\n",
              " '/content/train/9cd21965001c54fc2296309f3f60d29698b8766c.tif',\n",
              " '/content/train/5991be1bdfea7f09a100951888c6f11cbea8bc5e.tif',\n",
              " '/content/train/581dddec53064991ca72f745fe36d2fa0e830330.tif',\n",
              " '/content/train/ebb757f36720fd0649f62dadf4c844c0502b2658.tif',\n",
              " '/content/train/212fae650057234da8cbac657a1efd9b6a744f8b.tif',\n",
              " '/content/train/3e79e11f66163cf902b5076b006453bd9aa76151.tif',\n",
              " '/content/train/f4c2d2281f277ad9f6fe7bc2a19ab8353b2c6317.tif',\n",
              " '/content/train/c3335730e1064ec2247e7f82145812bc601bb811.tif',\n",
              " '/content/train/176360f8386401cdf1338650f0c1a6b8fff62bcd.tif',\n",
              " '/content/train/080019026137493b72a538f4371380ff0d06b0dd.tif',\n",
              " '/content/train/47b553a73500b8a26417402fe7debef4a25c939a.tif',\n",
              " '/content/train/8b93f98c762503e611983c849a4695a41a6cad73.tif',\n",
              " '/content/train/06ad78a0314f5be437d75803aea9fd3d24295bd0.tif',\n",
              " '/content/train/7008472a14e129f563292049febc5e26d980f37c.tif',\n",
              " '/content/train/64acad83ebf6f651f2b9976c5d312d3dec37f7b0.tif',\n",
              " '/content/train/f8ae6a7054b015e580415c956475348435f2f854.tif',\n",
              " '/content/train/0c68aad13b8d54c733201131174cda4fa0bf65b6.tif',\n",
              " '/content/train/fb50ae9c289ee4ef3289958c5e8aa96e0e2af655.tif',\n",
              " '/content/train/47f1815b589de8c6acb97299302e3abe8e36ec10.tif',\n",
              " '/content/train/11141cc46b96ea62fa0bd5c132d87876dc4b6267.tif',\n",
              " '/content/train/6ce6f18983d33011b813db52986ed25417ab8f75.tif',\n",
              " '/content/train/b31733dbab554e0d7e32a9b997ad417edc444a8d.tif',\n",
              " '/content/train/4a2534f21177f9eec67706b495ee77c5c94dd8a0.tif',\n",
              " '/content/train/cc5d6e055890f994c27525790ad3539405d14b2d.tif',\n",
              " '/content/train/3180ea6342f654d44c876b637eab04a7f8602a93.tif',\n",
              " '/content/train/bc2ee1b4d43030f48649e2cefe2ff21a5fdb8e49.tif',\n",
              " '/content/train/e51896be2d465b86a18db84b8e2b07021f2e6b0d.tif',\n",
              " '/content/train/81778f7095afed9201c73fdabb8644d5f8f580f9.tif',\n",
              " '/content/train/32eb4e1eb734917a053c8158dc9fd2bbd340666c.tif',\n",
              " '/content/train/2ecf085f8abd3cb50ae68ae79dd40bb92ea88280.tif',\n",
              " '/content/train/0187cc8cd69ca4da4dc5ea252d4489b3868d5e18.tif',\n",
              " '/content/train/3d1bf5fd48e75bd29e20ef0a9c28183916492e5a.tif',\n",
              " '/content/train/85fc35f952847f1178d1d2472cc97fa82cbd1a53.tif',\n",
              " '/content/train/9e40d5c3a972b879ae1a6f5b9a479da720497daf.tif',\n",
              " '/content/train/c1b07f6ec7888fcd4f1796b043b0b2732aa6c611.tif',\n",
              " '/content/train/7af8259b38221709b51f94eca8d8b1a04e808dcb.tif',\n",
              " '/content/train/9e81714d1d376ce58e1ee3584e6eb83f8edd37c7.tif',\n",
              " '/content/train/032006bacd61332a0086173a8e252fc57ce2b572.tif',\n",
              " '/content/train/26e905ba247a0a628217352641080eb32cc62192.tif',\n",
              " '/content/train/ed7543be55fe6b2d7d16bbbc52b9121a96d9042a.tif',\n",
              " '/content/train/0f502d381e2b976f2ad49592c7fdead6ee10675f.tif',\n",
              " '/content/train/8973be3f093b1358e7d398eec3802c963653ac61.tif',\n",
              " '/content/train/827f6252ddb107c17c7a61527e950fcfdf5ff665.tif',\n",
              " '/content/train/4ef13b86a5d0c0b85ed74ff1f6aa97def25d46df.tif',\n",
              " '/content/train/b0d8fc20c35025629a032633e321670a2603de18.tif',\n",
              " '/content/train/fdb060ddb871b84c4f55b22a2c2bade9f141e427.tif',\n",
              " '/content/train/9f8f7eb6eaecd4dc703ffdc58f1e6f29ac375a02.tif',\n",
              " '/content/train/b57bf936f1c96f3fbd7d2c16e212592e612219d1.tif',\n",
              " '/content/train/cfb8b228b2ca8b9683c97c351366e11c3f16f12b.tif',\n",
              " '/content/train/e897836c125aa2111a4a0014cea25879b4be1ff9.tif',\n",
              " '/content/train/f3d9aec64661027cf02df626642c5f22c0265664.tif',\n",
              " '/content/train/b6a20a694b78664a8d3570b4749d30240f343184.tif',\n",
              " '/content/train/e352234db85ca551cd9d6abcbd54126f652b9195.tif',\n",
              " '/content/train/aec45b96ee2a9af56b24820b6215715e037eb0a3.tif',\n",
              " '/content/train/e25b0f6cc7e599e296e8528e83e0e6cdf3c3a7cc.tif',\n",
              " '/content/train/d441dafa3704241b081dfe44804df3ff6ebc51f5.tif',\n",
              " '/content/train/cf7e06160ab039afe32873892edaf9c54c9603b1.tif',\n",
              " '/content/train/749a553cd4f5486615ef28b0256575d58763548e.tif',\n",
              " '/content/train/b2bf16f1eafa7ca479cb35881a3abdba5866a43f.tif',\n",
              " '/content/train/7f79f9876ae65614e8047de17210164a3bdfbb4f.tif',\n",
              " '/content/train/cc3542005295b7f309527a590e2983f0afcc233e.tif',\n",
              " '/content/train/1656fd314332d2393feddc84aea20e00270ec132.tif',\n",
              " '/content/train/6f5be16336d5cf5a72907a62dff4d49247770f88.tif',\n",
              " '/content/train/a61a7f8b3c5c75747db57faa9753ae9164150676.tif',\n",
              " '/content/train/9dec85fd006b024000709a392c134ebdee89559b.tif',\n",
              " '/content/train/41f52cc7a1b0f70603e0928e8f167778be1f455d.tif',\n",
              " '/content/train/ea4cfe6e361e68a2dfdf7d1beb0860af68a0e019.tif',\n",
              " '/content/train/a01fae95cbd27710c01c582faa5d4474cb1d61d3.tif',\n",
              " '/content/train/e49baea954985f9a0bb931952c28c81f4c5dd62b.tif',\n",
              " '/content/train/5e6b90d32d42e9682191f6eb95c5b0c28cb20d56.tif',\n",
              " '/content/train/71b9288d3e042df52e59f167ca1798a14d81a1b8.tif',\n",
              " '/content/train/d5d21b3ef4ede850be63dd028300657af1d59184.tif',\n",
              " '/content/train/75e928bf7c3abb25290b778cb54ce004e4384b32.tif',\n",
              " '/content/train/8a0987202a4294555b06b0e946cdf8cd0f017324.tif',\n",
              " '/content/train/17214a72788b6ac24074e37c6565f90486a58073.tif',\n",
              " '/content/train/37c56ecae57753d2bb6c291c3c23585da02c540c.tif',\n",
              " '/content/train/cab3f47dc9e6dd9423119d8b3eb79e89bd09cb61.tif',\n",
              " '/content/train/cffc868e1122484d0bced6cc255837b9cd5306fa.tif',\n",
              " '/content/train/db2ddc81ad2e6e27cefb9a0a61b901c954d18dfd.tif',\n",
              " '/content/train/101249929ddf62a40363b4542a26df3d256d23b6.tif',\n",
              " '/content/train/b675b0d6eb7e57b55cf2a2246acab22c1caf10f9.tif',\n",
              " '/content/train/167fd9b5bc32a691a2bc102687a9198e608f890c.tif',\n",
              " '/content/train/af0899ed346655a2b52d0708854318ca1e7f515d.tif',\n",
              " '/content/train/8a36a89635aa351bb87c8bfd76198637061f2bce.tif',\n",
              " '/content/train/c9ae04ee1c23f4e37f28bfe7a2fe1546611bd7d0.tif',\n",
              " '/content/train/11d2c8ba4112f61e476296d535490addeff0a93b.tif',\n",
              " '/content/train/901f58d77b6e26f5dee7c846c0516f75454c9997.tif',\n",
              " '/content/train/04ec0e3ba97ac1ecc41a62b1f92884f687056908.tif',\n",
              " '/content/train/755928259006287f57ab43798dadfd47784fa4ea.tif',\n",
              " '/content/train/869d383de4f89905156658e0001fbb6f19f837ae.tif',\n",
              " '/content/train/9c13f7be361a90d4251080f77de693f39b4caaf6.tif',\n",
              " '/content/train/6b2e14abc8faf4e28e506f7d0c065de395b837ad.tif',\n",
              " '/content/train/1cb7c67b46ca68e792cdbfdeb0686deef478a770.tif',\n",
              " '/content/train/d53db0919a39386277b1aba80ac35bef9d2f5426.tif',\n",
              " '/content/train/f23a47c40920fb199a3b7318081b32f17c90212f.tif',\n",
              " '/content/train/981a11cb385250bfa970e6d88c7bde930b37079a.tif',\n",
              " '/content/train/8b978cc1e6c4384ecf82920e02002322982ece66.tif',\n",
              " '/content/train/7d48e595cf78d17eda931502cc241d8d0aa288ad.tif',\n",
              " '/content/train/6cf85e4d0d7b20cf4b0666bf43e35f46a1478059.tif',\n",
              " '/content/train/f2dd37abcaa74de247f73769ce8826ceaaa11e83.tif',\n",
              " '/content/train/a94941d64e54cf16bfe0fd4c4b9d0d6f22bd61dc.tif',\n",
              " '/content/train/ca6f3017489445ba71dfa343d6272ec86d2206a0.tif',\n",
              " '/content/train/8b3dddbcbe857ba85600f16518aeb67580e8defe.tif',\n",
              " '/content/train/75d526973e5454733740268e9854281e59633ee3.tif',\n",
              " '/content/train/715248cb9fbd6e13f8aff9eefeb4e4c0b3e2b8e8.tif',\n",
              " '/content/train/731dc3dda0f6060b5959b5c216f043fb2b72c2da.tif',\n",
              " '/content/train/53fc5ab24f987c75631774cca4c53e7764033e52.tif',\n",
              " '/content/train/fdaa5be2310e9c1df5ac0d30d20b724388fe1a59.tif',\n",
              " '/content/train/4f2b4678be879c2b96a2909f99f4888730a7ea8b.tif',\n",
              " '/content/train/c135d4d232c62178d131d6502f5bc8f2560d8da4.tif',\n",
              " '/content/train/6cc396de6d767934ecf0bdb46def915ba1f53348.tif',\n",
              " '/content/train/1b192d0f3e669059b9987b08c4815d94fa52b83c.tif',\n",
              " '/content/train/16ccbf069cdab42fe312f14f869e9e68df341b7b.tif',\n",
              " '/content/train/ab3ba9920e84439538dafe1fb953f8ecd33a6344.tif',\n",
              " '/content/train/8946669e8c60179cee24fb7674a94a06362e7d73.tif',\n",
              " '/content/train/714331a581b8092757ecc8169e49426abd8bf656.tif',\n",
              " '/content/train/1f1c2d2e9ae9bd1c903b5389b95bfe5fb81c516f.tif',\n",
              " '/content/train/dd573b190912a7abedf1db556fc427fb0d23a5ca.tif',\n",
              " '/content/train/e2f25b886ebdc9be0b871cb0f07aaf4da0f25e78.tif',\n",
              " '/content/train/9ff12fe3f42b9463de1fd3c01ce712a81407816c.tif',\n",
              " '/content/train/62bcaa2708af8c11d1193b538b1037a3fb5a0459.tif',\n",
              " '/content/train/b6cd832fac1469067eec722f94b90492e03127ed.tif',\n",
              " '/content/train/f1bcf85dc2f26d055564eb5b106b1580355421bb.tif',\n",
              " '/content/train/3f5f797c37eb79eea44805ccf77fe2c43d45af78.tif',\n",
              " '/content/train/9655264c0e72538c5e2135b7442074090e818b71.tif',\n",
              " '/content/train/756fcd5e51c3706379638b90adc0ba19c54054cf.tif',\n",
              " '/content/train/52954fa2035a446861ba94b4d7443e4525aa6110.tif',\n",
              " '/content/train/d801d8ea71ae8d741fb1732e0f0725ced55211fd.tif',\n",
              " '/content/train/3db1b3eba22bb021a9cb781417db57f8b48b067d.tif',\n",
              " '/content/train/9d0fe2e43ea321e9f4ff49dd080319c087b8ef03.tif',\n",
              " '/content/train/2fd40a8c82f1f10c371536e4e6a021177e431a77.tif',\n",
              " '/content/train/3fa6503d9c32d58ae98032068e04b29aa1209c11.tif',\n",
              " '/content/train/5e35decccc210f5ebd0d02af5552a256b4e0675a.tif',\n",
              " '/content/train/958ea940002cb8a5757b9b3d66c1a244cba92cde.tif',\n",
              " '/content/train/7b10597a930be3a349a44e8ee84e50d505c7d771.tif',\n",
              " '/content/train/77fc215556ca5a5cf28475bddfd3a19065a1cba8.tif',\n",
              " '/content/train/b8f4def0bf6d51109c0e6062dc5138964b7739a6.tif',\n",
              " '/content/train/adba8cf376ed1ce92cb369359aa7b180ae7576e7.tif',\n",
              " '/content/train/cb280fa06fccf3783ac3d3ab694b04de96dd6ae8.tif',\n",
              " '/content/train/c45e8de4afc209a0c5702d0044d1f71bc44b690e.tif',\n",
              " '/content/train/d41102f97f114af824c340aa51d493ce8095e7ec.tif',\n",
              " '/content/train/8266e5548133ead058f1d8c8c47a007770498cab.tif',\n",
              " '/content/train/58f84a7170f641871f059bf308086449d08f6f7c.tif',\n",
              " '/content/train/fd0706757a21cb41095fdaacb1eedbc0141f71b7.tif',\n",
              " '/content/train/3044cf50743e650512b0a12a4a16b5db7fa69945.tif',\n",
              " '/content/train/7c6b2e1f1632273587735601a9e5c7ad41fd9236.tif',\n",
              " '/content/train/dd7a191a45be241a3b3c40ad82c9fcadd64a1e6a.tif',\n",
              " '/content/train/ce4ca25c247b4501d01ff7c2db9b0797e69a6b65.tif',\n",
              " '/content/train/19dac076247be43d1f87ab865a86130fd0974da3.tif',\n",
              " '/content/train/d6b0f342f558a96b4b86af72f81949bed509b74d.tif',\n",
              " '/content/train/f977444831a4708c9b0ab7105e281745cbb4433c.tif',\n",
              " '/content/train/cca13c56cec10bc91728981812157459f3dc55aa.tif',\n",
              " '/content/train/f16b0d7a763fc10da4f184fbddf4c0e25d10a343.tif',\n",
              " '/content/train/ca2841b79b33e10b1a9ee31fd49e863235955b78.tif',\n",
              " '/content/train/622d70371e739de0cf115b7a8f59da6935c6951b.tif',\n",
              " '/content/train/52a65cc55c65a7978928c795db797d3c7ddfaae1.tif',\n",
              " '/content/train/fa1b667a07428042ae162538c333997f75ecbf20.tif',\n",
              " '/content/train/8bb97a4f3de7ccafa030453d991d4a70aa4ad726.tif',\n",
              " '/content/train/070b5e6d4929acfd882d4feac1c298c21bc68fff.tif',\n",
              " '/content/train/9c5d9ef111d2dc6f875a7caee2a85c5aae7df223.tif',\n",
              " '/content/train/e06f2a59e0620554f67612ec41d611c724af56b4.tif',\n",
              " '/content/train/0fcf08a6b72a63d85286c3d0319ac4cd89a99ad6.tif',\n",
              " '/content/train/af6d967aaa99f9c37ce07094331bc85030ad2bc2.tif',\n",
              " '/content/train/a457c815ed14e48f885b6c3dd22e614f8023f7a9.tif',\n",
              " '/content/train/9d2478620301e7d3e200fcc8b3aedf7d4d7b8445.tif',\n",
              " '/content/train/2abcc078713be3fe106cf5475782d66cd1300f61.tif',\n",
              " '/content/train/60c647ada048a7335679d38b2e357eba59155109.tif',\n",
              " '/content/train/0bebcdd39ea8185b5e1ea3c923f6f5ad171938d1.tif',\n",
              " '/content/train/6f4126c2d60a63c48d1e9dd12bb72684eef4b348.tif',\n",
              " '/content/train/d56b463f1150761574f797ac4d47b5ec63ebc3b4.tif',\n",
              " '/content/train/7012e8eda76c2c165c2efc9c54f5d5a194ba81d4.tif',\n",
              " '/content/train/bdb8f69977f87ff82531307e3353fd2ecb72eefa.tif',\n",
              " '/content/train/9b3ecd6f35e203c418bb1268f44c4becb7113842.tif',\n",
              " '/content/train/986a5915e7921f4a5928572f8feae17eeb9809cd.tif',\n",
              " '/content/train/082d8a7e9b1775f992efae96ad67fd7eb40ba8d1.tif',\n",
              " '/content/train/2181d3e5b7a695374f7d77db7bd103926ca5e086.tif',\n",
              " '/content/train/99a2d9e0ef7085778ca5c277c467cd9cf92f99a7.tif',\n",
              " '/content/train/f794e62e4b240a79bb73e9fa0ec4442783650e41.tif',\n",
              " '/content/train/6515d63d5e961ef16ef9c77806233df2cf8e4d75.tif',\n",
              " '/content/train/8305a611d5b090778cca98565ad28cce73b5906f.tif',\n",
              " '/content/train/dd4e2681021c84eb74fe553851db2629b27cea63.tif',\n",
              " '/content/train/136b08616f309d8807720dc72b5aeaa5c5b745f5.tif',\n",
              " '/content/train/651137ab6ead56956c1fe0830e83bf74d3f789c6.tif',\n",
              " '/content/train/9b62ebf938d501498fda1b57a7171036611d8421.tif',\n",
              " '/content/train/2930f72628eea679416555e9dce32d3962b232e3.tif',\n",
              " '/content/train/ce4111d3217749289f77720730c7a18bc4a1673f.tif',\n",
              " '/content/train/8e254ae80751dd53a394c581c453b30751dfaf04.tif',\n",
              " '/content/train/42981e759088ed496d4ffe41598763d9c39a0b53.tif',\n",
              " '/content/train/c8a367be658dd8b72caa780411cb3b68b5a5fba3.tif',\n",
              " '/content/train/ae515c62b59b6036a287b924f2043591daf758fe.tif',\n",
              " '/content/train/4e72cda3fc99d37b126dfc42bbbfcaa856a6eafb.tif',\n",
              " '/content/train/d6f5e03d5480fd1a4bcaa823b735ca4e4b8c072d.tif',\n",
              " '/content/train/826cb6fd0535490fb5babcc110124d3e77e1d4ae.tif',\n",
              " '/content/train/3c4c2cd8bb5d29b3f6752ebf69070660c2c410d6.tif',\n",
              " '/content/train/2f2ce4524a661cb5462c8274c6b1ac8e75af8b75.tif',\n",
              " '/content/train/ccc0bc153a5d2dd2bd160238ae41624ee89615ad.tif',\n",
              " '/content/train/9e6da64f7c9b53cda7dd114a38a7f9c0d6e686b2.tif',\n",
              " '/content/train/a0365c691c188c0c94179fb457723f201b72cc74.tif',\n",
              " '/content/train/6b8e7c8cb6bd948b57a9f9766529f8a10a78a015.tif',\n",
              " '/content/train/3a8ab22815c17130150ff601fd404e28f037857d.tif',\n",
              " '/content/train/5efc96239262eeab7c7a040b71828e031e992bbe.tif',\n",
              " '/content/train/f2cafee5f155b08d77fd1a9c98d4d13952fe232b.tif',\n",
              " '/content/train/3f94a2f09254be613b550079b9822cea29490417.tif',\n",
              " '/content/train/5cb89eed7ed8b0995a79d62ef1545b671c8f63b4.tif',\n",
              " '/content/train/ee008235001d954355d51a8e69c56ebf00d2ac0b.tif',\n",
              " '/content/train/0f6f437917d5ca37617e7d4ef3c579a1c5b45741.tif',\n",
              " '/content/train/ff52d9066c7aebb2aa1e7a500d00ec197353b285.tif',\n",
              " '/content/train/2597e7a330c8cd876a115e755efc9a2ca581e1ff.tif',\n",
              " '/content/train/45d9b7bb650e0b6a016abd1bde5125f7b6cdbd02.tif',\n",
              " '/content/train/23080420dc581dcfdc3e62543607c2ef341fadfa.tif',\n",
              " '/content/train/63363d5f250d6ab61372ad241d7738d43bca25c9.tif',\n",
              " '/content/train/3b37ef3763d15f97c5efafab0d688ce8886c1193.tif',\n",
              " '/content/train/cfd47023c04b8fadc730f52464994c9989288731.tif',\n",
              " '/content/train/4626843dfcb7fef5f4955bff8c7650040e827db7.tif',\n",
              " '/content/train/77827a16302d1817e72d5632ffe2c49ed5a8fc6e.tif',\n",
              " '/content/train/c2bd5cf22869282725dcdfeef898f59318bdea4b.tif',\n",
              " '/content/train/d44add71c1447e648d3e16078a69d68b9cbdcb4e.tif',\n",
              " '/content/train/1e090bfff3669b6114cbbc637d74dfea5bfa9de8.tif',\n",
              " '/content/train/b3ce51d712370b93ec496d0d160d329bb4e163a2.tif',\n",
              " '/content/train/f31bbb3c6b6d8cc5c93609bdf8f7ecb5466340e5.tif',\n",
              " '/content/train/e9ff3fb4edf90b0284ff3d525e9f7e982ee9e84d.tif',\n",
              " '/content/train/723e0838cdd9eccc637815e3a73d73d47a366590.tif',\n",
              " '/content/train/3c59ac6d3ccf27c820ca79b5463e2bbfc286c18a.tif',\n",
              " '/content/train/a022c3b4e2cd27de9b45b1372e1a260af7a71b3f.tif',\n",
              " '/content/train/1fb9efc14da34b6cde38a3626ff9d30a0301c2cf.tif',\n",
              " '/content/train/30c5989769819117bfb412130e9517ba21c44523.tif',\n",
              " '/content/train/243a60ff38c178d21bccb7561c899208d902538a.tif',\n",
              " '/content/train/29366b09fcc75fc7b5ca9871c831f91f00a23f78.tif',\n",
              " '/content/train/0da11110599c64db2d804b18371698fe392da001.tif',\n",
              " '/content/train/21d4da2ebf8312bf9cd0a36fa34d7390af23ba70.tif',\n",
              " '/content/train/d41944fcaa66458d9f692b31599adf4184577b5b.tif',\n",
              " '/content/train/a7d664dd875910831eade038ed6e959e735d2e5c.tif',\n",
              " '/content/train/1269a4fb3e41a39e5165693915a6ebd8d75e6034.tif',\n",
              " '/content/train/a361f5bb69f2e36d148ffbd441f0ae284439bf6e.tif',\n",
              " '/content/train/57ba153c96a390fbdd1614749409e52bfb39a522.tif',\n",
              " '/content/train/ae28ac6488cc2273ecb8f44d4797503ab21e153d.tif',\n",
              " '/content/train/3fb39f8f523d9e98d4a3d38301549b822856a1d6.tif',\n",
              " '/content/train/9a98877b6b65eb065a8413de92ad6b137b6158ef.tif',\n",
              " '/content/train/0012e50d4d9df5169d37252195a4664517420067.tif',\n",
              " '/content/train/cbb3c79e7c42606cc47ccf6cfb6e2cf54a32ec4b.tif',\n",
              " '/content/train/2a953b6e1995291dfe6ddd71633b31252d23b3ec.tif',\n",
              " '/content/train/0a24c64658a8aaee84ad8365941d055f78ceb2d7.tif',\n",
              " '/content/train/7a9b12dd9318f7deb3a62c710656376d265d457a.tif',\n",
              " '/content/train/c979085b70be72f7ec66d64818d55b57dfdeeef7.tif',\n",
              " '/content/train/5599036ddcc54b501405b0913b64376d3a679866.tif',\n",
              " '/content/train/5ab424bf6967a47b4dae222c4bb7fbb7f034d4a1.tif',\n",
              " '/content/train/5b3c7a2d34a99442ff171b28bbbc74c63176ee10.tif',\n",
              " '/content/train/85bd1b35669f5ea420d5ed7f840cc7b8895abafc.tif',\n",
              " '/content/train/e976fb9c3bcf5d77a1fb15dca2c5f8db79acd40f.tif',\n",
              " '/content/train/52160e33b3a80ce4fb2b9ee7704a6ecfaad0b61f.tif',\n",
              " '/content/train/58fd20be6169b4400389c7a43e0709e88d77737b.tif',\n",
              " '/content/train/18c6979f6f64aa3c16b77220d5833fa8d092b136.tif',\n",
              " '/content/train/97da9cf8dc8fc594d4ada927736e45493643b51c.tif',\n",
              " '/content/train/fd6e16b09c68d3363fb6b37eacff86d7b884614b.tif',\n",
              " '/content/train/79c60a194c41f1f1c9480be3bab5886f53d60276.tif',\n",
              " '/content/train/49123331741863a5a13f15a8b39c19bf2c36f29b.tif',\n",
              " '/content/train/80ae1776846ac751659bc70826cf5cdb40422d70.tif',\n",
              " '/content/train/21d85cdd672c8effda552eef2605cf6b240a5745.tif',\n",
              " '/content/train/4c544fb90889c9eaf41747c61b67f09cfc238522.tif',\n",
              " '/content/train/0aeab90d0a509047fb2aafae66fc39efe979a27d.tif',\n",
              " '/content/train/52a53f42cab04ba49dc2d5476b309d28d0c701ef.tif',\n",
              " '/content/train/2c0149640034105b2beb5ac42cd64ba714457874.tif',\n",
              " '/content/train/3785c5add174ace85f4aa8fa1f136e3fbda7ffa2.tif',\n",
              " '/content/train/3b6a8cbf6e57569867d09f726e45f31c09ac3653.tif',\n",
              " '/content/train/e48c1c3f0d8fc5a4063342044477f8506982835c.tif',\n",
              " '/content/train/3d71c4155e80c78134900fc442f9553f2516143a.tif',\n",
              " '/content/train/268cb118e385932d46272aba81c173f73371878b.tif',\n",
              " '/content/train/d00960d1737a2710992d3ba7d597050afaafa84e.tif',\n",
              " '/content/train/1b4bc00c9ecd1a29b405b2d3140f41f3d027404d.tif',\n",
              " '/content/train/7de78372c84769db133b1273d5696bacf6f46ae5.tif',\n",
              " '/content/train/93d3591255a8f1f2ec6dc158a7845841d430a085.tif',\n",
              " '/content/train/91bdd730041442f4a8bad477440d443e831e32f0.tif',\n",
              " '/content/train/70cc4c26ec0190f1e4d886a845e959cc38381971.tif',\n",
              " '/content/train/fc724c4b4bfd66d2231714012f3cf96f132ab602.tif',\n",
              " '/content/train/b8524d38e7144be0687d130db6ec3a63b86796c8.tif',\n",
              " '/content/train/9174b5f194ba40cf41aafb66a43f51f33fd1d5e5.tif',\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***3. Model Building***"
      ],
      "metadata": {
        "id": "ISUTBnGe72tT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()\n",
        "gc.collect()\n",
        "\n",
        "def rotate_img(image):\n",
        "    return np.rot90(image, np.random.choice([-1, 0, 1, 2]))\n",
        "\n",
        "# Generators\n",
        "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    zoom_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True,\n",
        "    preprocessing_function=rotate_img,\n",
        "    brightness_range=[0.4, 1.2]\n",
        ")\n",
        "'''\n",
        "(rescale = 1./255,\n",
        "                                       horizontal_flip = True,\n",
        "                                       vertical_flip = True,\n",
        "                                       rotation_range = 180,\n",
        "                                       zoom_range = 0.4, \n",
        "                                       width_shift_range = 0.3,\n",
        "                                       height_shift_range = 0.3,\n",
        "                                       shear_range = 0.3,\n",
        "                                       channel_shift_range = 0.3\n",
        "                                      )\n",
        "'''\n",
        "val_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale = 1./255)\n",
        "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale = 1./255)"
      ],
      "metadata": {
        "id": "2L3l2U-LhC1-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "class custom_generator(tf.keras.utils.Sequence) :\n",
        "  \n",
        "    def __init__(self, images, labels, batch_size) :\n",
        "        self.images = images\n",
        "        self.labels = labels\n",
        "        self.batch_size = batch_size\n",
        "    \n",
        "    \n",
        "    def __len__(self) :\n",
        "        return (np.ceil(len(self.images) / float(self.batch_size))).astype(np.int)\n",
        "  \n",
        "  \n",
        "    def __getitem__(self, idx) :\n",
        "        with tf.device('/cpu:0'): \n",
        "            batch_x = self.images[idx * self.batch_size : (idx+1) * self.batch_size]\n",
        "            batch_y = self.labels[idx * self.batch_size : (idx+1) * self.batch_size]\n",
        "    \n",
        "        return batch_x, batch_y\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "gaahAuOELfQH",
        "outputId": "c8d598e6-d7db-472d-bb2f-61c91ec33f20"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nclass custom_generator(tf.keras.utils.Sequence) :\\n  \\n    def __init__(self, images, labels, batch_size) :\\n        self.images = images\\n        self.labels = labels\\n        self.batch_size = batch_size\\n    \\n    \\n    def __len__(self) :\\n        return (np.ceil(len(self.images) / float(self.batch_size))).astype(np.int)\\n  \\n  \\n    def __getitem__(self, idx) :\\n        with tf.device('/cpu:0'): \\n            batch_x = self.images[idx * self.batch_size : (idx+1) * self.batch_size]\\n            batch_y = self.labels[idx * self.batch_size : (idx+1) * self.batch_size]\\n    \\n        return batch_x, batch_y\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for model_name in transfer_learning_model_list[0:1]:\n",
        "    train_accuracy, validation_accuracy, train_loss, validation_loss, total_probas, total_votes = [], [], [], [], [], []\n",
        "    for kfold, (train_indices, validation_indices) in enumerate(StratifiedKFold(n_splits =  number_of_splits, \n",
        "                                                                                shuffle = True, \n",
        "                                                                                random_state = random_state\n",
        "                                                                               ).split(data_proc.df_train_original['label'].values.tolist(), \n",
        "                                                                                       data_proc.df_train_original['label'].values.tolist()\n",
        "                                                                                      )):\n",
        "        print(f\"Model : {model_name}, k-fold : {kfold + 1}, length of train data : {len(train_indices)}, length of validation data : {len(validation_indices)}\")\n",
        "        data_proc.split_data_based_on_indices(train_indices = train_indices, validation_indices = validation_indices)\n",
        "\n",
        "        train_datagen_flow_color = train_datagen.flow_from_directory(image_processing_train_path,\n",
        "                                                                     target_size = (image_size, image_size),\n",
        "                                                                     class_mode = 'binary',\n",
        "                                                                     batch_size = batch_size,\n",
        "                                                                     color_mode = 'grayscale',\n",
        "                                                                     shuffle = True,\n",
        "                                                                     seed = random_state\n",
        "                                                                    )\n",
        "        val_datagen_flow_color = val_datagen.flow_from_directory(image_processing_validation_path,\n",
        "                                                                 target_size = (image_size, image_size),\n",
        "                                                                 class_mode = 'binary',\n",
        "                                                                 batch_size = batch_size,\n",
        "                                                                 color_mode = 'grayscale',\n",
        "                                                                 shuffle = True,\n",
        "                                                                 seed = random_state\n",
        "                                                                )\n",
        "        test_datagen_flow_color = test_datagen.flow_from_directory(image_processing_test_path,\n",
        "                                                                   target_size = (image_size, image_size),\n",
        "                                                                   batch_size = batch_size,\n",
        "                                                                   class_mode = 'binary',\n",
        "                                                                   color_mode = 'grayscale',\n",
        "                                                                   shuffle = True,\n",
        "                                                                   seed = random_state\n",
        "                                                                  )\n",
        "        \n",
        "        tf.random.set_seed(random_state)\n",
        "        np.random.seed(random_state)\n",
        "\n",
        "        # Pre-trained model build\n",
        "        print(f\"Building pretainined model for {model_name}\")\n",
        "        pretrained_model = model_proc.build_pretained_model(model_name = model_name)\n",
        "        #print(f\"Displying structure and summary pretainined model for {model_name}\")\n",
        "        #model_proc.model_summary_and_display_structure(pretrained_model)\n",
        "        \n",
        "        # Plug the pre-trained model to custom model\n",
        "        print(f\"Plugging in the pretainined model for {model_name} to custom model\")\n",
        "        model = Sequential()\n",
        "        for layer in pretrained_model.layers:\n",
        "            model.add(layer)\n",
        "        for layer in model.layers:\n",
        "            layer.trainable= False\n",
        "        model.add(GlobalAveragePooling2D())\n",
        "        model.add(Dropout(dropout_layer))\n",
        "        model.add(Dense(256, use_bias=False))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(Dropout(dropout_layer))\n",
        "        model.add(Dense(1))\n",
        "\n",
        "        # Model compile\n",
        "        print(\"Compiling the model...\")\n",
        "        model.compile(optimizer = 'adam',\n",
        "                      loss = tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "                      metrics = ['accuracy']) \n",
        "\n",
        "        # Model fit\n",
        "        print(\"Model fit...\")\n",
        "        history = model.fit(train_datagen_flow_color,\n",
        "                            epochs = 10,\n",
        "                            steps_per_epoch = len(train_datagen_flow_color),\n",
        "                            validation_data = val_datagen_flow_color,\n",
        "                            validation_steps = len(val_datagen_flow_color),\n",
        "                            verbose = 1\n",
        "                           )\n",
        "\n",
        "        # Model save\n",
        "        print(\"Saving model...\")\n",
        "        tf.keras.backend.clear_session()\n",
        "        gc.collect()\n",
        "        model.save('tumor_detection_' + model_name + '_k' + str(kfold) + '.h5')\n",
        "        saved_model_names_list.append('tumor_detection_' + model_name + '_k' + str(kfold))\n",
        "        \n",
        "        # Append accuracy and loss\n",
        "        print(f\"Storing train and validation accuracy and loss for model {model_name}, fold {kfold}\")\n",
        "        train_accuracy.append(history.history['accuracy'])\n",
        "        validation_accuracy.append(history.history['val_accuracy'])\n",
        "        train_loss.append(history.history['loss'])\n",
        "        validation_loss.append(history.history['val_loss'])\n",
        "\n",
        "        # Plot train and val accuracy and loss\n",
        "        print(f\"Plotting train and validation accuracy and loss for model {model_name}, fold {kfold}\")\n",
        "        model_proc.plot_model_accuracy_and_loss(history = history, model_name = model_name)\n",
        "\n",
        "        # Model Predict\n",
        "        step_size_test = np.ceil(test_datagen_flow_color.n / test_datagen_flow_color.batch_size)\n",
        "        test_datagen_flow_color.reset()\n",
        "        pred = model.predict_generator(test_datagen_flow_color, steps = step_size_test, verbose = 1)\n",
        "        probas_sigmoid = tf.sigmoid(pred)\n",
        "        probas_sigmoid = probas_sigmoid.numpy().flatten() * 100\n",
        "        predictions = [1 if x > 50.0 else 0 for x in probas_sigmoid]\n",
        "        total_probas.append(probas_sigmoid)\n",
        "        total_votes.append(pred)\n",
        "\n",
        "    temp_df_model_name = pd.DataFrame([model_name])\n",
        "    temp_df_model_name.columns = ['model_name']\n",
        "\n",
        "    temp_df_training_accuracy = pd.DataFrame(train_accuracy).T\n",
        "    temp_df_training_accuracy.columns = training_accuracy_col_list\n",
        "\n",
        "    temp_df_training_loss = pd.DataFrame(train_loss).T\n",
        "    temp_df_training_loss.columns = training_loss_col_list\n",
        "\n",
        "    temp_df_validation_accuracy = pd.DataFrame(validation_accuracy).T\n",
        "    temp_df_validation_accuracy.columns = validation_accuracy_col_list\n",
        "\n",
        "    temp_df_validation_loss = pd.DataFrame(validation_loss).T\n",
        "    temp_df_validation_loss.columns = validation_loss_col_list\n",
        "\n",
        "    temp_df_model_kpi = pd.concat([temp_df_model_name,\n",
        "                                   temp_df_training_accuracy, \n",
        "                                   temp_df_training_loss, \n",
        "                                   temp_df_validation_accuracy, \n",
        "                                   temp_df_validation_loss], axis=1)\n",
        "    temp_df_model_kpi.to_csv(model + '_kpi.csv')\n",
        "    consolidated_df_model_kpi = consolidated_df_model_kpi.append(temp_df_model_kpi)\n",
        "\n",
        "\n",
        "# voting across kfold\n",
        "# voting across ensemble models        \n",
        "# kpi print\n"
      ],
      "metadata": {
        "id": "10lQvL9Y78jH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ff18ca1c-90ab-4ec4-b594-5502812dbb4b"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model : VGG19, k-fold : 1, length of train data : 720, length of validation data : 180\n",
            "\n",
            "*****************************************************\n",
            "*****************************************************\n",
            "Starting to split data based on indices...\n",
            "\n",
            "*****************************************************\n",
            "*****************************************************\n",
            "Starting to create labels for train...\n",
            "Completed building labels for train...\n",
            "*****************************************************\n",
            "*****************************************************\n",
            "\n",
            "\n",
            "*****************************************************\n",
            "*****************************************************\n",
            "Starting to create labels for validation...\n",
            "Completed building labels for validation...\n",
            "*****************************************************\n",
            "*****************************************************\n",
            "\n",
            "\n",
            "*****************************************************\n",
            "*****************************************************\n",
            "Starting to remove files under /content/image_processing/train/positive...\n",
            "*****************************************************\n",
            "*****************************************************\n",
            "\n",
            "\n",
            "*****************************************************\n",
            "*****************************************************\n",
            "Starting to remove files under /content/image_processing/train/negative...\n",
            "*****************************************************\n",
            "*****************************************************\n",
            "\n",
            "Copying test_positive_file_list under /content/image_processing/train/positive\n",
            "Copying test_negative_file_list under /content/image_processing/train/negative\n",
            "File count under /content/image_processing/train/positive after moving new files is: 360\n",
            "File count under /content/image_processing/train/negative after moving new files is : 360\n",
            "\n",
            "*****************************************************\n",
            "*****************************************************\n",
            "Starting to remove files under /content/image_processing/validation/positive...\n",
            "*****************************************************\n",
            "*****************************************************\n",
            "\n",
            "\n",
            "*****************************************************\n",
            "*****************************************************\n",
            "Starting to remove files under /content/image_processing/validation/negative...\n",
            "*****************************************************\n",
            "*****************************************************\n",
            "\n",
            "Copying test_positive_file_list under /content/image_processing/validation/positive\n",
            "Copying test_negative_file_list under /content/image_processing/validation/negative\n",
            "File count under /content/image_processing/validation/positive after moving new files is: 90\n",
            "File count under /content/image_processing/validation/negative after moving new files is : 90\n",
            "Completed spliting the data sets based on indices...\n",
            "*****************************************************\n",
            "*****************************************************\n",
            "\n",
            "Found 720 images belonging to 2 classes.\n",
            "Found 180 images belonging to 2 classes.\n",
            "Found 100 images belonging to 2 classes.\n",
            "Building pretainined model for VGG19\n",
            "Model: \"vgg19\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 96, 96, 3)]       0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 96, 96, 64)        1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 96, 96, 64)        36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 48, 48, 64)        0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 48, 48, 128)       73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 48, 48, 128)       147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 24, 24, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 24, 24, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 24, 24, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 24, 24, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv4 (Conv2D)       (None, 24, 24, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 12, 12, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 12, 12, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 12, 12, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 12, 12, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv4 (Conv2D)       (None, 12, 12, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 6, 6, 512)         0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 6, 6, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 6, 6, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 6, 6, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv4 (Conv2D)       (None, 6, 6, 512)         2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 3, 3, 512)         0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 20,024,384\n",
            "Trainable params: 20,024,384\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Plugging in the pretainined model for VGG19 to custom model\n",
            "Compiling the model...\n",
            "Model fit...\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-86e2c259fd7d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     72\u001b[0m                             \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_datagen_flow_color\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m                             \u001b[0mvalidation_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_datagen_flow_color\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m                             \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m                            )\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'sequential/block1_conv1/Conv2D' defined at (most recent call last):\n    File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n      \"__main__\", mod_spec)\n    File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n      exec(code, run_globals)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"/usr/local/lib/python3.7/dist-packages/traitlets/config/application.py\", line 846, in launch_instance\n      app.start()\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelapp.py\", line 612, in start\n      self.io_loop.start()\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 149, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.7/asyncio/base_events.py\", line 541, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.7/asyncio/base_events.py\", line 1786, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.7/asyncio/events.py\", line 88, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/ioloop.py\", line 690, in <lambda>\n      lambda f: self._run_callback(functools.partial(callback, future))\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/ioloop.py\", line 743, in _run_callback\n      ret = callback()\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/gen.py\", line 787, in inner\n      self.run()\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/gen.py\", line 748, in run\n      yielded = self.gen.send(value)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 365, in process_one\n      yield gen.maybe_future(dispatch(*args))\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/gen.py\", line 209, in wrapper\n      yielded = next(result)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 268, in dispatch_shell\n      yield gen.maybe_future(handler(stream, idents, msg))\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/gen.py\", line 209, in wrapper\n      yielded = next(result)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 545, in execute_request\n      user_expressions, allow_stdin,\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/gen.py\", line 209, in wrapper\n      yielded = next(result)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/ipkernel.py\", line 306, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2855, in run_cell\n      raw_cell, store_history, silent, shell_futures)\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2881, in _run_cell\n      return runner(coro)\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 3058, in run_cell_async\n      interactivity=interactivity, compiler=compiler, result=result)\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 3249, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 3326, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"<ipython-input-20-86e2c259fd7d>\", line 74, in <module>\n      verbose = 1\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1409, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1051, in train_function\n      return step_function(self, iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1040, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1030, in run_step\n      outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 889, in train_step\n      y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 490, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/sequential.py\", line 374, in call\n      return super(Sequential, self).call(inputs, training=training, mask=mask)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py\", line 459, in call\n      inputs, training=training, mask=mask)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py\", line 596, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/layers/convolutional/base_conv.py\", line 250, in call\n      outputs = self.convolution_op(inputs, self.kernel)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/layers/convolutional/base_conv.py\", line 232, in convolution_op\n      name=self.__class__.__name__)\nNode: 'sequential/block1_conv1/Conv2D'\ninput depth must be evenly divisible by filter depth: 1 vs 3\n\t [[{{node sequential/block1_conv1/Conv2D}}]] [Op:__inference_train_function_3580]"
          ]
        }
      ]
    }
  ]
}