{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/srilamaiti/SM_MIDS_W207_HW/blob/main/01_Introduction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHLcriKWLRe4"
      },
      "source": [
        "# Lab 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7X58hOMTUH-w"
      },
      "outputs": [],
      "source": [
        "# Import the libraries we'll use below.\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nNOD-Z7SzAq"
      },
      "source": [
        "## Data as matrices\n",
        "Data usually comes in the form of matrices. The Python Numpy library makes it easy to manipulate matrices efficiently. See the [Numpy Tutorial](https://docs.scipy.org/doc/numpy/user/quickstart.html) for details."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KWlmuAMwTZ3P"
      },
      "outputs": [],
      "source": [
        "# Print these to make sure you understand what is being generated.\n",
        "A = np.array([1, 2, 3])\n",
        "B = np.arange(1, 13).reshape(3, 4)\n",
        "C = np.ones((2, 3))\n",
        "D = np.eye(3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A"
      ],
      "metadata": {
        "id": "cLNs5bPUmJ7-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "A.shape"
      ],
      "metadata": {
        "id": "sCDE_QFMHniw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "B"
      ],
      "metadata": {
        "id": "HtN3pxWImLSt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "B.shape"
      ],
      "metadata": {
        "id": "wJcRgkhDHqcO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "C"
      ],
      "metadata": {
        "id": "KdFmHdW9mP_N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "C.shape"
      ],
      "metadata": {
        "id": "s1nU5gCkHtQ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "D"
      ],
      "metadata": {
        "id": "0OAlxF5pmTG6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "D.shape"
      ],
      "metadata": {
        "id": "WchnZDvSHw5L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4wvvzKoUIAN"
      },
      "source": [
        "---\n",
        "### Exercise 1: Matrix manipulation (8 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xS9iWoZtl-VA"
      },
      "source": [
        "Perform the following computations using numpy functions and print the results. Note that the `*` operator implies matrix multiplication -- make sure the dimensions align!\n",
        "1. 2A + 1\n",
        "2. Sum the rows of B\n",
        "3. Sum the columns of B\n",
        "4. Number of elements of B greater than 5\n",
        "5. C + C\n",
        "6. A * B\n",
        "7. (B * B) - D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HJtwrjdO6TbS"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n",
        "print(\"2A + 1\\n\", 2*A + 1)\n",
        "# axis = 1 performs row wise operations, and 0 performs column wise operations\n",
        "print(\"Sum the rows of B\\n\", np.sum(B, axis = 1)) \n",
        "print(\"Sum the columns of B\\n\", np.sum(B, axis = 0))\n",
        "print(\"Number of elements of B greater than 5\\n\", np.count_nonzero(B > 5))\n",
        "print(\"C + C\\n\", C + C)\n",
        "print(\"A * B\\n\", np.dot(A, B))\n",
        "#print(\"(B * B) - D\\n\", np.multiply(B,B) - D)\n",
        "# The reason of transposinmg is that, we can not do the matrix multiplication.\n",
        "print(\"(B * B) - D\\n\", np.dot(B, np.transpose(B)) - D)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5q53jAdel-VB"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbCRG2-uUKCT"
      },
      "source": [
        "## Data for Supervised Learning\n",
        "Supervised learning is all about learning to make predictions: given an input $x$ (e.g. home square footage), can we produce an output $\\hat{y}$ (e.g. estimated value) as close to the actual observed output $y$ (e.g. sale price) as possible. Note that the \"hat\" above $y$ is used to denote an estimated or predicted value.\n",
        "\n",
        "Let's start by generating some artificial data. We'll create a vector of inputs, $X$, and a corresponding vector of target outputs $Y$. In general, we'll refer to invidual examples with a lowercase ($x$), and a vector or matrix containing multiple examples with a capital ($X$)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ulmn_bFdU87t"
      },
      "outputs": [],
      "source": [
        "def create_1d_data(num_examples=10, w=2, b=1, random_scale=1):\n",
        "  \"\"\"Create X, Y data with a linear relationship with added noise.\n",
        "\n",
        "  Args:\n",
        "    num_examples: number of examples to generate\n",
        "    w: desired slope\n",
        "    b: desired intercept\n",
        "    random_scale: add uniform noise between -random_scale and +random_scale\n",
        "\n",
        "  Returns:\n",
        "    X and Y with shape (num_examples)\n",
        "  \"\"\"\n",
        "  X = np.arange(num_examples)\n",
        "  np.random.seed(4)  # consistent random number generation\n",
        "  deltas = np.random.uniform(low=-random_scale, high=random_scale, size=X.shape)\n",
        "  Y = b + deltas + w * X\n",
        "  return X, Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6qJg0IiYVJ8U"
      },
      "outputs": [],
      "source": [
        "# Create some artificial data using create_1d_data.\n",
        "X, Y = create_1d_data()\n",
        "plt.scatter(X, Y)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(X), len(Y)"
      ],
      "metadata": {
        "id": "A38djKPw9XW-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "id": "N-tHWB6Z9kNk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y"
      ],
      "metadata": {
        "id": "TQJehf219mqV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6coKbXSpXOz"
      },
      "source": [
        "---\n",
        "### Exercise 2: Models for Data (8 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HF1VBswbl-VE"
      },
      "source": [
        "A model is a function that takes an input $x$ and produces a prediction $\\hat{y}$.\n",
        "\n",
        "Let's consider two possible models for this data:\n",
        "1. $M_1(x) = x+5$ \n",
        "2. $M_2(x) = 2x+1$\n",
        "\n",
        "Compute the predictions of models $M_1$ and $M_2$ for the values in $X$. These predictions should be vectors of the same shape as $Y$. Then plot the prediction lines of these two models overlayed on the \"observed\" data $(X, Y)$. Use [plt.plot()](https://matplotlib.org/api/_as_gen/matplotlib.pyplot.plot.html) to draw the lines."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AHIY5kNXUIAP"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n",
        "# Create some artificial data using create_1d_data.\n",
        "X, M1 = create_1d_data(w = 1, b = 5)\n",
        "\n",
        "X, M2 = create_1d_data(w = 2, b = 1)\n",
        "\n",
        "plt.scatter(X, M1)\n",
        "plt.scatter(X, M2)\n",
        "plt.xlabel(\"X\")\n",
        "plt.ylabel(\"Predicted Y\")\n",
        "plt.title(\"Linear Regression : X Vs Y\")\n",
        "plt.legend([\"Model1 : M1\", \"Model2 : M2\"], loc = \"lower right\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvOcDuzyl-VF"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NH-0soZiWx9x"
      },
      "source": [
        "## Evaluation Metrics\n",
        "\n",
        "How good are our models? Intuitively, the better the model, the more closely it fits the data we have. That is, for each $x$, we'll compare $y$, the true value, with $\\hat{y}$, the predicted value. This comparison is often called the *loss* or the *error*. One common such comparison is *squared error*: $(y-\\hat{y})^2$. Averaging over all our data points, we get the *mean squared error*:\n",
        "\n",
        "\\begin{equation}\n",
        "\\textit{MSE} = \\frac{1}{|Y|} \\sum_{y_i \\in Y}(y_i - \\hat{y}_i)^2\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_AyY2DpxYLI0"
      },
      "source": [
        "---\n",
        "### Exercise 3: Computing MSE (8 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DgRHo-ml-VG"
      },
      "source": [
        "Write a function for computing the MSE metric and use it to compute the MSE for the two models above, $M_1$ and $M_2$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uCeAfI5mW9sg"
      },
      "outputs": [],
      "source": [
        "def MSE(true_values, predicted_values):\n",
        "    \"\"\"Return the MSE between true_values and predicted values.\"\"\"\n",
        "    # YOUR CODE HERE\n",
        "    return np.sum((true_values - predicted_values) * (true_values - predicted_values)) / len(true_values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uF-x9DI2ZOKq"
      },
      "outputs": [],
      "source": [
        "np.set_printoptions(suppress=True, precision=10)\n",
        "print('MSE for M1:', MSE(Y, M1))\n",
        "print('MSE for M2:', MSE(Y, M2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gglLmwpjl-VG"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDiy3OZwZlwj"
      },
      "source": [
        "## Generalization\n",
        "\n",
        "Our data $(X, Y)$ represents just a sample of all possible input-output pairs we might care about. A model will be useful to the extent we can apply it to new inputs. Consider the more complex model below, which appears to produce a much smaller mean squared error."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ns1siZ9DZvSY"
      },
      "outputs": [],
      "source": [
        "# Fit an 8-th degree polynomial to (X, Y). See np.polyfit for details.\n",
        "polynomial_model_coefficients = np.polyfit(X, Y, deg=8)\n",
        "polynomial_model = np.poly1d(polynomial_model_coefficients)\n",
        "M3 = polynomial_model(X)\n",
        "fig = plt.scatter(X, Y)\n",
        "plt.plot(X, M3, '-k')\n",
        "print ('MSE for M3:', MSE(Y, M3))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.set_printoptions(suppress=True, precision=10)\n",
        "\n",
        "for deg in range(1,15):\n",
        "    polynomial_model_coefficients = np.polyfit(X, Y, deg=deg)\n",
        "    polynomial_model = np.poly1d(polynomial_model_coefficients)\n",
        "    M_deg = polynomial_model(X)\n",
        "    fig = plt.scatter(X, Y)\n",
        "    plt.plot(X, Y, '-*')\n",
        "    plt.plot(X, M_deg, '-k')\n",
        "    print (f'MSE for M_deg({deg}):', np.round(MSE(Y, M_deg), 10))\n",
        "    plt.show(block = False)"
      ],
      "metadata": {
        "id": "pMZa_aYtwjTh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2m9YmLMZ1EV"
      },
      "source": [
        "---\n",
        "### Exercise 4: Generalization (8 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fcgd6wZel-VH"
      },
      "source": [
        "Explain whether you expect $M_3$ to be better than $M_2$ at predicting the labels for new unseen inputs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0Zpx79_aQEC"
      },
      "source": [
        "*Writen answer:*"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Though Mean Square Error(MSE) matric for M3 is more than MSE of M2 (.1094 vs .00), I do not think M3 prediction( a polynomial regression) generalizes well with unseen data over M2's(linear regression) predictions. I have done an experiment with polynomial degree and noticed that with each degree increase, MSE drops and the predicted line passes well covering all X values, which is overfitting and lack of generalization."
      ],
      "metadata": {
        "id": "FLHFFORhA_3e"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9EH9D7Faf9n"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6hIdZHngdrET"
      },
      "source": [
        "## Review\n",
        "\n",
        "* In **Supervised Machine Learning**, we must start with data in the form $(X,Y)$ where $X$ are the inputs and $Y$ are the output labels.\n",
        "* A **model** is a function that maps an input $x$ to an output $y$. The model's output is referred to as a **prediction**, denoted by $\\hat{y}$.\n",
        "* We **evaluate** predictions by comparing them to the true labels. This measurement is called a **loss** or **error**. For real-valued data, **mean squared error** is a common metric.\n",
        "* A model is only as good as its ability to **generalize** to new examples."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "01 Introduction.ipynb",
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}