{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "0mavHZlbpFpR",
        "m2j3vtPothqH",
        "jStvd4wGp8Ju",
        "i2353h6hNEnz",
        "GSEWn5BEN1Sz"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/srilamaiti/SM_MIDS_W207_HW/blob/main/tumor_detection_xception_mobilenet_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***1. Setup***"
      ],
      "metadata": {
        "id": "NUylKvIS6Lsf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***A. Installing New Libraries***"
      ],
      "metadata": {
        "id": "5dlGr3VX6DyA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kAIyFDyH5uLR",
        "outputId": "0de51dc5-3737-4fb1-c2c2-449c6a87882c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: imgaug in /usr/local/lib/python3.8/dist-packages (0.4.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from imgaug) (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.8/dist-packages (from imgaug) (1.21.6)\n",
            "Requirement already satisfied: scikit-image>=0.14.2 in /usr/local/lib/python3.8/dist-packages (from imgaug) (0.18.3)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.8/dist-packages (from imgaug) (4.6.0.66)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.8/dist-packages (from imgaug) (1.8.5.post1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from imgaug) (1.15.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from imgaug) (1.7.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.8/dist-packages (from imgaug) (7.1.2)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.8/dist-packages (from imgaug) (2.9.0)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image>=0.14.2->imgaug) (1.3.0)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.8/dist-packages (from scikit-image>=0.14.2->imgaug) (2021.11.2)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image>=0.14.2->imgaug) (2.6.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->imgaug) (1.4.4)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->imgaug) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->imgaug) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->imgaug) (0.11.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install imgaug"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install livelossplot"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91Xb-Plzo2E5",
        "outputId": "a15820bb-7e10-4bd8-e89b-fa6d89e5fa9d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting livelossplot\n",
            "  Downloading livelossplot-0.5.5-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from livelossplot) (3.2.2)\n",
            "Requirement already satisfied: bokeh in /usr/local/lib/python3.8/dist-packages (from livelossplot) (2.3.3)\n",
            "Requirement already satisfied: tornado>=5.1 in /usr/local/lib/python3.8/dist-packages (from bokeh->livelossplot) (6.0.4)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from bokeh->livelossplot) (2.8.2)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.8/dist-packages (from bokeh->livelossplot) (6.0)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.8/dist-packages (from bokeh->livelossplot) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.8/dist-packages (from bokeh->livelossplot) (4.1.1)\n",
            "Requirement already satisfied: Jinja2>=2.9 in /usr/local/lib/python3.8/dist-packages (from bokeh->livelossplot) (2.11.3)\n",
            "Requirement already satisfied: pillow>=7.1.0 in /usr/local/lib/python3.8/dist-packages (from bokeh->livelossplot) (7.1.2)\n",
            "Requirement already satisfied: packaging>=16.8 in /usr/local/lib/python3.8/dist-packages (from bokeh->livelossplot) (21.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from Jinja2>=2.9->bokeh->livelossplot) (2.0.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=16.8->bokeh->livelossplot) (3.0.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.1->bokeh->livelossplot) (1.15.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->livelossplot) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->livelossplot) (1.4.4)\n",
            "Installing collected packages: livelossplot\n",
            "Successfully installed livelossplot-0.5.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***B. Importing Libraries***"
      ],
      "metadata": {
        "id": "UQBd_dFh6S1S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***a. Importing General Purpose Libraries***"
      ],
      "metadata": {
        "id": "Iv-y8vdS62gV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import joblib\n",
        "import glob\n",
        "import random\n",
        "from itertools import product\n",
        "import gc\n",
        "import subprocess\n",
        "import shutil\n",
        "import copy\n",
        "import statistics as st\n",
        "from scipy import stats\n",
        "from pathlib import Path\n",
        "\n",
        "pd.set_option('display.max_rows', None)\n",
        "pd.set_option('display.max_columns', None)"
      ],
      "metadata": {
        "id": "ujHcENda69HI"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***b. Importing Image Processing and Visualization Libraries***"
      ],
      "metadata": {
        "id": "xM_Fw_tt7EpU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from imutils import rotate as rotate\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "import matplotlib.patches as patches\n",
        "from matplotlib.patches import Polygon\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "from skimage.color import gray2rgb\n",
        "import skimage.io as skio\n",
        "from imgaug import augmenters as img_aug\n",
        "import imgaug as iaug\n",
        "import matplotlib as mpl\n",
        "mpl.rcParams['figure.figsize'] = (12, 10)\n",
        "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']"
      ],
      "metadata": {
        "id": "0NV7G1UoIi4I"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***c. Importing Sklearn Functionalities***"
      ],
      "metadata": {
        "id": "qSyqwXIMIp7t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import shuffle\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.decomposition import IncrementalPCA\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import auc\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "import sklearn"
      ],
      "metadata": {
        "id": "fUh7ts6QI8Lx"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***d. Importing Tensorflow Libraries***"
      ],
      "metadata": {
        "id": "2C55GxBKnW3V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from livelossplot import PlotLossesKeras\n",
        "from keras.utils.layer_utils import count_params\n",
        "\n",
        "from tensorflow.keras.layers import RandomFlip\n",
        "from tensorflow.keras.layers import RandomZoom\n",
        "from tensorflow.keras.layers import RandomRotation\n",
        "from tensorflow.keras.layers import Conv1D\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import Concatenate\n",
        "from tensorflow.keras.layers import MaxPooling1D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.layers import AveragePooling2D\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import GlobalMaxPooling2D\n",
        "from tensorflow.keras.layers import GlobalAveragePooling1D\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
        "from tensorflow.keras.layers import Lambda\n",
        "from tensorflow.keras.layers import Multiply\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.layers import Bidirectional\n",
        "from tensorflow.keras.layers import PReLU\n",
        "from keras.layers.core import Activation\n",
        "from keras.layers.convolutional import SeparableConv1D\n",
        "from keras.layers.convolutional import SeparableConv2D\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.applications.vgg19 import VGG19\n",
        "from keras.applications.densenet import *\n",
        "from keras.applications.resnet import ResNet152\n",
        "from keras.applications.nasnet import NASNetMobile\n",
        "from keras.applications.nasnet import NASNetLarge\n",
        "from keras.applications.efficientnet import EfficientNetB7\n",
        "from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
        "from keras.applications.nasnet import preprocess_input\n",
        "from keras.applications import MobileNetV2\n",
        "from keras.applications.xception import Xception\n",
        "from keras.applications.inception_v3 import *\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import array_to_img\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.preprocessing.image import save_img\n",
        "\n",
        "from tensorflow.python.ops.numpy_ops import np_config\n",
        "\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "\n",
        "from tensorflow.keras.losses import mae\n",
        "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
        "from tensorflow.keras.losses import binary_crossentropy\n",
        "\n",
        "from keras.models import Model\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.regularizers import l1\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from keras.models import load_model\n"
      ],
      "metadata": {
        "id": "eUXe1TURnkN5"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***C. Mounting Google Drive***"
      ],
      "metadata": {
        "id": "JLAsViNZnt1V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Required to read the data from Kaggle\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = \"/content/gdrive/MyDrive/Kaggle\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bCewn8D_n4oL",
        "outputId": "414822b1-5998-447a-8e87-87b4ebf1e6cd"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***D. Downloading Data from Kaggle***"
      ],
      "metadata": {
        "id": "0mavHZlbpFpR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!bash /content/gdrive/MyDrive/Kaggle/download_kaggle_data.ksh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qxaSmgjsoxfh",
        "outputId": "4f4bc484-b02b-4cfb-eefd-5fa409150aab"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading histopathologic-cancer-detection.zip to /content\n",
            "100% 6.29G/6.31G [00:37<00:00, 189MB/s]\n",
            "100% 6.31G/6.31G [00:37<00:00, 183MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!kaggle competitions download -c histopathologic-cancer-detection\n",
        "#!unzip -o -qq \\*.zip  && rm *.zip"
      ],
      "metadata": {
        "id": "fDXH4brO_sGj"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***E. Defining Vartiables***"
      ],
      "metadata": {
        "id": "aZ9PZBKVtI__"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "#sample_size = 80000\n",
        "sample_size = 1000\n",
        "#batch_size = 256\n",
        "batch_size = 128\n",
        "#epochs = 10\n",
        "epochs = 3\n",
        "\n",
        "image_size = 96\n",
        "#number_of_splits = 8\n",
        "number_of_splits = 3\n",
        "run_mode = ['interim_test', 'final_test']\n",
        "\n",
        "# Transfer learning model list\n",
        "transfer_learning_model_list = ['VGG16', \n",
        "                                'VGG19', \n",
        "                                'DenseNet201', \n",
        "                                'InceptionV3', \n",
        "                                'ResNet50', \n",
        "                                'EfficientNetB7', \n",
        "                                'MobileNet', \n",
        "                                'Xception'\n",
        "                               ]\n",
        "learning_rate_list = [.01, .001, .0001, .00001]\n",
        "optimizer_list = ['sgd', 'adam']\n",
        "dropout_list = [.2, .4, .6]\n",
        "kernel_size_list = [(3,3), (4,4), (5,5)]\n",
        "dense_layer_node_list = [512, 256, 128]\n",
        "fully_conneted_layer_list = [1, 2, 3]\n",
        "epoch_list = [5, 10, 15, 20]\n",
        "\n",
        "train_path = os.getcwd() + \"/train/\"\n",
        "test_path = os.getcwd() + \"/test/\"\n",
        "\n",
        "original_input_file_list = train_path + '*.tif'\n",
        "original_output_file_list = test_path + '*.tif'\n",
        "\n",
        "current_working_dir = os.getcwd()\n",
        "\n",
        "train_label_file = 'train_labels.csv'\n",
        "test_label_file = 'sample_submission.csv'\n",
        "\n",
        "image_file_extension = '.tif'\n",
        "\n",
        "train_files_path = os.path.join(current_working_dir, train_path)\n",
        "test_files_path = os.path.join(current_working_dir, test_path)\n",
        "\n",
        "image_processing_train_positive_path = '/content/image_processing/train/positive'\n",
        "image_processing_train_negative_path = '/content/image_processing/train/negative'\n",
        "\n",
        "image_processing_validation_positive_path = '/content/image_processing/validation/positive'\n",
        "image_processing_validation_negative_path = '/content/image_processing/validation/negative'\n",
        "\n",
        "image_processing_test_positive_path = '/content/image_processing/test/positive'\n",
        "image_processing_test_negative_path = '/content/image_processing/test/negative'\n",
        "\n",
        "image_processing_train_path = \"/content/image_processing/train/\"\n",
        "image_processing_validation_path = \"/content/image_processing/validation/\"\n",
        "image_processing_test_path = \"/content/image_processing/test/\"\n",
        "\n",
        "random.seed(1)\n",
        "random_state = 1234\n",
        "\n",
        "dropout_rate = .5\n",
        "\n",
        "consolidated_df_model_kpi = pd.DataFrame()\n",
        "\n",
        "df_model_kfold_epoch_pred_pct = pd.DataFrame()\n",
        "df_model_kfold_epoch_pred_bin = pd.DataFrame()\n",
        "\n",
        "saved_model_names_list = []\n",
        "\n",
        "grayscale_image_augmentation_list = ['adjust_random_brightness',\n",
        "                                     'adjust_random_contrast',\n",
        "                                     'random_flip_left_right',\n",
        "                                     'random_flip_up_down',\n",
        "                                     'rotate_image_by_angle',\n",
        "                                     'rotate_image_by_90_or_180_or_270_deg',\n",
        "                                     'random_zoom',\n",
        "                                     'resize_with_crop_or_pad'\n",
        "                                    ]\n",
        "'''"
      ],
      "metadata": {
        "id": "e4rSklTftQY-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "f978f124-b621-4f3e-a138-c23d1ef1b2c8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n#sample_size = 80000\\nsample_size = 1000\\n#batch_size = 256\\nbatch_size = 128\\n#epochs = 10\\nepochs = 3\\n\\nimage_size = 96\\n#number_of_splits = 8\\nnumber_of_splits = 3\\nrun_mode = [\\'interim_test\\', \\'final_test\\']\\n\\n# Transfer learning model list\\ntransfer_learning_model_list = [\\'VGG16\\', \\n                                \\'VGG19\\', \\n                                \\'DenseNet201\\', \\n                                \\'InceptionV3\\', \\n                                \\'ResNet50\\', \\n                                \\'EfficientNetB7\\', \\n                                \\'MobileNet\\', \\n                                \\'Xception\\'\\n                               ]\\nlearning_rate_list = [.01, .001, .0001, .00001]\\noptimizer_list = [\\'sgd\\', \\'adam\\']\\ndropout_list = [.2, .4, .6]\\nkernel_size_list = [(3,3), (4,4), (5,5)]\\ndense_layer_node_list = [512, 256, 128]\\nfully_conneted_layer_list = [1, 2, 3]\\nepoch_list = [5, 10, 15, 20]\\n\\ntrain_path = os.getcwd() + \"/train/\"\\ntest_path = os.getcwd() + \"/test/\"\\n\\noriginal_input_file_list = train_path + \\'*.tif\\'\\noriginal_output_file_list = test_path + \\'*.tif\\'\\n\\ncurrent_working_dir = os.getcwd()\\n\\ntrain_label_file = \\'train_labels.csv\\'\\ntest_label_file = \\'sample_submission.csv\\'\\n\\nimage_file_extension = \\'.tif\\'\\n\\ntrain_files_path = os.path.join(current_working_dir, train_path)\\ntest_files_path = os.path.join(current_working_dir, test_path)\\n\\nimage_processing_train_positive_path = \\'/content/image_processing/train/positive\\'\\nimage_processing_train_negative_path = \\'/content/image_processing/train/negative\\'\\n\\nimage_processing_validation_positive_path = \\'/content/image_processing/validation/positive\\'\\nimage_processing_validation_negative_path = \\'/content/image_processing/validation/negative\\'\\n\\nimage_processing_test_positive_path = \\'/content/image_processing/test/positive\\'\\nimage_processing_test_negative_path = \\'/content/image_processing/test/negative\\'\\n\\nimage_processing_train_path = \"/content/image_processing/train/\"\\nimage_processing_validation_path = \"/content/image_processing/validation/\"\\nimage_processing_test_path = \"/content/image_processing/test/\"\\n\\nrandom.seed(1)\\nrandom_state = 1234\\n\\ndropout_rate = .5\\n\\nconsolidated_df_model_kpi = pd.DataFrame()\\n\\ndf_model_kfold_epoch_pred_pct = pd.DataFrame()\\ndf_model_kfold_epoch_pred_bin = pd.DataFrame()\\n\\nsaved_model_names_list = []\\n\\ngrayscale_image_augmentation_list = [\\'adjust_random_brightness\\',\\n                                     \\'adjust_random_contrast\\',\\n                                     \\'random_flip_left_right\\',\\n                                     \\'random_flip_up_down\\',\\n                                     \\'rotate_image_by_angle\\',\\n                                     \\'rotate_image_by_90_or_180_or_270_deg\\',\\n                                     \\'random_zoom\\',\\n                                     \\'resize_with_crop_or_pad\\'\\n                                    ]\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class config_defition:\n",
        "    \"\"\"\n",
        "    This class is a static class holding all the configuration parameters.\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        Constructor method to define all the variables.\n",
        "        \"\"\"\n",
        "        #self.sample_size = 80000\n",
        "        self.sample_size = 1000\n",
        "        self.batch_size = 128\n",
        "        #self.epochs = 10\n",
        "        self.epochs = 3\n",
        "        self.image_size = 96\n",
        "        #self.number_of_splits = 8\n",
        "        self.number_of_splits = 3\n",
        "        self.dropout_rate = .5\n",
        "        self.run_mode = ['interim_test', 'final_test']\n",
        "\n",
        "        # Transfer learning model list\n",
        "        self.transfer_learning_model_list = ['VGG16', \n",
        "                                             'VGG19', \n",
        "                                             'DenseNet201', \n",
        "                                             'InceptionV3', \n",
        "                                             'ResNet50', \n",
        "                                             'EfficientNetB7', \n",
        "                                             'MobileNet', \n",
        "                                             'Xception'\n",
        "                                            ]\n",
        "        self.learning_rate_list = [.01, .001, .0001, .00001]\n",
        "        self.optimizer_list = ['sgd', 'adam']\n",
        "        self.dropout_list = [.2, .4, .6]\n",
        "        \n",
        "        self.train_path = os.getcwd() + \"/train/\"\n",
        "        self.test_path = os.getcwd() + \"/test/\"\n",
        "        self.original_input_file_list = self.train_path + '*.tif'\n",
        "        self.original_output_file_list = self.test_path + '*.tif'\n",
        "        self.current_working_dir = os.getcwd()\n",
        "        self.train_label_file = 'train_labels.csv'\n",
        "        self.test_label_file = 'sample_submission.csv'\n",
        "        self.image_file_extension = '.tif'\n",
        "        self.root_directory = '/content/image_processing'\n",
        "        self.train_files_path = os.path.join(self.current_working_dir, \n",
        "                                             self.train_path\n",
        "                                            )\n",
        "        self.test_files_path = os.path.join(self.current_working_dir, \n",
        "                                            self.test_path\n",
        "                                           )\n",
        "        \n",
        "        self.image_processing_train_positive_path = '/content/image_processing/train/positive'\n",
        "        self.image_processing_train_negative_path = '/content/image_processing/train/negative'\n",
        "\n",
        "        self.image_processing_validation_positive_path = '/content/image_processing/validation/positive'\n",
        "        self.image_processing_validation_negative_path = '/content/image_processing/validation/negative'\n",
        "\n",
        "        self.image_processing_test_positive_path = '/content/image_processing/test/positive'\n",
        "        self.image_processing_test_negative_path = '/content/image_processing/test/negative'\n",
        "\n",
        "        self.image_processing_train_path = \"/content/image_processing/train/\"\n",
        "        self.image_processing_validation_path = \"/content/image_processing/validation/\"\n",
        "        self.image_processing_test_path = \"/content/image_processing/test/\"\n",
        "        \n",
        "        random.seed(1)\n",
        "        self.random_state = 1234\n",
        "\n",
        "        self.consolidated_history_df = pd.DataFrame()\n",
        "        self.consolidated_test_kpi_df = pd.DataFrame()\n",
        "        self.consolidated_pred_df = pd.DataFrame()\n",
        "        self.test_kpi_df = pd.DataFrame()\n",
        "        self.temp_pred_df = pd.DataFrame()\n",
        "        \n",
        "        self.consolidated_df_model_kpi = pd.DataFrame()\n",
        "        self.saved_model_names_list = []\n",
        "        self.grayscale_image_augmentation_list = ['adjust_random_brightness',\n",
        "                                                  'adjust_random_contrast',\n",
        "                                                  'random_flip_left_right',\n",
        "                                                  'random_flip_up_down',\n",
        "                                                  'rotate_image_by_angle',\n",
        "                                                  'rotate_image_by_90_or_180_or_270_deg',\n",
        "                                                  'random_zoom',\n",
        "                                                  'resize_with_crop_or_pad'\n",
        "                                                 ]\n",
        "        \n",
        "cfg_proc = config_defition()"
      ],
      "metadata": {
        "id": "Pwn6f7t4Tlfu"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***F. Misclenious Processing Class***"
      ],
      "metadata": {
        "id": "m2j3vtPothqH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class misc_processing:\n",
        "    \"\"\"\n",
        "    This class contains methods for misclenious processings.\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        None\n",
        "  \n",
        "    def create_dir_structure(self, root_directory):\n",
        "        \"\"\"\n",
        "        This method creates a directory tree in the form below:-\n",
        "        image_processing--| train         |---positive\n",
        "                          |               |---negative\n",
        "                          |  \n",
        "                          | validation    |---positive\n",
        "                          |               |---negative\n",
        "                          |\n",
        "                          | test          |---positive\n",
        "                          |               |---negative\n",
        "\n",
        "        \"\"\"\n",
        "        dirpath = Path(root_directory)\n",
        "        if dirpath.exists() and dirpath.is_dir():\n",
        "            shutil.rmtree(f'{root_directory}')\n",
        "        os.makedirs(f'{root_directory}', \n",
        "                    exist_ok = True\n",
        "                   )\n",
        "        for sub_folder in ['train', 'validation', 'test']:\n",
        "            for grp in ['positive', 'negative']:\n",
        "                os.makedirs(f'{root_directory}/{sub_folder}/{grp}', \n",
        "                            exist_ok = True\n",
        "                           )\n",
        "\n",
        "    def remove_files_from_dir(self, path):\n",
        "        \"\"\"\n",
        "        This method deletes all files under a given path.\n",
        "        \"\"\"\n",
        "        print()\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"*****************************************************\")\n",
        "        print(f\"Starting to remove files under {path}...\")\n",
        "        shutil.rmtree(path)\n",
        "        os.mkdir(path)\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"*****************************************************\")\n",
        "        print()\n",
        "    \n",
        "    def generate_fully_qualified_file_name_list(self, file_list):\n",
        "        \"\"\"\n",
        "        This method generates a list of fully qualified file names.\n",
        "        \"\"\"\n",
        "        qualified_file_name_list = [os.path.join(cfg_proc.current_working_dir, cfg_proc.train_path) + \n",
        "                                    img + \n",
        "                                    cfg_proc.image_file_extension \n",
        "                                    for img in file_list\n",
        "                                   ]\n",
        "        return qualified_file_name_list\n",
        "\n",
        "    def print_image_original(self, image_file_list, label_list):\n",
        "        \"\"\"\n",
        "        This method prints original images.\n",
        "        \"\"\"\n",
        "        nrows, ncols = 1,4 #print first 4 images\n",
        "        f, axs = plt.subplots(nrows, ncols, figsize=(14,12))\n",
        "        for i, image in enumerate(image_file_list):\n",
        "            axs[i].imshow(array_to_img(image))\n",
        "            pf = Polygon(((32, 32), (64, 32), (64, 64), (32, 64)),\n",
        "                         fc=(0.0, 0.0, 0.0, 0.0), \n",
        "                         ec=(0.0, 0.9, 0.0 ,0.9), lw=4, linestyle='--')\n",
        "            pf.set_edgecolor('r')\n",
        "            axs[i].add_patch(pf)\n",
        "            axs[i].set(title=label_list[i])\n",
        "\n",
        "    def print_image_in_diff_orientation(self, image_file):\n",
        "        \"\"\"\n",
        "        This method prints images.\n",
        "        \"\"\"\n",
        "        tf.random.set_seed(1234)\n",
        "        fig = plt.figure(figsize=(14, 12))\n",
        "        #fig = plt.figure()\n",
        "        image = skio.imread(image_file, plugin = \"tifffile\")\n",
        "        \n",
        "        # plot original\n",
        "        ax = fig.add_subplot(1, 5, 1)\n",
        "        ax.imshow(array_to_img(image))\n",
        "        pf = Polygon(((32, 32), (64, 32), (64, 64), (32, 64)),\n",
        "                fc = (0.0, 0.0, 0.0, 0.0), \n",
        "                ec = (0.0, 0.9, 0.0 ,0.9), lw=4, linestyle='--')\n",
        "        pf.set_edgecolor('r')\n",
        "        ax.add_patch(pf)\n",
        "        ax.set_title('Original', size=15);\n",
        "        \n",
        "        # resize\n",
        "        ax = fig.add_subplot(1, 5, 2)\n",
        "        img_resize = tf.image.resize(image, size=(224, 224))\n",
        "        ax.imshow(array_to_img(img_resize))\n",
        "        pf = Polygon(((80, 80), (144, 80), (144, 144), (80, 144)),\n",
        "                fc = (0.0, 0.0, 0.0, 0.0), \n",
        "                ec = (0.0, 0.9, 0.0 ,0.9), lw=4, linestyle='--')\n",
        "        pf.set_edgecolor('r')\n",
        "        ax.add_patch(pf)\n",
        "        ax.set_title('Step 1: Resize', size=15);\n",
        "        \n",
        "        # adjust brightness\n",
        "        ax = fig.add_subplot(1, 5, 3)\n",
        "        img_bright = tf.image.adjust_brightness(img_resize, 0.3)\n",
        "        ax.imshow(array_to_img(img_bright))\n",
        "        pf = Polygon(((80, 80), (144, 80), (144, 144), (80, 144)),\n",
        "                fc = (0.0, 0.0, 0.0, 0.0), \n",
        "                ec = (0.0, 0.9, 0.0 ,0.9), lw=4, linestyle='--')\n",
        "        pf.set_edgecolor('r')\n",
        "        ax.add_patch(pf)\n",
        "        ax.set_title('Step 2: Brightness', size=15);\n",
        "        \n",
        "        # adjust contrast\n",
        "        ax = fig.add_subplot(1, 5, 4)\n",
        "        img_contrast = tf.image.adjust_contrast(img_bright, contrast_factor=3)\n",
        "        ax.imshow(array_to_img(img_contrast))\n",
        "        pf = Polygon(((80, 80), (144, 80), (144, 144), (80, 144)),\n",
        "                fc = (0.0, 0.0, 0.0, 0.0), \n",
        "                ec = (0.0, 0.9, 0.0 ,0.9), lw=4, linestyle='--')\n",
        "        pf.set_edgecolor('r')\n",
        "        ax.add_patch(pf)\n",
        "        ax.set_title('Step 3: Contrast', size=15);\n",
        "        \n",
        "        # flip left right\n",
        "        ax = fig.add_subplot(1, 5, 5)\n",
        "        img_flip = tf.image.flip_left_right(img_contrast)\n",
        "        ax.imshow(array_to_img(img_flip))\n",
        "        pf = Polygon(((80, 80), (144, 80), (144, 144), (80, 144)),\n",
        "                fc = (0.0, 0.0, 0.0, 0.0), \n",
        "                ec = (0.0, 0.9, 0.0 ,0.9), lw=4, linestyle='--')\n",
        "        pf.set_edgecolor('r')\n",
        "        ax.add_patch(pf)\n",
        "        ax.set_title('Step 4: Flip left right');\n",
        "\n",
        "    def get_id_and_label_list(self, file_path, file_extension):\n",
        "        \"\"\"\n",
        "        This function gets the imgae id and corresponding label.\n",
        "        \"\"\"\n",
        "        file_list = []\n",
        "        for file_name in glob.glob(file_path + '*' + file_extension):\n",
        "            file_list.append(file_name)\n",
        "        return file_list\n",
        "\n",
        "    def compute_mean_and_std(self, image_file_list, r_mid_pos = 48, c_mid_pos = 48):\n",
        "        \"\"\"\n",
        "        This method computes mean and std at the center of the image.\n",
        "        \"\"\"\n",
        "        center_pixel_value_list = []\n",
        "        for image_file in image_file_list:\n",
        "            image = skio.imread(image_file, plugin = \"tifffile\")\n",
        "            center_pixel_value_list.append(image[r_mid_pos, c_mid_pos])\n",
        "        np_array_center_pixel_value = np.array(center_pixel_value_list)\n",
        "        return np.mean(np_array_center_pixel_value), np.std(np_array_center_pixel_value)\n",
        "\n",
        "    def copy_file_from_one_to_other(self, file_names, dest_path):\n",
        "        \"This method moves chunks of files in one to other.\"\n",
        "        os.system('cp -r ' + file_names + ' ' + dest_path)\n",
        "\n",
        "    def process_copy_files(self, file_name_list, dest_path):\n",
        "        \"\"\"\"\n",
        "        This method processes moving files from one dir to the other. \n",
        "        This is the master process to run actual moving in chunks.\n",
        "        \"\"\"\n",
        "        '''\n",
        "        process_chunk_size = 100\n",
        "        for idx in range(0, len(file_name_list), process_chunk_size):\n",
        "            if idx % 10000 == 0:\n",
        "                print(\"Processing index: \", idx)\n",
        "            self.copy_file_from_one_to_other(' '.join(file_name_list[idx : idx + process_chunk_size]), dest_path)\n",
        "        '''\n",
        "        for file in file_name_list:\n",
        "            shutil.copy(file, dest_path)\n",
        "    \n",
        "    def check_file_count_in_a_directory(self, dir_path):\n",
        "        \"\"\"\n",
        "        This method checks the file count in a directory\n",
        "        \"\"\"\n",
        "        cmd_string = 'ls ' + dir_path + \" | wc -l\"\n",
        "        file_count = int(subprocess.check_output(cmd_string, shell=True, text=True).strip())\n",
        "        return file_count\n",
        "\n",
        "    def get_mini_batch_data(self, image_list, mini_batch_size):\n",
        "        \"\"\"\n",
        "        This method performs as a generator to spit out data in small batches.\n",
        "        \"\"\"\n",
        "        return (image_list[idx : idx + mini_batch_size] for idx in range(0, len(image_list), mini_batch_size))\n",
        "\n",
        "    def get_aug_step_list(self):\n",
        "        \"\"\"\n",
        "        This method executes image augmentation pipeline.\n",
        "        \"\"\"\n",
        "        sometimes = lambda aug: img_aug.Sometimes(0.5, aug)\n",
        "        img_aug_seq = img_aug.Sequential(\n",
        "        [\n",
        "            # apply the following augmenters to most images\n",
        "            img_aug.Fliplr(0.5), # horizontally flip 50% of all images\n",
        "            img_aug.Flipud(0.2), # vertically flip 20% of all images\n",
        "            sometimes(img_aug.Affine(\n",
        "                scale={\"x\": (0.9, 1.1), \"y\": (0.9, 1.1)}, # scale images to 80-120% of their size, individually per axis\n",
        "                translate_percent={\"x\": (-0.1, 0.1), \"y\": (-0.1, 0.1)}, # translate by -20 to +20 percent (per axis)\n",
        "                rotate=(-10, 10), # rotate by -45 to +45 degrees\n",
        "                shear=(-5, 5), # shear by -16 to +16 degrees\n",
        "                order=[0, 1], # use nearest neighbour or bilinear interpolation (fast)\n",
        "                cval=(0, 255), # if mode is constant, use a cval between 0 and 255\n",
        "                mode=iaug.ALL # use any of scikit-image's warping modes (see 2nd image from the top for examples)\n",
        "            )),\n",
        "            # execute 0 to 5 of the following (less important) augmenters per image\n",
        "            # don't execute all of them, as that would often be way too strong\n",
        "            img_aug.SomeOf((0, 5),\n",
        "                [\n",
        "                    sometimes(img_aug.Superpixels(p_replace=(0, 1.0), n_segments=(20, 200))), # convert images into their superpixel representation\n",
        "                    img_aug.OneOf([\n",
        "                        img_aug.GaussianBlur((0, 1.0)), # blur images with a sigma between 0 and 3.0\n",
        "                        img_aug.AverageBlur(k=(3, 5)), # blur image using local means with kernel sizes between 2 and 7\n",
        "                        img_aug.MedianBlur(k=(3, 5)), # blur image using local medians with kernel sizes between 2 and 7\n",
        "                    ]),\n",
        "                    img_aug.Sharpen(alpha=(0, 1.0), lightness=(0.9, 1.1)), # sharpen images\n",
        "                    img_aug.Emboss(alpha=(0, 1.0), strength=(0, 2.0)), # emboss images\n",
        "                    # search either for all edges or for directed edges,\n",
        "                    # blend the result with the original image using a blobby mask\n",
        "                    img_aug.SimplexNoiseAlpha(img_aug.OneOf([\n",
        "                        img_aug.EdgeDetect(alpha=(0.5, 1.0)),\n",
        "                        img_aug.DirectedEdgeDetect(alpha=(0.5, 1.0), direction=(0.0, 1.0)),\n",
        "                    ])),\n",
        "                    img_aug.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.01*255), per_channel=0.5), # add gaussian noise to images\n",
        "                    img_aug.OneOf([\n",
        "                        img_aug.Dropout((0.01, 0.05), per_channel=0.5), # randomly remove up to 10% of the pixels\n",
        "                        img_aug.CoarseDropout((0.01, 0.03), size_percent=(0.01, 0.02), per_channel=0.2),\n",
        "                    ]),\n",
        "                    img_aug.Invert(0.01, per_channel=True), # invert color channels\n",
        "                    img_aug.Add((-2, 2), per_channel=0.5), # change brightness of images (by -10 to 10 of original value)\n",
        "                    img_aug.AddToHueAndSaturation((-1, 1)), # change hue and saturation\n",
        "                    # either change the brightness of the whole image (sometimes\n",
        "                    # per channel) or change the brightness of subareas\n",
        "                    img_aug.OneOf([\n",
        "                        img_aug.Multiply((0.9, 1.1), per_channel=0.5),\n",
        "                        img_aug.FrequencyNoiseAlpha(\n",
        "                            exponent=(-1, 0),\n",
        "                            first=img_aug.Multiply((0.9, 1.1), per_channel=True),\n",
        "                            second=img_aug.ContrastNormalization((0.9, 1.1))\n",
        "                        )\n",
        "                    ]),\n",
        "                    sometimes(img_aug.ElasticTransformation(alpha=(0.5, 3.5), sigma=0.25)), # move pixels locally around (with random strengths)\n",
        "                    sometimes(img_aug.PiecewiseAffine(scale=(0.01, 0.05))), # sometimes move parts of the image around\n",
        "                    sometimes(img_aug.PerspectiveTransform(scale=(0.01, 0.1)))\n",
        "                ],\n",
        "                random_order=True\n",
        "            )\n",
        "        ],\n",
        "        random_order=True\n",
        "        )\n",
        "        return img_aug_seq\n",
        "\n",
        "    def get_id_label_map(self, df, filter_list):\n",
        "        \"\"\"\n",
        "        This method generates the id and label dictionary.\n",
        "        \"\"\"\n",
        "        return {k : v for k, v in zip(df[df.id.isin(filter_list)].id.values, \n",
        "                                      df[df.id.isin(filter_list)].label.values\n",
        "                                     )\n",
        "               }\n",
        "\n",
        "    def image_data_generator(self, list_files, label_list, batch_size, augment=False):\n",
        "        \"\"\"\n",
        "        This method is a generrator function to produce mini batch of data.\n",
        "        \"\"\"\n",
        "        image_augmentation_steps = self.get_aug_step_list()\n",
        "        while True:\n",
        "            shuffle(list_files)\n",
        "            for mini_batch in self.get_mini_batch_data(list_files, batch_size):\n",
        "                X = [cv2.imread(x) for x in mini_batch]\n",
        "                y = label_list\n",
        "                if augment:\n",
        "                    aug_X = image_augmentation_steps.augment_images(X)\n",
        "                    aug_y = y\n",
        "                    X = X + aug_X\n",
        "                X = [preprocess_input(x) for x in X]\n",
        "                \n",
        "        yield np.array(X), np.array(y)\n",
        "\n",
        "misc_proc = misc_processing()\n",
        "misc_proc.create_dir_structure(cfg_proc.root_directory)"
      ],
      "metadata": {
        "id": "KMaqq9V4toXo"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***G. Visualization Processing Class***"
      ],
      "metadata": {
        "id": "jStvd4wGp8Ju"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class data_viz_processing:\n",
        "    \"\"\"\n",
        "    This class contains methods to display various plots.\n",
        "    \"\"\"\n",
        "    def count_plot(self, data, label_col, title_val):\n",
        "        \"\"\"\n",
        "        This method plots count plot of the input data set.\n",
        "        \"\"\"\n",
        "        sns.countplot(data = data, x = label_col)\n",
        "        plt.title(title_val)\n",
        "        plt.show(block = False)\n",
        "\n",
        "    def pie_chart_plot(self, data, label_col, title_val):\n",
        "        \"\"\"\n",
        "        This method plots pie chart based on the given data.\n",
        "        \"\"\"\n",
        "        fig = px.pie(data, \n",
        "                     values = data[label_col].value_counts().values, \n",
        "                     names = data[label_col].unique())\n",
        "        fig.update_layout(\n",
        "                      title={\n",
        "                             'text'    : title_val,\n",
        "                             'y'       : .99,\n",
        "                             'x'       :  0.5,\n",
        "                             'xanchor' : 'center',\n",
        "                             'yanchor' : 'top'\n",
        "                            }\n",
        "                          )\n",
        "        fig.show()\n",
        "        plt.show(block = False)\n",
        "\n",
        "data_viz = data_viz_processing()"
      ],
      "metadata": {
        "id": "myB5dDG2qBTr"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***H. Image Processing Class***"
      ],
      "metadata": {
        "id": "i2353h6hNEnz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class image_processing:\n",
        "    \"\"\"\n",
        "    This class contains methods for image processing.\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        None\n",
        "    \n",
        "    def read_image_file_in_np_array(self, image_list):\n",
        "        \"\"\"\n",
        "        This method reads each image file in a Numpy array and returns it.\n",
        "        \"\"\"\n",
        "        return np.asarray([skio.imread(image_file, plugin = \"tifffile\") for image_file in image_list])\n",
        "    \n",
        "    def convert_np_array_to_tensor(self, np_image_array):\n",
        "        \"\"\"\n",
        "        This method converts the numpy array representation of each image in tensor.\n",
        "        \"\"\"\n",
        "        return tf.convert_to_tensor(np_image_array, dtype = tf.float32)\n",
        "\n",
        "    def convert_int_tf_to_float(self, tf_image_list):\n",
        "        \"\"\"\n",
        "        This method converts integer TF value to float.\n",
        "        \"\"\"\n",
        "        return np.asanyarray([tf.cast(img, tf.float32) for img in tf_image_list])\n",
        "    \n",
        "    def convert_from_rgb_to_grayscale(self, tf_image_list, large_list_ind = False):\n",
        "        \"\"\"\n",
        "        This method converts color image to grayscale.\n",
        "        \"\"\"\n",
        "        if large_list_ind == False:\n",
        "            return tf.image.rgb_to_grayscale(tf_image_list) / 255.0\n",
        "        else:\n",
        "            None\n",
        "    \n",
        "    def combine_train_val(self, x_train, X_val, y_train, y_val):\n",
        "        \"\"\"\n",
        "        This method combines train and validation data, shuffles them and \n",
        "        returns back suffled data for k-fold cross validation.\n",
        "        \"\"\"\n",
        "        X_train_kfold = tf.concat([X_train, X_val] , axis = 0)\n",
        "        y_train_kfold = tf.concat([y_train, y_val] , axis = 0)\n",
        "\n",
        "        print(\"Shuffling the kfold train data...\")\n",
        "        tf.random.set_seed(1234) # for reproducibility\n",
        "    \n",
        "        test_shuffle_indices = tf.random.shuffle(tf.range(tf.shape(X_train_kfold)[0], dtype = tf.int32))\n",
        "        X_train_kfold = tf.gather(X_train_kfold, test_shuffle_indices)\n",
        "        y_train_kfold = tf.gather(y_train_kfold, test_shuffle_indices).numpy()\n",
        "        \n",
        "        print(f\"X_train_kfold shape: {X_train_kfold.shape}\")\n",
        "        print(f\"y_train_kfold shape: {y_train_kfold.shape}\")\n",
        "\n",
        "    def adjust_brightness(self, tf_image_list, delta):\n",
        "        \"\"\"\n",
        "        This method adjusts the image brightness.\n",
        "        \"\"\"\n",
        "        return tf.image.adjust_brightness(tf_image_list, delta = delta)\n",
        "\n",
        "    def adjust_random_brightness(self, tf_image_list, max_delta = .3, seed = (1,2)):\n",
        "        \"\"\"\n",
        "        This method adjusts random image brightness.\n",
        "        \"\"\"\n",
        "        return tf.image.stateless_random_brightness(tf_image_list, max_delta = max_delta, seed = seed)\n",
        "\n",
        "    def adjust_contrast(self, tf_image_list, contrast_factor):\n",
        "        \"\"\"\n",
        "        This method adjusts contrast of the image.\n",
        "        \"\"\"\n",
        "        return tf.image.adjust_contrast(tf_image_list, contrast_factor = contrast_factor)\n",
        "\n",
        "    def adjust_random_contrast(self, contrast_factor, lower = .2, upper = .5, seed = (1,2)):\n",
        "        \"\"\"\n",
        "        This method randomly contrasts images during training.\n",
        "        \"\"\"\n",
        "        return tf.image.stateless_random_contrast(contrast_factor, lower, upper, seed)\n",
        "\n",
        "    def flip_left_right(self, tf_image_list):\n",
        "        \"\"\"\n",
        "        This method applies flips the image from left to right.\n",
        "        \"\"\"\n",
        "        return tf.image.flip_left_right(tf_image_list)\n",
        "\n",
        "    def random_flip_left_right(self, tf_image_list, seed = (1,2)):\n",
        "        \"\"\"\n",
        "        This method randomly flips images left-right during training.\n",
        "        \"\"\"\n",
        "        return tf.image.stateless_random_flip_left_right(tf_image_list, seed)\n",
        "\n",
        "    def flip_up_down(self, tf_image_list):\n",
        "        \"\"\"\n",
        "        This method flips the image up-down.\n",
        "        \"\"\"\n",
        "        return tf.image.flip_up_down(tf_image_list)\n",
        "    \n",
        "    def random_flip_up_down(self, tf_image_list, seed = (1,2)):\n",
        "        \"\"\"\n",
        "        This method flips the image up-down.\n",
        "        \"\"\"\n",
        "        return tf.image.stateless_random_flip_up_down(tf_image_list, seed)\n",
        "\n",
        "    def rotate_image_by_90_or_180_or_270_deg(self, tf_image_list, k = 1):\n",
        "        \"\"\"\n",
        "        This method rotates images by 90/180/270 degrees.\n",
        "        k = 1 : 90 degree rotation\n",
        "        k = 2 : 180 degree rotation\n",
        "        k = 3 : 270 degree rotation\n",
        "        \"\"\"\n",
        "        return tf.image.rot90(tf_image_list, k)\n",
        "\n",
        "    def rotate_image_by_angle(self, tf_image_list, angle = tf.constant(np.pi/8)):\n",
        "        \"\"\"\n",
        "        This method rotates images by a given angle.\n",
        "        \"\"\"\n",
        "        rotate_layer = tf.keras.layers.RandomRotation(0.2)\n",
        "        rotated_image = rotate_layer(tf_image_list) \n",
        "        return rotated_image    \n",
        "    \n",
        "    def random_zoom(self, tf_image_list):\n",
        "        \"\"\"\n",
        "        This method zooms the image.\n",
        "        \"\"\"\n",
        "        zoom_layer = tf.keras.layers.RandomZoom(.5, .2)\n",
        "        zoomed_image = zoom_layer(tf_image_list) \n",
        "        return zoomed_image\n",
        "\n",
        "    def random_crop(self, tf_image_list, crop_height = 16, crop_width = 16):\n",
        "        \"\"\"\n",
        "        This method randomly crops the image.\n",
        "        \"\"\"\n",
        "        crop_layer = tf.keras.layers.RandomCrop(crop_height, crop_width)\n",
        "        cropped_image = crop_layer(tf_image_list) \n",
        "        return cropped_image\n",
        "\n",
        "    def resize_with_crop_or_pad(self, tf_image_list, crop_height = 32, crop_width = 32):\n",
        "        \"\"\"\n",
        "        This method crops and resizes the central part of the image.\n",
        "        \"\"\"\n",
        "        cropped_image = tf.image.resize_with_crop_or_pad(tf_image_list, crop_height, crop_width)\n",
        "        resized_image = tf.image.resize(cropped_image, [96, 96])\n",
        "        return resized_image\n",
        "\n",
        "    def image_augmentation_pipeline(self, train_image_list, test_image_list, validation_image_list):\n",
        "        \"\"\"\n",
        "        This method executes image augmentation tasks.\n",
        "        \"\"\"\n",
        "        for img_aug_func in grayscale_image_augmentation_list:\n",
        "            \n",
        "            print(\"Image augmentation function : \", img_aug_func)\n",
        "            \n",
        "            if img_aug_func == 'adjust_random_brightness':\n",
        "      \n",
        "                print(\"Handling random brightness adjustment for train_image_list\")\n",
        "                train_image_aug_list = self.adjust_random_brightness(tf_image_list = train_image_list, \n",
        "                                                                     max_delta = np.round(random.uniform(.1, .5),1)\n",
        "                                                                    )\n",
        "                gc.collect()\n",
        "                tf.keras.backend.clear_session()\n",
        "                print(f\"Shape of train_image_aug_list : {train_image_aug_list.shape}\")\n",
        "\n",
        "            elif img_aug_func == 'adjust_random_contrast':\n",
        "      \n",
        "                print(\"Handling contrast adjustment for X_train_positive_aug_tf\")\n",
        "                train_image_aug_list = self.adjust_random_contrast(tf_image_list = train_image_aug_list, \n",
        "                                                                   lower = np.round(random.uniform(.1, .3),1), \n",
        "                                                                   upper = np.round(random.uniform(.4, .6),1)\n",
        "                                                                  )\n",
        "                gc.collect()\n",
        "                tf.keras.backend.clear_session()\n",
        "                print(f\"Shape of train_image_aug_list : {train_image_aug_list.shape}\")\n",
        "\n",
        "            elif img_aug_func == 'random_flip_left_right':\n",
        "                \n",
        "                print(\"Handling random flip left and right for train_image_list\")\n",
        "                train_image_aug_list = self.random_flip_left_right(tf_image_list = train_image_aug_list)\n",
        "                gc.collect()\n",
        "                print(f\"Shape of X_train_positive_aug_tf : {train_image_aug_list.shape}\")\n",
        "\n",
        "            elif img_aug_func == 'random_flip_up_down':\n",
        "\n",
        "                print(\"Handling random flip up and down for train_image_list\")\n",
        "                train_image_aug_list = self.random_flip_up_down(tf_image_list = train_image_aug_list)\n",
        "                gc.collect()\n",
        "                tf.keras.backend.clear_session()\n",
        "                print(f\"Shape of X_train_positive_aug_tf : {train_image_aug_list.shape}\")\n",
        "\n",
        "            elif img_aug_func == 'rotate_image_by_angle':\n",
        "                \n",
        "                print(\"Handling image rotation by an angle for train_image_list\")\n",
        "                train_image_aug_list = self.rotate_image_by_angle(tf_image_list = train_image_aug_list)\n",
        "                gc.collect()\n",
        "                tf.keras.backend.clear_session()\n",
        "                print(f\"Shape of X_train_positive_aug_tf : {train_image_aug_list.shape}\")\n",
        "            \n",
        "            elif img_aug_func == 'rotate_image_by_90_or_180_or_270_deg':\n",
        "\n",
        "                print(\"Handling image rotation by 90 deg angle for train_image_list\")\n",
        "                train_image_aug_list = self.rotate_image_by_90_or_180_or_270_deg(tf_image_list = train_image_aug_list, \n",
        "                                                                                 k = random.randrange(1, 3)\n",
        "                                                                                )\n",
        "                gc.collect()\n",
        "                print(f\"Shape of X_train_positive_aug_tf : {train_image_aug_list.shape}\")\n",
        "\n",
        "            elif img_aug_func == 'random_zoom':\n",
        "\n",
        "                print(\"Handling random zoom for X_train_positive_aug_tf\")\n",
        "                train_image_aug_list = self.random_zoom(tf_image_list = train_image_aug_list)\n",
        "                gc.collect()\n",
        "                tf.keras.backend.clear_session()\n",
        "                print(f\"Shape of X_train_positive_aug_tf : {train_image_aug_list.shape}\")\n",
        "        \n",
        "            elif img_aug_func == 'resize_with_crop_or_pad':\n",
        "\n",
        "                print(\"Handling resize with crop or pad for train_image_list\")\n",
        "                train_image_aug_list = self.resize_with_crop_or_pad(tf_image_list = train_image_aug_list)\n",
        "                gc.collect()\n",
        "                print(f\"Shape of X_train_positive_aug_tf : {train_image_aug_list.shape}\")\n",
        "        \n",
        "        return train_image_aug_list\n",
        "\n",
        "img_proc = image_processing()"
      ],
      "metadata": {
        "id": "o4VmIP_cNQCS"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***I. Misclenious Model Building, Metric Reporting and Plotting Class***"
      ],
      "metadata": {
        "id": "GSEWn5BEN1Sz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class misc_model_functionality_processing:\n",
        "    \"\"\"\n",
        "    This class contains misclenious methods, required for model KPI or model plotting.\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        tf.random.set_seed(cfg_proc.random_state)\n",
        "        np.random.seed(cfg_proc.random_state)\n",
        "        tf.keras.backend.clear_session()\n",
        "\n",
        "    def model_summary_and_display_structure(self, model):\n",
        "        \"\"\"\n",
        "        This method shows model summary and displays the model structure.\n",
        "        \"\"\"\n",
        "        model.summary()\n",
        "        tf.keras.utils.plot_model(model)\n",
        "        plt.show(block = False)\n",
        "\n",
        "    def model_save(self, model, model_name):\n",
        "        \"\"\"\n",
        "        This method saves the model in a h5 file.\n",
        "        \"\"\"\n",
        "        tf.keras.backend.clear_session()\n",
        "        model.save(model_name + '.h5')\n",
        "    \n",
        "    def model_evaluation(self, model, X_test, y_test):\n",
        "        \"\"\"\n",
        "        This method evaluates the test data for a given model.\n",
        "        \"\"\"\n",
        "        self.test_results = model.evaluate(X_test, y_test)\n",
        "        print('\\nTest Loss : {:.2f}%'.format(self.test_results[0] * 100))\n",
        "        print('\\nTest Accuracy :  {:.2f}%'.format(self.test_results[1] * 100))\n",
        "\n",
        "    def model_prediction(self, model, X_test):\n",
        "        \"\"\"\n",
        "        This method predicts for a given model.\n",
        "        \"\"\"\n",
        "        # transform logits to probabilities\n",
        "        self.pred_logits = model.predict(X_test)\n",
        "        self.probas = tf.sigmoid(self.pred_logits)\n",
        "        self.probas = self.probas.numpy().flatten() * 100\n",
        "\n",
        "    def plot_model_accuracy_and_loss(self, history, model_name):\n",
        "        \"\"\"\n",
        "        This method plots model training and validation accuracies.\n",
        "        \"\"\"\n",
        "        tf.keras.backend.clear_session()\n",
        "\n",
        "        hist = history.history\n",
        "        x_arr = np.arange(len(hist['loss'])) + 1\n",
        "        \n",
        "        fig = plt.figure(figsize=(12, 4))\n",
        "        ax = fig.add_subplot(1, 2, 1)\n",
        "        ax.plot(x_arr, hist['loss'], '-o', label = 'Train loss')\n",
        "        ax.plot(x_arr, hist['val_loss'], '--<', label = 'Validation loss')\n",
        "        ax.legend(fontsize=15)\n",
        "        ax.set_xlabel('Epoch', size = 15)\n",
        "        ax.set_ylabel('Loss', size = 15)\n",
        "\n",
        "        ax = fig.add_subplot(1, 2, 2)\n",
        "        ax.plot(x_arr, hist['accuracy'], '-o', label = 'Train acc.')\n",
        "        ax.plot(x_arr, hist['val_accuracy'], '--<', label = 'Validation acc.')\n",
        "        ax.legend(fontsize = 15)\n",
        "        ax.set_xlabel('Epoch', size = 15)\n",
        "        ax.set_ylabel('Accuracy', size = 15)\n",
        "        ax.set_ylim(0,1)\n",
        "        plt.title(f\"Training and validation loss and accuracies for model : {model_name}\")\n",
        "        plt.show(block = False)\n",
        "\n",
        "    def build_pretained_model(self, model_name):\n",
        "        \"\"\"\n",
        "        This function utilizes transfer learning of a given model.\n",
        "        \"\"\"\n",
        "        tf.random.set_seed(random_state)\n",
        "        np.random.seed(random_state)\n",
        "        tf.keras.backend.clear_session()\n",
        "        input_shape = (image_size, image_size, 3)\n",
        "        if model_name == 'VGG19':\n",
        "            pretrained_model = VGG19(weights = 'imagenet', include_top = False, input_shape = input_shape)\n",
        "        elif model_name == 'DenseNet201':\n",
        "            pretrained_model = tf.keras.applications.densenet.DenseNet201(weights = 'imagenet', include_top = False, input_shape = input_shape)\n",
        "        elif model_name == 'ResNet50':\n",
        "            pretrained_model = tf.keras.applications.resnet50.ResNet50(weights = 'imagenet', include_top = False, input_shape = input_shape)\n",
        "        elif model_name == 'VGG16':\n",
        "            pretrained_model = VGG16(weights = 'imagenet', include_top = False, input_shape = input_shape)\n",
        "        elif model_name == 'EfficientNetB7':\n",
        "            pretrained_model = tf.keras.applications.efficientnet.EfficientNetB7(weights = 'imagenet', include_top = False, input_shape = input_shape)\n",
        "        elif model_name == 'MobileNet':\n",
        "            pretrained_model = tf.keras.applications.MobileNet(weights = 'imagenet', include_top = False, input_shape = input_shape)\n",
        "        elif model_name == 'Xception':\n",
        "            pretrained_model = tf.keras.applications.Xception(weights = 'imagenet', include_top = False, input_shape = input_shape)\n",
        "        elif model_name == 'InceptionV3':\n",
        "            pretrained_model = tf.keras.applications.InceptionV3(weights = 'imagenet', include_top = False, input_shape = input_shape)\n",
        "        self.model_summary_and_display_structure(pretrained_model)\n",
        "        return pretrained_model\n",
        "\n",
        "    def model_plot_test_vs_predicted(self, X_test, y_test, y_pred):\n",
        "        \"\"\"\n",
        "        This method plots actual vs prected results against each images.\n",
        "        \"\"\"\n",
        "        # plot test data and associated predicred\n",
        "        fig = plt.figure(figsize=(20, 20))\n",
        "        \n",
        "        for j, example in enumerate(X_test[:20]):\n",
        "            ax = fig.add_subplot(8, 4, j+1)\n",
        "            ax.set_xticks([])\n",
        "            ax.set_yticks([])\n",
        "            ax.imshow(array_to_img(example))\n",
        "            if y_test[j]==0:\n",
        "                true_label = 'No Cancer'\n",
        "            else:\n",
        "                true_label = 'Cancer'\n",
        "    \n",
        "            ax.text(\n",
        "                0.5, -0.15, \n",
        "                'True Label: {:s}\\nPr(Cancer)={:.0f}%'.format(y_test, self.probas[j]), \n",
        "                size = 16, \n",
        "                color = 'grey',\n",
        "                horizontalalignment = 'center',\n",
        "                verticalalignment = 'center', \n",
        "                transform = ax.transAxes)\n",
        "    \n",
        "        plt.tight_layout()\n",
        "        plt.show(block = False)\n",
        "    \n",
        "    def plot_model_result_confusion_matrix(self, threshold_val, y_pred_probas, y_test):\n",
        "        \"\"\"\n",
        "        This method plots confusion matrix.\n",
        "        \"\"\"\n",
        "        predictions_val = [1 if x > threshold_val else 0 for x in y_pred_probas]\n",
        "        #print(\"a\")\n",
        "        model_confusion_matrix = confusion_matrix(y_test, predictions_val)\n",
        "        print('True Negatives: ', model_confusion_matrix[0][0])\n",
        "        print('False Positives: ', model_confusion_matrix[0][1])\n",
        "        print('False Negatives: ', model_confusion_matrix[1][0])\n",
        "        print('True Positives: ', model_confusion_matrix[1][1])\n",
        "        print('Total : ', np.sum(model_confusion_matrix[1]))\n",
        "        #print(\"b\")\n",
        "        #plot_confusion_matrix(y_pred_probas, ['Cancer', 'No Cancer'])\n",
        "        print('ROC AUC Score = ', roc_auc_score(y_test, predictions_val))\n",
        "        #print(\"c\")\n",
        "        fig, ax = plot_confusion_matrix(conf_mat = model_confusion_matrix,\n",
        "                                       show_absolute = True,\n",
        "                                       show_normed = True,\n",
        "                                       colorbar = True,\n",
        "                                       cmap = 'Dark2')\n",
        "        plt.title(f'Confusion matrix with threshold {threshold_val}')\n",
        "        plt.ylabel('Actual label')\n",
        "        plt.xlabel('Predicted label')\n",
        "        plt.show(block = False)\n",
        "\n",
        "    def plot_roc_auc_curve(self, y_pred_probas, y_test):\n",
        "        \"\"\"\n",
        "        This method plots ROC AUC Curve.\n",
        "        \"\"\"\n",
        "        #predictions_val = [1 if x > threshold_val else 0 for x in y_pred_probas]\n",
        "        fpr, tpr, thresholds = roc_curve(y_test, \n",
        "                                         y_pred_probas\n",
        "                                        )\n",
        "        auc_val = auc(fpr, tpr)\n",
        "        \n",
        "        plt.figure(1)\n",
        "        plt.plot([0, 1], [0, 1], 'k--')\n",
        "        plt.plot(fpr, tpr, label='area = {:.2f}'.format(auc_val))\n",
        "        plt.xlabel('False positive rate')\n",
        "        plt.ylabel('True positive rate')\n",
        "        plt.title('ROC Curve')\n",
        "        plt.legend(loc = 'best')\n",
        "        plt.show(block = False)\n",
        "\n",
        "    def generate_report(self, threshold_val, y_pred_probas, y_test):\n",
        "        \"\"\"\n",
        "        This method generates model performance report.\n",
        "        \"\"\"\n",
        "        predictions_val = [1 if x > threshold_val else 0 for x in y_pred_probas]\n",
        "        model_report = classification_report(y_test, \n",
        "                                             predictions_val, \n",
        "                                             target_names = ['No Cancer', \n",
        "                                                             'Cancer'\n",
        "                                                            ]\n",
        "                                                )\n",
        "        print(f\"Classification report with threshold value {threshold_val}\")\n",
        "        print(model_report)\n",
        "\n",
        "    def ensemble_across_model_kfolds(self, df):\n",
        "        \"\"\"\n",
        "        This method performs ensemble method across model and all kfolds\n",
        "        using majority voting.\n",
        "        \"\"\"\n",
        "        df_kfold_ensemble_stats = df.groupby(['model', 'output_pos']).agg({'pred_bin' : [stats.mode], \n",
        "                                                                           'pred_pct' : [np.mean, np.min, np.max]}).reset_index()\n",
        "        df_kfold_ensemble_stats.columns = ['model', 'output_pos', 'majority_pred_bin', 'avg_pred_pct', 'min_pred_pct', 'max_pred_pct']\n",
        "        df_kfold_ensemble_stats[['majority_class_value', 'majority_count']] = pd.DataFrame(df_kfold_ensemble_stats['majority_pred_bin'].tolist(), \n",
        "                                                                                           index = df_kfold_ensemble_stats.index)\n",
        "        df_kfold_ensemble_stats['majority_class_value'] = df_kfold_ensemble_stats['majority_class_value'].apply(lambda x : x[0])\n",
        "        df_kfold_ensemble_stats['majority_count'] = df_kfold_ensemble_stats['majority_count'].apply(lambda x : x[0])\n",
        "        df_kfold_ensemble_stats['fmt_majority_class_value'] = np.where(df_kfold_ensemble_stats['majority_count'] == 2, \n",
        "                                                                       1, \n",
        "                                                                       df_kfold_ensemble_stats['majority_class_value'])\n",
        "        \n",
        "        # assigning back the actual value corresponding to output_pos\n",
        "        df_kfold_ensemble_stats['actual'] = df_kfold_ensemble_stats['output_pos'].apply(lambda x : data_proc.y_test[x-1])\n",
        "        # majority_class_prob will be calculated based on the majority_class.\n",
        "        df_kfold_ensemble_stats['majority_class_prob'] = None\n",
        "        for index_val, rec in df_kfold_ensemble_stats.iterrows():\n",
        "            model, output_pos, majority_pred_bin = rec[0], rec[1], rec[2]\n",
        "            avg_pred_pct, min_pred_pct, max_pred_pct = rec[3], rec[4], rec[5]\n",
        "            majority_class_value = rec[6]\n",
        "            majority_count = rec[7]\n",
        "            fmt_majority_class_value = rec[8]\n",
        "            actual= rec[9]\n",
        "            majority_class_prob = np.mean(df[(df.model == model) &\n",
        "                                             (df.output_pos == output_pos) &\n",
        "                                             (df.pred_bin == fmt_majority_class_value)\n",
        "                                            ]['pred_pct'])\n",
        "            #print(model, output_pos, fmt_majority_class_value, majority_class_prob)\n",
        "            df_kfold_ensemble_stats.iloc[index_val, -1] = majority_class_prob\n",
        "\n",
        "        df_kfold_ensemble_stats.head()\n",
        "        return df_kfold_ensemble_stats\n",
        "\n",
        "    def ensemble_across_models(self, df):\n",
        "        \"\"\"\n",
        "        This method performs ensemble methods across models using majority voting.\n",
        "        \"\"\"\n",
        "        df_ensemble_stats = df.groupby(['output_pos']).agg({'pred_bin' : [stats.mode], 'pred_pct' : [np.mean, np.min, np.max]}).reset_index()\n",
        "        df_ensemble_stats.columns = ['output_pos', 'majority_pred_bin', 'avg_pred_pct', 'min_pred_pct', 'max_pred_pct']\n",
        "        df_ensemble_stats[['majority_class_value', 'majority_count']] = pd.DataFrame(df_ensemble_stats['majority_pred_bin'].tolist(), \n",
        "                                                                                     index=df_ensemble_stats.index)\n",
        "        df_ensemble_stats['majority_class_value'] = df_ensemble_stats['majority_class_value'].apply(lambda x : x[0])\n",
        "        df_ensemble_stats['majority_count'] = df_ensemble_stats['majority_count'].apply(lambda x : x[0])\n",
        "        df_ensemble_stats['fmt_majority_class_value'] = np.where(df_ensemble_stats['majority_count'] == 2, \n",
        "                                                                 1, \n",
        "                                                                 df_ensemble_stats['majority_class_value'])\n",
        "        # assigning back the actual value corresponding to output_pos\n",
        "        df_ensemble_stats['actual'] = df_ensemble_stats['output_pos'].apply(lambda x : data_proc.y_test[x-1])\n",
        "        \n",
        "        # majority_class_prob will be calculated based on the majority_class.\n",
        "        df_ensemble_stats['majority_class_prob'] = None\n",
        "        \n",
        "        for index, rec in df_ensemble_stats.iterrows():\n",
        "            output_pos, majority_pred_bin = rec[0], rec[1]\n",
        "            avg_pred_pct, min_pred_pct, max_pred_pct = rec[2], rec[3], rec[4]\n",
        "            majority_class_value = rec[5]\n",
        "            majority_count = rec[6]\n",
        "            fmt_majority_class_value = rec[7]\n",
        "            actual= rec[8]\n",
        "\n",
        "            majority_class_prob = np.mean(df_actual_vs_pred_bin_pred_pct[(df.output_pos == output_pos) &\n",
        "                                                                         (df.pred_bin == fmt_majority_class_value)\n",
        "                                                                        ]['pred_pct'])\n",
        "            #print(model, output_pos, fmt_majority_class_value, majority_class_prob)\n",
        "            df_ensemble_stats.iloc[index, -1] = majority_class_prob\n",
        "\n",
        "        \n",
        "        df_ensemble_stats.head()\n",
        "        return df_ensemble_stats\n",
        "\n",
        "    def display_model_stats_across_all_spilts(self, model_name, consolidated_df_model_kpi, df_actual_vs_pred_bin_pred_pct):\n",
        "        \"\"\"\n",
        "        This function displays model specific summary stats across all splits.\n",
        "        \"\"\"\n",
        "        # Displays test accuracy and loss across all spilts.\n",
        "        for fold_idx in range(0, number_of_splits):\n",
        "            print('------------------------------------------------------------------------')\n",
        "            accuracy = df_actual_vs_pred_bin_pred_pct[(df_actual_vs_pred_bin_pred_pct.model == model_name) & \n",
        "                                                      (df_actual_vs_pred_bin_pred_pct.kfold == fold_idx + 1)\n",
        "                                                    ]['test_accuracy'].drop_duplicates() * 100\n",
        "            loss = df_actual_vs_pred_bin_pred_pct[(df_actual_vs_pred_bin_pred_pct.model == model_name) & \n",
        "                                                  (df_actual_vs_pred_bin_pred_pct.kfold == fold_idx + 1)\n",
        "                                                ]['test_loss'].drop_duplicates()\n",
        "            print(f'> Model {model_name} : Fold: {fold_idx + 1} - Loss: {loss[0]} - Accuracy: {accuracy[0]}%')\n",
        "            print('------------------------------------------------------------------------')\n",
        "\n",
        "        # Average and std for train accuracy and loss\n",
        "        average_train_accuracy_per_fold = consolidated_df_model_kpi[(consolidated_df_model_kpi.model == model_name) & \n",
        "                                                                    (consolidated_df_model_kpi.epoch == epochs)\n",
        "                                                                   ].groupby(['model']).agg({'accuracy': np.mean}).values[0][0]\n",
        "        std_for_average_train_accuracy_per_fold = consolidated_df_model_kpi[(consolidated_df_model_kpi.model == model_name) & \n",
        "                                                                    (consolidated_df_model_kpi.epoch == epochs)\n",
        "                                                                   ].groupby(['model']).agg({'accuracy': np.std}).values[0][0]\n",
        "    \n",
        "        average_train_loss_per_fold = consolidated_df_model_kpi[(consolidated_df_model_kpi.model == model_name) & \n",
        "                                                                    (consolidated_df_model_kpi.epoch == epochs)\n",
        "                                                                   ].groupby(['model']).agg({'loss': np.mean}).values[0][0]\n",
        "        std_for_average_train_loss_per_fold = consolidated_df_model_kpi[(consolidated_df_model_kpi.model == model_name) & \n",
        "                                                                    (consolidated_df_model_kpi.epoch == epochs)\n",
        "                                                                   ].groupby(['model']).agg({'loss': np.std}).values[0][0]\n",
        "\n",
        "        # Average and std for validation accuracy and loss\n",
        "        average_validation_accuracy_per_fold = consolidated_df_model_kpi[(consolidated_df_model_kpi.model == model_name) & \n",
        "                                                                    (consolidated_df_model_kpi.epoch == epochs)\n",
        "                                                                   ].groupby(['model']).agg({'val_accuracy': np.mean}).values[0][0]\n",
        "        std_for_average_validation_accuracy_per_fold = consolidated_df_model_kpi[(consolidated_df_model_kpi.model == model_name) & \n",
        "                                                                    (consolidated_df_model_kpi.epoch == epochs)\n",
        "                                                                   ].groupby(['model']).agg({'val_accuracy': np.std}).values[0][0]\n",
        "    \n",
        "        average_validation_loss_per_fold = consolidated_df_model_kpi[(consolidated_df_model_kpi.model == model_name) & \n",
        "                                                                    (consolidated_df_model_kpi.epoch == epochs)\n",
        "                                                                   ].groupby(['model']).agg({'val_loss': np.mean}).values[0][0]\n",
        "        std_for_average_validation_loss_per_fold = consolidated_df_model_kpi[(consolidated_df_model_kpi.model == model_name) & \n",
        "                                                                    (consolidated_df_model_kpi.epoch == epochs)\n",
        "                                                                   ].groupby(['model']).agg({'val_loss': np.std}).values[0][0]\n",
        "\n",
        "        # Average and std for test accuracy and loss\n",
        "        average_test_accuracy_per_fold = np.mean(df_actual_vs_pred_bin_pred_pct[df_actual_vs_pred_bin_pred_pct.model == model_name].test_accuracy)\n",
        "        std_for_average_test_accuracy_per_fold = np.std(df_actual_vs_pred_bin_pred_pct[df_actual_vs_pred_bin_pred_pct.model == model_name].test_accuracy)\n",
        "    \n",
        "        average_test_loss_per_fold = np.mean(df_actual_vs_pred_bin_pred_pct[df_actual_vs_pred_bin_pred_pct.model == model_name].test_loss)\n",
        "        std_for_average_test_loss_per_fold = np.std(df_actual_vs_pred_bin_pred_pct[df_actual_vs_pred_bin_pred_pct.model == model_name].test_loss)\n",
        "    \n",
        "        print(f'Average train, validation and test accuracy and loss for all folds for the model : {model_name}')\n",
        "        print(f'> Train accuracy: {average_train_accuracy_per_fold} (+- {std_for_average_test_accuracy_per_fold})')\n",
        "        print(f'> Train loss: {average_train_loss_per_fold} (+- {std_for_average_train_accuracy_per_fold})')\n",
        "\n",
        "        print(f'> Validation accuracy: {average_validation_accuracy_per_fold} (+- {std_for_average_validation_accuracy_per_fold})')\n",
        "        print(f'> Validation loss: {average_validation_loss_per_fold} (+- {std_for_average_validation_loss_per_fold})')\n",
        "    \n",
        "        print(f'> Test accuracy: {average_test_accuracy_per_fold} (+- {std_for_average_test_accuracy_per_fold})')\n",
        "        print(f'> Test loss: {average_test_loss_per_fold} (+- {std_for_average_test_loss_per_fold})')\n",
        "\n",
        "model_proc = misc_model_functionality_processing()"
      ],
      "metadata": {
        "id": "HC8mI7nSOBnZ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***2. Data Processing***"
      ],
      "metadata": {
        "id": "GMct-xh6t74w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class data_processing:\n",
        "    \"\"\"\n",
        "    This class mimics the data processing pipeline.\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, run_mode):\n",
        "        self.train_file_list = []\n",
        "        self.test_file_list = []\n",
        "        self.run_mode = run_mode\n",
        "        np.random.seed(cfg_proc.random_state)\n",
        "                \n",
        "    def get_file_names_list(self):\n",
        "        \"\"\"\n",
        "    \t  This method builds the list of train and test files.\n",
        "        It also reads the original color images and save them with _gs extension \n",
        "        in the same path as the original image. The grayscale images will be \n",
        "        used for modeling whereas the color images are used for data \n",
        "        visualization purposes.\n",
        "    \t  \"\"\"\n",
        "        print()\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"Starting to build fully qualified train and test file name lists...\")\n",
        "        # Original input images are color which we will later convert to grascale.\n",
        "        self.train_file_color_list = misc_proc.get_id_and_label_list(cfg_proc.train_files_path, cfg_proc.image_file_extension)\n",
        "        self.test_file_color_list = misc_proc.get_id_and_label_list(cfg_proc.test_files_path, cfg_proc.image_file_extension)\n",
        "        self.train_file_list = []\n",
        "\n",
        "        # Loading the input images as grayscale images and saving them back with \n",
        "        # \"_gs\" extension to distinguish.\n",
        "        # We are also adding 90/180/270 deg rotation images in the train set.\n",
        "        # For modeling purpose, we will use the grayscale images and \n",
        "        # for visualization purposes we will use the original color images.\n",
        "        for image_file in self.train_file_color_list:\n",
        "\n",
        "            img_gs = load_img(image_file, color_mode = \"grayscale\")\n",
        "            img_array_gs = img_to_array(img_gs)\n",
        "            save_img(image_file.split(\".\")[0] + \n",
        "                     '_gs' + \n",
        "                     cfg_proc.image_file_extension, \n",
        "                     img_array_gs\n",
        "                    )\n",
        "            self.train_file_list.append(image_file.split(\".\")[0] + '_gs' + \n",
        "                                        cfg_proc.image_file_extension\n",
        "                                       )\n",
        "            \n",
        "        if self.run_mode == 'interim_test':\n",
        "            print(f\"Length of train_file_list : {len(self.train_file_list)}\")\n",
        "            print(f\"Length of test_file_list : {len(self.test_file_list)}\")\n",
        "        print(\"Completed building train and test file name lists...\")\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"*****************************************************\")\n",
        "        print()\n",
        "\n",
        "    def get_label_info(self):\n",
        "        \"\"\"\n",
        "    \t  This method reads the train and test label information from \n",
        "        train_labels.csv and sample_submission.csv.\n",
        "        These files have the below structure:-\n",
        "        id and label.\n",
        "        Corresponding to the train or test id, there will be an image file \n",
        "        prssent in the respective train oo test folder.\n",
        "    \t  \"\"\"\n",
        "        print()\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"Starting to get label info...\")\n",
        "        self.train_label = pd.read_csv(cfg_proc.train_label_file)\n",
        "        self.test_label = pd.read_csv(cfg_proc.test_label_file)\n",
        "        if self.run_mode == 'interim_test':\n",
        "            print(f\"Number of train labels : {len(self.train_label)}\")\n",
        "            print(f\"Number of test labels : {len(self.test_label)}\")\n",
        "\n",
        "        self.qualified_train_file_names_list = misc_proc.generate_fully_qualified_file_name_list(self.train_label.id.values.tolist())\n",
        "        self.qualified_test_file_names_list = misc_proc.generate_fully_qualified_file_name_list(self.test_label.id.values.tolist())\n",
        "        \n",
        "        self.train_label_positive = self.train_label[self.train_label['label'] == 1]\n",
        "        self.train_label_negative = self.train_label[self.train_label['label'] == 0]\n",
        "        \n",
        "        print(\"Completed getting label info...\")\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"*****************************************************\")\n",
        "        print()\n",
        "\n",
        "    def create_labels(self, train_val_test_ind, data):\n",
        "        \"\"\"\n",
        "        This method creates label of given length.\n",
        "        \"\"\"\n",
        "        print()\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"*****************************************************\")\n",
        "        print(f\"Starting to create labels for {train_val_test_ind}...\")\n",
        "        if train_val_test_ind.lower() == 'train':\n",
        "            self.y_train = np.asarray(data['label'].values.tolist())\n",
        "        elif train_val_test_ind.lower() == 'test':\n",
        "            self.y_test = np.asarray(data['label'].values.tolist())\n",
        "        elif train_val_test_ind.lower() == 'validation':\n",
        "            self.y_validation = np.asarray(data['label'].values.tolist())    \n",
        "        print(f\"Completed building labels for {train_val_test_ind}...\")\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"*****************************************************\")\n",
        "        print()\n",
        "\n",
        "    def split_data_based_on_indices(self, train_indices, validation_indices):\n",
        "        \"\"\"\n",
        "        This method splits data based on indices.\n",
        "        \"\"\"\n",
        "        print()\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"Starting to split data based on indices...\")\n",
        "        # New train and validation set and corresponding labels based on the kfold split process generated indices.\n",
        "        self.df_train = self.df_train_original.iloc[train_indices]\n",
        "        self.df_validation = self.df_train_original.iloc[validation_indices]\n",
        "        self.create_labels(train_val_test_ind = 'train', data = self.df_train)\n",
        "        self.create_labels(train_val_test_ind = 'validation', data = self.df_validation)\n",
        "        \n",
        "        if self.run_mode == 'interim_test':\n",
        "            print(f\"Length of train data : {len(self.df_train)}, length of validation data : {len(self.df_validation)}, length of test data : {len(self.df_test)}\")\n",
        "            print(f\"Length of train positive data : {len(self.df_train[self.df_train.label == 1])}, length of validation positive data : {len(self.df_validation[self.df_validation.label == 1])}, length of test positive data : {len(self.df_test[self.df_test.label == 1])}\")\n",
        "            print(f\"Length of train negative data : {len(self.df_train[self.df_train.label == 0])}, length of validation negative data : {len(self.df_validation[self.df_validation.label == 0])}, length of test negative data : {len(self.df_test[self.df_test.label == 0])}\")\n",
        "        \n",
        "        \"\"\"\n",
        "        Both df_train and df_validation have three columns id, id_gs and label.\n",
        "        id is the original color file name without extension and id_gs is the\n",
        "        grayscale file name, derived off id column along with a \"_gs\" suffix.\n",
        "        For modeling purpose, we will use the _gs file and for data visulaization\n",
        "        purposes, we will use the original color images.\n",
        "        Thus, to move the files in a different directory, we will move the \n",
        "        grayscale images.\n",
        "        \"\"\"\n",
        "\n",
        "        misc_proc.remove_files_from_dir(cfg_proc.image_processing_train_positive_path)\n",
        "        misc_proc.remove_files_from_dir(cfg_proc.image_processing_train_negative_path)\n",
        "        self.train_positive_file_list = misc_proc.generate_fully_qualified_file_name_list(self.df_train[self.df_train.label == 1].id_gs.values.tolist())\n",
        "        self.train_negative_file_list = misc_proc.generate_fully_qualified_file_name_list(self.df_train[self.df_train.label == 0].id_gs.values.tolist())\n",
        "        print(f\"Copying test_positive_file_list under {cfg_proc.image_processing_train_positive_path}\")\n",
        "        misc_proc.process_copy_files(self.train_positive_file_list, cfg_proc.image_processing_train_positive_path)\n",
        "        print(f\"Copying test_negative_file_list under {cfg_proc.image_processing_train_negative_path}\")\n",
        "        misc_proc.process_copy_files(self.train_negative_file_list, cfg_proc.image_processing_train_negative_path)\n",
        "        print(f\"File count under {cfg_proc.image_processing_train_positive_path} after moving new files is: {misc_proc.check_file_count_in_a_directory(cfg_proc.image_processing_train_positive_path)}\")\n",
        "        print(f\"File count under {cfg_proc.image_processing_train_negative_path} after moving new files is : {misc_proc.check_file_count_in_a_directory(cfg_proc.image_processing_train_negative_path)}\")\n",
        "        \n",
        "        misc_proc.remove_files_from_dir(cfg_proc.image_processing_validation_positive_path)\n",
        "        misc_proc.remove_files_from_dir(cfg_proc.image_processing_validation_negative_path)\n",
        "        self.validation_positive_file_list = misc_proc.generate_fully_qualified_file_name_list(self.df_validation[self.df_validation.label == 1].id_gs.values.tolist())\n",
        "        self.validation_negative_file_list = misc_proc.generate_fully_qualified_file_name_list(self.df_validation[self.df_validation.label == 0].id_gs.values.tolist())\n",
        "        print(f\"Copying test_positive_file_list under {cfg_proc.image_processing_validation_positive_path}\")\n",
        "        misc_proc.process_copy_files(self.validation_positive_file_list, cfg_proc.image_processing_validation_positive_path)\n",
        "        print(f\"Copying test_negative_file_list under {cfg_proc.image_processing_validation_negative_path}\")\n",
        "        misc_proc.process_copy_files(self.validation_negative_file_list, cfg_proc.image_processing_validation_negative_path)\n",
        "        print(f\"File count under {cfg_proc.image_processing_validation_positive_path} after moving new files is: {misc_proc.check_file_count_in_a_directory(cfg_proc.image_processing_validation_positive_path)}\")\n",
        "        print(f\"File count under {cfg_proc.image_processing_validation_negative_path} after moving new files is : {misc_proc.check_file_count_in_a_directory(cfg_proc.image_processing_validation_negative_path)}\")\n",
        "\n",
        "        '''\n",
        "        misc_proc.remove_files_from_dir(image_processing_test_positive_path)\n",
        "        misc_proc.remove_files_from_dir(image_processing_test_negative_path)\n",
        "        self.test_positive_file_list = misc_proc.generate_fully_qualified_file_name_list(self.df_test[self.df_test.label == 1].id_gs.values.tolist())\n",
        "        self.test_negative_file_list = misc_proc.generate_fully_qualified_file_name_list(self.df_test[self.df_test.label == 0].id_gs.values.tolist())\n",
        "        print(f\"Copying test_positive_file_list under {image_processing_test_positive_path}\")\n",
        "        misc_proc.process_copy_files(self.test_positive_file_list, image_processing_test_positive_path)\n",
        "        print(f\"Copying test_negative_file_list under {image_processing_test_negative_path}\")\n",
        "        misc_proc.process_copy_files(self.test_negative_file_list, image_processing_test_negative_path)\n",
        "        print(f\"File count under {image_processing_test_positive_path} after moving new files is: {misc_proc.check_file_count_in_a_directory(image_processing_test_positive_path)}\")\n",
        "        print(f\"File count under {image_processing_test_negative_path} after moving new files is : {misc_proc.check_file_count_in_a_directory(image_processing_test_negative_path)}\")\n",
        "        '''\n",
        "        print(\"Completed spliting the data sets based on indices...\")\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"*****************************************************\")\n",
        "        print()\n",
        "\n",
        "    def initial_split_data(self):\n",
        "        \"\"\"\n",
        "    \t  This method uses train data to split into train, validation and test sets.\n",
        "    \t  The reason we are repurposing the train set is because we do not have labels for test data.\n",
        "    \t  We also see data imbalance issue and thus we are undersampling the most populated class (negative images).\n",
        "    \t  \"\"\"\n",
        "        print()\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"Starting to split data...\")\n",
        "\n",
        "        \"\"\"\n",
        "        Extracting top sample_size records from train_label_positive and \n",
        "        train_label_negative seperately and then combine them together so \n",
        "        that distribution is uniform.\n",
        "        \"\"\"\n",
        "        self.train_label_sample_positive = self.train_label_positive.head(cfg_proc.sample_size)\n",
        "        self.train_label_sample_negative = self.train_label_negative.head(cfg_proc.sample_size)\n",
        "        self.train_label_processed = pd.concat([self.train_label_sample_negative, \n",
        "          \t                                    self.train_label_sample_positive\n",
        "        \t                                     ], \n",
        "        \t                                     axis = 0).reset_index(drop = True)\n",
        "\n",
        "        \"\"\"\n",
        "        Getting the remaining records (length of uiverse - sample size) serves\n",
        "        as test data set. We have also made sure distribution is uniform here.\n",
        "        \"\"\"\n",
        "        '''\n",
        "        remaining_length = 50 #len(self.train_label_positive) - len(self.train_label_sample_positive)\n",
        "        self.test_positive_df = self.train_label_positive[sample_size : sample_size + remaining_length]\n",
        "        self.test_negative_df = self.train_label_negative[sample_size : sample_size + remaining_length]\n",
        "        self.df_test = pd.concat([self.test_positive_df, self.test_negative_df], axis = 0).reset_index(drop = True)\n",
        "        self.df_test = shuffle(self.df_test, random_state = random_state)\n",
        "        self.create_labels(train_val_test_ind = 'test', data = self.df_test)\n",
        "        '''\n",
        "\n",
        "        # shuffle\n",
        "        self.train_label_processed = shuffle(self.train_label_processed, random_state = cfg_proc.random_state)\n",
        "        label = self.train_label_processed['label']\n",
        "        self.df_train, self.df_test = train_test_split(self.train_label_processed, \n",
        "          \t                                           test_size = 0.1, \n",
        "        \t                                             random_state =  cfg_proc.random_state, \n",
        "        \t                                             stratify = label\n",
        "        \t                                            )\n",
        "        self.create_labels(train_val_test_ind = 'train', data = self.df_train)\n",
        "        self.create_labels(train_val_test_ind = 'test', data = self.df_test)\n",
        "        self.df_train['id_gs'] = self.df_train['id'].apply(lambda x : x + '_gs')\n",
        "        self.df_test['id_gs']  = self.df_test['id'].apply(lambda x : x + '_gs')\n",
        "        self.df_train_original = copy.deepcopy(self.df_train)\n",
        "\n",
        "        \"\"\"\n",
        "        At this point, df_test has three columns id, id_gs and label.\n",
        "        id denotes original color image name without extension and id_gs is the\n",
        "        grayscale image name derived off id column data, suffixed with '_gs'\n",
        "        extension.\n",
        "        We will use grayscale images for all our training, so while moving the\n",
        "        images to appropriate directory, we need to move the grayscale images.\n",
        "        \"\"\"\n",
        "        misc_proc.create_dir_structure(root_directory = '/content/image_processing')\n",
        "        misc_proc.remove_files_from_dir(cfg_proc.image_processing_test_positive_path)\n",
        "        misc_proc.remove_files_from_dir(cfg_proc.image_processing_test_negative_path)\n",
        "        self.test_positive_file_list = misc_proc.generate_fully_qualified_file_name_list(self.df_test[self.df_test.label == 1].id_gs.values.tolist())\n",
        "        self.test_negative_file_list = misc_proc.generate_fully_qualified_file_name_list(self.df_test[self.df_test.label == 0].id_gs.values.tolist())\n",
        "        print(f\"Copying test_positive_file_list under {cfg_proc.image_processing_test_positive_path}\")\n",
        "        misc_proc.process_copy_files(self.test_positive_file_list, cfg_proc.image_processing_test_positive_path)\n",
        "        print(f\"Copying test_negative_file_list under {cfg_proc.image_processing_test_negative_path}\")\n",
        "        misc_proc.process_copy_files(self.test_negative_file_list, cfg_proc.image_processing_test_negative_path)\n",
        "        print(f\"File count under {cfg_proc.image_processing_test_positive_path} is {misc_proc.check_file_count_in_a_directory(cfg_proc.image_processing_test_positive_path)}\")\n",
        "        print(f\"File count under {cfg_proc.image_processing_test_negative_path} is {misc_proc.check_file_count_in_a_directory(cfg_proc.image_processing_test_negative_path)}\")\n",
        "\n",
        "        self.sample_positive_label = self.train_label_sample_positive['label'].values.tolist()\n",
        "        self.sample_negative_label = self.train_label_sample_negative['label'].values.tolist()\n",
        "\n",
        "        self.df_train_positive = self.df_train[self.df_train.label == 1]\n",
        "        self.df_train_negative = self.df_train[self.df_train.label == 0]\n",
        "\n",
        "        self.df_test_positive = self.df_test[self.df_test.label == 1]\n",
        "        self.df_test_negative = self.df_test[self.df_test.label == 0]\n",
        "\n",
        "        # Train color files\n",
        "        self.train_positive_color_file_list = misc_proc.generate_fully_qualified_file_name_list(self.df_train_positive.id.values.tolist())\n",
        "        self.train_negative_color_file_list = misc_proc.generate_fully_qualified_file_name_list(self.df_train_negative.id.values.tolist())\n",
        "\n",
        "        # Test color files\n",
        "        self.test_positive_color_file_list = misc_proc.generate_fully_qualified_file_name_list(self.df_test_positive.id.tolist())\n",
        "        self.test_negative_color_file_list = misc_proc.generate_fully_qualified_file_name_list(self.df_test_negative.id.tolist())\n",
        "\n",
        "        # Train grayscale files\n",
        "        self.train_positive_file_list = misc_proc.generate_fully_qualified_file_name_list(self.df_train_positive.id_gs.values.tolist())\n",
        "        self.train_negative_file_list = misc_proc.generate_fully_qualified_file_name_list(self.df_train_negative.id_gs.values.tolist())\n",
        "\n",
        "        # Test grayscale files\n",
        "        self.test_positive_file_list = misc_proc.generate_fully_qualified_file_name_list(self.df_test_positive.id_gs.tolist())\n",
        "        self.test_negative_file_list = misc_proc.generate_fully_qualified_file_name_list(self.df_test_negative.id_gs.tolist())\n",
        "\n",
        "        if self.run_mode == 'interim_test':\n",
        "            \n",
        "            print(f\"Length of df_train : {len(self.df_train)}\")\n",
        "            print(f\"Length of df_test : {len(self.df_test)}\")\n",
        "            print(f\"Length of y_train : {len(self.y_train)}\")\n",
        "            print(f\"Length of y_test : {len(self.y_test)}\")\n",
        "\n",
        "            print(\"Positive and negative images distribution in df_train\")\n",
        "            print(self.df_train['label'].value_counts())\n",
        "\n",
        "            print(\"Positive and negative images distribution in df_test\")\n",
        "            print(self.df_test['label'].value_counts())\n",
        "\n",
        "            print(f\"Length of df_train_positive : {len(self.df_train_positive)}\")\n",
        "            print(f\"Length of df_train_positive : {len(self.df_train_positive)}\")\n",
        "\n",
        "            print(f\"Length of df_test_positive : {len(self.df_test_positive)}\")\n",
        "            print(f\"Length of df_test_negative : {len(self.df_test_negative)}\")\n",
        "\n",
        "            print(f\"Length of train_positive_file_list : {len(self.train_positive_file_list)}\")\n",
        "            print(f\"Length of train_negative_file_list : {len(self.train_negative_file_list)}\")\n",
        "\n",
        "            print(f\"Length of test_positive_file_list : {len(self.test_positive_file_list)}\")\n",
        "            print(f\"Length of test_negative_file_list : {len(self.test_negative_file_list)}\")\n",
        "\n",
        "        print(\"Completed spliting the data sets...\")\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"*****************************************************\")\n",
        "        print()\n",
        "\n",
        "    def get_data_distribution(self, train_or_test_ind):\n",
        "        \"\"\"\n",
        "     \t  This method shows the distribution of positive and negative images in the data set. \n",
        "     \t  \"\"\"\n",
        "        print()\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"*****************************************************\")\n",
        "        print(f\"Starting to get data distributions for {train_or_test_ind}...\")\n",
        "        if train_or_test_ind.lower() == 'train':\n",
        "            print(\"Data distribution in the train data set\")\n",
        "            print(self.train_label['label'].value_counts())\n",
        "            data_viz.count_plot(data = self.train_label, \n",
        "                                 label_col = 'label',\n",
        "                                 title_val = \"Distribution of Labels in Train Data\"\n",
        "                                )\n",
        "            data_viz.pie_chart_plot(data = self.train_label, \n",
        "                                     label_col = 'label',\n",
        "                                     title_val = \"Train Label Percentage Pie Chart\"\n",
        "                                    )\n",
        "        elif train_or_test_ind.lower() == 'test':\n",
        "            print(\"Data distribution in the test data set\")\n",
        "            print(self.test_label['label'].value_counts())  \n",
        "            data_viz.count_plot(data = self.test_label, \n",
        "                                 label_col = 'label',\n",
        "                                 title_val = \"Distribution of Labels in Test Data\"\n",
        "                                )\n",
        "            data_viz.pie_chart_plot(data = self.test_label, \n",
        "                                     label_col = 'label',\n",
        "                                     title_val = \"Test Label Percentage Pie Chart\"\n",
        "                                    )\n",
        "        print(f\"Completed getting data distributions for {train_or_test_ind}...\")\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"*****************************************************\")\n",
        "        print()\n",
        "\n",
        "    def check_duplicate_ids(self, train_or_test_ind):\n",
        "        \"\"\"\n",
        "    \t  This method checks if there is any duplicate ids in the data set.\n",
        "    \t  \"\"\"\n",
        "        print()\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"*****************************************************\")\n",
        "        print(f\"Starting to check duplicates for {train_or_test_ind}...\")\n",
        "        if train_or_test_ind.lower() == 'train':\n",
        "            df_train_id_count = pd.DataFrame(self.train_label.groupby(['id'])['id'].count())\n",
        "            df_train_id_count.columns = ['id_count']\n",
        "            df_train_id_count.reset_index(inplace = True)\n",
        "            print(\"Number of train duplicate entries : \", len(df_train_id_count[df_train_id_count.id_count > 1]))\n",
        "        elif train_or_test_ind.lower() == 'test':\n",
        "            df_test_id_count = pd.DataFrame(self.test_label.groupby(['id'])['id'].count())\n",
        "            df_test_id_count.columns = ['id_count']\n",
        "            df_test_id_count.reset_index(inplace = True)\n",
        "            print(\"Number of test duplicate entries : \", len(df_test_id_count[df_test_id_count.id_count > 1]))\n",
        "        print(f\"Completed checking duplicates for {train_or_test_ind}...\")\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"*****************************************************\")\n",
        "        print()\n",
        "\n",
        "    def data_visualization(self, train_or_test_ind, positive_or_negative_ind, image_list, number_of_images = 5):\n",
        "        \"\"\"\n",
        "        This method visualizes the data.\n",
        "        \"\"\"\n",
        "        print()\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"*****************************************************\")\n",
        "        print(f\"Starting data visualization for {train_or_test_ind} and {positive_or_negative_ind}...\")\n",
        "        if train_or_test_ind.lower() == 'train':\n",
        "            print(f\"Displaying training {positive_or_negative_ind.lower()} images\")\n",
        "        if train_or_test_ind.lower() == 'test':\n",
        "            print(f\"Displaying test {positive_or_negative_ind.lower()} images\")\n",
        "\n",
        "        for image in image_list[:number_of_images]:\n",
        "            misc_proc.print_image_in_diff_orientation(image)\n",
        "            plt.show(block = False)\n",
        "\n",
        "        print(f\"Completed getting data visualizations for {train_or_test_ind}...\")\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"*****************************************************\")\n",
        "        print()\n",
        "\n",
        "    def get_image_summary_stats(self):\n",
        "        \"\"\"\n",
        "        This method gets positive and negative images summary stats at the picture level and each color (R, G, B) channel level.\n",
        "        \"\"\"\n",
        "        print()\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"Starting to get positive and negative images summary stats...\")\n",
        "\n",
        "        # Whole image wise stats\n",
        "        print(\"Mean and standard deviation at center for positive train images: \", misc_proc.compute_mean_and_std(self.train_positive_color_file_list))\n",
        "        print(\"Mean and standard deviation at center for negative train images: \", misc_proc.compute_mean_and_std(self.train_negative_color_file_list))\n",
        "\n",
        "        number_of_bins = 64 \n",
        "        figw, axw = plt.subplots(1,2, sharey = True, sharex = True, figsize = (8,2), dpi = 150)\n",
        "        axw[0].hist(img_proc.read_image_file_in_np_array(self.train_positive_color_file_list)[:,:,:,(0,1,2)].flatten(),\n",
        "                                                        bins = number_of_bins, \n",
        "                                                        density = True);\n",
        "        axw[1].hist(img_proc.read_image_file_in_np_array(self.train_negative_color_file_list)[:,:,:,(0,1,2)].flatten(),\n",
        "                                                        bins = number_of_bins, \n",
        "                                                        density = True);\n",
        "\n",
        "        axw[0].set_title(\"Train positive images\");\n",
        "        axw[1].set_title(\"Train negative images\");\n",
        "\n",
        "        axw[0].set_xlabel(\"Mean brightness\")\n",
        "        axw[1].set_xlabel(\"Mean brightness\")\n",
        "        axw[0].set_ylabel(\"Relative frequency\")\n",
        "        axw[1].set_ylabel(\"Relative frequency\")\n",
        "        plt.show(block = False);\n",
        "\n",
        "        # Channel wise stats\n",
        "        print(\"Average across red, green and blue channels for train positive images\")\n",
        "        print(np.mean(img_proc.read_image_file_in_np_array(self.train_positive_color_file_list), axis = (0,1,2)))\n",
        "        print(\"Standard Deviation across red, green and blue channels for Train positive images\")\n",
        "        print(np.std(img_proc.read_image_file_in_np_array(self.train_positive_color_file_list), axis = (0,1,2)))\n",
        "\n",
        "        print(\"Average across red, green and blue channels for train X_train_img_file_negative images\")\n",
        "        print(np.mean(img_proc.read_image_file_in_np_array(self.train_negative_color_file_list), axis = (0,1,2)))\n",
        "        print(\"Standard Deviation across red, green and blue channels for train X_train_img_file_negative images\")\n",
        "        print(np.std(img_proc.read_image_file_in_np_array(self.train_negative_color_file_list), axis = (0,1,2)))\n",
        "\n",
        "        # Red Channel\n",
        "        figr, axr = plt.subplots(1,2, sharey = True, sharex = True, figsize = (8,2), dpi = 150)\n",
        "        axr[0].hist(img_proc.read_image_file_in_np_array(self.train_positive_color_file_list)[:,:,:,(0)].flatten(),\n",
        "                                                        bins = number_of_bins, \n",
        "                                                        density = True);\n",
        "        axr[1].hist(img_proc.read_image_file_in_np_array(self.train_negative_color_file_list)[:,:,:,(0)].flatten(),\n",
        "                                                        bins = number_of_bins, \n",
        "                                                        density = True);\n",
        "\n",
        "        axr[0].set_title(\"Train positive images\");\n",
        "        axr[1].set_title(\"Train negative images\");\n",
        "\n",
        "        axr[0].set_xlabel(\"Mean red brightness\")\n",
        "        axr[1].set_xlabel(\"Mean red brightness\")\n",
        "        axr[0].set_ylabel(\"Relative frequency\")\n",
        "        axr[1].set_ylabel(\"Relative frequency\")\n",
        "        plt.show(block = False);\n",
        "\n",
        "        # Green Channel\n",
        "        figg, axg = plt.subplots(1,2, sharey = True, sharex = True, figsize = (8,2), dpi = 150)\n",
        "        axg[0].hist(img_proc.read_image_file_in_np_array(self.train_positive_color_file_list)[:,:,:,(1)].flatten(),\n",
        "                                                        bins = number_of_bins, \n",
        "                                                        density = True);\n",
        "        axg[1].hist(img_proc.read_image_file_in_np_array(self.train_negative_color_file_list)[:,:,:,(1)].flatten(),\n",
        "                                                        bins = number_of_bins, \n",
        "                                                        density = True);\n",
        "\n",
        "        axg[0].set_title(\"Train positive images\");\n",
        "        axg[1].set_title(\"Train negative images\");\n",
        "\n",
        "        axg[0].set_xlabel(\"Mean green brightness\")\n",
        "        axg[1].set_xlabel(\"Mean green brightness\")\n",
        "        axg[0].set_ylabel(\"Relative frequency\")\n",
        "        axg[1].set_ylabel(\"Relative frequency\")\n",
        "        plt.show(block = False);\n",
        "\n",
        "        # Blue Channel\n",
        "        figb, axb = plt.subplots(1,2, sharey = True, sharex = True, figsize = (8,2), dpi = 150)\n",
        "        axb[0].hist(img_proc.read_image_file_in_np_array(self.train_positive_color_file_list)[:,:,:,(2)].flatten(),\n",
        "                                                        bins = number_of_bins, \n",
        "                                                        density = True);\n",
        "        axb[1].hist(img_proc.read_image_file_in_np_array(self.train_negative_color_file_list)[:,:,:,(2)].flatten(),\n",
        "                                                        bins = number_of_bins, \n",
        "                                                        density = True);\n",
        "\n",
        "        axb[0].set_title(\"Train positive images\");\n",
        "        axb[1].set_title(\"Train negative images\");\n",
        "\n",
        "        axb[0].set_xlabel(\"Mean blue brightness\")\n",
        "        axb[1].set_xlabel(\"Mean blue brightness\")\n",
        "        axb[0].set_ylabel(\"Relative frequency\")\n",
        "        axb[1].set_ylabel(\"Relative frequency\")\n",
        "        plt.show(block = False);\n",
        "\n",
        "        print(f\"Completed get positive and negative images summary stats...\")\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"*****************************************************\")\n",
        "        print()\n",
        "\n",
        "    def data_processing_pipeline(self):\n",
        "        \"\"\"\n",
        "        This method performs required data processing steps.\n",
        "        \"\"\"\n",
        "        print()\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"Starting data processing pipeline...\")\n",
        "        self.get_file_names_list()\n",
        "        self.get_label_info()\n",
        "        self.initial_split_data()\n",
        "        \n",
        "        if self.run_mode == 'interim_test':\n",
        "            self.check_duplicate_ids('train')\n",
        "            self.check_duplicate_ids('test')\n",
        "            self.get_data_distribution('train')\n",
        "            self.get_data_distribution('test')\n",
        "            self.get_image_summary_stats()\n",
        "            \n",
        "        #self.move_files()\n",
        "        print(\"Completed data processing pipeline...\")\n",
        "        print()\n",
        "        print(\"*****************************************************\")\n",
        "        print(\"*****************************************************\")\n",
        "\n",
        "'''\n",
        "data_proc = data_processing(run_mode = 'final_test')\n",
        "'''\n",
        "# Used for testing\n",
        "#data_proc = data_processing(run_mode = 'interim_test') \n",
        "data_proc = data_processing(run_mode = 'final_test')\n",
        "data_proc.data_processing_pipeline()\n",
        "\n",
        "# Data visualizations\n",
        "data_proc.data_visualization(train_or_test_ind = 'train', positive_or_negative_ind = 'positive', image_list = data_proc.train_positive_color_file_list)\n",
        "data_proc.data_visualization(train_or_test_ind = 'train', positive_or_negative_ind = 'negative', image_list = data_proc.train_positive_color_file_list)"
      ],
      "metadata": {
        "id": "9ASpSKwV7EnJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8aa6308-b4e9-4a98-b249-65f58d8f2350"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "*****************************************************\n",
            "*****************************************************\n",
            "Starting data processing pipeline...\n",
            "\n",
            "*****************************************************\n",
            "*****************************************************\n",
            "Starting to build fully qualified train and test file name lists...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Length of train data : {len(data_proc.df_train)}\")\n",
        "print(f\"Length of test data : {len(data_proc.df_test)}\")"
      ],
      "metadata": {
        "id": "o67jG5rOF6xn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab69f0e7-61bc-4cd8-fe42-b0a45eec18f7"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of train data : 144000\n",
            "Length of test data : 16000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -ltr /content/image_processing/test/positive/*.tif|wc -l\n",
        "!ls -ltr /content/image_processing/test/negative/*.tif|wc -l"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ug0Fd0AkNVZK",
        "outputId": "ff4a5a35-fe49-457c-f505-a5089e17a178"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8000\n",
            "8000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***3. Model Building***"
      ],
      "metadata": {
        "id": "ISUTBnGe72tT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def soft_voting_cllasifier(df):\n",
        "    voting_df = df.groupby(['y_test_index', 'actual_val']).agg({'sigmoid_val' : np.mean}).reset_index()\n",
        "    voting_df.columns = ['y_test_index', \n",
        "                         'actual_val',\n",
        "                         'assigned_probability'\n",
        "                    ]\n",
        "    voting_df['assigned_binary_value'] = np.where(voting_df['assigned_probability'] > .5,\n",
        "                                                  1,\n",
        "                                                  0\n",
        "                                                 )\n",
        "    return voting_df\n",
        "    '''\n",
        "    for pos in df['y_test_index'].drop_duplicates().tolist():\n",
        "        #print(f\"pos : {pos}\")\n",
        "        pos_val, neg_val = [],[]\n",
        "        pos_proba, neg_proba = 0,0\n",
        "        for rec in df[df.y_test_index == pos].values.tolist():\n",
        "            #print(rec)\n",
        "            y_test_index = rec[0]\n",
        "            sigmoid_val = rec[1]\n",
        "            th50_bin_pred_val = rec[2]\n",
        "            actual_val = rec[3]\n",
        "            kfold = rec[4]\n",
        "            if int(th50_bin_pred_val) == 0:\n",
        "                neg_val.append(sigmoid_val)\n",
        "            else:\n",
        "                pos_val.append(sigmoid_val)\n",
        "        \n",
        "        #print(sum(pos_val) , len(pos_val), sum(neg_val) , len(neg_val))\n",
        "        # Unanimously negative\n",
        "        if len(pos_val) == 0:\n",
        "            pos_proba = 0\n",
        "        else:\n",
        "            pos_proba = sum(pos_val) / len(pos_val)\n",
        "        # Unanimously positive\n",
        "        if len(neg_val) == 0:\n",
        "            neg_proba == 0\n",
        "        else:\n",
        "            neg_proba = sum(neg_val) / len(neg_val)\n",
        "        assigned_proba = np.max(np.asarray([pos_proba, neg_proba]))\n",
        "        if  np.where(np.asarray([pos_proba, neg_proba]) == assigned_proba)[0][0] == 0:\n",
        "            assigned_bin = 1\n",
        "        else:\n",
        "            assigned_bin = 0\n",
        "        #print(pos, assigned_proba,  assigned_bin)\n",
        "        clf_list.append((pos, assigned_proba,  assigned_bin))\n",
        "        #print(\"***\")\n",
        "    df_clf = pd.DataFrame(clf_list, columns = ['y_test_index', \n",
        "                                               'assigned_probability', \n",
        "                                               'assigned_binary_value'\n",
        "                                              ]\n",
        "                         ).drop_duplicates()\n",
        "    df_actual = df[['y_test_index', 'actual_val']].drop_duplicates()\n",
        "    df_clf = pd.merge(df_clf, df_actual, how = 'inner', on = 'y_test_index')\n",
        "    df_clf['actual_val'] = df_clf['actual_val'].astype(int)\n",
        "    return df_clf\n",
        "    '''"
      ],
      "metadata": {
        "id": "ou6znlH7qnkR"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def hard_voting_cllasifier(df):\n",
        "    agg_df = df.groupby(['y_test_index']).agg({'th50_bin_pred_val': [np.size, np.min, np.max, stats.mode]}).reset_index()\n",
        "    agg_df.columns = ['y_test_index', \n",
        "                      'th50_bin_pred_val_count', \n",
        "                      'th50_bin_pred_val_min', \n",
        "                      'th50_bin_pred_val_max',\n",
        "                      'pred_bin'\n",
        "                     ]\n",
        "    agg_df[['majority_class_value', 'majority_count']] = pd.DataFrame(agg_df['pred_bin'].tolist(), index = agg_df.index)\n",
        "    agg_df['majority_class_value'] = agg_df['majority_class_value'].apply(lambda x : x[0])\n",
        "    agg_df['majority_count'] = agg_df['majority_count'].apply(lambda x : x[0])\n",
        "    agg_df['assigned_binary_value'] = np.where((agg_df['th50_bin_pred_val_min'] == agg_df['th50_bin_pred_val_max']) | (agg_df['majority_count'] < cfg_proc.number_of_splits), agg_df['majority_class_value'], -1)\n",
        "    agg_df['assigned_binary_value'] = np.where(agg_df['majority_count'] * 2 == agg_df['th50_bin_pred_val_count'], 1, agg_df['assigned_binary_value'])\n",
        "\n",
        "    clf_list = []\n",
        "    for rec in agg_df[['y_test_index', 'assigned_binary_value']].values.tolist():\n",
        "        avg_sigmoid_val = cfg_proc.consolidated_pred_df[(cfg_proc.consolidated_pred_df.y_test_index == rec[0]) & (cfg_proc.consolidated_pred_df.th50_bin_pred_val == rec[1])]['sigmoid_val'].mean()\n",
        "        clf_list.append((rec[0], avg_sigmoid_val, rec[1]))\n",
        "    df_clf = pd.DataFrame(clf_list)\n",
        "    df_clf.columns   = ['y_test_index', \n",
        "                        'assigned_probability', \n",
        "                        'assigned_binary_value'\n",
        "                       ]\n",
        "    df_clf['y_test_index'] = df_clf['y_test_index'].apply(lambda x : int(x))\n",
        "    df_clf = pd.merge(df_clf, \n",
        "                      df[['y_test_index', 'actual_val']].drop_duplicates(), \n",
        "                      how = 'inner', \n",
        "                      on = 'y_test_index'\n",
        "                     )\n",
        "    df_clf['actual_val'] = df_clf['actual_val'].astype(int)\n",
        "    return df_clf"
      ],
      "metadata": {
        "id": "Rwv2V8jVpNk8"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_roc(name, labels, predictions, **kwargs):\n",
        "  fp, tp, _ = sklearn.metrics.roc_curve(labels, predictions)\n",
        "\n",
        "  plt.plot(100*fp, 100*tp, label=name, linewidth=2, **kwargs)\n",
        "  plt.xlabel('False positives [%]')\n",
        "  plt.ylabel('True positives [%]')\n",
        "  plt.xlim([-0.5,20])\n",
        "  plt.ylim([80,100.5])\n",
        "  plt.grid(True)\n",
        "  ax = plt.gca()\n",
        "  ax.set_aspect('equal')\n",
        "  plt.show(block = False)\n",
        "\n",
        "def plot_metrics(history):\n",
        "  metrics = ['loss', 'accuracy', 'precision', 'recall']\n",
        "  for n, metric in enumerate(metrics):\n",
        "    name = metric.replace(\"_\",\" \").capitalize()\n",
        "    plt.subplot(2,2,n+1)\n",
        "    plt.plot(history.epoch, \n",
        "             history.history[metric], \n",
        "             color = colors[0], \n",
        "             label = 'Train')\n",
        "    plt.plot(history.epoch, \n",
        "             history.history['val_'+ metric],\n",
        "             color=colors[1], \n",
        "             linestyle=\"--\", \n",
        "             label = 'Validation')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel(name)\n",
        "    if metric == 'loss':\n",
        "      plt.ylim([0, plt.ylim()[1]])\n",
        "    elif metric == 'auc':\n",
        "      plt.ylim([0.8,1])\n",
        "    else:\n",
        "      plt.ylim([0,1])\n",
        "\n",
        "    plt.legend()\n",
        "    plt.show(block = False)\n",
        "\n",
        "def plot_cm(labels, predictions, p=0.5):\n",
        "  cm = confusion_matrix(labels, predictions > p)\n",
        "  plt.figure(figsize=(5,5))\n",
        "  sns.heatmap(cm, annot=True, fmt=\"d\")\n",
        "  plt.title('Confusion matrix @{:.2f}'.format(p))\n",
        "  plt.ylabel('Actual label')\n",
        "  plt.xlabel('Predicted label')\n",
        "\n",
        "  print('True Negatives: ', cm[0][0])\n",
        "  print('False Positives: ', cm[0][1])\n",
        "  print('False Negatives: ', cm[1][0])\n",
        "  print('True Positives: ', cm[1][1])\n",
        "  print('Total : ', np.sum(cm[1]))\n",
        "  plt.show(block = False)"
      ],
      "metadata": {
        "id": "GFyVnBuWfcpK"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data generators\n",
        "\n",
        "'''\n",
        "rotation rules\n",
        "(x, y) -90->  (-y, x)\n",
        "(x, y) -180-> (-x, -y)\n",
        "(x, y) -270-> (y, -x)\n",
        "(x, y) 90-> (y, -x)\n",
        "(x, y) 180-> (-x, -y)\n",
        "(x, y) 270-> (-y, x)\n",
        "'''\n",
        "\n",
        "\n",
        "\n",
        "pred_list = []\n",
        "def custom_augmentation(np_tensor):\n",
        " \n",
        "    def random_contrast(np_tensor):\n",
        "        return tf.image.random_contrast(np_tensor, 0.1, 5)\n",
        " \n",
        "    def random_hue(np_tensor):\n",
        "        return tf.image.random_hue(np_tensor, 0.5)\n",
        " \n",
        "    def random_saturation(np_tensor):\n",
        "        return tf.image.random_saturation(np_tensor, 0.2, 3)\n",
        " \n",
        "    def gaussian_noise(np_tensor):\n",
        "        mean = 0\n",
        "        # variance: randomly between 1 to 25\n",
        "        var = np.random.randint(1, 26)\n",
        "        # sigma is square root of the variance value\n",
        "        noise = np.random.normal(mean,var**0.5,np_tensor.shape)\n",
        "        return np.clip(np_tensor + noise, 0, 255).astype('int')\n",
        "\n",
        "    augmnted_tensor = random_contrast(np_tensor)\n",
        "    #augmnted_tensor = random_hue(augmnted_tensor)\n",
        "    #augmnted_tensor = random_saturation(augmnted_tensor)\n",
        "    #augmented_tensor = gaussian_noise(augmnted_tensor)\n",
        "  \n",
        "    return np.array(augmnted_tensor)\n",
        "\n",
        "# Train data generator\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   horizontal_flip = True,\n",
        "                                   vertical_flip = True,\n",
        "                                   rotation_range = 180,\n",
        "                                   zoom_range = 0.4, \n",
        "                                   width_shift_range = 0.3,\n",
        "                                   height_shift_range = 0.3,\n",
        "                                   shear_range = 0.3\n",
        "                                   #,preprocessing_function = custom_augmentation \n",
        "                                  )\n",
        "\n",
        "# Validation data generator\n",
        "val_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    rescale = 1.0/255\n",
        "    )\n",
        "\n",
        "# Test data generator\n",
        "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    rescale = 1.0/255\n",
        "    )\n",
        "\n",
        "for kfold, (train_indices, validation_indices) in enumerate(StratifiedKFold(n_splits     =  cfg_proc.number_of_splits, \n",
        "                                                                            shuffle      = True, \n",
        "                                                                            random_state = cfg_proc.random_state\n",
        "                                                                           ).split(data_proc.df_train_original['label'].values.tolist(), \n",
        "                                                                                   data_proc.df_train_original['label'].values.tolist()\n",
        "                                                                                  )):\n",
        "    '''\n",
        "    if kfold > 0:\n",
        "        break\n",
        "    '''\n",
        "    print(f\"k-fold : {kfold + 1}, length of train data : {len(train_indices)}, length of validation data : {len(validation_indices)}\")\n",
        "    data_proc.split_data_based_on_indices(train_indices = train_indices, validation_indices = validation_indices)\n",
        "\n",
        "    train_dataset_from_data_generator = train_datagen.flow_from_directory(cfg_proc.image_processing_train_path,\n",
        "                                                                          target_size = (cfg_proc.image_size, cfg_proc.image_size),\n",
        "                                                                          class_mode = 'binary',\n",
        "                                                                          batch_size = cfg_proc.batch_size,\n",
        "                                                                          color_mode = 'rgb',\n",
        "                                                                          shuffle    = True,\n",
        "                                                                          seed       = cfg_proc.random_state\n",
        "                                                                         )\n",
        "    validation_dataset_from_data_generator = val_datagen.flow_from_directory(cfg_proc.image_processing_validation_path,\n",
        "                                                                             target_size = (cfg_proc.image_size, cfg_proc.image_size),\n",
        "                                                                             class_mode = 'binary',\n",
        "                                                                             batch_size = cfg_proc.batch_size,\n",
        "                                                                             color_mode = 'rgb',\n",
        "                                                                             shuffle = True,\n",
        "                                                                             seed    = cfg_proc.random_state\n",
        "                                                                           )\n",
        "    test_dataset_from_data_generator = test_datagen.flow_from_directory(cfg_proc.image_processing_test_path,\n",
        "                                                                        target_size = (cfg_proc.image_size, cfg_proc.image_size),\n",
        "                                                                        batch_size = cfg_proc.batch_size,\n",
        "                                                                        class_mode = 'binary',\n",
        "                                                                        color_mode = 'rgb',\n",
        "                                                                        shuffle    = False,\n",
        "                                                                        seed       = cfg_proc.random_state\n",
        "                                                                       )\n",
        "        \n",
        "    tf.random.set_seed(cfg_proc.random_state)\n",
        "    np.random.seed(cfg_proc.random_state)\n",
        "\n",
        "    input_shape = (cfg_proc.image_size, cfg_proc.image_size, 3)\n",
        "    inputs = Input(input_shape)\n",
        "\n",
        "    xception = Xception(include_top = False, input_shape = input_shape)(inputs)\n",
        "    mobile_net = MobileNetV2(include_top = False, input_shape = input_shape)(inputs)\n",
        "    xception.trainable = True\n",
        "    mobile_net.trainable = True\n",
        "\n",
        "    outputs = Concatenate(axis=-1)([GlobalAveragePooling2D()(xception), GlobalAveragePooling2D()(mobile_net)])\n",
        "    outputs = Dropout(0.5)(outputs)\n",
        "    outputs = Dense(1, activation = 'sigmoid')(outputs)\n",
        "    model = Model(inputs, outputs)\n",
        "    trainable_count = count_params(model.trainable_weights)\n",
        "    non_trainable_count = count_params(model.non_trainable_weights)\n",
        "    print(f\"Traininable parameters : {trainable_count}, non trainable parameters : {non_trainable_count}\")\n",
        "\n",
        "    metrics_list = [\n",
        "      keras.metrics.TruePositives(name  = 'tp'),\n",
        "      keras.metrics.FalsePositives(name = 'fp'),\n",
        "      keras.metrics.TrueNegatives(name  = 'tn'),\n",
        "      keras.metrics.FalseNegatives(name = 'fn'), \n",
        "      keras.metrics.BinaryAccuracy(name = 'accuracy'),\n",
        "      keras.metrics.Precision(name      = 'precision'),\n",
        "      keras.metrics.Recall(name         = 'recall'),\n",
        "      keras.metrics.AUC(name            = 'auc'),\n",
        "      keras.metrics.AUC(name            = 'prc', \n",
        "                        curve = 'PR'\n",
        "                       ) # precision-recall curve\n",
        "    ]\n",
        "    model.compile(optimizer = Adam(learning_rate = 0.0001, \n",
        "                                   decay = 0.00001\n",
        "                                  ),\n",
        "                  loss = tf.keras.losses.BinaryCrossentropy(),\n",
        "                  metrics = metrics_list\n",
        "                  )\n",
        "    model.summary()\n",
        "    tf.keras.utils.plot_model(model, \n",
        "                              to_file='model_structure.png', \n",
        "                              show_shapes = True,\n",
        "                              show_layer_names = True)\n",
        "    plt.show(block = False)\n",
        "\n",
        "    history = model.fit(train_dataset_from_data_generator,\n",
        "                        epochs = cfg_proc.epochs,\n",
        "                        steps_per_epoch = len(train_dataset_from_data_generator),\n",
        "                        validation_data = validation_dataset_from_data_generator,\n",
        "                        validation_steps = len(validation_dataset_from_data_generator),\n",
        "                        verbose = 1\n",
        "                      )\n",
        "\n",
        "    # Model save\n",
        "    print(\"Saving model...\")\n",
        "    tf.keras.backend.clear_session()\n",
        "    gc.collect()\n",
        "    model_name = f'tumor_detection_xception_mobilenet_combo_{kfold + 1}'\n",
        "    model.save(model_name + '.h5')\n",
        "    tf.keras.backend.clear_session()\n",
        "    gc.collect()\n",
        "\n",
        "    # Plot metrices\n",
        "    print(\"Plotting the metrices...\")\n",
        "    plot_metrics(history)\n",
        "    \n",
        "    # Collecting train and validation metrices and append it back to consolidated one\n",
        "    temp_result_df = pd.DataFrame()\n",
        "    temp_result_df = pd.DataFrame(history.history)\n",
        "    temp_result_df['kfold'] = kfold + 1\n",
        "    cfg_proc.consolidated_history_df = pd.concat([temp_result_df, \n",
        "                                                  cfg_proc.consolidated_history_df\n",
        "                                                 ], \n",
        "                                                 axis = 0\n",
        "                                                )\n",
        "\n",
        "    # Model Predict, transform logits to probabilities\n",
        "    print(\"Model predict....\")\n",
        "    step_size_test = np.ceil(test_dataset_from_data_generator.n / test_dataset_from_data_generator.batch_size)\n",
        "    test_dataset_from_data_generator.reset()\n",
        "    probas_sigmoid = model.predict(test_dataset_from_data_generator, \n",
        "                                   batch_size = cfg_proc.batch_size, \n",
        "                                   verbose = 1\n",
        "                                  )\n",
        "    predictions_binary_th50 = [1 if x > .5 else 0 for x in probas_sigmoid]\n",
        "\n",
        "    # Model evaluate\n",
        "    print(\"Model evaluate and test metrices....\")\n",
        "    test_results = model.evaluate(test_dataset_from_data_generator, \n",
        "                                  batch_size = cfg_proc.batch_size,\n",
        "                                  verbose = 0\n",
        "                                 )   \n",
        "    test_kpi_dict = {}\n",
        "    for name, value in zip(model.metrics_names, test_results):\n",
        "        print(name, ': ', value)\n",
        "        test_kpi_dict[name] = value\n",
        "        print()\n",
        "\n",
        "    # Plot Confusion Matric\n",
        "    print(\"Confusion Matrix...\")\n",
        "    #plot_cm(data_proc.y_test, probas_sigmoid)\n",
        "    model_proc.plot_model_result_confusion_matrix(threshold_val = .5, \n",
        "                                                  y_pred_probas = probas_sigmoid, \n",
        "                                                  y_test        = test_dataset_from_data_generator.classes)\n",
        "    \n",
        "    print(\"Ploting AOC-AUC...\")\n",
        "    model_proc.plot_roc_auc_curve(y_pred_probas = probas_sigmoid, \n",
        "                                  y_test = test_dataset_from_data_generator.classes\n",
        "                                 )\n",
        "    \n",
        "    print(f\"Classification report with 50% threshold\")\n",
        "    model_proc.generate_report(threshold_val = 0.5, \n",
        "                               y_pred_probas = probas_sigmoid, \n",
        "                               y_test = test_dataset_from_data_generator.classes\n",
        "                              )\n",
        "    \n",
        "    temp_pred_df = pd.DataFrame(np.concatenate([probas_sigmoid, \n",
        "                                                np.asarray(predictions_binary_th50).reshape(-1,1),\n",
        "                                                test_dataset_from_data_generator.classes.reshape(-1,1)\n",
        "                                               ], \n",
        "                                               axis = 1\n",
        "                                              ))\n",
        "    temp_pred_df.columns = ['sigmoid_val', \n",
        "                            'th50_bin_pred_val', \n",
        "                            'actual_val'\n",
        "                           ]\n",
        "    temp_pred_df['kfold'] = kfold + 1\n",
        "    temp_pred_df.insert(0, 'y_test_index', range(1, 1 + len(temp_pred_df)))\n",
        "    cfg_proc.consolidated_pred_df = pd.concat([temp_pred_df, \n",
        "                                               cfg_proc.consolidated_pred_df\n",
        "                                              ], \n",
        "                                              axis = 0\n",
        "                                             )\n",
        "    print(\"********************************************\")\n",
        "    print(\"********************************************\")\n",
        "\n",
        "    test_kpi_df = pd.DataFrame([kfold + 1,\n",
        "                                test_kpi_dict['loss'], \n",
        "                                test_kpi_dict['accuracy'],\n",
        "                                test_kpi_dict['tp'],\n",
        "                                test_kpi_dict['fp'],\n",
        "                                test_kpi_dict['tn'],\n",
        "                                test_kpi_dict['fn'],\n",
        "                                test_kpi_dict['precision'],\n",
        "                                test_kpi_dict['recall'],\n",
        "                                test_kpi_dict['auc'],\n",
        "                                test_kpi_dict['prc']\n",
        "                               ]).T\n",
        "    test_kpi_df.columns = ['kfold', \n",
        "                           'test_loss', \n",
        "                           'test_accuracy',\n",
        "                           'test_true_positive',\n",
        "                           'test_false_positive',\n",
        "                           'test_true_negative',\n",
        "                           'test_false_negative',\n",
        "                           'test_precission',\n",
        "                           'test_recall',\n",
        "                           'test_auc',\n",
        "                           'test_prc'\n",
        "                          ]\n",
        "    cfg_proc.consolidated_test_kpi_df = pd.concat([test_kpi_df, \n",
        "                                                   cfg_proc.consolidated_test_kpi_df\n",
        "                                                  ], \n",
        "                                                  axis = 0\n",
        "                                                 )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Xv4rrJ4ivweJ",
        "outputId": "69c96d6c-0e56-4438-891f-b35450356aa0"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "k-fold : 1, length of train data : 126000, length of validation data : 18000\n",
            "\n",
            "*****************************************************\n",
            "*****************************************************\n",
            "Starting to split data based on indices...\n",
            "\n",
            "*****************************************************\n",
            "*****************************************************\n",
            "Starting to create labels for train...\n",
            "Completed building labels for train...\n",
            "*****************************************************\n",
            "*****************************************************\n",
            "\n",
            "\n",
            "*****************************************************\n",
            "*****************************************************\n",
            "Starting to create labels for validation...\n",
            "Completed building labels for validation...\n",
            "*****************************************************\n",
            "*****************************************************\n",
            "\n",
            "\n",
            "*****************************************************\n",
            "*****************************************************\n",
            "Starting to remove files under /content/image_processing/train/positive...\n",
            "*****************************************************\n",
            "*****************************************************\n",
            "\n",
            "\n",
            "*****************************************************\n",
            "*****************************************************\n",
            "Starting to remove files under /content/image_processing/train/negative...\n",
            "*****************************************************\n",
            "*****************************************************\n",
            "\n",
            "Copying test_positive_file_list under /content/image_processing/train/positive\n",
            "Copying test_negative_file_list under /content/image_processing/train/negative\n",
            "File count under /content/image_processing/train/positive after moving new files is: 63000\n",
            "File count under /content/image_processing/train/negative after moving new files is : 63000\n",
            "\n",
            "*****************************************************\n",
            "*****************************************************\n",
            "Starting to remove files under /content/image_processing/validation/positive...\n",
            "*****************************************************\n",
            "*****************************************************\n",
            "\n",
            "\n",
            "*****************************************************\n",
            "*****************************************************\n",
            "Starting to remove files under /content/image_processing/validation/negative...\n",
            "*****************************************************\n",
            "*****************************************************\n",
            "\n",
            "Copying test_positive_file_list under /content/image_processing/validation/positive\n",
            "Copying test_negative_file_list under /content/image_processing/validation/negative\n",
            "File count under /content/image_processing/validation/positive after moving new files is: 9000\n",
            "File count under /content/image_processing/validation/negative after moving new files is : 9000\n",
            "Completed spliting the data sets based on indices...\n",
            "*****************************************************\n",
            "*****************************************************\n",
            "\n",
            "Found 126000 images belonging to 2 classes.\n",
            "Found 18000 images belonging to 2 classes.\n",
            "Found 16000 images belonging to 2 classes.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "83683744/83683744 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_96_no_top.h5\n",
            "9406464/9406464 [==============================] - 0s 0us/step\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 96, 96, 3)]  0           []                               \n",
            "                                                                                                  \n",
            " xception (Functional)          (None, 3, 3, 2048)   20861480    ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " mobilenetv2_1.00_96 (Functiona  (None, 3, 3, 1280)  2257984     ['input_1[0][0]']                \n",
            " l)                                                                                               \n",
            "                                                                                                  \n",
            " global_average_pooling2d (Glob  (None, 2048)        0           ['xception[0][0]']               \n",
            " alAveragePooling2D)                                                                              \n",
            "                                                                                                  \n",
            " global_average_pooling2d_1 (Gl  (None, 1280)        0           ['mobilenetv2_1.00_96[0][0]']    \n",
            " obalAveragePooling2D)                                                                            \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 3328)         0           ['global_average_pooling2d[0][0]'\n",
            "                                                                 , 'global_average_pooling2d_1[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 3328)         0           ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 1)            3329        ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 23,122,793\n",
            "Trainable params: 23,034,153\n",
            "Non-trainable params: 88,640\n",
            "__________________________________________________________________________________________________\n",
            "Traininable parameters : 23034153, non trainable parameters : 88640\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 96, 96, 3)]  0           []                               \n",
            "                                                                                                  \n",
            " xception (Functional)          (None, 3, 3, 2048)   20861480    ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " mobilenetv2_1.00_96 (Functiona  (None, 3, 3, 1280)  2257984     ['input_1[0][0]']                \n",
            " l)                                                                                               \n",
            "                                                                                                  \n",
            " global_average_pooling2d (Glob  (None, 2048)        0           ['xception[0][0]']               \n",
            " alAveragePooling2D)                                                                              \n",
            "                                                                                                  \n",
            " global_average_pooling2d_1 (Gl  (None, 1280)        0           ['mobilenetv2_1.00_96[0][0]']    \n",
            " obalAveragePooling2D)                                                                            \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 3328)         0           ['global_average_pooling2d[0][0]'\n",
            "                                                                 , 'global_average_pooling2d_1[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 3328)         0           ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 1)            3329        ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 23,122,793\n",
            "Trainable params: 23,034,153\n",
            "Non-trainable params: 88,640\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-74dc502e2145>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m     history = model.fit(train_dataset_from_data_generator,\n\u001b[0m\u001b[1;32m    151\u001b[0m                         \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcfg_proc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m                         \u001b[0msteps_per_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset_from_data_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1407\u001b[0m                 _r=1):\n\u001b[1;32m   1408\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1410\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    978\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 980\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    981\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    982\u001b[0m       _, _, filtered_flat_args = (\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2451\u001b[0m       (graph_function,\n\u001b[1;32m   2452\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2453\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2454\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1858\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1859\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1860\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1861\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1862\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    495\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 497\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    498\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cfg_proc.consolidated_test_kpi_df.head()"
      ],
      "metadata": {
        "id": "dVXeb92At6il",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "dd6ed460-2abb-4d8b-a3e0-ab398a2b89ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   kfold  test_loss  test_accuracy  test_true_positive  test_false_positive  \\\n",
              "0    8.0   0.275273       0.905563              7389.0                900.0   \n",
              "0    7.0   0.284415       0.908375              6800.0                266.0   \n",
              "0    6.0   0.213075       0.922625              7151.0                389.0   \n",
              "0    5.0   0.289130       0.894313              6468.0                159.0   \n",
              "0    4.0   0.260095       0.906000              6681.0                185.0   \n",
              "\n",
              "   test_true_negative  test_false_negative  test_precission  test_recall  \\\n",
              "0              7100.0                611.0         0.891422     0.923625   \n",
              "0              7734.0               1200.0         0.962355     0.850000   \n",
              "0              7611.0                849.0         0.948408     0.893875   \n",
              "0              7841.0               1532.0         0.976007     0.808500   \n",
              "0              7815.0               1319.0         0.973056     0.835125   \n",
              "\n",
              "   test_auc  test_prc  \n",
              "0  0.964715  0.961007  \n",
              "0  0.967279  0.971211  \n",
              "0  0.973799  0.976030  \n",
              "0  0.970071  0.974946  \n",
              "0  0.973844  0.977671  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-aadeeb05-f357-4c24-b97e-b07a1dc6a5a2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>kfold</th>\n",
              "      <th>test_loss</th>\n",
              "      <th>test_accuracy</th>\n",
              "      <th>test_true_positive</th>\n",
              "      <th>test_false_positive</th>\n",
              "      <th>test_true_negative</th>\n",
              "      <th>test_false_negative</th>\n",
              "      <th>test_precission</th>\n",
              "      <th>test_recall</th>\n",
              "      <th>test_auc</th>\n",
              "      <th>test_prc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8.0</td>\n",
              "      <td>0.275273</td>\n",
              "      <td>0.905563</td>\n",
              "      <td>7389.0</td>\n",
              "      <td>900.0</td>\n",
              "      <td>7100.0</td>\n",
              "      <td>611.0</td>\n",
              "      <td>0.891422</td>\n",
              "      <td>0.923625</td>\n",
              "      <td>0.964715</td>\n",
              "      <td>0.961007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7.0</td>\n",
              "      <td>0.284415</td>\n",
              "      <td>0.908375</td>\n",
              "      <td>6800.0</td>\n",
              "      <td>266.0</td>\n",
              "      <td>7734.0</td>\n",
              "      <td>1200.0</td>\n",
              "      <td>0.962355</td>\n",
              "      <td>0.850000</td>\n",
              "      <td>0.967279</td>\n",
              "      <td>0.971211</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6.0</td>\n",
              "      <td>0.213075</td>\n",
              "      <td>0.922625</td>\n",
              "      <td>7151.0</td>\n",
              "      <td>389.0</td>\n",
              "      <td>7611.0</td>\n",
              "      <td>849.0</td>\n",
              "      <td>0.948408</td>\n",
              "      <td>0.893875</td>\n",
              "      <td>0.973799</td>\n",
              "      <td>0.976030</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.0</td>\n",
              "      <td>0.289130</td>\n",
              "      <td>0.894313</td>\n",
              "      <td>6468.0</td>\n",
              "      <td>159.0</td>\n",
              "      <td>7841.0</td>\n",
              "      <td>1532.0</td>\n",
              "      <td>0.976007</td>\n",
              "      <td>0.808500</td>\n",
              "      <td>0.970071</td>\n",
              "      <td>0.974946</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4.0</td>\n",
              "      <td>0.260095</td>\n",
              "      <td>0.906000</td>\n",
              "      <td>6681.0</td>\n",
              "      <td>185.0</td>\n",
              "      <td>7815.0</td>\n",
              "      <td>1319.0</td>\n",
              "      <td>0.973056</td>\n",
              "      <td>0.835125</td>\n",
              "      <td>0.973844</td>\n",
              "      <td>0.977671</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-aadeeb05-f357-4c24-b97e-b07a1dc6a5a2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-aadeeb05-f357-4c24-b97e-b07a1dc6a5a2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-aadeeb05-f357-4c24-b97e-b07a1dc6a5a2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cfg_proc.consolidated_test_kpi_df.describe()"
      ],
      "metadata": {
        "id": "1GqgPvx4TvwD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "a968e509-38b2-4c0a-aabf-22e6232e23de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         kfold  test_loss  test_accuracy  test_true_positive  \\\n",
              "count  8.00000   8.000000       8.000000            8.000000   \n",
              "mean   4.50000   0.247594       0.912148         6937.250000   \n",
              "std    2.44949   0.034549       0.010482          308.286393   \n",
              "min    1.00000   0.197844       0.894313         6468.000000   \n",
              "25%    2.75000   0.220859       0.905891         6770.250000   \n",
              "50%    4.50000   0.248781       0.911531         6880.500000   \n",
              "75%    6.25000   0.277558       0.920937         7175.250000   \n",
              "max    8.00000   0.289130       0.925250         7389.000000   \n",
              "\n",
              "       test_false_positive  test_true_negative  test_false_negative  \\\n",
              "count              8.00000             8.00000             8.000000   \n",
              "mean             342.87500          7657.12500          1062.750000   \n",
              "std              247.49917           247.49917           308.286393   \n",
              "min              159.00000          7100.00000           611.000000   \n",
              "25%              184.50000          7597.25000           824.750000   \n",
              "50%              241.50000          7758.50000          1119.500000   \n",
              "75%              402.75000          7815.50000          1229.750000   \n",
              "max              900.00000          7841.00000          1532.000000   \n",
              "\n",
              "       test_precission  test_recall  test_auc  test_prc  \n",
              "count         8.000000     8.000000  8.000000  8.000000  \n",
              "mean          0.954635     0.867156  0.972362  0.974998  \n",
              "std           0.028384     0.038536  0.004523  0.006410  \n",
              "min           0.891422     0.808500  0.964715  0.961007  \n",
              "25%           0.946876     0.846281  0.969373  0.974012  \n",
              "50%           0.966024     0.860062  0.973821  0.976851  \n",
              "75%           0.973257     0.896906  0.975982  0.978826  \n",
              "max           0.976007     0.923625  0.976774  0.980477  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-39fd48e8-e8c5-4962-bcc4-8526cd046187\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>kfold</th>\n",
              "      <th>test_loss</th>\n",
              "      <th>test_accuracy</th>\n",
              "      <th>test_true_positive</th>\n",
              "      <th>test_false_positive</th>\n",
              "      <th>test_true_negative</th>\n",
              "      <th>test_false_negative</th>\n",
              "      <th>test_precission</th>\n",
              "      <th>test_recall</th>\n",
              "      <th>test_auc</th>\n",
              "      <th>test_prc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>8.00000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>8.00000</td>\n",
              "      <td>8.00000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>8.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>4.50000</td>\n",
              "      <td>0.247594</td>\n",
              "      <td>0.912148</td>\n",
              "      <td>6937.250000</td>\n",
              "      <td>342.87500</td>\n",
              "      <td>7657.12500</td>\n",
              "      <td>1062.750000</td>\n",
              "      <td>0.954635</td>\n",
              "      <td>0.867156</td>\n",
              "      <td>0.972362</td>\n",
              "      <td>0.974998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>2.44949</td>\n",
              "      <td>0.034549</td>\n",
              "      <td>0.010482</td>\n",
              "      <td>308.286393</td>\n",
              "      <td>247.49917</td>\n",
              "      <td>247.49917</td>\n",
              "      <td>308.286393</td>\n",
              "      <td>0.028384</td>\n",
              "      <td>0.038536</td>\n",
              "      <td>0.004523</td>\n",
              "      <td>0.006410</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.00000</td>\n",
              "      <td>0.197844</td>\n",
              "      <td>0.894313</td>\n",
              "      <td>6468.000000</td>\n",
              "      <td>159.00000</td>\n",
              "      <td>7100.00000</td>\n",
              "      <td>611.000000</td>\n",
              "      <td>0.891422</td>\n",
              "      <td>0.808500</td>\n",
              "      <td>0.964715</td>\n",
              "      <td>0.961007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>2.75000</td>\n",
              "      <td>0.220859</td>\n",
              "      <td>0.905891</td>\n",
              "      <td>6770.250000</td>\n",
              "      <td>184.50000</td>\n",
              "      <td>7597.25000</td>\n",
              "      <td>824.750000</td>\n",
              "      <td>0.946876</td>\n",
              "      <td>0.846281</td>\n",
              "      <td>0.969373</td>\n",
              "      <td>0.974012</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>4.50000</td>\n",
              "      <td>0.248781</td>\n",
              "      <td>0.911531</td>\n",
              "      <td>6880.500000</td>\n",
              "      <td>241.50000</td>\n",
              "      <td>7758.50000</td>\n",
              "      <td>1119.500000</td>\n",
              "      <td>0.966024</td>\n",
              "      <td>0.860062</td>\n",
              "      <td>0.973821</td>\n",
              "      <td>0.976851</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>6.25000</td>\n",
              "      <td>0.277558</td>\n",
              "      <td>0.920937</td>\n",
              "      <td>7175.250000</td>\n",
              "      <td>402.75000</td>\n",
              "      <td>7815.50000</td>\n",
              "      <td>1229.750000</td>\n",
              "      <td>0.973257</td>\n",
              "      <td>0.896906</td>\n",
              "      <td>0.975982</td>\n",
              "      <td>0.978826</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>8.00000</td>\n",
              "      <td>0.289130</td>\n",
              "      <td>0.925250</td>\n",
              "      <td>7389.000000</td>\n",
              "      <td>900.00000</td>\n",
              "      <td>7841.00000</td>\n",
              "      <td>1532.000000</td>\n",
              "      <td>0.976007</td>\n",
              "      <td>0.923625</td>\n",
              "      <td>0.976774</td>\n",
              "      <td>0.980477</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-39fd48e8-e8c5-4962-bcc4-8526cd046187')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-39fd48e8-e8c5-4962-bcc4-8526cd046187 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-39fd48e8-e8c5-4962-bcc4-8526cd046187');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cfg_proc.consolidated_history_df.head()"
      ],
      "metadata": {
        "id": "YMg9xiLjsRAf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "outputId": "bb356aa4-f65f-4ba6-edac-82e68838aecc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       loss       tp      fp       tn       fn  accuracy  precision    recall  \\\n",
              "0  0.367506  51895.0  9154.0  53846.0  11105.0  0.839214   0.850055  0.823730   \n",
              "1  0.288401  54353.0  6507.0  56493.0   8647.0  0.879730   0.893082  0.862746   \n",
              "2  0.262522  55204.0  5869.0  57131.0   7796.0  0.891548   0.903902  0.876254   \n",
              "3  0.245596  55764.0  5396.0  57604.0   7236.0  0.899746   0.911772  0.885143   \n",
              "4  0.232169  56184.0  4988.0  58012.0   6816.0  0.906317   0.918459  0.891810   \n",
              "\n",
              "        auc       prc  val_loss  val_tp  val_fp  val_tn  val_fn  val_accuracy  \\\n",
              "0  0.916634  0.922278  0.651264  5312.0   202.0  8798.0  3688.0      0.783889   \n",
              "1  0.948494  0.952517  0.416773  6646.0   231.0  8769.0  2354.0      0.856389   \n",
              "2  0.957190  0.960738  0.266736  7511.0   367.0  8633.0  1489.0      0.896889   \n",
              "3  0.962442  0.965427  0.231008  8258.0   861.0  8139.0   742.0      0.910944   \n",
              "4  0.966276  0.969187  0.217157  8163.0   718.0  8282.0   837.0      0.913611   \n",
              "\n",
              "   val_precision  val_recall   val_auc   val_prc  kfold  \n",
              "0       0.963366    0.590222  0.917418  0.929164      8  \n",
              "1       0.966410    0.738444  0.955322  0.960695      8  \n",
              "2       0.953415    0.834556  0.968630  0.970397      8  \n",
              "3       0.905582    0.917556  0.969641  0.968881      8  \n",
              "4       0.919153    0.907000  0.972027  0.972774      8  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-757c789f-dbdb-4385-958a-ecb0ad0eba76\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>tp</th>\n",
              "      <th>fp</th>\n",
              "      <th>tn</th>\n",
              "      <th>fn</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>auc</th>\n",
              "      <th>prc</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>val_tp</th>\n",
              "      <th>val_fp</th>\n",
              "      <th>val_tn</th>\n",
              "      <th>val_fn</th>\n",
              "      <th>val_accuracy</th>\n",
              "      <th>val_precision</th>\n",
              "      <th>val_recall</th>\n",
              "      <th>val_auc</th>\n",
              "      <th>val_prc</th>\n",
              "      <th>kfold</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.367506</td>\n",
              "      <td>51895.0</td>\n",
              "      <td>9154.0</td>\n",
              "      <td>53846.0</td>\n",
              "      <td>11105.0</td>\n",
              "      <td>0.839214</td>\n",
              "      <td>0.850055</td>\n",
              "      <td>0.823730</td>\n",
              "      <td>0.916634</td>\n",
              "      <td>0.922278</td>\n",
              "      <td>0.651264</td>\n",
              "      <td>5312.0</td>\n",
              "      <td>202.0</td>\n",
              "      <td>8798.0</td>\n",
              "      <td>3688.0</td>\n",
              "      <td>0.783889</td>\n",
              "      <td>0.963366</td>\n",
              "      <td>0.590222</td>\n",
              "      <td>0.917418</td>\n",
              "      <td>0.929164</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.288401</td>\n",
              "      <td>54353.0</td>\n",
              "      <td>6507.0</td>\n",
              "      <td>56493.0</td>\n",
              "      <td>8647.0</td>\n",
              "      <td>0.879730</td>\n",
              "      <td>0.893082</td>\n",
              "      <td>0.862746</td>\n",
              "      <td>0.948494</td>\n",
              "      <td>0.952517</td>\n",
              "      <td>0.416773</td>\n",
              "      <td>6646.0</td>\n",
              "      <td>231.0</td>\n",
              "      <td>8769.0</td>\n",
              "      <td>2354.0</td>\n",
              "      <td>0.856389</td>\n",
              "      <td>0.966410</td>\n",
              "      <td>0.738444</td>\n",
              "      <td>0.955322</td>\n",
              "      <td>0.960695</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.262522</td>\n",
              "      <td>55204.0</td>\n",
              "      <td>5869.0</td>\n",
              "      <td>57131.0</td>\n",
              "      <td>7796.0</td>\n",
              "      <td>0.891548</td>\n",
              "      <td>0.903902</td>\n",
              "      <td>0.876254</td>\n",
              "      <td>0.957190</td>\n",
              "      <td>0.960738</td>\n",
              "      <td>0.266736</td>\n",
              "      <td>7511.0</td>\n",
              "      <td>367.0</td>\n",
              "      <td>8633.0</td>\n",
              "      <td>1489.0</td>\n",
              "      <td>0.896889</td>\n",
              "      <td>0.953415</td>\n",
              "      <td>0.834556</td>\n",
              "      <td>0.968630</td>\n",
              "      <td>0.970397</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.245596</td>\n",
              "      <td>55764.0</td>\n",
              "      <td>5396.0</td>\n",
              "      <td>57604.0</td>\n",
              "      <td>7236.0</td>\n",
              "      <td>0.899746</td>\n",
              "      <td>0.911772</td>\n",
              "      <td>0.885143</td>\n",
              "      <td>0.962442</td>\n",
              "      <td>0.965427</td>\n",
              "      <td>0.231008</td>\n",
              "      <td>8258.0</td>\n",
              "      <td>861.0</td>\n",
              "      <td>8139.0</td>\n",
              "      <td>742.0</td>\n",
              "      <td>0.910944</td>\n",
              "      <td>0.905582</td>\n",
              "      <td>0.917556</td>\n",
              "      <td>0.969641</td>\n",
              "      <td>0.968881</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.232169</td>\n",
              "      <td>56184.0</td>\n",
              "      <td>4988.0</td>\n",
              "      <td>58012.0</td>\n",
              "      <td>6816.0</td>\n",
              "      <td>0.906317</td>\n",
              "      <td>0.918459</td>\n",
              "      <td>0.891810</td>\n",
              "      <td>0.966276</td>\n",
              "      <td>0.969187</td>\n",
              "      <td>0.217157</td>\n",
              "      <td>8163.0</td>\n",
              "      <td>718.0</td>\n",
              "      <td>8282.0</td>\n",
              "      <td>837.0</td>\n",
              "      <td>0.913611</td>\n",
              "      <td>0.919153</td>\n",
              "      <td>0.907000</td>\n",
              "      <td>0.972027</td>\n",
              "      <td>0.972774</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-757c789f-dbdb-4385-958a-ecb0ad0eba76')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-757c789f-dbdb-4385-958a-ecb0ad0eba76 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-757c789f-dbdb-4385-958a-ecb0ad0eba76');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cfg_proc.consolidated_history_df.describe()"
      ],
      "metadata": {
        "id": "xFe7R6UmTsoF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "outputId": "d80b2014-6ab1-4bfa-bb23-2a5fe46814b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            loss            tp           fp            tn            fn  \\\n",
              "count  80.000000     80.000000    80.000000     80.000000     80.000000   \n",
              "mean    0.244117  55864.675000  5440.900000  57559.100000   7135.325000   \n",
              "std     0.049995   1605.102803  1476.613184   1476.613184   1605.102803   \n",
              "min     0.193430  51816.000000  4011.000000  53607.000000   5541.000000   \n",
              "25%     0.207033  55286.250000  4417.750000  57150.500000   5975.500000   \n",
              "50%     0.229169  56381.000000  4952.000000  58048.000000   6619.000000   \n",
              "75%     0.262428  57024.500000  5849.500000  58582.250000   7713.750000   \n",
              "max     0.369623  57459.000000  9393.000000  58989.000000  11184.000000   \n",
              "\n",
              "        accuracy  precision     recall        auc        prc   val_loss  \\\n",
              "count  80.000000  80.000000  80.000000  80.000000  80.000000  80.000000   \n",
              "mean    0.900189   0.911201   0.886741   0.961309   0.964345   0.331455   \n",
              "std     0.024433   0.024294   0.025478   0.017046   0.016042   0.220817   \n",
              "min     0.837127   0.846680   0.822476   0.915729   0.921149   0.180457   \n",
              "25%     0.892298   0.904312   0.877560   0.957297   0.960616   0.223880   \n",
              "50%     0.907861   0.919258   0.894937   0.967084   0.969895   0.241134   \n",
              "75%     0.917514   0.928099   0.905151   0.973010   0.975164   0.331756   \n",
              "max     0.923936   0.934715   0.912048   0.976266   0.978509   1.626822   \n",
              "\n",
              "            val_tp       val_fp       val_tn       val_fn  val_accuracy  \\\n",
              "count    80.000000    80.000000    80.000000    80.000000     80.000000   \n",
              "mean   7243.487500   418.500000  8581.500000  1756.512500      0.879166   \n",
              "std    1351.919255   255.229259   255.229259  1351.919255      0.065622   \n",
              "min    2160.000000    11.000000  7953.000000   594.000000      0.619389   \n",
              "25%    6972.500000   253.000000  8400.000000   895.500000      0.869972   \n",
              "50%    7788.000000   377.000000  8623.000000  1212.000000      0.908833   \n",
              "75%    8104.500000   600.000000  8747.000000  2027.500000      0.917361   \n",
              "max    8406.000000  1047.000000  8989.000000  6840.000000      0.930889   \n",
              "\n",
              "       val_precision  val_recall    val_auc    val_prc      kfold  \n",
              "count      80.000000   80.000000  80.000000  80.000000  80.000000  \n",
              "mean        0.949366    0.804832   0.964163   0.966726   4.500000  \n",
              "std         0.025674    0.150213   0.017255   0.013777   2.305744  \n",
              "min         0.888510    0.240000   0.864846   0.902748   1.000000  \n",
              "25%         0.931722    0.774722   0.961433   0.963211   2.750000  \n",
              "50%         0.954310    0.865333   0.969498   0.970212   4.500000  \n",
              "75%         0.966921    0.900500   0.974383   0.975253   6.250000  \n",
              "max         0.994933    0.934000   0.979540   0.980895   8.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-319f9f86-8141-4fc1-9e00-f4d3aabb8fb7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>tp</th>\n",
              "      <th>fp</th>\n",
              "      <th>tn</th>\n",
              "      <th>fn</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>auc</th>\n",
              "      <th>prc</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>val_tp</th>\n",
              "      <th>val_fp</th>\n",
              "      <th>val_tn</th>\n",
              "      <th>val_fn</th>\n",
              "      <th>val_accuracy</th>\n",
              "      <th>val_precision</th>\n",
              "      <th>val_recall</th>\n",
              "      <th>val_auc</th>\n",
              "      <th>val_prc</th>\n",
              "      <th>kfold</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>80.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>80.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.244117</td>\n",
              "      <td>55864.675000</td>\n",
              "      <td>5440.900000</td>\n",
              "      <td>57559.100000</td>\n",
              "      <td>7135.325000</td>\n",
              "      <td>0.900189</td>\n",
              "      <td>0.911201</td>\n",
              "      <td>0.886741</td>\n",
              "      <td>0.961309</td>\n",
              "      <td>0.964345</td>\n",
              "      <td>0.331455</td>\n",
              "      <td>7243.487500</td>\n",
              "      <td>418.500000</td>\n",
              "      <td>8581.500000</td>\n",
              "      <td>1756.512500</td>\n",
              "      <td>0.879166</td>\n",
              "      <td>0.949366</td>\n",
              "      <td>0.804832</td>\n",
              "      <td>0.964163</td>\n",
              "      <td>0.966726</td>\n",
              "      <td>4.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.049995</td>\n",
              "      <td>1605.102803</td>\n",
              "      <td>1476.613184</td>\n",
              "      <td>1476.613184</td>\n",
              "      <td>1605.102803</td>\n",
              "      <td>0.024433</td>\n",
              "      <td>0.024294</td>\n",
              "      <td>0.025478</td>\n",
              "      <td>0.017046</td>\n",
              "      <td>0.016042</td>\n",
              "      <td>0.220817</td>\n",
              "      <td>1351.919255</td>\n",
              "      <td>255.229259</td>\n",
              "      <td>255.229259</td>\n",
              "      <td>1351.919255</td>\n",
              "      <td>0.065622</td>\n",
              "      <td>0.025674</td>\n",
              "      <td>0.150213</td>\n",
              "      <td>0.017255</td>\n",
              "      <td>0.013777</td>\n",
              "      <td>2.305744</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.193430</td>\n",
              "      <td>51816.000000</td>\n",
              "      <td>4011.000000</td>\n",
              "      <td>53607.000000</td>\n",
              "      <td>5541.000000</td>\n",
              "      <td>0.837127</td>\n",
              "      <td>0.846680</td>\n",
              "      <td>0.822476</td>\n",
              "      <td>0.915729</td>\n",
              "      <td>0.921149</td>\n",
              "      <td>0.180457</td>\n",
              "      <td>2160.000000</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>7953.000000</td>\n",
              "      <td>594.000000</td>\n",
              "      <td>0.619389</td>\n",
              "      <td>0.888510</td>\n",
              "      <td>0.240000</td>\n",
              "      <td>0.864846</td>\n",
              "      <td>0.902748</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.207033</td>\n",
              "      <td>55286.250000</td>\n",
              "      <td>4417.750000</td>\n",
              "      <td>57150.500000</td>\n",
              "      <td>5975.500000</td>\n",
              "      <td>0.892298</td>\n",
              "      <td>0.904312</td>\n",
              "      <td>0.877560</td>\n",
              "      <td>0.957297</td>\n",
              "      <td>0.960616</td>\n",
              "      <td>0.223880</td>\n",
              "      <td>6972.500000</td>\n",
              "      <td>253.000000</td>\n",
              "      <td>8400.000000</td>\n",
              "      <td>895.500000</td>\n",
              "      <td>0.869972</td>\n",
              "      <td>0.931722</td>\n",
              "      <td>0.774722</td>\n",
              "      <td>0.961433</td>\n",
              "      <td>0.963211</td>\n",
              "      <td>2.750000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.229169</td>\n",
              "      <td>56381.000000</td>\n",
              "      <td>4952.000000</td>\n",
              "      <td>58048.000000</td>\n",
              "      <td>6619.000000</td>\n",
              "      <td>0.907861</td>\n",
              "      <td>0.919258</td>\n",
              "      <td>0.894937</td>\n",
              "      <td>0.967084</td>\n",
              "      <td>0.969895</td>\n",
              "      <td>0.241134</td>\n",
              "      <td>7788.000000</td>\n",
              "      <td>377.000000</td>\n",
              "      <td>8623.000000</td>\n",
              "      <td>1212.000000</td>\n",
              "      <td>0.908833</td>\n",
              "      <td>0.954310</td>\n",
              "      <td>0.865333</td>\n",
              "      <td>0.969498</td>\n",
              "      <td>0.970212</td>\n",
              "      <td>4.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.262428</td>\n",
              "      <td>57024.500000</td>\n",
              "      <td>5849.500000</td>\n",
              "      <td>58582.250000</td>\n",
              "      <td>7713.750000</td>\n",
              "      <td>0.917514</td>\n",
              "      <td>0.928099</td>\n",
              "      <td>0.905151</td>\n",
              "      <td>0.973010</td>\n",
              "      <td>0.975164</td>\n",
              "      <td>0.331756</td>\n",
              "      <td>8104.500000</td>\n",
              "      <td>600.000000</td>\n",
              "      <td>8747.000000</td>\n",
              "      <td>2027.500000</td>\n",
              "      <td>0.917361</td>\n",
              "      <td>0.966921</td>\n",
              "      <td>0.900500</td>\n",
              "      <td>0.974383</td>\n",
              "      <td>0.975253</td>\n",
              "      <td>6.250000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>0.369623</td>\n",
              "      <td>57459.000000</td>\n",
              "      <td>9393.000000</td>\n",
              "      <td>58989.000000</td>\n",
              "      <td>11184.000000</td>\n",
              "      <td>0.923936</td>\n",
              "      <td>0.934715</td>\n",
              "      <td>0.912048</td>\n",
              "      <td>0.976266</td>\n",
              "      <td>0.978509</td>\n",
              "      <td>1.626822</td>\n",
              "      <td>8406.000000</td>\n",
              "      <td>1047.000000</td>\n",
              "      <td>8989.000000</td>\n",
              "      <td>6840.000000</td>\n",
              "      <td>0.930889</td>\n",
              "      <td>0.994933</td>\n",
              "      <td>0.934000</td>\n",
              "      <td>0.979540</td>\n",
              "      <td>0.980895</td>\n",
              "      <td>8.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-319f9f86-8141-4fc1-9e00-f4d3aabb8fb7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-319f9f86-8141-4fc1-9e00-f4d3aabb8fb7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-319f9f86-8141-4fc1-9e00-f4d3aabb8fb7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cfg_proc.consolidated_pred_df.head()"
      ],
      "metadata": {
        "id": "-eeEXZVHsTBp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "c60e633e-57fa-4260-eba6-53861b9a1156"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   y_test_index  sigmoid_val  th50_bin_pred_val  actual_val  kfold\n",
              "0             1     0.001552                0.0         0.0      8\n",
              "1             2     0.006053                0.0         0.0      8\n",
              "2             3     0.035473                0.0         0.0      8\n",
              "3             4     0.000001                0.0         0.0      8\n",
              "4             5     0.004516                0.0         0.0      8"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-92a4fdd6-b769-484e-9ef3-8865a2f02ff8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>y_test_index</th>\n",
              "      <th>sigmoid_val</th>\n",
              "      <th>th50_bin_pred_val</th>\n",
              "      <th>actual_val</th>\n",
              "      <th>kfold</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0.001552</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0.006053</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0.035473</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0.000001</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0.004516</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-92a4fdd6-b769-484e-9ef3-8865a2f02ff8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-92a4fdd6-b769-484e-9ef3-8865a2f02ff8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-92a4fdd6-b769-484e-9ef3-8865a2f02ff8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cfg_proc.consolidated_pred_df.describe()"
      ],
      "metadata": {
        "id": "n6_HOu2uTyP9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "b17e0b53-aac4-4fba-cfc7-a6b5060e6349"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        y_test_index   sigmoid_val  th50_bin_pred_val     actual_val  \\\n",
              "count  128000.000000  1.280000e+05           128000.0  128000.000000   \n",
              "mean     8000.500000  4.577944e-01                0.0       0.500000   \n",
              "std      4618.820187  4.547854e-01                0.0       0.500002   \n",
              "min         1.000000  5.686481e-09                0.0       0.000000   \n",
              "25%      4000.750000  4.085690e-03                0.0       0.000000   \n",
              "50%      8000.500000  2.392410e-01                0.0       0.500000   \n",
              "75%     12000.250000  9.938101e-01                0.0       1.000000   \n",
              "max     16000.000000  1.000000e+00                0.0       1.000000   \n",
              "\n",
              "               kfold  \n",
              "count  128000.000000  \n",
              "mean        4.500000  \n",
              "std         2.291297  \n",
              "min         1.000000  \n",
              "25%         2.750000  \n",
              "50%         4.500000  \n",
              "75%         6.250000  \n",
              "max         8.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-32aad415-ff4c-4071-8f53-c7f64031311f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>y_test_index</th>\n",
              "      <th>sigmoid_val</th>\n",
              "      <th>th50_bin_pred_val</th>\n",
              "      <th>actual_val</th>\n",
              "      <th>kfold</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>128000.000000</td>\n",
              "      <td>1.280000e+05</td>\n",
              "      <td>128000.0</td>\n",
              "      <td>128000.000000</td>\n",
              "      <td>128000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>8000.500000</td>\n",
              "      <td>4.577944e-01</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>4.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>4618.820187</td>\n",
              "      <td>4.547854e-01</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.500002</td>\n",
              "      <td>2.291297</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>5.686481e-09</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>4000.750000</td>\n",
              "      <td>4.085690e-03</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.750000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>8000.500000</td>\n",
              "      <td>2.392410e-01</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>4.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>12000.250000</td>\n",
              "      <td>9.938101e-01</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>6.250000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>16000.000000</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>8.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-32aad415-ff4c-4071-8f53-c7f64031311f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-32aad415-ff4c-4071-8f53-c7f64031311f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-32aad415-ff4c-4071-8f53-c7f64031311f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cfg_proc.consolidated_pred_df['th50_bin_pred_val'] = np.where(cfg_proc.consolidated_pred_df['sigmoid_val'] < .5, 0, 1)"
      ],
      "metadata": {
        "id": "oslznJ7p_s0e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cfg_proc.consolidated_history_df.to_csv('/content/gdrive/MyDrive/Kaggle/consolidated_history.csv', index = False)\n",
        "cfg_proc.consolidated_test_kpi_df.to_csv('/content/gdrive/MyDrive/Kaggle/consolidated_test_kpi.csv', index = False)\n",
        "cfg_proc.consolidated_pred_df.to_csv('/content/gdrive/MyDrive/Kaggle/consolidated_pred.csv', index = False)"
      ],
      "metadata": {
        "id": "Bd44KWNEucIf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Calling ensemble soft voting...\")\n",
        "df_soft_voting_clf = soft_voting_cllasifier(cfg_proc.consolidated_pred_df)\n",
        "df_soft_voting_clf.head()"
      ],
      "metadata": {
        "id": "s7_JezIqFGeH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "485ee3c5-45c1-4a8e-fb65-ff63113c3b66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calling ensemble soft voting...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   y_test_index  assigned_probability  assigned_binary_value  actual_val\n",
              "0             1              0.002610                      0           0\n",
              "1             2              0.004862                      0           0\n",
              "2             3              0.050395                      0           0\n",
              "3             4              0.000099                      0           0\n",
              "4             5              0.014855                      0           0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bc59fe68-2e81-4969-ab7c-62f5b46969f3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>y_test_index</th>\n",
              "      <th>assigned_probability</th>\n",
              "      <th>assigned_binary_value</th>\n",
              "      <th>actual_val</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0.002610</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0.004862</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0.050395</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0.000099</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0.014855</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bc59fe68-2e81-4969-ab7c-62f5b46969f3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bc59fe68-2e81-4969-ab7c-62f5b46969f3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bc59fe68-2e81-4969-ab7c-62f5b46969f3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_accuracy_soft_voting = accuracy_score(df_soft_voting_clf['actual_val'].values.tolist(), df_soft_voting_clf['assigned_binary_value'].values.tolist())\n",
        "final_precision_soft_voting = precision_score(df_soft_voting_clf['assigned_binary_value'].values.tolist(), df_soft_voting_clf['actual_val'].values.tolist())\n",
        "final_recall_soft_voting = recall_score(df_soft_voting_clf['assigned_binary_value'].values.tolist(), df_soft_voting_clf['actual_val'].values.tolist())\n",
        "final_f1_score_soft_voting = f1_score(df_soft_voting_clf['assigned_binary_value'].values.tolist(), df_soft_voting_clf['actual_val'].values.tolist())\n",
        "fpr, tpr, thresholds = roc_curve(df_soft_voting_clf['actual_val'].values.tolist(), df_soft_voting_clf['assigned_probability'].values.tolist())\n",
        "final_auc_val_soft_voting = auc(fpr, tpr)\n",
        "print(f\"Final Ensemble Accuracy : {final_accuracy_soft_voting}\")\n",
        "print(f\"Final Ensemble Precision : {final_precision_soft_voting}\")\n",
        "print(f\"Final Ensemble Recall : {final_recall_soft_voting}\")\n",
        "print(f\"Final Ensemble F1 Score : {final_f1_score_soft_voting}\")\n",
        "print(f\"Final Ensemble AUC Score : {final_auc_val_soft_voting}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uzn2J3rbypzS",
        "outputId": "7104efef-81a9-4120-d183-347f81dfd55b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Ensemble Accuracy : 0.9074375\n",
            "Final Ensemble Precision : 0.95975\n",
            "Final Ensemble Recall : 0.8688468937422202\n",
            "Final Ensemble F1 Score : 0.9120389618102986\n",
            "Final Ensemble AUC Score : 0.971894328125\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_soft_voting_clf['final_accuracy_soft_voting'] = final_accuracy_soft_voting\n",
        "df_soft_voting_clf['final_precision_soft_voting'] = final_precision_soft_voting\n",
        "df_soft_voting_clf['final_recall_soft_voting'] = final_recall_soft_voting\n",
        "df_soft_voting_clf['final_auc_val_soft_voting'] = final_auc_val_soft_voting\n",
        "df_soft_voting_clf['final_f1_score_soft_voting'] = final_f1_score_soft_voting\n",
        "df_soft_voting_clf.to_csv('soft_voting_clf_result.csv', index = False)"
      ],
      "metadata": {
        "id": "lsyhTOTKQXB_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Calling ensemble hard voting...\")\n",
        "df_hard_voting_clf = hard_voting_cllasifier(cfg_proc.consolidated_pred_df)\n",
        "df_hard_voting_clf.head()"
      ],
      "metadata": {
        "id": "YiTw242_0TaU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "73792032-637f-4227-a227-4c49c072d126"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calling ensemble hard voting...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   y_test_index  assigned_probability  assigned_binary_value  actual_val\n",
              "0             1              0.002610                    0.0           0\n",
              "1             2              0.004862                    0.0           0\n",
              "2             3              0.050395                    0.0           0\n",
              "3             4              0.000099                    0.0           0\n",
              "4             5              0.014855                    0.0           0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-579dbfe7-cb01-45d0-a58a-01f14eb593af\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>y_test_index</th>\n",
              "      <th>assigned_probability</th>\n",
              "      <th>assigned_binary_value</th>\n",
              "      <th>actual_val</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0.002610</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0.004862</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0.050395</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0.000099</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0.014855</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-579dbfe7-cb01-45d0-a58a-01f14eb593af')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-579dbfe7-cb01-45d0-a58a-01f14eb593af button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-579dbfe7-cb01-45d0-a58a-01f14eb593af');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_accuracy_hard_voting = accuracy_score(df_hard_voting_clf['assigned_binary_value'].values.tolist(), df_hard_voting_clf['assigned_binary_value'].values.tolist())\n",
        "final_precision_hard_voting = precision_score(df_hard_voting_clf['assigned_binary_value'].values.tolist(), df_hard_voting_clf['assigned_binary_value'].values.tolist())\n",
        "final_recall_hard_voting = recall_score(df_hard_voting_clf['assigned_binary_value'].values.tolist(), df_hard_voting_clf['assigned_binary_value'].values.tolist())\n",
        "final_f1_score_hard_voting = f1_score(df_hard_voting_clf['assigned_binary_value'].values.tolist(), df_hard_voting_clf['assigned_binary_value'].values.tolist())\n",
        "fpr, tpr, thresholds = roc_curve(df_hard_voting_clf['assigned_binary_value'].values.tolist(), df_hard_voting_clf['assigned_probability'].values.tolist())\n",
        "final_auc_val_hard_voting = auc(fpr, tpr)\n",
        "print(f\"Final Ensemble Accuracy : {final_accuracy_hard_voting}\")\n",
        "print(f\"Final Ensemble Precision : {final_precision_hard_voting}\")\n",
        "print(f\"Final Ensemble Recall : {final_recall_hard_voting}\")\n",
        "print(f\"Final Ensemble F1 Score : {final_f1_score_hard_voting}\")\n",
        "print(f\"Final Ensemble AUC Score : {final_auc_val_hard_voting}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wpsSGmJdyp2t",
        "outputId": "45c89b04-c782-4b8b-db96-0a5e9a722903"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Ensemble Accuracy : 1.0\n",
            "Final Ensemble Precision : 1.0\n",
            "Final Ensemble Recall : 1.0\n",
            "Final Ensemble F1 Score : 1.0\n",
            "Final Ensemble AUC Score : 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_hard_voting_clf['final_accuracy_hard_voting'] = final_accuracy_hard_voting\n",
        "df_hard_voting_clf['final_precision_hard_voting'] = final_precision_hard_voting\n",
        "df_hard_voting_clf['final_recall_hard_voting'] = final_recall_hard_voting\n",
        "df_hard_voting_clf['final_auc_val_hard_voting'] = final_auc_val_hard_voting\n",
        "df_hard_voting_clf['final_f1_score_hard_voting'] = final_f1_score_hard_voting\n",
        "df_hard_voting_clf.to_csv('hard_voting_clf_result.csv', index = False)"
      ],
      "metadata": {
        "id": "bBJuhaZPQvFV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_soft_voting_clf.columns = ['y_test_index', 'soft_voting_assigned_probability', 'soft_voting_assigned_binary_value',\n",
        "       'actual_val', 'final_accuracy_soft_voting',\n",
        "       'final_precision_soft_voting', 'final_recall_soft_voting',\n",
        "       'final_auc_val_soft_voting', 'final_f1_score_soft_voting']\n",
        "df_hard_voting_clf.columns = ['y_test_index', 'hard_voting_assigned_probability', 'hard_voting_assigned_binary_value',\n",
        "       'actual_val', 'final_accuracy_hard_voting',\n",
        "       'final_precision_hard_voting', 'final_recall_hard_voting',\n",
        "       'final_auc_val_hard_voting', 'final_f1_score_hard_voting']\n",
        "df_soft_voting_clf.drop(columns = ['actual_val'], inplace = True)"
      ],
      "metadata": {
        "id": "r6wbGPmsAWS4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_voting_combined = pd.concat([df_hard_voting_clf, df_soft_voting_clf], axis = 1)\n",
        "df_voting_combined"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "1BvbmlpEyD0d",
        "outputId": "8693a27f-38ef-4524-e9fa-aace4c9d84e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       y_test_index  hard_voting_assigned_probability  \\\n",
              "0                 1                          0.002610   \n",
              "1                 2                          0.004862   \n",
              "2                 3                          0.050395   \n",
              "3                 4                          0.000099   \n",
              "4                 5                          0.014855   \n",
              "...             ...                               ...   \n",
              "15995         15996                          0.999301   \n",
              "15996         15997                          0.994406   \n",
              "15997         15998                          0.995782   \n",
              "15998         15999                          0.913913   \n",
              "15999         16000                          0.895114   \n",
              "\n",
              "       hard_voting_assigned_binary_value  actual_val  \\\n",
              "0                                      0           0   \n",
              "1                                      0           0   \n",
              "2                                      0           0   \n",
              "3                                      0           0   \n",
              "4                                      0           0   \n",
              "...                                  ...         ...   \n",
              "15995                                  1           1   \n",
              "15996                                  1           1   \n",
              "15997                                  1           1   \n",
              "15998                                  1           1   \n",
              "15999                                  1           1   \n",
              "\n",
              "       final_accuracy_hard_voting  final_precision_hard_voting  \\\n",
              "0                             1.0                          1.0   \n",
              "1                             1.0                          1.0   \n",
              "2                             1.0                          1.0   \n",
              "3                             1.0                          1.0   \n",
              "4                             1.0                          1.0   \n",
              "...                           ...                          ...   \n",
              "15995                         1.0                          1.0   \n",
              "15996                         1.0                          1.0   \n",
              "15997                         1.0                          1.0   \n",
              "15998                         1.0                          1.0   \n",
              "15999                         1.0                          1.0   \n",
              "\n",
              "       final_recall_hard_voting  final_auc_val_hard_voting  \\\n",
              "0                           1.0                        1.0   \n",
              "1                           1.0                        1.0   \n",
              "2                           1.0                        1.0   \n",
              "3                           1.0                        1.0   \n",
              "4                           1.0                        1.0   \n",
              "...                         ...                        ...   \n",
              "15995                       1.0                        1.0   \n",
              "15996                       1.0                        1.0   \n",
              "15997                       1.0                        1.0   \n",
              "15998                       1.0                        1.0   \n",
              "15999                       1.0                        1.0   \n",
              "\n",
              "       final_f1_score_hard_voting  y_test_index  \\\n",
              "0                             1.0             1   \n",
              "1                             1.0             2   \n",
              "2                             1.0             3   \n",
              "3                             1.0             4   \n",
              "4                             1.0             5   \n",
              "...                           ...           ...   \n",
              "15995                         1.0         15996   \n",
              "15996                         1.0         15997   \n",
              "15997                         1.0         15998   \n",
              "15998                         1.0         15999   \n",
              "15999                         1.0         16000   \n",
              "\n",
              "       soft_voting_assigned_probability  soft_voting_assigned_binary_value  \\\n",
              "0                              0.002610                                  0   \n",
              "1                              0.004862                                  0   \n",
              "2                              0.050395                                  0   \n",
              "3                              0.000099                                  0   \n",
              "4                              0.014855                                  0   \n",
              "...                                 ...                                ...   \n",
              "15995                          0.999301                                  1   \n",
              "15996                          0.994406                                  1   \n",
              "15997                          0.995782                                  1   \n",
              "15998                          0.913913                                  1   \n",
              "15999                          0.895114                                  1   \n",
              "\n",
              "       final_accuracy_soft_voting  final_precision_soft_voting  \\\n",
              "0                        0.907438                      0.95975   \n",
              "1                        0.907438                      0.95975   \n",
              "2                        0.907438                      0.95975   \n",
              "3                        0.907438                      0.95975   \n",
              "4                        0.907438                      0.95975   \n",
              "...                           ...                          ...   \n",
              "15995                    0.907438                      0.95975   \n",
              "15996                    0.907438                      0.95975   \n",
              "15997                    0.907438                      0.95975   \n",
              "15998                    0.907438                      0.95975   \n",
              "15999                    0.907438                      0.95975   \n",
              "\n",
              "       final_recall_soft_voting  final_auc_val_soft_voting  \\\n",
              "0                      0.868847                   0.971894   \n",
              "1                      0.868847                   0.971894   \n",
              "2                      0.868847                   0.971894   \n",
              "3                      0.868847                   0.971894   \n",
              "4                      0.868847                   0.971894   \n",
              "...                         ...                        ...   \n",
              "15995                  0.868847                   0.971894   \n",
              "15996                  0.868847                   0.971894   \n",
              "15997                  0.868847                   0.971894   \n",
              "15998                  0.868847                   0.971894   \n",
              "15999                  0.868847                   0.971894   \n",
              "\n",
              "       final_f1_score_soft_voting  \n",
              "0                        0.912039  \n",
              "1                        0.912039  \n",
              "2                        0.912039  \n",
              "3                        0.912039  \n",
              "4                        0.912039  \n",
              "...                           ...  \n",
              "15995                    0.912039  \n",
              "15996                    0.912039  \n",
              "15997                    0.912039  \n",
              "15998                    0.912039  \n",
              "15999                    0.912039  \n",
              "\n",
              "[16000 rows x 17 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9fafa7fe-4e38-44c2-b32e-d00250e9457c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>y_test_index</th>\n",
              "      <th>hard_voting_assigned_probability</th>\n",
              "      <th>hard_voting_assigned_binary_value</th>\n",
              "      <th>actual_val</th>\n",
              "      <th>final_accuracy_hard_voting</th>\n",
              "      <th>final_precision_hard_voting</th>\n",
              "      <th>final_recall_hard_voting</th>\n",
              "      <th>final_auc_val_hard_voting</th>\n",
              "      <th>final_f1_score_hard_voting</th>\n",
              "      <th>y_test_index</th>\n",
              "      <th>soft_voting_assigned_probability</th>\n",
              "      <th>soft_voting_assigned_binary_value</th>\n",
              "      <th>final_accuracy_soft_voting</th>\n",
              "      <th>final_precision_soft_voting</th>\n",
              "      <th>final_recall_soft_voting</th>\n",
              "      <th>final_auc_val_soft_voting</th>\n",
              "      <th>final_f1_score_soft_voting</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0.002610</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.002610</td>\n",
              "      <td>0</td>\n",
              "      <td>0.907438</td>\n",
              "      <td>0.95975</td>\n",
              "      <td>0.868847</td>\n",
              "      <td>0.971894</td>\n",
              "      <td>0.912039</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0.004862</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.004862</td>\n",
              "      <td>0</td>\n",
              "      <td>0.907438</td>\n",
              "      <td>0.95975</td>\n",
              "      <td>0.868847</td>\n",
              "      <td>0.971894</td>\n",
              "      <td>0.912039</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0.050395</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3</td>\n",
              "      <td>0.050395</td>\n",
              "      <td>0</td>\n",
              "      <td>0.907438</td>\n",
              "      <td>0.95975</td>\n",
              "      <td>0.868847</td>\n",
              "      <td>0.971894</td>\n",
              "      <td>0.912039</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0.000099</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4</td>\n",
              "      <td>0.000099</td>\n",
              "      <td>0</td>\n",
              "      <td>0.907438</td>\n",
              "      <td>0.95975</td>\n",
              "      <td>0.868847</td>\n",
              "      <td>0.971894</td>\n",
              "      <td>0.912039</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0.014855</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5</td>\n",
              "      <td>0.014855</td>\n",
              "      <td>0</td>\n",
              "      <td>0.907438</td>\n",
              "      <td>0.95975</td>\n",
              "      <td>0.868847</td>\n",
              "      <td>0.971894</td>\n",
              "      <td>0.912039</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15995</th>\n",
              "      <td>15996</td>\n",
              "      <td>0.999301</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>15996</td>\n",
              "      <td>0.999301</td>\n",
              "      <td>1</td>\n",
              "      <td>0.907438</td>\n",
              "      <td>0.95975</td>\n",
              "      <td>0.868847</td>\n",
              "      <td>0.971894</td>\n",
              "      <td>0.912039</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15996</th>\n",
              "      <td>15997</td>\n",
              "      <td>0.994406</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>15997</td>\n",
              "      <td>0.994406</td>\n",
              "      <td>1</td>\n",
              "      <td>0.907438</td>\n",
              "      <td>0.95975</td>\n",
              "      <td>0.868847</td>\n",
              "      <td>0.971894</td>\n",
              "      <td>0.912039</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15997</th>\n",
              "      <td>15998</td>\n",
              "      <td>0.995782</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>15998</td>\n",
              "      <td>0.995782</td>\n",
              "      <td>1</td>\n",
              "      <td>0.907438</td>\n",
              "      <td>0.95975</td>\n",
              "      <td>0.868847</td>\n",
              "      <td>0.971894</td>\n",
              "      <td>0.912039</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15998</th>\n",
              "      <td>15999</td>\n",
              "      <td>0.913913</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>15999</td>\n",
              "      <td>0.913913</td>\n",
              "      <td>1</td>\n",
              "      <td>0.907438</td>\n",
              "      <td>0.95975</td>\n",
              "      <td>0.868847</td>\n",
              "      <td>0.971894</td>\n",
              "      <td>0.912039</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15999</th>\n",
              "      <td>16000</td>\n",
              "      <td>0.895114</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>16000</td>\n",
              "      <td>0.895114</td>\n",
              "      <td>1</td>\n",
              "      <td>0.907438</td>\n",
              "      <td>0.95975</td>\n",
              "      <td>0.868847</td>\n",
              "      <td>0.971894</td>\n",
              "      <td>0.912039</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>16000 rows × 17 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9fafa7fe-4e38-44c2-b32e-d00250e9457c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9fafa7fe-4e38-44c2-b32e-d00250e9457c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9fafa7fe-4e38-44c2-b32e-d00250e9457c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 177
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_voting_combined = df_voting_combined[['y_test_index',\n",
        "                                         'actual_val',\n",
        "                                         'hard_voting_assigned_probability',\n",
        "                                         'soft_voting_assigned_probability',\n",
        "                                         'hard_voting_assigned_binary_value',\n",
        "                                         'soft_voting_assigned_binary_value',\n",
        "                                         'final_accuracy_hard_voting',\n",
        "                                         'final_accuracy_soft_voting',\n",
        "                                         'final_precision_hard_voting',\n",
        "                                         'final_precision_soft_voting',\n",
        "                                         'final_recall_hard_voting', \n",
        "                                         'final_recall_soft_voting',\n",
        "                                         'final_auc_val_hard_voting',\n",
        "                                         'final_auc_val_soft_voting',\n",
        "                                         'final_f1_score_hard_voting',\n",
        "                                         'final_f1_score_soft_voting'\n",
        "                                        ]]\n",
        "df_voting_combined = df_voting_combined.iloc[:,1:]"
      ],
      "metadata": {
        "id": "wVW12kcTAm9k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_voting_combined"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "X7LV-jY58cz2",
        "outputId": "498044a9-480c-4e8a-adf4-5d89193fa063"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       y_test_index  actual_val  hard_voting_assigned_probability  \\\n",
              "0                 1           0                          0.002610   \n",
              "1                 2           0                          0.004862   \n",
              "2                 3           0                          0.050395   \n",
              "3                 4           0                          0.000099   \n",
              "4                 5           0                          0.014855   \n",
              "...             ...         ...                               ...   \n",
              "15995         15996           1                          0.999301   \n",
              "15996         15997           1                          0.994406   \n",
              "15997         15998           1                          0.995782   \n",
              "15998         15999           1                          0.913913   \n",
              "15999         16000           1                          0.895114   \n",
              "\n",
              "       soft_voting_assigned_probability  hard_voting_assigned_binary_value  \\\n",
              "0                              0.002610                                  0   \n",
              "1                              0.004862                                  0   \n",
              "2                              0.050395                                  0   \n",
              "3                              0.000099                                  0   \n",
              "4                              0.014855                                  0   \n",
              "...                                 ...                                ...   \n",
              "15995                          0.999301                                  1   \n",
              "15996                          0.994406                                  1   \n",
              "15997                          0.995782                                  1   \n",
              "15998                          0.913913                                  1   \n",
              "15999                          0.895114                                  1   \n",
              "\n",
              "       soft_voting_assigned_binary_value  final_accuracy_hard_voting  \\\n",
              "0                                      0                         1.0   \n",
              "1                                      0                         1.0   \n",
              "2                                      0                         1.0   \n",
              "3                                      0                         1.0   \n",
              "4                                      0                         1.0   \n",
              "...                                  ...                         ...   \n",
              "15995                                  1                         1.0   \n",
              "15996                                  1                         1.0   \n",
              "15997                                  1                         1.0   \n",
              "15998                                  1                         1.0   \n",
              "15999                                  1                         1.0   \n",
              "\n",
              "       final_accuracy_soft_voting  final_precision_hard_voting  \\\n",
              "0                        0.907438                          1.0   \n",
              "1                        0.907438                          1.0   \n",
              "2                        0.907438                          1.0   \n",
              "3                        0.907438                          1.0   \n",
              "4                        0.907438                          1.0   \n",
              "...                           ...                          ...   \n",
              "15995                    0.907438                          1.0   \n",
              "15996                    0.907438                          1.0   \n",
              "15997                    0.907438                          1.0   \n",
              "15998                    0.907438                          1.0   \n",
              "15999                    0.907438                          1.0   \n",
              "\n",
              "       final_precision_soft_voting  final_recall_hard_voting  \\\n",
              "0                          0.95975                       1.0   \n",
              "1                          0.95975                       1.0   \n",
              "2                          0.95975                       1.0   \n",
              "3                          0.95975                       1.0   \n",
              "4                          0.95975                       1.0   \n",
              "...                            ...                       ...   \n",
              "15995                      0.95975                       1.0   \n",
              "15996                      0.95975                       1.0   \n",
              "15997                      0.95975                       1.0   \n",
              "15998                      0.95975                       1.0   \n",
              "15999                      0.95975                       1.0   \n",
              "\n",
              "       final_recall_soft_voting  final_auc_val_hard_voting  \\\n",
              "0                      0.868847                        1.0   \n",
              "1                      0.868847                        1.0   \n",
              "2                      0.868847                        1.0   \n",
              "3                      0.868847                        1.0   \n",
              "4                      0.868847                        1.0   \n",
              "...                         ...                        ...   \n",
              "15995                  0.868847                        1.0   \n",
              "15996                  0.868847                        1.0   \n",
              "15997                  0.868847                        1.0   \n",
              "15998                  0.868847                        1.0   \n",
              "15999                  0.868847                        1.0   \n",
              "\n",
              "       final_auc_val_soft_voting  final_f1_score_hard_voting  \\\n",
              "0                       0.971894                         1.0   \n",
              "1                       0.971894                         1.0   \n",
              "2                       0.971894                         1.0   \n",
              "3                       0.971894                         1.0   \n",
              "4                       0.971894                         1.0   \n",
              "...                          ...                         ...   \n",
              "15995                   0.971894                         1.0   \n",
              "15996                   0.971894                         1.0   \n",
              "15997                   0.971894                         1.0   \n",
              "15998                   0.971894                         1.0   \n",
              "15999                   0.971894                         1.0   \n",
              "\n",
              "       final_f1_score_soft_voting  \n",
              "0                        0.912039  \n",
              "1                        0.912039  \n",
              "2                        0.912039  \n",
              "3                        0.912039  \n",
              "4                        0.912039  \n",
              "...                           ...  \n",
              "15995                    0.912039  \n",
              "15996                    0.912039  \n",
              "15997                    0.912039  \n",
              "15998                    0.912039  \n",
              "15999                    0.912039  \n",
              "\n",
              "[16000 rows x 16 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a0f9a0a3-803e-4657-a5b1-9787ea05cafc\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>y_test_index</th>\n",
              "      <th>actual_val</th>\n",
              "      <th>hard_voting_assigned_probability</th>\n",
              "      <th>soft_voting_assigned_probability</th>\n",
              "      <th>hard_voting_assigned_binary_value</th>\n",
              "      <th>soft_voting_assigned_binary_value</th>\n",
              "      <th>final_accuracy_hard_voting</th>\n",
              "      <th>final_accuracy_soft_voting</th>\n",
              "      <th>final_precision_hard_voting</th>\n",
              "      <th>final_precision_soft_voting</th>\n",
              "      <th>final_recall_hard_voting</th>\n",
              "      <th>final_recall_soft_voting</th>\n",
              "      <th>final_auc_val_hard_voting</th>\n",
              "      <th>final_auc_val_soft_voting</th>\n",
              "      <th>final_f1_score_hard_voting</th>\n",
              "      <th>final_f1_score_soft_voting</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.002610</td>\n",
              "      <td>0.002610</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.907438</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.95975</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.868847</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.971894</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.912039</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0.004862</td>\n",
              "      <td>0.004862</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.907438</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.95975</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.868847</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.971894</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.912039</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0.050395</td>\n",
              "      <td>0.050395</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.907438</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.95975</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.868847</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.971894</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.912039</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000099</td>\n",
              "      <td>0.000099</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.907438</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.95975</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.868847</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.971894</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.912039</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0.014855</td>\n",
              "      <td>0.014855</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.907438</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.95975</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.868847</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.971894</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.912039</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15995</th>\n",
              "      <td>15996</td>\n",
              "      <td>1</td>\n",
              "      <td>0.999301</td>\n",
              "      <td>0.999301</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.907438</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.95975</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.868847</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.971894</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.912039</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15996</th>\n",
              "      <td>15997</td>\n",
              "      <td>1</td>\n",
              "      <td>0.994406</td>\n",
              "      <td>0.994406</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.907438</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.95975</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.868847</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.971894</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.912039</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15997</th>\n",
              "      <td>15998</td>\n",
              "      <td>1</td>\n",
              "      <td>0.995782</td>\n",
              "      <td>0.995782</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.907438</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.95975</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.868847</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.971894</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.912039</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15998</th>\n",
              "      <td>15999</td>\n",
              "      <td>1</td>\n",
              "      <td>0.913913</td>\n",
              "      <td>0.913913</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.907438</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.95975</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.868847</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.971894</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.912039</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15999</th>\n",
              "      <td>16000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.895114</td>\n",
              "      <td>0.895114</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.907438</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.95975</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.868847</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.971894</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.912039</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>16000 rows × 16 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a0f9a0a3-803e-4657-a5b1-9787ea05cafc')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a0f9a0a3-803e-4657-a5b1-9787ea05cafc button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a0f9a0a3-803e-4657-a5b1-9787ea05cafc');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 180
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_voting_combined.to_csv('/content/gdrive/MyDrive/Kaggle/combined_voting_results.csv', index = False)"
      ],
      "metadata": {
        "id": "_3PTM1QkQ7Vl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9Qw7-aeRQ7aj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jrJLB1lgQ7gB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_img = load_img(data_proc.train_file_list[0], color_mode =\"grayscale\")\n",
        "test_img_arry = img_to_array(test_img)\n",
        "print(type(test_img))\n",
        "print(test_img.format)\n",
        "print(test_img.mode)\n",
        "print(test_img.size)\n",
        "print(test_img.getbands())\n",
        "print(test_img_arry.shape)\n",
        "\n",
        "test_img1 = load_img(data_proc.train_file_list[0])\n",
        "test_img1_arry = img_to_array(test_img1)\n",
        "print(test_img1_arry.shape)\n",
        "print(test_img1.getbands())"
      ],
      "metadata": {
        "id": "F-_a0JOfmzX3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0df55f9c-465d-428b-cb01-f51323cd72b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'PIL.TiffImagePlugin.TiffImageFile'>\n",
            "TIFF\n",
            "L\n",
            "(96, 96)\n",
            "('L',)\n",
            "(96, 96, 1)\n",
            "(96, 96, 3)\n",
            "('R', 'G', 'B')\n"
          ]
        }
      ]
    }
  ]
}